{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU setting\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2,3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jan 30 17:58:46 2020       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 440.33.01    Driver Version: 440.33.01    CUDA Version: 10.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce GTX 1080    Off  | 00000000:03:00.0 Off |                  N/A |\r\n",
      "| 58%   63C    P0    59W / 210W |      0MiB /  8119MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  GeForce GTX TIT...  Off  | 00000000:04:00.0 Off |                  N/A |\r\n",
      "| 39%   82C    P0    96W / 250W |      0MiB / 12210MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import datasets, models, transforms\n",
    "from matplotlib.pyplot import imshow, imsave\n",
    "from PIL import Image\n",
    "from collections import OrderedDict\n",
    "\n",
    "import copy\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility function to measure time\n",
    "\n",
    "import time\n",
    "import math\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility function to measure time\n",
    "\n",
    "import time\n",
    "import math\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = (\"cuda:0\" if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KMNet_vgg16bn: atros, index pooling(segnet), blur pooling, until pool4\n",
    "\n",
    "\n",
    "class KMNet_vgg16bn(nn.Module):\n",
    "    def __init__(self, in_channels=3, n_classes=34):\n",
    "        super(KMNet_vgg16bn, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.n_classes = n_classes\n",
    "        \n",
    "        model = models.vgg16_bn(pretrained=True)\n",
    "                \n",
    "        #cityscape input (1, 3,1024, 2048)\n",
    "              \n",
    "        self.encoder1 = model.features[0:6]      # maxpool: size / 2\n",
    "        self.encoder2 = model.features[7:13]     # maxpool: size / 4\n",
    "        self.encoder3 = model.features[14:23]     # maxpool: size / 8\n",
    "        # atrous\n",
    "        self.encoder3[0] = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=(3,3), stride=(1,1), padding=(2,2), dilation=(2,2))\n",
    "        self.encoder4 = model.features[24:33]     # maxpool: size / 16\n",
    "        # atrous\n",
    "        self.encoder4[0] = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=(3,3), stride=(1,1), padding=(4,4), dilation=(4,4))\n",
    "        \n",
    "        self.downsample = nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, return_indices=True)\n",
    "        self.upsample = nn.MaxUnpool2d(kernel_size=2, stride=2, padding=0)   # input size * 2\n",
    "        self.blurpool = BlurPooling()\n",
    "        \n",
    "        self.bridge = nn.Sequential(OrderedDict([\n",
    "            ('conv1', nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=(3,3), stride=(1,1), padding=(1,1), bias=False)),\n",
    "            ('bn1', nn.BatchNorm2d(1024)),\n",
    "            ('relu1', nn.ReLU(inplace=True)),\n",
    "            ('conv2', nn.Conv2d(in_channels=1024, out_channels=512, kernel_size=(3,3), stride=(1,1), padding=(1,1), bias=False)),\n",
    "            ('bn2', nn.BatchNorm2d(512)),\n",
    "            ('relu2', nn.ReLU(inplace=True)),\n",
    "        ]))\n",
    "\n",
    "\n",
    "        \n",
    "        self.decoder1 = nn.Sequential(OrderedDict([\n",
    "            ('conv1',nn.Conv2d(in_channels=1024, out_channels=512, kernel_size=(3,3), stride=(1,1), padding=(1,1), bias=False)),\n",
    "            ('bn1', nn.BatchNorm2d(512)),\n",
    "            ('relu1',nn.ReLU(inplace=True)),\n",
    "            ('conv2', nn.Conv2d(in_channels=512, out_channels=256, kernel_size=(3,3), stride=(1,1), padding=(1,1), bias=False)),\n",
    "            ('bn2', nn.BatchNorm2d(256)),\n",
    "            ('relu2',nn.ReLU(inplace=True)),\n",
    "        ]))\n",
    "        \n",
    "        self.decoder2 = nn.Sequential(OrderedDict([\n",
    "            ('conv1',nn.Conv2d(in_channels=512, out_channels=256, kernel_size=(3,3), stride=(1,1), padding=(1,1), bias=False)),\n",
    "            ('bn1',nn.BatchNorm2d(256)),\n",
    "            ('relu1',nn.ReLU(inplace=True)),\n",
    "            ('conv2',nn.Conv2d(in_channels=256, out_channels=128, kernel_size=(3,3), stride=(1,1), padding=(1,1), bias=False)),\n",
    "            ('bn2', nn.BatchNorm2d(128)),\n",
    "            ('relu2', nn.ReLU(inplace=True)),\n",
    "        ]))\n",
    "        \n",
    "        self.decoder3 = nn.Sequential(OrderedDict([\n",
    "            ('conv1',nn.Conv2d(in_channels=256, out_channels=128, kernel_size=(3,3), stride=(1,1), padding=(1,1), bias=False)),\n",
    "            ('bn1',nn.BatchNorm2d(128)),\n",
    "            ('relu1', nn.ReLU(inplace=True)),\n",
    "            ('conv2',nn.Conv2d(in_channels=128, out_channels=64, kernel_size=(3,3), stride=(1,1), padding=(1,1), bias=False)),\n",
    "            ('bn2', nn.BatchNorm2d(64)),\n",
    "            ('relu2',nn.ReLU(inplace=True)),\n",
    "        ]))\n",
    "        \n",
    "        self.decoder4 = nn.Sequential(OrderedDict([\n",
    "            ('conv1',nn.Conv2d(in_channels=128, out_channels=64, kernel_size=(3,3), stride=(1,1), padding=(1,1), bias=False)),\n",
    "            ('bn1',nn.BatchNorm2d(64)),\n",
    "            ('relu1',nn.ReLU(inplace=True)),\n",
    "        ]))\n",
    "        \n",
    "        self.last_conv = nn.Sequential(OrderedDict([\n",
    "            ('conv1',nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3,3), padding=(1,1), bias=False)),\n",
    "            ('bn1',nn.BatchNorm2d(64)),\n",
    "            ('relu1',nn.ReLU(inplace=True)),\n",
    "            ('conv2',nn.Conv2d(in_channels=64, out_channels=n_classes, kernel_size=(1,1))),\n",
    "        ]))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #y_, idx_= self.in_layer(x)\n",
    "        y_1 = self.encoder1(x)\n",
    "        #print('y1')\n",
    "        #print(y_1.shape)\n",
    "        y_2,idx1 = self.downsample(y_1)\n",
    "        #print('y_2_down')\n",
    "        #print(y_2.shape)\n",
    "#         print('idx1')\n",
    "#         print(idx1.shape)\n",
    "        \n",
    "        y_2 = self.encoder2(y_2)\n",
    "#         print('y2')\n",
    "#         print(y_2.shape)\n",
    "        y_3, idx2 = self.downsample(y_2)\n",
    "#         print('y3_down')\n",
    "#         print(y_3.shape)\n",
    "#         print('idx2')\n",
    "#         print(idx2.shape)\n",
    "        \n",
    "        y_3 = self.encoder3(y_3)\n",
    "#         print('y3')\n",
    "#         print(y_3.shape)\n",
    "        y_4, idx3 = self.downsample(y_3)\n",
    "#         print('y4_down')\n",
    "#         print(y_4.shape)\n",
    "#         print('idx3')\n",
    "#         print(idx3.shape)\n",
    "        \n",
    "        y_4 = self.encoder4(y_4)\n",
    "#         print('y_4')\n",
    "#         print(y_4.shape)\n",
    "        y_5, idx4 = self.downsample(y_4)\n",
    "#         print('y5_down')\n",
    "#         print(y_5.shape)\n",
    "#         print('idx4')\n",
    "#         print(idx4.shape)\n",
    "        \n",
    "        y_5 = self.bridge(y_5)\n",
    "#         print('y_5')\n",
    "#         print(y_5.shape)\n",
    "        d_4 = self.upsample(y_5, idx4)\n",
    "#         print('d_4_up')\n",
    "#         print(d_4.shape)\n",
    "        \n",
    "        y_4 = self.blurpool(y_4)\n",
    "        d_4 = torch.cat((d_4,y_4), dim=1)\n",
    "#         print('1st concat ok')\n",
    "#         print('d4_concat')\n",
    "#         print(d_4.shape)\n",
    "        d_4 = self.decoder1(d_4)\n",
    "#         print('1st deco ok')\n",
    "#         print('d4_deco')\n",
    "#         print(d_4.shape)\n",
    "        d_4 = self.upsample(d_4, idx3)\n",
    "#         print('d4_up')\n",
    "#         print(d_4.shape)\n",
    "        \n",
    "        y_3 = self.blurpool(y_3)\n",
    "        d_3 = torch.cat((d_4, y_3), dim=1)\n",
    "#         print('2nd concat ok')\n",
    "#         print('d3_concat')\n",
    "#         print(d_3.shape)\n",
    "        d_3 = self.decoder2(d_3)\n",
    "#         print('2nd deco ok')\n",
    "#         print('d3_deco')\n",
    "#         print(d_3.shape)\n",
    "        d_3 = self.upsample(d_3, idx2)\n",
    "#         print('d3_up')\n",
    "#         print(d_3.shape)\n",
    "        \n",
    "#         print('8')\n",
    "        \n",
    "        y_2 = self.blurpool(y_2)\n",
    "        d_2 = torch.cat((d_3,y_2), dim=1)\n",
    "        d_2 = self.decoder3(d_2)\n",
    "        d_2 = self.upsample(d_2, idx1)\n",
    "        \n",
    "        \n",
    "        y_1 = self.blurpool(y_1)\n",
    "        d_1 = torch.cat((d_2,y_1), dim=1)\n",
    "        d_1 = self.decoder4(d_1)      \n",
    "        \n",
    "        y_ = self.last_conv(d_1)\n",
    "#         print('14')\n",
    "        y_ = F.interpolate(y_, (x.size(-2), x.size(-1)), mode='bilinear', align_corners=True)\n",
    "#         print('15')\n",
    "#         _, y_ = torch.max(y_, dim=1)\n",
    "        \n",
    "        return y_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Blur Pooling\n",
    "\n",
    ": Concatenation helps the decoder to recover positional data. In this case, the boundary data of original image is critical. For the concatenating images' boundary to be more specific, we introduce Blur Pooling. It generates average blurred images from concatenation image. From average pooling, the boundary data of original image is blurred well. After that, original image is subtracted by blurred image so that the boundary data is emphasized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlurPooling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BlurPooling, self).__init__()\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        blur = torch.zeros(x.size(0), x.size(1), x.size(2), x.size(3))\n",
    "        blur = blur.detach().numpy()\n",
    "        img_np = x.cpu().detach().numpy()\n",
    "        #blur = np.zeros([img_np.size(0),img_np.size(1), img_np.size(2), img_np.size(3)])\n",
    "        #print('input_img')\n",
    "        #print(img_np.shape)\n",
    "        for i in range(x.size(0)):\n",
    "            for j in range(x.size(1)):\n",
    "                blur[i][j] = cv2.blur(img_np[i][j], (8,16))\n",
    "        #blur = cv2.blur(img_np, (8,16))\n",
    "        y_ = img_np - 1.05*blur\n",
    "        y_ = torch.from_numpy(y_).float().to(device)\n",
    "    \n",
    "        return y_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n"
     ]
    }
   ],
   "source": [
    "a = torch.zeros([4,2,3])\n",
    "#print(a[0][0][0])\n",
    "b = np.zeros([4,2,3])\n",
    "print(b[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMNet_vgg16bn(\n",
      "  (encoder1): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "  )\n",
      "  (encoder2): Sequential(\n",
      "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ReLU(inplace=True)\n",
      "  )\n",
      "  (encoder3): Sequential(\n",
      "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
      "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): ReLU(inplace=True)\n",
      "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (19): ReLU(inplace=True)\n",
      "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (22): ReLU(inplace=True)\n",
      "  )\n",
      "  (encoder4): Sequential(\n",
      "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4))\n",
      "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (26): ReLU(inplace=True)\n",
      "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (32): ReLU(inplace=True)\n",
      "  )\n",
      "  (downsample): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (upsample): MaxUnpool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
      "  (blurpool): BlurPooling()\n",
      "  (bridge): Sequential(\n",
      "    (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace=True)\n",
      "  )\n",
      "  (decoder1): Sequential(\n",
      "    (conv1): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace=True)\n",
      "  )\n",
      "  (decoder2): Sequential(\n",
      "    (conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace=True)\n",
      "  )\n",
      "  (decoder3): Sequential(\n",
      "    (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace=True)\n",
      "  )\n",
      "  (decoder4): Sequential(\n",
      "    (conv1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace=True)\n",
      "  )\n",
      "  (last_conv): Sequential(\n",
      "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(64, 34, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "model = KMNet_vgg16bn(n_classes=34).to(device)\n",
    "print(model)\n",
    "\n",
    "#summary(model, input_size=(3,1024,2048))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskToTensor(object):\n",
    "    def __call__(self, img):\n",
    "        return torch.from_numpy(np.array(img, dtype=np.int32)).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_transform = transforms.Compose([\n",
    "    transforms.RandomCrop(size=(1000,2000), padding_mode='constant'),\n",
    "    transforms.Resize(size=(512,1024)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.28689554, 0.32513303, 0.28389177], std=[0.18696375, 0.19017339, 0.18720214]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_transform = transforms.Compose([\n",
    "    transforms.Resize(size=(512,1024)),\n",
    "    MaskToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMeanIoU(label, yhat, n_classes=34, ignore_class=[0,1,2,3,4,5,6,9,10,14,15,16,18,29,30]):\n",
    "    if ignore_class==None:\n",
    "        ignore_len = 0\n",
    "    else:\n",
    "        ignore_len = len(ignore_class)\n",
    "    iou = np.zeros(n_classes-ignore_len)\n",
    "    minus = 0\n",
    "    for i in range(n_classes):\n",
    "        if np.isin(i, ignore_class):\n",
    "            minus+=1\n",
    "            continue\n",
    "#         print(i-minus)\n",
    "        tfpn = torch.eq(yhat, i)\n",
    "\n",
    "        tp = len(tfpn[(tfpn==True) & (label==i) &(yhat==i)])\n",
    "        fp = len(tfpn[(tfpn==True) & (label!=i) & (yhat==i)])\n",
    "        fn = len(tfpn[(tfpn==False) & (label==i) & (yhat!=i)])\n",
    "        tn = len(tfpn[(tfpn==False) & (label!=i) & (yhat!=i)])\n",
    "        \n",
    "        if tp==0:\n",
    "            iou[i-minus] = 0.0\n",
    "        else:\n",
    "            iou[i-minus] = tp/(tp+fp+fn)\n",
    "#         print(iou[i-minus])\n",
    "            \n",
    "    mIoU = np.mean(iou)\n",
    "#     print(iou)\n",
    "    \n",
    "    return mIoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = datasets.Cityscapes(root='/home/km/data/cityscapes', split='train', mode='fine', target_type='semantic', transform=img_transform, target_transform=target_transform)\n",
    "val_set = datasets.Cityscapes(root='/home/km/data/cityscapes', split='val', mode='fine', target_type='semantic', transform=img_transform, target_transform=target_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2975"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 512, 1024])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 512, 1024])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_set[0][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using multi-GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use 2 GPUs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/km/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py:26: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 0 which\n",
      "    has less than 75% of the memory or cores of GPU 1. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): KMNet_vgg16bn(\n",
       "    (encoder1): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "    (encoder2): Sequential(\n",
       "      (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (9): ReLU(inplace=True)\n",
       "      (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (12): ReLU(inplace=True)\n",
       "    )\n",
       "    (encoder3): Sequential(\n",
       "      (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "      (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (16): ReLU(inplace=True)\n",
       "      (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (19): ReLU(inplace=True)\n",
       "      (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (22): ReLU(inplace=True)\n",
       "    )\n",
       "    (encoder4): Sequential(\n",
       "      (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4))\n",
       "      (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (26): ReLU(inplace=True)\n",
       "      (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (29): ReLU(inplace=True)\n",
       "      (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (32): ReLU(inplace=True)\n",
       "    )\n",
       "    (downsample): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (upsample): MaxUnpool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
       "    (blurpool): BlurPooling()\n",
       "    (bridge): Sequential(\n",
       "      (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU(inplace=True)\n",
       "    )\n",
       "    (decoder1): Sequential(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU(inplace=True)\n",
       "    )\n",
       "    (decoder2): Sequential(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU(inplace=True)\n",
       "    )\n",
       "    (decoder3): Sequential(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU(inplace=True)\n",
       "    )\n",
       "    (decoder4): Sequential(\n",
       "      (conv1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU(inplace=True)\n",
       "    )\n",
       "    (last_conv): Sequential(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.device_count() > 1:\n",
    "  print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "  # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "  model = nn.DataParallel(model)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "val_loader = DataLoader(dataset=val_set, batch_size=10, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optim = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iter = 90000\n",
    "max_epoch = max_iter//(len(train_set)//batch_size)\n",
    "step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "\n",
    "class PolyLR(_LRScheduler):\n",
    "    def __init__(self, optimizer, max_iter, power=0.9, last_epoch=-1):\n",
    "        self.max_iter = max_iter\n",
    "        self.power = power\n",
    "        super(PolyLR, self).__init__(optimizer, last_epoch)\n",
    "        \n",
    "    def get_lr(self):\n",
    "        return [base_lr*(1-self.last_epoch/self.max_iter)**self.power \n",
    "                for base_lr in self.base_lrs]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import StepLR\n",
    "#scheduler = StepLR(optim, step_size=50, gamma=0.9)\n",
    "scheduler = PolyLR(optim, max_iter = max_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th Epoch, 5th Step, learning rate = 0.009999499998611083 - Loss: 2.8305823802948\n",
      "1th Epoch, 10th Step, learning rate = 0.00999899999444422 - Loss: 2.11367130279541\n",
      "1th Epoch, 15th Step, learning rate = 0.009998499987499236 - Loss: 2.1761856079101562\n",
      "1th Epoch, 20th Step, learning rate = 0.009997999977775967 - Loss: 1.970829963684082\n",
      "1th Epoch, 25th Step, learning rate = 0.00999749996527424 - Loss: 1.8596738576889038\n",
      "1th Epoch, 30th Step, learning rate = 0.009996999949993889 - Loss: 2.6632227897644043\n",
      "1th Epoch, 35th Step, learning rate = 0.009996499931934738 - Loss: 1.6601877212524414\n",
      "1th Epoch, 40th Step, learning rate = 0.009995999911096622 - Loss: 1.935294270515442\n",
      "1th Epoch, 45th Step, learning rate = 0.009995499887479371 - Loss: 1.6238504648208618\n",
      "1th Epoch, 50th Step, learning rate = 0.00999499986108281 - Loss: 1.5821216106414795\n",
      "1th Epoch, 55th Step, learning rate = 0.009994499831906777 - Loss: 1.956046462059021\n",
      "1th Epoch, 60th Step, learning rate = 0.009993999799951093 - Loss: 1.6125179529190063\n",
      "1th Epoch, 65th Step, learning rate = 0.009993499765215597 - Loss: 1.5772764682769775\n",
      "1th Epoch, 70th Step, learning rate = 0.009992999727700113 - Loss: 1.804239273071289\n",
      "1th Epoch, 75th Step, learning rate = 0.009992499687404472 - Loss: 1.6390200853347778\n",
      "1th Epoch, 80th Step, learning rate = 0.009991999644328505 - Loss: 1.8215885162353516\n",
      "1th Epoch, 85th Step, learning rate = 0.009991499598472044 - Loss: 1.2132641077041626\n",
      "1th Epoch, 90th Step, learning rate = 0.009990999549834914 - Loss: 1.3717308044433594\n",
      "1th Epoch, 95th Step, learning rate = 0.009990499498416947 - Loss: 2.1075425148010254\n",
      "1th Epoch, 100th Step, learning rate = 0.009989999444217976 - Loss: 1.4420075416564941\n",
      "10 "
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/home/km/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/parallel_apply.py\", line 60, in _worker\n    output = module(*input, **kwargs)\n  File \"/home/km/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 541, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"<ipython-input-7-b2fe7438f891>\", line 159, in forward\n    d_1 = self.decoder4(d_1)\n  File \"/home/km/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 541, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/home/km/anaconda3/lib/python3.7/site-packages/torch/nn/modules/container.py\", line 92, in forward\n    input = module(input)\n  File \"/home/km/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 541, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/home/km/anaconda3/lib/python3.7/site-packages/torch/nn/modules/batchnorm.py\", line 81, in forward\n    exponential_average_factor, self.eps)\n  File \"/home/km/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\", line 1670, in batch_norm\n    training, momentum, eps, torch.backends.cudnn.enabled\nRuntimeError: CUDA out of memory. Tried to allocate 640.00 MiB (GPU 0; 7.93 GiB total capacity; 6.53 GiB already allocated; 390.06 MiB free; 558.71 MiB cached)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-a34452ad337c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                     \u001b[0myhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/parallel_apply.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0;31m# (https://bugs.python.org/issue2651), so we work around it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyErrorMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/home/km/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/parallel_apply.py\", line 60, in _worker\n    output = module(*input, **kwargs)\n  File \"/home/km/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 541, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"<ipython-input-7-b2fe7438f891>\", line 159, in forward\n    d_1 = self.decoder4(d_1)\n  File \"/home/km/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 541, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/home/km/anaconda3/lib/python3.7/site-packages/torch/nn/modules/container.py\", line 92, in forward\n    input = module(input)\n  File \"/home/km/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 541, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/home/km/anaconda3/lib/python3.7/site-packages/torch/nn/modules/batchnorm.py\", line 81, in forward\n    exponential_average_factor, self.eps)\n  File \"/home/km/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\", line 1670, in batch_norm\n    training, momentum, eps, torch.backends.cudnn.enabled\nRuntimeError: CUDA out of memory. Tried to allocate 640.00 MiB (GPU 0; 7.93 GiB total capacity; 6.53 GiB already allocated; 390.06 MiB free; 558.71 MiB cached)\n"
     ]
    }
   ],
   "source": [
    "totalLoss = 0\n",
    "trainLoss = []\n",
    "\n",
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "best_miou = 0\n",
    "\n",
    "model.train()\n",
    "for epoch in range(max_epoch):\n",
    "    for idx, (images, labels) in enumerate(train_loader):\n",
    "        start = time.time()\n",
    "        x, y = images.to(device), labels.to(device)\n",
    "        yhat = model(x)\n",
    "#         print(epoch,step)\n",
    "        \n",
    "        loss = criterion(yhat, y)\n",
    "        totalLoss += loss.item()\n",
    "        \n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        if (step+1)%5 == 0:\n",
    "            print('{}th Epoch, {}th Step, learning rate = {} - Loss: {}'.format(epoch+1, step+1, scheduler.get_lr()[0], loss.item()))\n",
    "            trainLoss.append(totalLoss/5)\n",
    "            totalLoss = 0\n",
    "            \n",
    "        if (step+1)%100 == 0:\n",
    "            model.eval()\n",
    "            mIoU = 0\n",
    "            curr = 0\n",
    "            with torch.no_grad():\n",
    "                for idx, (images, labels) in enumerate(val_loader):\n",
    "                    x, y = images.to(device), labels.to(device)\n",
    "                    yhat = model(x)\n",
    "                    \n",
    "                    loss = criterion(yhat, y)\n",
    "\n",
    "                    _, y_pred = torch.max(yhat.cpu(), dim=1)\n",
    "                    mIoU += getMeanIoU(y.cpu(), y_pred)*len(y)\n",
    "                    curr += len(y)\n",
    "                    print(curr, end=' ')\n",
    "                    if curr==300:\n",
    "                        print()\n",
    "                    \n",
    "            mIoU /= len(val_set)\n",
    "            print()\n",
    "            print('*'*27, 'Test', '*'*27)\n",
    "            print('time:{}, {}th Step, Loss: {}, Mean IoU = {:.3f}%'.format(timeSince(start), step+1, loss.item(), mIoU*100))\n",
    "            print('*'*60)\n",
    "            \n",
    "            model.train()\n",
    "        \n",
    "        step+=1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '/root/km/models/KMNet/KMNet_vgg16bn.pth'\n",
    "torch.save(model.state_dict(), PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()   #  model load 후 이어서 학습하기 위해서는 model.eval() 한번 호출이 필요\n",
    "mIoU = 0\n",
    "curr = 0\n",
    "with torch.no_grad():\n",
    "    for idx, (images, labels) in enumerate(val_loader):\n",
    "        x, y = images.to(device), labels.to(device)\n",
    "        yhat = model(x)\n",
    "\n",
    "        loss = criterion(yhat, y)\n",
    "\n",
    "        _, y_pred = torch.max(yhat.cpu(), dim=1)\n",
    "        mIoU += getMeanIoU(y.cpu(), y_pred)*len(y)\n",
    "        curr += len(y)\n",
    "        print(curr, end=' ')\n",
    "        if curr==300:\n",
    "            print()\n",
    "\n",
    "mIoU /= len(val_set)\n",
    "print()\n",
    "print('*'*27, 'Test', '*'*27)\n",
    "print('time:{}, {}th Step, Loss: {}, Mean IoU = {:.3f}%'.format(timeSince(start), step+1, loss.item(), mIoU*100))\n",
    "print('*'*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(trainLoss)), trainLoss, marker='.')\n",
    "plt.xlabel(\"steps\")\n",
    "plt.ylabel(\"train loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = datasets.Cityscapes(root='/root/km/data/cityscapes', split='test', mode='fine', target_type='semantic', transform=img_transform, target_transform=target_transform)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=10, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KMNet_model = model\n",
    "KMNet_model.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KMNet_model.eval()\n",
    "print('<{}th step>'.format(step+1))\n",
    "\n",
    "curr = 0\n",
    "y_preds = torch.Tensor([]).type(torch.long)\n",
    "with torch.no_grad():\n",
    "    for idx, (images, labels) in enumerate(test_loader):\n",
    "        x, y =images.to(device), labels.to(device)\n",
    "        yhat = KMNet_model(x)\n",
    "        \n",
    "        loss = criterion(yhat, y)\n",
    "        \n",
    "        _, y_pred = torch.max(yhat.cpu(), dim=1)\n",
    "        y_preds = torch.cat([y_preds, y_pred], dim=0)\n",
    "        curr += len(y)\n",
    "        if(curr%50)==0 or curr==len(test_data):\n",
    "            print(curr, end=' ')\n",
    "            \n",
    "print(\"Prediction Ended\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = datasets.Cityscapes(root='/root/km/data/cityscapes', split='test', mode='fine', target_type='semantic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensorToMask(object):\n",
    "    def __call__(self, tensor):\n",
    "        mask = tensor.type(torch.uint8)\n",
    "        \n",
    "        return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestTransform(object):\n",
    "    def __call__(self, tensor, size=(1024, 2048)):\n",
    "        test_transform = transforms.Compose([\n",
    "            TensorToMask(),\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize(size=size),\n",
    "        ])\n",
    "        \n",
    "        return test_transform(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform = transforms.Compose([\n",
    "    TensorToMask(),\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize(size=(1024,2048)),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = 15, 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(a,b))\n",
    "\n",
    "for i in range(10):\n",
    "    ax = fig.add_subplot(5, 2, i+1)\n",
    "    ax.imshow(test_img[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(a,b))\n",
    "\n",
    "for i in range(10):\n",
    "    ax = fig.add_subplot(5, 2, i+1)\n",
    "    y_img = test_transform(y_preds[i])\n",
    "    ax.imshow(y_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
