1th Epoch, 5th Step, learning rate = 0.009999499998611083 - Loss: 2.5632164478302, aux loss1: 2.8320279121398926, 
		 aux loss2: 2.852858304977417, total loss: 4.55396842956543
1th Epoch, 10th Step, learning rate = 0.00999899999444422 - Loss: 2.175163745880127, aux loss1: 2.2126920223236084, 
		 aux loss2: 2.2058348655700684, total loss: 3.7213053703308105
1th Epoch, 15th Step, learning rate = 0.009998499987499236 - Loss: 2.1135385036468506, aux loss1: 2.07486891746521, 
		 aux loss2: 2.069516181945801, total loss: 3.56380558013916
1th Epoch, 20th Step, learning rate = 0.009997999977775967 - Loss: 2.069350004196167, aux loss1: 2.1445319652557373, 
		 aux loss2: 2.140613079071045, total loss: 3.5689549446105957
1th Epoch, 25th Step, learning rate = 0.00999749996527424 - Loss: 1.7303882837295532, aux loss1: 1.7455083131790161, 
		 aux loss2: 1.6842752695083618, total loss: 2.927750825881958
1th Epoch, 30th Step, learning rate = 0.009996999949993889 - Loss: 1.7612242698669434, aux loss1: 1.766827940940857, 
		 aux loss2: 1.7154700756072998, total loss: 2.9774606227874756
1th Epoch, 35th Step, learning rate = 0.009996499931934738 - Loss: 1.7648504972457886, aux loss1: 1.7914844751358032, 
		 aux loss2: 1.6959303617477417, total loss: 2.980668067932129
1th Epoch, 40th Step, learning rate = 0.009995999911096622 - Loss: 1.9081978797912598, aux loss1: 1.9163572788238525, 
		 aux loss2: 1.9020310640335083, total loss: 3.24391770362854
1th Epoch, 45th Step, learning rate = 0.009995499887479371 - Loss: 1.8078570365905762, aux loss1: 1.8455778360366821, 
		 aux loss2: 1.767309546470642, total loss: 3.0684542655944824
1th Epoch, 50th Step, learning rate = 0.00999499986108281 - Loss: 1.75971257686615, aux loss1: 1.8965381383895874, 
		 aux loss2: 1.7530746459960938, total loss: 3.0299038887023926
1th Epoch, 55th Step, learning rate = 0.009994499831906777 - Loss: 1.518449068069458, aux loss1: 1.6512166261672974, 
		 aux loss2: 1.5433998107910156, total loss: 2.631173849105835
1th Epoch, 60th Step, learning rate = 0.009993999799951093 - Loss: 1.713647723197937, aux loss1: 1.7865082025527954, 
		 aux loss2: 1.69880211353302, total loss: 2.9291210174560547
1th Epoch, 65th Step, learning rate = 0.009993499765215597 - Loss: 1.680760145187378, aux loss1: 1.8201115131378174, 
		 aux loss2: 1.704363465309143, total loss: 2.908539295196533
1th Epoch, 70th Step, learning rate = 0.009992999727700113 - Loss: 1.7152639627456665, aux loss1: 1.8557806015014648, 
		 aux loss2: 1.7425447702407837, total loss: 2.9690160751342773
1th Epoch, 75th Step, learning rate = 0.009992499687404472 - Loss: 1.63370680809021, aux loss1: 1.8091882467269897, 
		 aux loss2: 1.6259770393371582, total loss: 2.8268542289733887
1th Epoch, 80th Step, learning rate = 0.009991999644328505 - Loss: 1.4328510761260986, aux loss1: 1.5801169872283936, 
		 aux loss2: 1.4076956510543823, total loss: 2.4699645042419434
1th Epoch, 85th Step, learning rate = 0.009991499598472044 - Loss: 1.7574187517166138, aux loss1: 1.9344065189361572, 
		 aux loss2: 1.744646430015564, total loss: 3.0355992317199707
1th Epoch, 90th Step, learning rate = 0.009990999549834914 - Loss: 1.7233977317810059, aux loss1: 1.8732960224151611, 
		 aux loss2: 1.7240430116653442, total loss: 2.975003719329834
1th Epoch, 95th Step, learning rate = 0.009990499498416947 - Loss: 1.603689432144165, aux loss1: 1.7853392362594604, 
		 aux loss2: 1.5803236961364746, total loss: 2.77142071723938
1th Epoch, 100th Step, learning rate = 0.009989999444217976 - Loss: 1.4896167516708374, aux loss1: 1.6704154014587402, 
		 aux loss2: 1.4567276239395142, total loss: 2.573432445526123
<100th step>
*************************** Test ***************************
time:3m 28s, 100th Step, Loss: 2.137075424194336, Mean IoU = 9.439%
************************************************************
1th Epoch, 105th Step, learning rate = 0.009989499387237826 - Loss: 1.508836030960083, aux loss1: 1.6501573324203491, 
		 aux loss2: 1.4945868253707886, total loss: 2.6017181873321533
1th Epoch, 110th Step, learning rate = 0.00998899932747633 - Loss: 1.7358254194259644, aux loss1: 1.920224666595459, 
		 aux loss2: 1.7135378122329712, total loss: 2.9973082542419434
1th Epoch, 115th Step, learning rate = 0.009988499264933315 - Loss: 1.4007041454315186, aux loss1: 1.6156885623931885, 
		 aux loss2: 1.3961070775985718, total loss: 2.4438536167144775
1th Epoch, 120th Step, learning rate = 0.009987999199608615 - Loss: 1.5112574100494385, aux loss1: 1.7414299249649048, 
		 aux loss2: 1.5457152128219604, total loss: 2.651972532272339
1th Epoch, 125th Step, learning rate = 0.009987499131502056 - Loss: 1.4319334030151367, aux loss1: 1.6870405673980713, 
		 aux loss2: 1.452460527420044, total loss: 2.5190298557281494
1th Epoch, 130th Step, learning rate = 0.009986999060613469 - Loss: 1.613884687423706, aux loss1: 1.8815935850143433, 
		 aux loss2: 1.66872239112854, total loss: 2.8458518981933594
1th Epoch, 135th Step, learning rate = 0.009986498986942687 - Loss: 1.5797702074050903, aux loss1: 1.7771332263946533, 
		 aux loss2: 1.5863642692565918, total loss: 2.7474560737609863
1th Epoch, 140th Step, learning rate = 0.009985998910489534 - Loss: 1.707442283630371, aux loss1: 1.882219672203064, 
		 aux loss2: 1.7074024677276611, total loss: 2.955069065093994
1th Epoch, 145th Step, learning rate = 0.009985498831253842 - Loss: 1.461281180381775, aux loss1: 1.7340251207351685, 
		 aux loss2: 1.495611310005188, total loss: 2.579733371734619
1th Epoch, 150th Step, learning rate = 0.009984998749235443 - Loss: 1.4566025733947754, aux loss1: 1.72805917263031, 
		 aux loss2: 1.478827714920044, total loss: 2.566551446914673
1th Epoch, 155th Step, learning rate = 0.009984498664434164 - Loss: 1.610493779182434, aux loss1: 1.8838298320770264, 
		 aux loss2: 1.6733262538909912, total loss: 2.84497332572937
1th Epoch, 160th Step, learning rate = 0.009983998576849833 - Loss: 1.4091730117797852, aux loss1: 1.616946816444397, 
		 aux loss2: 1.4362350702285767, total loss: 2.4687511920928955
1th Epoch, 165th Step, learning rate = 0.009983498486482284 - Loss: 1.4406028985977173, aux loss1: 1.6678521633148193, 
		 aux loss2: 1.4635674953460693, total loss: 2.526385545730591
1th Epoch, 170th Step, learning rate = 0.009982998393331345 - Loss: 1.1253228187561035, aux loss1: 1.3687872886657715, 
		 aux loss2: 1.1348750591278076, total loss: 1.989909052848816
1th Epoch, 175th Step, learning rate = 0.009982498297396844 - Loss: 1.4263464212417603, aux loss1: 1.6364933252334595, 
		 aux loss2: 1.4771479368209839, total loss: 2.5081536769866943
1th Epoch, 180th Step, learning rate = 0.009981998198678612 - Loss: 1.610351324081421, aux loss1: 1.862112283706665, 
		 aux loss2: 1.7217276096343994, total loss: 2.8576760292053223
1th Epoch, 185th Step, learning rate = 0.009981498097176479 - Loss: 1.5258649587631226, aux loss1: 1.688226342201233, 
		 aux loss2: 1.5169132947921753, total loss: 2.6390981674194336
1th Epoch, 190th Step, learning rate = 0.009980997992890274 - Loss: 1.544332504272461, aux loss1: 1.73822021484375, 
		 aux loss2: 1.5824811458587646, total loss: 2.698791027069092
1th Epoch, 195th Step, learning rate = 0.009980497885819825 - Loss: 1.4262040853500366, aux loss1: 1.647973895072937, 
		 aux loss2: 1.4455400705337524, total loss: 2.498812198638916
1th Epoch, 200th Step, learning rate = 0.009979997775964963 - Loss: 1.3128710985183716, aux loss1: 1.6145460605621338, 
		 aux loss2: 1.3973766565322876, total loss: 2.3561854362487793
<200th step>
*************************** Test ***************************
time:3m 12s, 200th Step, Loss: 1.8033307790756226, Mean IoU = 9.880%
************************************************************
1th Epoch, 205th Step, learning rate = 0.009979497663325518 - Loss: 1.7319034337997437, aux loss1: 2.0104823112487793, 
		 aux loss2: 1.7636433839797974, total loss: 3.0405056476593018
1th Epoch, 210th Step, learning rate = 0.009978997547901318 - Loss: 1.3213425874710083, aux loss1: 1.586329460144043, 
		 aux loss2: 1.412489891052246, total loss: 2.3622374534606934
1th Epoch, 215th Step, learning rate = 0.009978497429692193 - Loss: 1.296753168106079, aux loss1: 1.6055927276611328, 
		 aux loss2: 1.397735595703125, total loss: 2.3375251293182373
1th Epoch, 220th Step, learning rate = 0.009977997308697972 - Loss: 1.5090683698654175, aux loss1: 1.7512691020965576, 
		 aux loss2: 1.595068335533142, total loss: 2.6724765300750732
1th Epoch, 225th Step, learning rate = 0.009977497184918487 - Loss: 1.2575958967208862, aux loss1: 1.5112003087997437, 
		 aux loss2: 1.335374116897583, total loss: 2.245105743408203
1th Epoch, 230th Step, learning rate = 0.009976997058353563 - Loss: 1.267466425895691, aux loss1: 1.55440354347229, 
		 aux loss2: 1.332541584968567, total loss: 2.2668042182922363
1th Epoch, 235th Step, learning rate = 0.009976496929003032 - Loss: 1.2007899284362793, aux loss1: 1.4923169612884521, 
		 aux loss2: 1.2641671895980835, total loss: 2.1541519165039062
1th Epoch, 240th Step, learning rate = 0.009975996796866723 - Loss: 1.4595041275024414, aux loss1: 1.694865345954895, 
		 aux loss2: 1.498504877090454, total loss: 2.5673656463623047
1th Epoch, 245th Step, learning rate = 0.009975496661944467 - Loss: 1.3048336505889893, aux loss1: 1.4985377788543701, 
		 aux loss2: 1.379000186920166, total loss: 2.305994987487793
1th Epoch, 250th Step, learning rate = 0.00997499652423609 - Loss: 1.2580358982086182, aux loss1: 1.5336464643478394, 
		 aux loss2: 1.3429096937179565, total loss: 2.255293846130371
1th Epoch, 255th Step, learning rate = 0.009974496383741422 - Loss: 1.3407974243164062, aux loss1: 1.5878666639328003, 
		 aux loss2: 1.4115700721740723, total loss: 2.3817856311798096
1th Epoch, 260th Step, learning rate = 0.009973996240460293 - Loss: 1.5434075593948364, aux loss1: 1.8425664901733398, 
		 aux loss2: 1.6232025623321533, total loss: 2.7454586029052734
1th Epoch, 265th Step, learning rate = 0.009973496094392534 - Loss: 1.2606033086776733, aux loss1: 1.5549589395523071, 
		 aux loss2: 1.3473777770996094, total loss: 2.2660422325134277
1th Epoch, 270th Step, learning rate = 0.009972995945537971 - Loss: 1.243262529373169, aux loss1: 1.510379672050476, 
		 aux loss2: 1.3088185787200928, total loss: 2.2199039459228516
1th Epoch, 275th Step, learning rate = 0.009972495793896434 - Loss: 1.3062721490859985, aux loss1: 1.5843932628631592, 
		 aux loss2: 1.3984010219573975, total loss: 2.3409504890441895
1th Epoch, 280th Step, learning rate = 0.009971995639467754 - Loss: 1.5266056060791016, aux loss1: 1.7832309007644653, 
		 aux loss2: 1.5847413539886475, total loss: 2.6954715251922607
1th Epoch, 285th Step, learning rate = 0.00997149548225176 - Loss: 1.4237656593322754, aux loss1: 1.6381301879882812, 
		 aux loss2: 1.505592942237854, total loss: 2.517441987991333
1th Epoch, 290th Step, learning rate = 0.009970995322248277 - Loss: 1.3222779035568237, aux loss1: 1.606306552886963, 
		 aux loss2: 1.3879101276397705, total loss: 2.3593339920043945
1th Epoch, 295th Step, learning rate = 0.009970495159457138 - Loss: 1.1780661344528198, aux loss1: 1.4190914630889893, 
		 aux loss2: 1.2474749088287354, total loss: 2.102783679962158
1th Epoch, 300th Step, learning rate = 0.009969994993878174 - Loss: 1.1180269718170166, aux loss1: 1.4257115125656128, 
		 aux loss2: 1.212180733680725, total loss: 2.0306127071380615
<300th step>
*************************** Test ***************************
time:3m 10s, 300th Step, Loss: 1.6319224834442139, Mean IoU = 11.446%
************************************************************
1th Epoch, 305th Step, learning rate = 0.009969494825511207 - Loss: 1.1975849866867065, aux loss1: 1.5267984867095947, 
		 aux loss2: 1.2840620279312134, total loss: 2.1692492961883545
1th Epoch, 310th Step, learning rate = 0.009968994654356073 - Loss: 1.3325812816619873, aux loss1: 1.6030364036560059, 
		 aux loss2: 1.4170998334884644, total loss: 2.3803319931030273
1th Epoch, 315th Step, learning rate = 0.009968494480412598 - Loss: 1.3685979843139648, aux loss1: 1.6922132968902588, 
		 aux loss2: 1.4432580471038818, total loss: 2.4535651206970215
1th Epoch, 320th Step, learning rate = 0.009967994303680611 - Loss: 1.359914779663086, aux loss1: 1.5627448558807373, 
		 aux loss2: 1.3725171089172363, total loss: 2.3777451515197754
1th Epoch, 325th Step, learning rate = 0.009967494124159941 - Loss: 1.2214988470077515, aux loss1: 1.4969947338104248, 
		 aux loss2: 1.2768784761428833, total loss: 2.1813488006591797
1th Epoch, 330th Step, learning rate = 0.009966993941850417 - Loss: 1.1931543350219727, aux loss1: 1.459398865699768, 
		 aux loss2: 1.2787065505981445, total loss: 2.1424567699432373
1th Epoch, 335th Step, learning rate = 0.00996649375675187 - Loss: 1.462484359741211, aux loss1: 1.781826376914978, 
		 aux loss2: 1.5712018013000488, total loss: 2.6255130767822266
1th Epoch, 340th Step, learning rate = 0.009965993568864125 - Loss: 1.3949754238128662, aux loss1: 1.636367917060852, 
		 aux loss2: 1.4337767362594604, total loss: 2.4593966007232666
1th Epoch, 345th Step, learning rate = 0.009965493378187015 - Loss: 1.565985083580017, aux loss1: 1.884084939956665, 
		 aux loss2: 1.658812403678894, total loss: 2.7947354316711426
1th Epoch, 350th Step, learning rate = 0.009964993184720366 - Loss: 1.3418960571289062, aux loss1: 1.6053571701049805, 
		 aux loss2: 1.438004732131958, total loss: 2.398705244064331
1th Epoch, 355th Step, learning rate = 0.009964492988464009 - Loss: 1.5516266822814941, aux loss1: 1.7243162393569946, 
		 aux loss2: 1.576465368270874, total loss: 2.699507713317871
1th Epoch, 360th Step, learning rate = 0.00996399278941777 - Loss: 1.2297062873840332, aux loss1: 1.5058494806289673, 
		 aux loss2: 1.3236513137817383, total loss: 2.2109217643737793
1th Epoch, 365th Step, learning rate = 0.00996349258758148 - Loss: 1.3442922830581665, aux loss1: 1.5911306142807007, 
		 aux loss2: 1.38504159450531, total loss: 2.375648021697998
1th Epoch, 370th Step, learning rate = 0.009962992382954967 - Loss: 1.301798939704895, aux loss1: 1.5852636098861694, 
		 aux loss2: 1.3726170063018799, total loss: 2.3264248371124268
2th Epoch, 375th Step, learning rate = 0.00996249217553806 - Loss: 1.4120995998382568, aux loss1: 1.7259503602981567, 
		 aux loss2: 1.485069990158081, total loss: 2.5239126682281494
2th Epoch, 380th Step, learning rate = 0.009961991965330586 - Loss: 1.0886811017990112, aux loss1: 1.389883041381836, 
		 aux loss2: 1.1724703311920166, total loss: 1.9746341705322266
2th Epoch, 385th Step, learning rate = 0.009961491752332378 - Loss: 1.3439959287643433, aux loss1: 1.609704852104187, 
		 aux loss2: 1.414756178855896, total loss: 2.3928098678588867
2th Epoch, 390th Step, learning rate = 0.009960991536543262 - Loss: 1.2142759561538696, aux loss1: 1.470526099205017, 
		 aux loss2: 1.2946375608444214, total loss: 2.1732888221740723
2th Epoch, 395th Step, learning rate = 0.009960491317963067 - Loss: 1.5190315246582031, aux loss1: 1.8744441270828247, 
		 aux loss2: 1.6272772550582886, total loss: 2.7322757244110107
2th Epoch, 400th Step, learning rate = 0.009959991096591621 - Loss: 1.1184018850326538, aux loss1: 1.4182054996490479, 
		 aux loss2: 1.1923390626907349, total loss: 2.020799160003662
<400th step>
*************************** Test ***************************
time:3m 9s, 400th Step, Loss: 1.683150291442871, Mean IoU = 13.021%
************************************************************
2th Epoch, 405th Step, learning rate = 0.009959490872428754 - Loss: 1.1328660249710083, aux loss1: 1.484147548675537, 
		 aux loss2: 1.2327600717544556, total loss: 2.071214437484741
2th Epoch, 410th Step, learning rate = 0.009958990645474295 - Loss: 1.0261565446853638, aux loss1: 1.3939181566238403, 
		 aux loss2: 1.1350067853927612, total loss: 1.8983347415924072
2th Epoch, 415th Step, learning rate = 0.009958490415728069 - Loss: 1.2555989027023315, aux loss1: 1.6036412715911865, 
		 aux loss2: 1.3672857284545898, total loss: 2.2836055755615234
2th Epoch, 420th Step, learning rate = 0.009957990183189908 - Loss: 1.1357908248901367, aux loss1: 1.5084209442138672, 
		 aux loss2: 1.2391968965530396, total loss: 2.083995819091797
2th Epoch, 425th Step, learning rate = 0.00995748994785964 - Loss: 1.0681545734405518, aux loss1: 1.4075645208358765, 
		 aux loss2: 1.1385363340377808, total loss: 1.945838451385498
2th Epoch, 430th Step, learning rate = 0.009956989709737095 - Loss: 1.1291576623916626, aux loss1: 1.4521695375442505, 
		 aux loss2: 1.2363418340682983, total loss: 2.059345245361328
2th Epoch, 435th Step, learning rate = 0.009956489468822096 - Loss: 1.305070400238037, aux loss1: 1.6292643547058105, 
		 aux loss2: 1.4593693017959595, total loss: 2.3775973320007324
2th Epoch, 440th Step, learning rate = 0.009955989225114478 - Loss: 0.9709612131118774, aux loss1: 1.3054354190826416, 
		 aux loss2: 1.03455650806427, total loss: 1.7764145135879517
2th Epoch, 445th Step, learning rate = 0.009955488978614068 - Loss: 1.0823115110397339, aux loss1: 1.4699922800064087, 
		 aux loss2: 1.2334957122802734, total loss: 2.016707420349121
2th Epoch, 450th Step, learning rate = 0.00995498872932069 - Loss: 1.0042575597763062, aux loss1: 1.3132025003433228, 
		 aux loss2: 1.0772359371185303, total loss: 1.8291127681732178
2th Epoch, 455th Step, learning rate = 0.009954488477234178 - Loss: 1.2560378313064575, aux loss1: 1.5714937448501587, 
		 aux loss2: 1.3617185354232788, total loss: 2.2721734046936035
2th Epoch, 460th Step, learning rate = 0.00995398822235436 - Loss: 1.3285008668899536, aux loss1: 1.6381256580352783, 
		 aux loss2: 1.4271742105484009, total loss: 2.39080810546875
2th Epoch, 465th Step, learning rate = 0.00995348796468106 - Loss: 1.2951290607452393, aux loss1: 1.626173496246338, 
		 aux loss2: 1.3876681327819824, total loss: 2.3380484580993652
2th Epoch, 470th Step, learning rate = 0.009952987704214109 - Loss: 1.1596993207931519, aux loss1: 1.488266110420227, 
		 aux loss2: 1.2682089805603027, total loss: 2.1134629249572754
2th Epoch, 475th Step, learning rate = 0.009952487440953336 - Loss: 1.0208535194396973, aux loss1: 1.3681244850158691, 
		 aux loss2: 1.1663529872894287, total loss: 1.8978320360183716
2th Epoch, 480th Step, learning rate = 0.00995198717489857 - Loss: 1.1050686836242676, aux loss1: 1.4837678670883179, 
		 aux loss2: 1.232635259628296, total loss: 2.043253183364868
2th Epoch, 485th Step, learning rate = 0.009951486906049635 - Loss: 1.1257305145263672, aux loss1: 1.4581389427185059, 
		 aux loss2: 1.2219566106796265, total loss: 2.051954746246338
2th Epoch, 490th Step, learning rate = 0.009950986634406366 - Loss: 1.3927627801895142, aux loss1: 1.6795330047607422, 
		 aux loss2: 1.4851841926574707, total loss: 2.490696430206299
2th Epoch, 495th Step, learning rate = 0.009950486359968588 - Loss: 1.1217820644378662, aux loss1: 1.4448819160461426, 
		 aux loss2: 1.2233318090438843, total loss: 2.044579267501831
2th Epoch, 500th Step, learning rate = 0.009949986082736126 - Loss: 1.4565961360931396, aux loss1: 1.753270149230957, 
		 aux loss2: 1.5163003206253052, total loss: 2.589097261428833
<500th step>
*************************** Test ***************************
time:3m 12s, 500th Step, Loss: 1.6499156951904297, Mean IoU = 12.989%
************************************************************
2th Epoch, 505th Step, learning rate = 0.009949485802708814 - Loss: 1.1981076002120972, aux loss1: 1.5113714933395386, 
		 aux loss2: 1.2650160789489746, total loss: 2.1575255393981934
2th Epoch, 510th Step, learning rate = 0.009948985519886475 - Loss: 0.9664286375045776, aux loss1: 1.3444795608520508, 
		 aux loss2: 1.060135841369629, total loss: 1.793826937675476
2th Epoch, 515th Step, learning rate = 0.009948485234268941 - Loss: 1.115156888961792, aux loss1: 1.4843015670776367, 
		 aux loss2: 1.2142010927200317, total loss: 2.0461277961730957
2th Epoch, 520th Step, learning rate = 0.00994798494585604 - Loss: 0.9885550737380981, aux loss1: 1.354309320449829, 
		 aux loss2: 1.0785578489303589, total loss: 1.8262710571289062
2th Epoch, 525th Step, learning rate = 0.009947484654647598 - Loss: 1.0783178806304932, aux loss1: 1.3924480676651, 
		 aux loss2: 1.1208794116973877, total loss: 1.9444040060043335
2th Epoch, 530th Step, learning rate = 0.009946984360643445 - Loss: 1.112421989440918, aux loss1: 1.4029258489608765, 
		 aux loss2: 1.1875263452529907, total loss: 2.008310317993164
2th Epoch, 535th Step, learning rate = 0.009946484063843406 - Loss: 1.1062729358673096, aux loss1: 1.4860986471176147, 
		 aux loss2: 1.2365909814834595, total loss: 2.046738862991333
2th Epoch, 540th Step, learning rate = 0.009945983764247315 - Loss: 1.4120382070541382, aux loss1: 1.8238656520843506, 
		 aux loss2: 1.5578503608703613, total loss: 2.5823380947113037
2th Epoch, 545th Step, learning rate = 0.009945483461854995 - Loss: 1.1007879972457886, aux loss1: 1.4655132293701172, 
		 aux loss2: 1.2295286655426025, total loss: 2.0322535037994385
2th Epoch, 550th Step, learning rate = 0.009944983156666276 - Loss: 1.1374095678329468, aux loss1: 1.5322932004928589, 
		 aux loss2: 1.258099913597107, total loss: 2.100337505340576
2th Epoch, 555th Step, learning rate = 0.009944482848680986 - Loss: 1.1236398220062256, aux loss1: 1.4172685146331787, 
		 aux loss2: 1.2046856880187988, total loss: 2.0306947231292725
2th Epoch, 560th Step, learning rate = 0.009943982537898952 - Loss: 1.349970817565918, aux loss1: 1.703466534614563, 
		 aux loss2: 1.4660567045211792, total loss: 2.4474334716796875
2th Epoch, 565th Step, learning rate = 0.009943482224320004 - Loss: 1.1042238473892212, aux loss1: 1.4814643859863281, 
		 aux loss2: 1.2169172763824463, total loss: 2.0354299545288086
2th Epoch, 570th Step, learning rate = 0.009942981907943968 - Loss: 0.8509172797203064, aux loss1: 1.2075825929641724, 
		 aux loss2: 0.9617193341255188, total loss: 1.5978798866271973
2th Epoch, 575th Step, learning rate = 0.009942481588770672 - Loss: 1.2697440385818481, aux loss1: 1.658126950263977, 
		 aux loss2: 1.4345080852508545, total loss: 2.3409852981567383
2th Epoch, 580th Step, learning rate = 0.009941981266799947 - Loss: 1.0951085090637207, aux loss1: 1.4537911415100098, 
		 aux loss2: 1.18155038356781, total loss: 2.003865957260132
2th Epoch, 585th Step, learning rate = 0.009941480942031618 - Loss: 1.285968542098999, aux loss1: 1.6648671627044678, 
		 aux loss2: 1.439150333404541, total loss: 2.361088991165161
2th Epoch, 590th Step, learning rate = 0.009940980614465513 - Loss: 1.2111047506332397, aux loss1: 1.562200903892517, 
		 aux loss2: 1.2849681377410889, total loss: 2.1937522888183594
2th Epoch, 595th Step, learning rate = 0.009940480284101461 - Loss: 1.2383171319961548, aux loss1: 1.6511560678482056, 
		 aux loss2: 1.344658613204956, total loss: 2.2715275287628174
2th Epoch, 600th Step, learning rate = 0.009939979950939289 - Loss: 1.1162328720092773, aux loss1: 1.5397964715957642, 
		 aux loss2: 1.2095526456832886, total loss: 2.061992883682251
<600th step>
*************************** Test ***************************
time:3m 12s, 600th Step, Loss: 1.3466458320617676, Mean IoU = 16.359%
************************************************************
2th Epoch, 605th Step, learning rate = 0.009939479614978828 - Loss: 1.4699257612228394, aux loss1: 1.8211886882781982, 
		 aux loss2: 1.6203380823135376, total loss: 2.6644175052642822
2th Epoch, 610th Step, learning rate = 0.0099389792762199 - Loss: 1.2392174005508423, aux loss1: 1.6192532777786255, 
		 aux loss2: 1.3858181238174438, total loss: 2.27932071685791
2th Epoch, 615th Step, learning rate = 0.009938478934662334 - Loss: 1.0988714694976807, aux loss1: 1.4532674551010132, 
		 aux loss2: 1.198171854019165, total loss: 2.014120578765869
2th Epoch, 620th Step, learning rate = 0.009937978590305962 - Loss: 1.2514841556549072, aux loss1: 1.5941765308380127, 
		 aux loss2: 1.4143943786621094, total loss: 2.29549503326416
2th Epoch, 625th Step, learning rate = 0.009937478243150612 - Loss: 1.1129097938537598, aux loss1: 1.505635380744934, 
		 aux loss2: 1.2388135194778442, total loss: 2.0601258277893066
2th Epoch, 630th Step, learning rate = 0.009936977893196107 - Loss: 0.9726007580757141, aux loss1: 1.3297759294509888, 
		 aux loss2: 1.0626609325408936, total loss: 1.796597957611084
2th Epoch, 635th Step, learning rate = 0.009936477540442275 - Loss: 1.099808931350708, aux loss1: 1.430944561958313, 
		 aux loss2: 1.2451332807540894, total loss: 2.0271456241607666
2th Epoch, 640th Step, learning rate = 0.00993597718488895 - Loss: 1.146777868270874, aux loss1: 1.5182684659957886, 
		 aux loss2: 1.236359715461731, total loss: 2.096802234649658
2th Epoch, 645th Step, learning rate = 0.009935476826535953 - Loss: 1.0418542623519897, aux loss1: 1.3842864036560059, 
		 aux loss2: 1.1623950004577637, total loss: 1.922098159790039
2th Epoch, 650th Step, learning rate = 0.009934976465383114 - Loss: 0.9580469727516174, aux loss1: 1.3238860368728638, 
		 aux loss2: 1.063927412033081, total loss: 1.780783772468567
2th Epoch, 655th Step, learning rate = 0.00993447610143026 - Loss: 1.317859172821045, aux loss1: 1.6876461505889893, 
		 aux loss2: 1.4397038221359253, total loss: 2.4000346660614014
2th Epoch, 660th Step, learning rate = 0.009933975734677221 - Loss: 1.0380356311798096, aux loss1: 1.4170562028884888, 
		 aux loss2: 1.1192424297332764, total loss: 1.9108495712280273
2th Epoch, 665th Step, learning rate = 0.009933475365123822 - Loss: 0.9265703558921814, aux loss1: 1.2720061540603638, 
		 aux loss2: 1.0161632299423218, total loss: 1.7146375179290771
2th Epoch, 670th Step, learning rate = 0.009932974992769891 - Loss: 1.0441728830337524, aux loss1: 1.3857156038284302, 
		 aux loss2: 1.164031982421875, total loss: 1.9255003929138184
2th Epoch, 675th Step, learning rate = 0.009932474617615258 - Loss: 1.0644557476043701, aux loss1: 1.4459806680679321, 
		 aux loss2: 1.1808161735534668, total loss: 1.970576524734497
2th Epoch, 680th Step, learning rate = 0.009931974239659747 - Loss: 1.082668662071228, aux loss1: 1.5125077962875366, 
		 aux loss2: 1.2366777658462524, total loss: 2.0310921669006348
2th Epoch, 685th Step, learning rate = 0.009931473858903188 - Loss: 0.9469983577728271, aux loss1: 1.3328032493591309, 
		 aux loss2: 1.0755680799484253, total loss: 1.7770665884017944
2th Epoch, 690th Step, learning rate = 0.009930973475345406 - Loss: 1.2885453701019287, aux loss1: 1.6727474927902222, 
		 aux loss2: 1.4230345487594604, total loss: 2.3595833778381348
2th Epoch, 695th Step, learning rate = 0.009930473088986232 - Loss: 1.1502662897109985, aux loss1: 1.5554965734481812, 
		 aux loss2: 1.3099453449249268, total loss: 2.1408934593200684
2th Epoch, 700th Step, learning rate = 0.009929972699825491 - Loss: 0.9413389563560486, aux loss1: 1.3046778440475464, 
		 aux loss2: 1.0099048614501953, total loss: 1.7367043495178223
<700th step>
*************************** Test ***************************
time:3m 10s, 700th Step, Loss: 1.6175533533096313, Mean IoU = 14.470%
************************************************************
2th Epoch, 705th Step, learning rate = 0.009929472307863013 - Loss: 1.3143937587738037, aux loss1: 1.6894029378890991, 
		 aux loss2: 1.3912361860275269, total loss: 2.377709150314331
2th Epoch, 710th Step, learning rate = 0.009928971913098623 - Loss: 0.9853833913803101, aux loss1: 1.310184359550476, 
		 aux loss2: 1.1001687049865723, total loss: 1.8185062408447266
2th Epoch, 715th Step, learning rate = 0.009928471515532148 - Loss: 1.2184370756149292, aux loss1: 1.5502536296844482, 
		 aux loss2: 1.305999994277954, total loss: 2.2059130668640137
2th Epoch, 720th Step, learning rate = 0.009927971115163414 - Loss: 1.0956186056137085, aux loss1: 1.4639021158218384, 
		 aux loss2: 1.2044814825057983, total loss: 2.0165820121765137
2th Epoch, 725th Step, learning rate = 0.009927470711992254 - Loss: 1.1718134880065918, aux loss1: 1.5475013256072998, 
		 aux loss2: 1.3067479133605957, total loss: 2.1587631702423096
2th Epoch, 730th Step, learning rate = 0.009926970306018492 - Loss: 1.1936177015304565, aux loss1: 1.5500236749649048, 
		 aux loss2: 1.3209607601165771, total loss: 2.187009334564209
2th Epoch, 735th Step, learning rate = 0.009926469897241953 - Loss: 1.023472785949707, aux loss1: 1.3524945974349976, 
		 aux loss2: 1.1485673189163208, total loss: 1.8886480331420898
2th Epoch, 740th Step, learning rate = 0.009925969485662468 - Loss: 1.0100955963134766, aux loss1: 1.3576841354370117, 
		 aux loss2: 1.1243422031402588, total loss: 1.8671376705169678
3th Epoch, 745th Step, learning rate = 0.009925469071279863 - Loss: 0.9657669067382812, aux loss1: 1.3393895626068115, 
		 aux loss2: 1.0418461561203003, total loss: 1.7843222618103027
3th Epoch, 750th Step, learning rate = 0.009924968654093966 - Loss: 1.0206197500228882, aux loss1: 1.367119550704956, 
		 aux loss2: 1.1109120845794678, total loss: 1.8751204013824463
3th Epoch, 755th Step, learning rate = 0.009924468234104603 - Loss: 1.0095791816711426, aux loss1: 1.3285925388336182, 
		 aux loss2: 1.1047487258911133, total loss: 1.850056529045105
3th Epoch, 760th Step, learning rate = 0.009923967811311604 - Loss: 1.0506432056427002, aux loss1: 1.4673885107040405, 
		 aux loss2: 1.1421982049942017, total loss: 1.9477390050888062
3th Epoch, 765th Step, learning rate = 0.00992346738571479 - Loss: 0.7635020613670349, aux loss1: 1.1768401861190796, 
		 aux loss2: 0.8498855233192444, total loss: 1.4565083980560303
3th Epoch, 770th Step, learning rate = 0.009922966957313996 - Loss: 0.9809265732765198, aux loss1: 1.3805421590805054, 
		 aux loss2: 1.0941970348358154, total loss: 1.8327680826187134
3th Epoch, 775th Step, learning rate = 0.009922466526109041 - Loss: 1.1575617790222168, aux loss1: 1.4897937774658203, 
		 aux loss2: 1.274429440498352, total loss: 2.114271640777588
3th Epoch, 780th Step, learning rate = 0.00992196609209976 - Loss: 0.9440077543258667, aux loss1: 1.3119523525238037, 
		 aux loss2: 1.0321547985076904, total loss: 1.750455379486084
3th Epoch, 785th Step, learning rate = 0.009921465655285976 - Loss: 1.0594606399536133, aux loss1: 1.3959811925888062, 
		 aux loss2: 1.1628849506378174, total loss: 1.9434089660644531
3th Epoch, 790th Step, learning rate = 0.009920965215667514 - Loss: 0.8428806066513062, aux loss1: 1.2295379638671875, 
		 aux loss2: 0.9684339761734009, total loss: 1.5991156101226807
3th Epoch, 795th Step, learning rate = 0.009920464773244205 - Loss: 1.05007004737854, aux loss1: 1.377193570137024, 
		 aux loss2: 1.1351196765899658, total loss: 1.9172760248184204
3th Epoch, 800th Step, learning rate = 0.009919964328015876 - Loss: 1.0532153844833374, aux loss1: 1.4776899814605713, 
		 aux loss2: 1.1752283573150635, total loss: 1.96661376953125
<800th step>
*************************** Test ***************************
time:3m 14s, 800th Step, Loss: 1.4228250980377197, Mean IoU = 16.517%
************************************************************
3th Epoch, 805th Step, learning rate = 0.009919463879982353 - Loss: 0.9320288300514221, aux loss1: 1.3434827327728271, 
		 aux loss2: 1.0548845529556274, total loss: 1.757027506828308
3th Epoch, 810th Step, learning rate = 0.009918963429143463 - Loss: 0.8679985404014587, aux loss1: 1.3059006929397583, 
		 aux loss2: 0.9851712584495544, total loss: 1.6538372039794922
3th Epoch, 815th Step, learning rate = 0.009918462975499032 - Loss: 0.8091387748718262, aux loss1: 1.228540301322937, 
		 aux loss2: 0.902990460395813, total loss: 1.5388970375061035
3th Epoch, 820th Step, learning rate = 0.009917962519048888 - Loss: 1.069793939590454, aux loss1: 1.4596279859542847, 
		 aux loss2: 1.1758034229278564, total loss: 1.978003740310669
3th Epoch, 825th Step, learning rate = 0.009917462059792858 - Loss: 0.8558816313743591, aux loss1: 1.2298715114593506, 
		 aux loss2: 0.928606390953064, total loss: 1.5962855815887451
3th Epoch, 830th Step, learning rate = 0.009916961597730768 - Loss: 0.8054769039154053, aux loss1: 1.260702133178711, 
		 aux loss2: 0.9181339144706726, total loss: 1.5509411096572876
3th Epoch, 835th Step, learning rate = 0.009916461132862446 - Loss: 0.9403400421142578, aux loss1: 1.3188729286193848, 
		 aux loss2: 1.039825201034546, total loss: 1.75193190574646
3th Epoch, 840th Step, learning rate = 0.00991596066518772 - Loss: 1.0950099229812622, aux loss1: 1.4290701150894165, 
		 aux loss2: 1.1855872869491577, total loss: 1.997965931892395
3th Epoch, 845th Step, learning rate = 0.009915460194706415 - Loss: 0.9824138879776001, aux loss1: 1.3534940481185913, 
		 aux loss2: 1.075366735458374, total loss: 1.8186087608337402
3th Epoch, 850th Step, learning rate = 0.009914959721418357 - Loss: 1.194930911064148, aux loss1: 1.5814616680145264, 
		 aux loss2: 1.3367363214492798, total loss: 2.204063892364502
3th Epoch, 855th Step, learning rate = 0.009914459245323377 - Loss: 1.3030329942703247, aux loss1: 1.7020601034164429, 
		 aux loss2: 1.4043785333633423, total loss: 2.3754024505615234
3th Epoch, 860th Step, learning rate = 0.009913958766421297 - Loss: 0.968278706073761, aux loss1: 1.3214163780212402, 
		 aux loss2: 1.0422217845916748, total loss: 1.7815923690795898
3th Epoch, 865th Step, learning rate = 0.009913458284711945 - Loss: 0.9542065262794495, aux loss1: 1.345874547958374, 
		 aux loss2: 1.0719702243804932, total loss: 1.786756992340088
3th Epoch, 870th Step, learning rate = 0.00991295780019515 - Loss: 0.926517903804779, aux loss1: 1.3012315034866333, 
		 aux loss2: 1.0119686126708984, total loss: 1.7216747999191284
3th Epoch, 875th Step, learning rate = 0.009912457312870738 - Loss: 0.9184165596961975, aux loss1: 1.3075463771820068, 
		 aux loss2: 1.0122270584106445, total loss: 1.715571403503418
3th Epoch, 880th Step, learning rate = 0.009911956822738533 - Loss: 0.8919887542724609, aux loss1: 1.244733214378357, 
		 aux loss2: 0.9894563555717468, total loss: 1.6611913442611694
3th Epoch, 885th Step, learning rate = 0.009911456329798365 - Loss: 0.8311732411384583, aux loss1: 1.2002525329589844, 
		 aux loss2: 0.9486819505691528, total loss: 1.5707218647003174
3th Epoch, 890th Step, learning rate = 0.009910955834050059 - Loss: 1.0564355850219727, aux loss1: 1.4796370267868042, 
		 aux loss2: 1.153573989868164, total loss: 1.9617563486099243
3th Epoch, 895th Step, learning rate = 0.009910455335493444 - Loss: 1.048944115638733, aux loss1: 1.433149814605713, 
		 aux loss2: 1.1479830741882324, total loss: 1.9380823373794556
3th Epoch, 900th Step, learning rate = 0.009909954834128341 - Loss: 0.9927197694778442, aux loss1: 1.4238743782043457, 
		 aux loss2: 1.1768354177474976, total loss: 1.8906161785125732
<900th step>
*************************** Test ***************************
time:3m 13s, 900th Step, Loss: 2.308612823486328, Mean IoU = 11.399%
************************************************************
3th Epoch, 905th Step, learning rate = 0.009909454329954584 - Loss: 1.175434947013855, aux loss1: 1.5994082689285278, 
		 aux loss2: 1.3459935188293457, total loss: 2.193655014038086
3th Epoch, 910th Step, learning rate = 0.009908953822971996 - Loss: 1.0056328773498535, aux loss1: 1.3845086097717285, 
		 aux loss2: 1.099217414855957, total loss: 1.8606724739074707
3th Epoch, 915th Step, learning rate = 0.009908453313180403 - Loss: 1.0510226488113403, aux loss1: 1.4273631572723389, 
		 aux loss2: 1.1544116735458374, total loss: 1.9409962892532349
3th Epoch, 920th Step, learning rate = 0.00990795280057963 - Loss: 0.9559010863304138, aux loss1: 1.34099543094635, 
		 aux loss2: 1.0120645761489868, total loss: 1.7630255222320557
3th Epoch, 925th Step, learning rate = 0.009907452285169508 - Loss: 0.9985486268997192, aux loss1: 1.3807145357131958, 
		 aux loss2: 1.0847184658050537, total loss: 1.8466503620147705
3th Epoch, 930th Step, learning rate = 0.009906951766949862 - Loss: 1.019493818283081, aux loss1: 1.4650096893310547, 
		 aux loss2: 1.1618667840957642, total loss: 1.923743486404419
3th Epoch, 935th Step, learning rate = 0.009906451245920517 - Loss: 0.9724142551422119, aux loss1: 1.4429162740707397, 
		 aux loss2: 1.0730531215667725, total loss: 1.8345104455947876
3th Epoch, 940th Step, learning rate = 0.009905950722081301 - Loss: 1.0227899551391602, aux loss1: 1.4303505420684814, 
		 aux loss2: 1.1437996625900269, total loss: 1.9094150066375732
3th Epoch, 945th Step, learning rate = 0.00990545019543204 - Loss: 0.9932385087013245, aux loss1: 1.3885539770126343, 
		 aux loss2: 1.1301368474960327, total loss: 1.8618594408035278
3th Epoch, 950th Step, learning rate = 0.009904949665972558 - Loss: 0.9126265048980713, aux loss1: 1.3570325374603271, 
		 aux loss2: 1.0279927253723145, total loss: 1.7309333086013794
3th Epoch, 955th Step, learning rate = 0.009904449133702685 - Loss: 1.1265522241592407, aux loss1: 1.5601643323898315, 
		 aux loss2: 1.2442419528961182, total loss: 2.0922982692718506
3th Epoch, 960th Step, learning rate = 0.009903948598622246 - Loss: 1.064153790473938, aux loss1: 1.468666672706604, 
		 aux loss2: 1.130550742149353, total loss: 1.9569741487503052
3th Epoch, 965th Step, learning rate = 0.00990344806073107 - Loss: 0.978283166885376, aux loss1: 1.369818091392517, 
		 aux loss2: 1.0370291471481323, total loss: 1.8040401935577393
3th Epoch, 970th Step, learning rate = 0.009902947520028977 - Loss: 0.90667325258255, aux loss1: 1.3503458499908447, 
		 aux loss2: 1.0072802305221558, total loss: 1.7146891355514526
3th Epoch, 975th Step, learning rate = 0.0099024469765158 - Loss: 0.8495395183563232, aux loss1: 1.2587077617645264, 
		 aux loss2: 0.9342294335365295, total loss: 1.6008436679840088
3th Epoch, 980th Step, learning rate = 0.009901946430191362 - Loss: 0.8872475624084473, aux loss1: 1.3825517892837524, 
		 aux loss2: 1.035407543182373, total loss: 1.716176152229309
3th Epoch, 985th Step, learning rate = 0.009901445881055489 - Loss: 0.9436025023460388, aux loss1: 1.4527846574783325, 
		 aux loss2: 1.0576215982437134, total loss: 1.802486538887024
3th Epoch, 990th Step, learning rate = 0.00990094532910801 - Loss: 0.9969537854194641, aux loss1: 1.3937568664550781, 
		 aux loss2: 1.0948628187179565, total loss: 1.853026032447815
3th Epoch, 995th Step, learning rate = 0.009900444774348746 - Loss: 1.0244308710098267, aux loss1: 1.4478291273117065, 
		 aux loss2: 1.1160008907318115, total loss: 1.9051799774169922
3th Epoch, 1000th Step, learning rate = 0.00989994421677753 - Loss: 0.9808637499809265, aux loss1: 1.4018819332122803, 
		 aux loss2: 1.0805959701538086, total loss: 1.8336668014526367
<1000th step>
*************************** Test ***************************
time:3m 13s, 1000th Step, Loss: 1.6446186304092407, Mean IoU = 15.271%
************************************************************
3th Epoch, 1005th Step, learning rate = 0.009899443656394183 - Loss: 0.9328461289405823, aux loss1: 1.3894473314285278, 
		 aux loss2: 1.0428386926651, total loss: 1.7668157815933228
3th Epoch, 1010th Step, learning rate = 0.009898943093198534 - Loss: 0.9675866365432739, aux loss1: 1.459142804145813, 
		 aux loss2: 1.134191870689392, total loss: 1.8590061664581299
3th Epoch, 1015th Step, learning rate = 0.009898442527190408 - Loss: 1.1394459009170532, aux loss1: 1.6011998653411865, 
		 aux loss2: 1.261610746383667, total loss: 2.124450206756592
3th Epoch, 1020th Step, learning rate = 0.009897941958369632 - Loss: 1.1393414735794067, aux loss1: 1.559321641921997, 
		 aux loss2: 1.2238879203796387, total loss: 2.0966930389404297
3th Epoch, 1025th Step, learning rate = 0.00989744138673603 - Loss: 0.9526779651641846, aux loss1: 1.4125348329544067, 
		 aux loss2: 1.0916163921356201, total loss: 1.8130849599838257
3th Epoch, 1030th Step, learning rate = 0.009896940812289432 - Loss: 0.9790902733802795, aux loss1: 1.3851464986801147, 
		 aux loss2: 1.0973321199417114, total loss: 1.8335671424865723
3th Epoch, 1035th Step, learning rate = 0.009896440235029662 - Loss: 1.064766526222229, aux loss1: 1.5018874406814575, 
		 aux loss2: 1.1716344356536865, total loss: 1.9839866161346436
3th Epoch, 1040th Step, learning rate = 0.009895939654956543 - Loss: 1.1389076709747314, aux loss1: 1.5112446546554565, 
		 aux loss2: 1.2259432077407837, total loss: 2.082658290863037
3th Epoch, 1045th Step, learning rate = 0.009895439072069906 - Loss: 0.903919517993927, aux loss1: 1.2628979682922363, 
		 aux loss2: 1.0018322467803955, total loss: 1.6835218667984009
3th Epoch, 1050th Step, learning rate = 0.009894938486369574 - Loss: 0.9463876485824585, aux loss1: 1.3650208711624146, 
		 aux loss2: 1.0194849967956543, total loss: 1.7636879682540894
3th Epoch, 1055th Step, learning rate = 0.009894437897855376 - Loss: 0.8541391491889954, aux loss1: 1.3130346536636353, 
		 aux loss2: 0.9454877972602844, total loss: 1.6262446641921997
3th Epoch, 1060th Step, learning rate = 0.009893937306527134 - Loss: 0.8058362007141113, aux loss1: 1.2270917892456055, 
		 aux loss2: 0.9142736196517944, total loss: 1.5396732091903687
3th Epoch, 1065th Step, learning rate = 0.009893436712384678 - Loss: 0.8294095396995544, aux loss1: 1.2522449493408203, 
		 aux loss2: 0.9229127168655396, total loss: 1.5742480754852295
3th Epoch, 1070th Step, learning rate = 0.00989293611542783 - Loss: 1.0376559495925903, aux loss1: 1.4982211589813232, 
		 aux loss2: 1.1610603332519531, total loss: 1.9515464305877686
3th Epoch, 1075th Step, learning rate = 0.00989243551565642 - Loss: 0.861230194568634, aux loss1: 1.246476173400879, 
		 aux loss2: 0.9595572352409363, total loss: 1.6189959049224854
3th Epoch, 1080th Step, learning rate = 0.00989193491307027 - Loss: 0.8959575295448303, aux loss1: 1.2799283266067505, 
		 aux loss2: 1.0130609273910522, total loss: 1.6851603984832764
3th Epoch, 1085th Step, learning rate = 0.009891434307669207 - Loss: 0.8771693706512451, aux loss1: 1.284401774406433, 
		 aux loss2: 0.9440115094184875, total loss: 1.640094518661499
3th Epoch, 1090th Step, learning rate = 0.00989093369945306 - Loss: 1.1528836488723755, aux loss1: 1.5563299655914307, 
		 aux loss2: 1.2267029285430908, total loss: 2.110463857650757
3th Epoch, 1095th Step, learning rate = 0.009890433088421653 - Loss: 0.9211663007736206, aux loss1: 1.3074374198913574, 
		 aux loss2: 1.0333188772201538, total loss: 1.7267251014709473
3th Epoch, 1100th Step, learning rate = 0.009889932474574809 - Loss: 1.0001927614212036, aux loss1: 1.4108458757400513, 
		 aux loss2: 1.0908315181732178, total loss: 1.8597791194915771
<1100th step>
*************************** Test ***************************
time:3m 14s, 1100th Step, Loss: 1.3768310546875, Mean IoU = 16.047%
************************************************************
3th Epoch, 1105th Step, learning rate = 0.009889431857912355 - Loss: 0.9151168465614319, aux loss1: 1.273595929145813, 
		 aux loss2: 0.9842238426208496, total loss: 1.6908851861953735
3th Epoch, 1110th Step, learning rate = 0.009888931238434122 - Loss: 1.1143357753753662, aux loss1: 1.5938278436660767, 
		 aux loss2: 1.2395001649856567, total loss: 2.0882842540740967
4th Epoch, 1115th Step, learning rate = 0.00988843061613993 - Loss: 0.7421674728393555, aux loss1: 1.114223599433899, 
		 aux loss2: 0.8311038017272949, total loss: 1.4088761806488037
4th Epoch, 1120th Step, learning rate = 0.009887929991029606 - Loss: 0.8919897079467773, aux loss1: 1.256577491760254, 
		 aux loss2: 0.9955751895904541, total loss: 1.667193055152893
4th Epoch, 1125th Step, learning rate = 0.009887429363102976 - Loss: 0.743268609046936, aux loss1: 1.2087186574935913, 
		 aux loss2: 0.8545882701873779, total loss: 1.4477195739746094
4th Epoch, 1130th Step, learning rate = 0.009886928732359865 - Loss: 1.000339388847351, aux loss1: 1.3596426248550415, 
		 aux loss2: 1.0872286558151245, total loss: 1.8431236743927002
4th Epoch, 1135th Step, learning rate = 0.009886428098800101 - Loss: 1.029569149017334, aux loss1: 1.5091214179992676, 
		 aux loss2: 1.1451401710510254, total loss: 1.9403616189956665
4th Epoch, 1140th Step, learning rate = 0.009885927462423508 - Loss: 1.1130017042160034, aux loss1: 1.4969171285629272, 
		 aux loss2: 1.150334119796753, total loss: 2.0222103595733643
4th Epoch, 1145th Step, learning rate = 0.009885426823229912 - Loss: 1.0396567583084106, aux loss1: 1.4577007293701172, 
		 aux loss2: 1.1347979307174683, total loss: 1.930886149406433
4th Epoch, 1150th Step, learning rate = 0.009884926181219139 - Loss: 0.8374660015106201, aux loss1: 1.2523683309555054, 
		 aux loss2: 0.924108624458313, total loss: 1.582819938659668
4th Epoch, 1155th Step, learning rate = 0.009884425536391014 - Loss: 0.8372648358345032, aux loss1: 1.2968969345092773, 
		 aux loss2: 0.9275128245353699, total loss: 1.597339153289795
4th Epoch, 1160th Step, learning rate = 0.009883924888745364 - Loss: 1.1120473146438599, aux loss1: 1.578436017036438, 
		 aux loss2: 1.2327677011489868, total loss: 2.0786852836608887
4th Epoch, 1165th Step, learning rate = 0.00988342423828201 - Loss: 1.0631663799285889, aux loss1: 1.507606029510498, 
		 aux loss2: 1.176858901977539, total loss: 1.986191749572754
4th Epoch, 1170th Step, learning rate = 0.009882923585000784 - Loss: 0.7956469058990479, aux loss1: 1.2457183599472046, 
		 aux loss2: 0.9084795117378235, total loss: 1.5327541828155518
4th Epoch, 1175th Step, learning rate = 0.009882422928901506 - Loss: 0.9881376028060913, aux loss1: 1.4187990427017212, 
		 aux loss2: 1.1279118061065674, total loss: 1.8649420738220215
4th Epoch, 1180th Step, learning rate = 0.009881922269984007 - Loss: 0.8436911106109619, aux loss1: 1.2721093893051147, 
		 aux loss2: 0.9457857012748718, total loss: 1.6036381721496582
4th Epoch, 1185th Step, learning rate = 0.009881421608248106 - Loss: 1.1857471466064453, aux loss1: 1.555981993675232, 
		 aux loss2: 1.2368180751800537, total loss: 2.1472690105438232
4th Epoch, 1190th Step, learning rate = 0.009880920943693633 - Loss: 0.8005037903785706, aux loss1: 1.2044130563735962, 
		 aux loss2: 0.9057797193527222, total loss: 1.524139642715454
4th Epoch, 1195th Step, learning rate = 0.009880420276320414 - Loss: 0.7992843389511108, aux loss1: 1.2768042087554932, 
		 aux loss2: 0.8963848948478699, total loss: 1.5408796072006226
4th Epoch, 1200th Step, learning rate = 0.009879919606128272 - Loss: 0.8664807677268982, aux loss1: 1.2405946254730225, 
		 aux loss2: 0.9325725436210632, total loss: 1.6116881370544434
<1200th step>
*************************** Test ***************************
time:3m 10s, 1200th Step, Loss: 1.4867935180664062, Mean IoU = 15.394%
************************************************************
4th Epoch, 1205th Step, learning rate = 0.00987941893311703 - Loss: 0.9981254935264587, aux loss1: 1.4012900590896606, 
		 aux loss2: 1.0951951742172241, total loss: 1.8565906286239624
4th Epoch, 1210th Step, learning rate = 0.00987891825728652 - Loss: 1.002905011177063, aux loss1: 1.470670461654663, 
		 aux loss2: 1.1096222400665283, total loss: 1.8879549503326416
4th Epoch, 1215th Step, learning rate = 0.009878417578636564 - Loss: 0.7989727258682251, aux loss1: 1.2521685361862183, 
		 aux loss2: 0.9055467844009399, total loss: 1.5368419885635376
4th Epoch, 1220th Step, learning rate = 0.009877916897166985 - Loss: 0.9452250599861145, aux loss1: 1.3990000486373901, 
		 aux loss2: 1.0253880023956299, total loss: 1.7750803232192993
4th Epoch, 1225th Step, learning rate = 0.009877416212877613 - Loss: 0.8522143363952637, aux loss1: 1.2377394437789917, 
		 aux loss2: 0.9390702247619629, total loss: 1.599164366722107
4th Epoch, 1230th Step, learning rate = 0.00987691552576827 - Loss: 0.8873894214630127, aux loss1: 1.3443450927734375, 
		 aux loss2: 0.9734584093093872, total loss: 1.6800763607025146
4th Epoch, 1235th Step, learning rate = 0.00987641483583878 - Loss: 1.0385442972183228, aux loss1: 1.5465965270996094, 
		 aux loss2: 1.1328860521316528, total loss: 1.9556777477264404
4th Epoch, 1240th Step, learning rate = 0.009875914143088972 - Loss: 0.8178911805152893, aux loss1: 1.238724708557129, 
		 aux loss2: 0.878754198551178, total loss: 1.5410103797912598
4th Epoch, 1245th Step, learning rate = 0.009875413447518671 - Loss: 1.2909860610961914, aux loss1: 1.696071982383728, 
		 aux loss2: 1.387687087059021, total loss: 2.3548824787139893
4th Epoch, 1250th Step, learning rate = 0.0098749127491277 - Loss: 0.8123495578765869, aux loss1: 1.2645424604415894, 
		 aux loss2: 0.903172492980957, total loss: 1.5529813766479492
4th Epoch, 1255th Step, learning rate = 0.009874412047915884 - Loss: 0.7808133363723755, aux loss1: 1.230521321296692, 
		 aux loss2: 0.8794345259666443, total loss: 1.5017436742782593
4th Epoch, 1260th Step, learning rate = 0.00987391134388305 - Loss: 1.0381845235824585, aux loss1: 1.437265157699585, 
		 aux loss2: 1.1416245698928833, total loss: 1.9260139465332031
4th Epoch, 1265th Step, learning rate = 0.009873410637029022 - Loss: 0.84384685754776, aux loss1: 1.256991982460022, 
		 aux loss2: 0.9405887126922607, total loss: 1.597179889678955
4th Epoch, 1270th Step, learning rate = 0.009872909927353625 - Loss: 0.9302365183830261, aux loss1: 1.4887622594833374, 
		 aux loss2: 1.0380859375, total loss: 1.7920994758605957
4th Epoch, 1275th Step, learning rate = 0.009872409214856687 - Loss: 1.1316251754760742, aux loss1: 1.6087056398391724, 
		 aux loss2: 1.255782127380371, total loss: 2.1165497303009033
4th Epoch, 1280th Step, learning rate = 0.009871908499538028 - Loss: 0.7476354837417603, aux loss1: 1.1826872825622559, 
		 aux loss2: 0.8699719905853271, total loss: 1.4504305124282837
4th Epoch, 1285th Step, learning rate = 0.009871407781397477 - Loss: 0.8973312973976135, aux loss1: 1.331666350364685, 
		 aux loss2: 1.0094661712646484, total loss: 1.700617790222168
4th Epoch, 1290th Step, learning rate = 0.009870907060434858 - Loss: 0.7946274876594543, aux loss1: 1.285567045211792, 
		 aux loss2: 0.9235569834709167, total loss: 1.5497204065322876
4th Epoch, 1295th Step, learning rate = 0.009870406336649996 - Loss: 0.8847094178199768, aux loss1: 1.336405634880066, 
		 aux loss2: 1.0060089826583862, total loss: 1.6880347728729248
4th Epoch, 1300th Step, learning rate = 0.009869905610042716 - Loss: 0.8131528496742249, aux loss1: 1.1924957036972046, 
		 aux loss2: 0.9343206286430359, total loss: 1.5446298122406006
<1300th step>
*************************** Test ***************************
time:3m 14s, 1300th Step, Loss: 1.2134172916412354, Mean IoU = 18.673%
************************************************************
4th Epoch, 1305th Step, learning rate = 0.009869404880612843 - Loss: 0.7047137022018433, aux loss1: 1.1850289106369019, 
		 aux loss2: 0.8186201453208923, total loss: 1.3876705169677734
4th Epoch, 1310th Step, learning rate = 0.0098689041483602 - Loss: 0.7172263264656067, aux loss1: 1.2235708236694336, 
		 aux loss2: 0.8084431290626526, total loss: 1.4076749086380005
4th Epoch, 1315th Step, learning rate = 0.009868403413284614 - Loss: 1.1192469596862793, aux loss1: 1.4892210960388184, 
		 aux loss2: 1.2114496231079102, total loss: 2.050593137741089
4th Epoch, 1320th Step, learning rate = 0.009867902675385912 - Loss: 0.9693920016288757, aux loss1: 1.439858078956604, 
		 aux loss2: 1.0703387260437012, total loss: 1.8294849395751953
4th Epoch, 1325th Step, learning rate = 0.009867401934663915 - Loss: 0.9993720054626465, aux loss1: 1.5194698572158813, 
		 aux loss2: 1.1189148426055908, total loss: 1.9027788639068604
4th Epoch, 1330th Step, learning rate = 0.00986690119111845 - Loss: 0.8294065594673157, aux loss1: 1.2353453636169434, 
		 aux loss2: 0.9288026690483093, total loss: 1.5715312957763672
4th Epoch, 1335th Step, learning rate = 0.009866400444749342 - Loss: 0.8924933671951294, aux loss1: 1.3743771314620972, 
		 aux loss2: 0.9844449162483215, total loss: 1.6985844373703003
4th Epoch, 1340th Step, learning rate = 0.009865899695556415 - Loss: 0.9192987084388733, aux loss1: 1.3728735446929932, 
		 aux loss2: 1.0212345123291016, total loss: 1.739654541015625
4th Epoch, 1345th Step, learning rate = 0.009865398943539492 - Loss: 0.9095120429992676, aux loss1: 1.3154568672180176, 
		 aux loss2: 1.004335641860962, total loss: 1.7058833837509155
4th Epoch, 1350th Step, learning rate = 0.009864898188698403 - Loss: 0.8910515308380127, aux loss1: 1.302367091178894, 
		 aux loss2: 0.9629736542701721, total loss: 1.6669511795043945
4th Epoch, 1355th Step, learning rate = 0.009864397431032968 - Loss: 0.6929632425308228, aux loss1: 1.0961177349090576, 
		 aux loss2: 0.7758820652961731, total loss: 1.3321514129638672
4th Epoch, 1360th Step, learning rate = 0.009863896670543014 - Loss: 0.9797160625457764, aux loss1: 1.4832234382629395, 
		 aux loss2: 1.0917539596557617, total loss: 1.861384630203247
4th Epoch, 1365th Step, learning rate = 0.009863395907228364 - Loss: 0.9998952746391296, aux loss1: 1.5046360492706299, 
		 aux loss2: 1.0861166715621948, total loss: 1.8857327699661255
4th Epoch, 1370th Step, learning rate = 0.009862895141088844 - Loss: 0.9196343421936035, aux loss1: 1.3812522888183594, 
		 aux loss2: 1.0311678647994995, total loss: 1.7464771270751953
4th Epoch, 1375th Step, learning rate = 0.009862394372124281 - Loss: 0.9820159077644348, aux loss1: 1.4594699144363403, 
		 aux loss2: 1.0767323970794678, total loss: 1.8505499362945557
4th Epoch, 1380th Step, learning rate = 0.009861893600334496 - Loss: 0.9062791466712952, aux loss1: 1.3099730014801025, 
		 aux loss2: 1.0113272666931152, total loss: 1.7038019895553589
4th Epoch, 1385th Step, learning rate = 0.009861392825719312 - Loss: 0.8416278958320618, aux loss1: 1.2296687364578247, 
		 aux loss2: 0.9397194385528564, total loss: 1.586416244506836
4th Epoch, 1390th Step, learning rate = 0.00986089204827856 - Loss: 0.7499050498008728, aux loss1: 1.1917791366577148, 
		 aux loss2: 0.8430392146110535, total loss: 1.4446544647216797
4th Epoch, 1395th Step, learning rate = 0.00986039126801206 - Loss: 0.7574962377548218, aux loss1: 1.21089768409729, 
		 aux loss2: 0.8557279706001282, total loss: 1.4630568027496338
4th Epoch, 1400th Step, learning rate = 0.009859890484919639 - Loss: 0.9398190975189209, aux loss1: 1.3843766450881958, 
		 aux loss2: 1.0319184064865112, total loss: 1.767899513244629
<1400th step>
*************************** Test ***************************
time:3m 12s, 1400th Step, Loss: 1.7863174676895142, Mean IoU = 13.314%
************************************************************
4th Epoch, 1405th Step, learning rate = 0.009859389699001117 - Loss: 0.9069840908050537, aux loss1: 1.3341054916381836, 
		 aux loss2: 1.000309705734253, total loss: 1.7073395252227783
4th Epoch, 1410th Step, learning rate = 0.009858888910256325 - Loss: 0.7114951610565186, aux loss1: 1.178059697151184, 
		 aux loss2: 0.8332558274269104, total loss: 1.398215413093567
4th Epoch, 1415th Step, learning rate = 0.009858388118685084 - Loss: 0.9075536727905273, aux loss1: 1.3430918455123901, 
		 aux loss2: 1.0130040645599365, total loss: 1.7156829833984375
4th Epoch, 1420th Step, learning rate = 0.009857887324287218 - Loss: 0.8847131729125977, aux loss1: 1.271828055381775, 
		 aux loss2: 0.9700998067855835, total loss: 1.6543015241622925
4th Epoch, 1425th Step, learning rate = 0.009857386527062553 - Loss: 0.6474816203117371, aux loss1: 1.0248943567276, 
		 aux loss2: 0.7475619316101074, total loss: 1.2539747953414917
4th Epoch, 1430th Step, learning rate = 0.009856885727010914 - Loss: 1.1148191690444946, aux loss1: 1.6811134815216064, 
		 aux loss2: 1.2729734182357788, total loss: 2.128342628479004
4th Epoch, 1435th Step, learning rate = 0.009856384924132123 - Loss: 0.7965046167373657, aux loss1: 1.2752320766448975, 
		 aux loss2: 0.8943720459938049, total loss: 1.5368231534957886
4th Epoch, 1440th Step, learning rate = 0.009855884118426006 - Loss: 0.853786826133728, aux loss1: 1.3189561367034912, 
		 aux loss2: 0.9811741709709167, total loss: 1.641943335533142
4th Epoch, 1445th Step, learning rate = 0.009855383309892385 - Loss: 0.7659758925437927, aux loss1: 1.2582117319107056, 
		 aux loss2: 0.8531977534294128, total loss: 1.4847185611724854
4th Epoch, 1450th Step, learning rate = 0.00985488249853109 - Loss: 0.7714934349060059, aux loss1: 1.2176717519760132, 
		 aux loss2: 0.8889020681381226, total loss: 1.4923558235168457
4th Epoch, 1455th Step, learning rate = 0.00985438168434194 - Loss: 1.1519052982330322, aux loss1: 1.5863430500030518, 
		 aux loss2: 1.2224081754684448, total loss: 2.1167714595794678
4th Epoch, 1460th Step, learning rate = 0.009853880867324761 - Loss: 0.8210523128509521, aux loss1: 1.2894539833068848, 
		 aux loss2: 0.9146249890327454, total loss: 1.5737384557724
4th Epoch, 1465th Step, learning rate = 0.00985338004747938 - Loss: 0.8171461820602417, aux loss1: 1.3176343441009521, 
		 aux loss2: 0.9283022284507751, total loss: 1.5837574005126953
4th Epoch, 1470th Step, learning rate = 0.009852879224805617 - Loss: 0.8409915566444397, aux loss1: 1.2968509197235107, 
		 aux loss2: 0.9586535692214966, total loss: 1.6135083436965942
4th Epoch, 1475th Step, learning rate = 0.009852378399303299 - Loss: 1.059051752090454, aux loss1: 1.447524905204773, 
		 aux loss2: 1.151602029800415, total loss: 1.953950047492981
4th Epoch, 1480th Step, learning rate = 0.009851877570972249 - Loss: 1.0220699310302734, aux loss1: 1.4049952030181885, 
		 aux loss2: 1.1117528676986694, total loss: 1.8882696628570557
5th Epoch, 1485th Step, learning rate = 0.009851376739812292 - Loss: 1.0821408033370972, aux loss1: 1.5233794450759888, 
		 aux loss2: 1.1635241508483887, total loss: 2.0045642852783203
5th Epoch, 1490th Step, learning rate = 0.009850875905823252 - Loss: 1.0953350067138672, aux loss1: 1.581167221069336, 
		 aux loss2: 1.1784628629684448, total loss: 2.0410704612731934
5th Epoch, 1495th Step, learning rate = 0.009850375069004953 - Loss: 0.7364555597305298, aux loss1: 1.144676685333252, 
		 aux loss2: 0.8396268486976624, total loss: 1.4157092571258545
5th Epoch, 1500th Step, learning rate = 0.009849874229357219 - Loss: 0.811014711856842, aux loss1: 1.233668565750122, 
		 aux loss2: 0.8783880472183228, total loss: 1.532470464706421
<1500th step>
*************************** Test ***************************
time:3m 11s, 1500th Step, Loss: 1.1756283044815063, Mean IoU = 19.650%
************************************************************
5th Epoch, 1505th Step, learning rate = 0.009849373386879875 - Loss: 0.9741331934928894, aux loss1: 1.4552958011627197, 
		 aux loss2: 1.0733075141906738, total loss: 1.8400449752807617
5th Epoch, 1510th Step, learning rate = 0.009848872541572745 - Loss: 1.0189363956451416, aux loss1: 1.5351850986480713, 
		 aux loss2: 1.1022173166275024, total loss: 1.9203789234161377
5th Epoch, 1515th Step, learning rate = 0.00984837169343565 - Loss: 0.8232736587524414, aux loss1: 1.3052477836608887, 
		 aux loss2: 0.9209441542625427, total loss: 1.5832257270812988
5th Epoch, 1520th Step, learning rate = 0.009847870842468421 - Loss: 1.014593243598938, aux loss1: 1.4794209003448486, 
		 aux loss2: 1.1472474336624146, total loss: 1.91731858253479
5th Epoch, 1525th Step, learning rate = 0.009847369988670874 - Loss: 1.0626535415649414, aux loss1: 1.4697399139404297, 
		 aux loss2: 1.1045230627059937, total loss: 1.9453847408294678
5th Epoch, 1530th Step, learning rate = 0.00984686913204284 - Loss: 0.9824894666671753, aux loss1: 1.5181652307510376, 
		 aux loss2: 1.0744154453277588, total loss: 1.867705225944519
5th Epoch, 1535th Step, learning rate = 0.009846368272584137 - Loss: 0.8018531799316406, aux loss1: 1.2003724575042725, 
		 aux loss2: 0.8899832367897034, total loss: 1.517958164215088
5th Epoch, 1540th Step, learning rate = 0.009845867410294596 - Loss: 0.8977063894271851, aux loss1: 1.3012946844100952, 
		 aux loss2: 0.9709175825119019, total loss: 1.6764618158340454
5th Epoch, 1545th Step, learning rate = 0.009845366545174034 - Loss: 0.838354229927063, aux loss1: 1.3408420085906982, 
		 aux loss2: 0.9390507340431213, total loss: 1.616227149963379
5th Epoch, 1550th Step, learning rate = 0.00984486567722228 - Loss: 0.9219622611999512, aux loss1: 1.3576852083206177, 
		 aux loss2: 1.0247817039489746, total loss: 1.739180564880371
5th Epoch, 1555th Step, learning rate = 0.009844364806439153 - Loss: 0.818713903427124, aux loss1: 1.2646822929382324, 
		 aux loss2: 0.9234068989753723, total loss: 1.567481279373169
5th Epoch, 1560th Step, learning rate = 0.009843863932824482 - Loss: 0.9172256588935852, aux loss1: 1.4062291383743286, 
		 aux loss2: 1.0368075370788574, total loss: 1.7538174390792847
5th Epoch, 1565th Step, learning rate = 0.009843363056378089 - Loss: 0.7749267220497131, aux loss1: 1.2842005491256714, 
		 aux loss2: 0.8952473402023315, total loss: 1.518285870552063
5th Epoch, 1570th Step, learning rate = 0.009842862177099796 - Loss: 0.7438287138938904, aux loss1: 1.1781319379806519, 
		 aux loss2: 0.8229897022247314, total loss: 1.4264642000198364
5th Epoch, 1575th Step, learning rate = 0.00984236129498943 - Loss: 0.7111073136329651, aux loss1: 1.1626635789871216, 
		 aux loss2: 0.820652961730957, total loss: 1.3881676197052002
5th Epoch, 1580th Step, learning rate = 0.009841860410046812 - Loss: 0.8159807324409485, aux loss1: 1.2477117776870728, 
		 aux loss2: 0.9186916351318359, total loss: 1.5577709674835205
5th Epoch, 1585th Step, learning rate = 0.009841359522271768 - Loss: 0.7994897961616516, aux loss1: 1.309936761856079, 
		 aux loss2: 0.9387562274932861, total loss: 1.567973256111145
5th Epoch, 1590th Step, learning rate = 0.00984085863166412 - Loss: 0.7997087836265564, aux loss1: 1.216939091682434, 
		 aux loss2: 0.8951015472412109, total loss: 1.5228312015533447
5th Epoch, 1595th Step, learning rate = 0.009840357738223695 - Loss: 1.407076120376587, aux loss1: 1.8061045408248901, 
		 aux loss2: 1.4406025409698486, total loss: 2.525148391723633
5th Epoch, 1600th Step, learning rate = 0.009839856841950313 - Loss: 0.8066824674606323, aux loss1: 1.2116682529449463, 
		 aux loss2: 0.882732629776001, total loss: 1.5232759714126587
<1600th step>
*************************** Test ***************************
time:3m 8s, 1600th Step, Loss: 1.079434871673584, Mean IoU = 20.963%
************************************************************
5th Epoch, 1605th Step, learning rate = 0.009839355942843799 - Loss: 0.7932559251785278, aux loss1: 1.1836811304092407, 
		 aux loss2: 0.8949166536331177, total loss: 1.5063269138336182
5th Epoch, 1610th Step, learning rate = 0.009838855040903979 - Loss: 0.7853149771690369, aux loss1: 1.2657136917114258, 
		 aux loss2: 0.8819586038589478, total loss: 1.5178124904632568
5th Epoch, 1615th Step, learning rate = 0.009838354136130672 - Loss: 0.6966222524642944, aux loss1: 1.1018362045288086, 
		 aux loss2: 0.7755935192108154, total loss: 1.337410569190979
5th Epoch, 1620th Step, learning rate = 0.009837853228523706 - Loss: 0.7005571126937866, aux loss1: 1.1482621431350708, 
		 aux loss2: 0.8000301122665405, total loss: 1.3650479316711426
5th Epoch, 1625th Step, learning rate = 0.009837352318082901 - Loss: 0.8863955140113831, aux loss1: 1.3034915924072266, 
		 aux loss2: 0.996271550655365, total loss: 1.6759517192840576
5th Epoch, 1630th Step, learning rate = 0.009836851404808085 - Loss: 0.7318269610404968, aux loss1: 1.2617759704589844, 
		 aux loss2: 0.8375397324562073, total loss: 1.445375680923462
5th Epoch, 1635th Step, learning rate = 0.009836350488699078 - Loss: 0.9125348329544067, aux loss1: 1.365490436553955, 
		 aux loss2: 1.006986141204834, total loss: 1.7249764204025269
5th Epoch, 1640th Step, learning rate = 0.009835849569755707 - Loss: 0.7198425531387329, aux loss1: 1.1378315687179565, 
		 aux loss2: 0.7974205017089844, total loss: 1.3801602125167847
5th Epoch, 1645th Step, learning rate = 0.00983534864797779 - Loss: 0.8368174433708191, aux loss1: 1.2647902965545654, 
		 aux loss2: 0.9063580632209778, total loss: 1.5787978172302246
5th Epoch, 1650th Step, learning rate = 0.009834847723365157 - Loss: 0.82647705078125, aux loss1: 1.281359314918518, 
		 aux loss2: 0.9082316160202026, total loss: 1.5741775035858154
5th Epoch, 1655th Step, learning rate = 0.009834346795917628 - Loss: 0.7614689469337463, aux loss1: 1.3233845233917236, 
		 aux loss2: 0.8733230233192444, total loss: 1.507813572883606
5th Epoch, 1660th Step, learning rate = 0.009833845865635025 - Loss: 0.7224903106689453, aux loss1: 1.2168214321136475, 
		 aux loss2: 0.8275815844535828, total loss: 1.4185694456100464
5th Epoch, 1665th Step, learning rate = 0.009833344932517175 - Loss: 0.7520521879196167, aux loss1: 1.2317192554473877, 
		 aux loss2: 0.8467620611190796, total loss: 1.4602727890014648
5th Epoch, 1670th Step, learning rate = 0.0098328439965639 - Loss: 0.7682543396949768, aux loss1: 1.2370350360870361, 
		 aux loss2: 0.8611695170402527, total loss: 1.483832597732544
5th Epoch, 1675th Step, learning rate = 0.009832343057775023 - Loss: 0.777356743812561, aux loss1: 1.258630394935608, 
		 aux loss2: 0.9237873554229736, total loss: 1.524460792541504
5th Epoch, 1680th Step, learning rate = 0.009831842116150367 - Loss: 0.6970018148422241, aux loss1: 1.1422499418258667, 
		 aux loss2: 0.8128748536109924, total loss: 1.3648266792297363
5th Epoch, 1685th Step, learning rate = 0.00983134117168976 - Loss: 0.7927778959274292, aux loss1: 1.3321373462677002, 
		 aux loss2: 0.9219868183135986, total loss: 1.561213731765747
5th Epoch, 1690th Step, learning rate = 0.009830840224393017 - Loss: 0.7126445770263672, aux loss1: 1.1678438186645508, 
		 aux loss2: 0.7970852851867676, total loss: 1.3818318843841553
5th Epoch, 1695th Step, learning rate = 0.009830339274259968 - Loss: 0.9005684852600098, aux loss1: 1.3978469371795654, 
		 aux loss2: 1.032486915588379, total loss: 1.732917308807373
5th Epoch, 1700th Step, learning rate = 0.009829838321290436 - Loss: 0.746887743473053, aux loss1: 1.132124423980713, 
		 aux loss2: 0.8411893844604492, total loss: 1.4230008125305176
<1700th step>
*************************** Test ***************************
time:3m 11s, 1700th Step, Loss: 1.3967312574386597, Mean IoU = 17.164%
************************************************************
5th Epoch, 1705th Step, learning rate = 0.00982933736548424 - Loss: 0.7955549359321594, aux loss1: 1.210263967514038, 
		 aux loss2: 0.8997429013252258, total loss: 1.518531322479248
5th Epoch, 1710th Step, learning rate = 0.009828836406841207 - Loss: 0.8300739526748657, aux loss1: 1.3301116228103638, 
		 aux loss2: 0.9362689852714539, total loss: 1.6036150455474854
5th Epoch, 1715th Step, learning rate = 0.00982833544536116 - Loss: 0.8390399217605591, aux loss1: 1.307470679283142, 
		 aux loss2: 0.9363352656364441, total loss: 1.6058152914047241
5th Epoch, 1720th Step, learning rate = 0.00982783448104392 - Loss: 0.7510688900947571, aux loss1: 1.2450300455093384, 
		 aux loss2: 0.8573542237281799, total loss: 1.4675195217132568
5th Epoch, 1725th Step, learning rate = 0.009827333513889314 - Loss: 0.9375662803649902, aux loss1: 1.4524118900299072, 
		 aux loss2: 1.0630929470062256, total loss: 1.7985270023345947
5th Epoch, 1730th Step, learning rate = 0.00982683254389716 - Loss: 0.5883745551109314, aux loss1: 1.0360422134399414, 
		 aux loss2: 0.7014956474304199, total loss: 1.1797854900360107
5th Epoch, 1735th Step, learning rate = 0.009826331571067288 - Loss: 0.8548738360404968, aux loss1: 1.26921546459198, 
		 aux loss2: 0.950518786907196, total loss: 1.615846037864685
5th Epoch, 1740th Step, learning rate = 0.009825830595399513 - Loss: 0.8647076487541199, aux loss1: 1.342949628829956, 
		 aux loss2: 0.9461150169372559, total loss: 1.64603853225708
5th Epoch, 1745th Step, learning rate = 0.009825329616893665 - Loss: 0.9725455045700073, aux loss1: 1.3717072010040283, 
		 aux loss2: 1.0434571504592896, total loss: 1.8014404773712158
5th Epoch, 1750th Step, learning rate = 0.009824828635549565 - Loss: 0.8916571140289307, aux loss1: 1.3975390195846558, 
		 aux loss2: 0.9790188670158386, total loss: 1.702526330947876
5th Epoch, 1755th Step, learning rate = 0.009824327651367036 - Loss: 0.751356303691864, aux loss1: 1.17279052734375, 
		 aux loss2: 0.8366991281509399, total loss: 1.437873125076294
5th Epoch, 1760th Step, learning rate = 0.0098238266643459 - Loss: 0.715278685092926, aux loss1: 1.1965179443359375, 
		 aux loss2: 0.8028967380523682, total loss: 1.395392656326294
5th Epoch, 1765th Step, learning rate = 0.00982332567448598 - Loss: 0.7214407920837402, aux loss1: 1.177833080291748, 
		 aux loss2: 0.8000131845474243, total loss: 1.3947960138320923
5th Epoch, 1770th Step, learning rate = 0.0098228246817871 - Loss: 0.8803160190582275, aux loss1: 1.2576172351837158, 
		 aux loss2: 0.9351038932800293, total loss: 1.6316428184509277
5th Epoch, 1775th Step, learning rate = 0.009822323686249084 - Loss: 0.8372650742530823, aux loss1: 1.221294641494751, 
		 aux loss2: 0.9569657444953918, total loss: 1.5864397287368774
5th Epoch, 1780th Step, learning rate = 0.009821822687871753 - Loss: 0.8614336252212524, aux loss1: 1.3577814102172852, 
		 aux loss2: 0.985196590423584, total loss: 1.6628466844558716
5th Epoch, 1785th Step, learning rate = 0.009821321686654933 - Loss: 0.6826912760734558, aux loss1: 1.0598714351654053, 
		 aux loss2: 0.7607499957084656, total loss: 1.30495285987854
5th Epoch, 1790th Step, learning rate = 0.009820820682598444 - Loss: 0.6379966139793396, aux loss1: 1.0993776321411133, 
		 aux loss2: 0.7510595917701721, total loss: 1.2682337760925293
5th Epoch, 1795th Step, learning rate = 0.00982031967570211 - Loss: 0.9596848487854004, aux loss1: 1.3213868141174316, 
		 aux loss2: 1.0051597356796265, total loss: 1.758164882659912
5th Epoch, 1800th Step, learning rate = 0.009819818665965752 - Loss: 0.7514271140098572, aux loss1: 1.1727036237716675, 
		 aux loss2: 0.8300871253013611, total loss: 1.4352730512619019
<1800th step>
*************************** Test ***************************
time:3m 11s, 1800th Step, Loss: 0.9670782089233398, Mean IoU = 21.465%
************************************************************
5th Epoch, 1805th Step, learning rate = 0.009819317653389196 - Loss: 1.0108803510665894, aux loss1: 1.355445384979248, 
		 aux loss2: 1.0710293054580688, total loss: 1.8459256887435913
5th Epoch, 1810th Step, learning rate = 0.009818816637972265 - Loss: 0.7776240110397339, aux loss1: 1.2073819637298584, 
		 aux loss2: 0.8712019920349121, total loss: 1.4883193969726562
5th Epoch, 1815th Step, learning rate = 0.009818315619714779 - Loss: 0.8098871111869812, aux loss1: 1.282393217086792, 
		 aux loss2: 0.930903971195221, total loss: 1.5669667720794678
5th Epoch, 1820th Step, learning rate = 0.009817814598616562 - Loss: 0.8679009079933167, aux loss1: 1.320196270942688, 
		 aux loss2: 0.9434401392936707, total loss: 1.6413358449935913
5th Epoch, 1825th Step, learning rate = 0.009817313574677437 - Loss: 0.7576170563697815, aux loss1: 1.2209302186965942, 
		 aux loss2: 0.8750782608985901, total loss: 1.4739274978637695
5th Epoch, 1830th Step, learning rate = 0.009816812547897227 - Loss: 0.7375655770301819, aux loss1: 1.1659637689590454, 
		 aux loss2: 0.8221209049224854, total loss: 1.4162030220031738
5th Epoch, 1835th Step, learning rate = 0.009816311518275755 - Loss: 0.8037526607513428, aux loss1: 1.2576484680175781, 
		 aux loss2: 0.9096260070800781, total loss: 1.5448975563049316
5th Epoch, 1840th Step, learning rate = 0.009815810485812843 - Loss: 0.8072301745414734, aux loss1: 1.2542486190795898, 
		 aux loss2: 0.9239539504051208, total loss: 1.5530864000320435
5th Epoch, 1845th Step, learning rate = 0.009815309450508316 - Loss: 0.7301905751228333, aux loss1: 1.2445123195648193, 
		 aux loss2: 0.8615929484367371, total loss: 1.448181390762329
5th Epoch, 1850th Step, learning rate = 0.009814808412361991 - Loss: 0.8668171763420105, aux loss1: 1.3899022340774536, 
		 aux loss2: 1.0047560930252075, total loss: 1.6856902837753296
5th Epoch, 1855th Step, learning rate = 0.009814307371373697 - Loss: 0.9952149391174316, aux loss1: 1.4426506757736206, 
		 aux loss2: 1.098014235496521, total loss: 1.867215871810913
6th Epoch, 1860th Step, learning rate = 0.009813806327543256 - Loss: 0.8343130946159363, aux loss1: 1.426434874534607, 
		 aux loss2: 0.9514255523681641, total loss: 1.6428136825561523
6th Epoch, 1865th Step, learning rate = 0.009813305280870486 - Loss: 1.0130608081817627, aux loss1: 1.5170012712478638, 
		 aux loss2: 1.1441800594329834, total loss: 1.9258332252502441
6th Epoch, 1870th Step, learning rate = 0.009812804231355214 - Loss: 0.6834967136383057, aux loss1: 1.2077593803405762, 
		 aux loss2: 0.8083201050758362, total loss: 1.369152545928955
6th Epoch, 1875th Step, learning rate = 0.00981230317899726 - Loss: 0.7309197187423706, aux loss1: 1.2163246870040894, 
		 aux loss2: 0.8313956260681152, total loss: 1.4283753633499146
6th Epoch, 1880th Step, learning rate = 0.009811802123796448 - Loss: 0.6755097508430481, aux loss1: 1.2886576652526855, 
		 aux loss2: 0.8015745282173157, total loss: 1.3827369213104248
6th Epoch, 1885th Step, learning rate = 0.009811301065752601 - Loss: 0.7886585593223572, aux loss1: 1.1962507963180542, 
		 aux loss2: 0.8648349046707153, total loss: 1.4934678077697754
6th Epoch, 1890th Step, learning rate = 0.00981080000486554 - Loss: 0.8255808353424072, aux loss1: 1.2751418352127075, 
		 aux loss2: 0.9375180602073669, total loss: 1.5831307172775269
6th Epoch, 1895th Step, learning rate = 0.009810298941135089 - Loss: 0.7551843523979187, aux loss1: 1.2033627033233643, 
		 aux loss2: 0.8495844602584839, total loss: 1.4560270309448242
6th Epoch, 1900th Step, learning rate = 0.00980979787456107 - Loss: 0.7663902044296265, aux loss1: 1.2676771879196167, 
		 aux loss2: 0.8529351949691772, total loss: 1.4878674745559692
<1900th step>
*************************** Test ***************************
time:3m 12s, 1900th Step, Loss: 1.016553521156311, Mean IoU = 22.428%
************************************************************
6th Epoch, 1905th Step, learning rate = 0.009809296805143305 - Loss: 0.7816611528396606, aux loss1: 1.24620521068573, 
		 aux loss2: 0.917445182800293, total loss: 1.52250075340271
6th Epoch, 1910th Step, learning rate = 0.009808795732881615 - Loss: 0.8171461224555969, aux loss1: 1.333114743232727, 
		 aux loss2: 0.9095634818077087, total loss: 1.5809060335159302
6th Epoch, 1915th Step, learning rate = 0.009808294657775826 - Loss: 0.8035780787467957, aux loss1: 1.3354192972183228, 
		 aux loss2: 0.9558718204498291, total loss: 1.586552619934082
6th Epoch, 1920th Step, learning rate = 0.009807793579825757 - Loss: 1.2412697076797485, aux loss1: 1.67155921459198, 
		 aux loss2: 1.3291733264923096, total loss: 2.274406909942627
6th Epoch, 1925th Step, learning rate = 0.009807292499031233 - Loss: 0.8100954294204712, aux loss1: 1.2245674133300781, 
		 aux loss2: 0.8925833702087402, total loss: 1.5344990491867065
6th Epoch, 1930th Step, learning rate = 0.009806791415392075 - Loss: 0.942134439945221, aux loss1: 1.331419825553894, 
		 aux loss2: 1.0291714668273926, total loss: 1.7532289028167725
6th Epoch, 1935th Step, learning rate = 0.009806290328908108 - Loss: 0.9256665706634521, aux loss1: 1.40468430519104, 
		 aux loss2: 1.0516148805618286, total loss: 1.7677178382873535
6th Epoch, 1940th Step, learning rate = 0.009805789239579149 - Loss: 0.977451741695404, aux loss1: 1.4308451414108276, 
		 aux loss2: 1.078241229057312, total loss: 1.8380017280578613
6th Epoch, 1945th Step, learning rate = 0.009805288147405024 - Loss: 0.9300233125686646, aux loss1: 1.4464285373687744, 
		 aux loss2: 1.020748496055603, total loss: 1.7722513675689697
6th Epoch, 1950th Step, learning rate = 0.009804787052385555 - Loss: 0.6261603832244873, aux loss1: 1.076541781425476, 
		 aux loss2: 0.7046958208084106, total loss: 1.2310012578964233
6th Epoch, 1955th Step, learning rate = 0.009804285954520566 - Loss: 0.6396963596343994, aux loss1: 1.170006275177002, 
		 aux loss2: 0.7500436305999756, total loss: 1.2907156944274902
6th Epoch, 1960th Step, learning rate = 0.009803784853809875 - Loss: 0.8118776082992554, aux loss1: 1.2681198120117188, 
		 aux loss2: 0.9045263528823853, total loss: 1.554124116897583
6th Epoch, 1965th Step, learning rate = 0.009803283750253305 - Loss: 0.6029576063156128, aux loss1: 1.0790413618087769, 
		 aux loss2: 0.6945801973342896, total loss: 1.2045021057128906
6th Epoch, 1970th Step, learning rate = 0.009802782643850682 - Loss: 0.851869523525238, aux loss1: 1.3540436029434204, 
		 aux loss2: 0.9324718713760376, total loss: 1.6310713291168213
6th Epoch, 1975th Step, learning rate = 0.009802281534601824 - Loss: 1.278314471244812, aux loss1: 1.7331335544586182, 
		 aux loss2: 1.399327039718628, total loss: 2.357985258102417
6th Epoch, 1980th Step, learning rate = 0.009801780422506557 - Loss: 0.6504313945770264, aux loss1: 1.1259937286376953, 
		 aux loss2: 0.7352438569068909, total loss: 1.2823270559310913
6th Epoch, 1985th Step, learning rate = 0.009801279307564699 - Loss: 0.8156850337982178, aux loss1: 1.253078579902649, 
		 aux loss2: 0.8907884359359741, total loss: 1.5479240417480469
6th Epoch, 1990th Step, learning rate = 0.009800778189776076 - Loss: 0.6959738731384277, aux loss1: 1.1097009181976318, 
		 aux loss2: 0.7878820300102234, total loss: 1.3440370559692383
6th Epoch, 1995th Step, learning rate = 0.009800277069140507 - Loss: 0.8364779949188232, aux loss1: 1.272230625152588, 
		 aux loss2: 0.9560677409172058, total loss: 1.600574254989624
6th Epoch, 2000th Step, learning rate = 0.009799775945657814 - Loss: 0.7805991768836975, aux loss1: 1.2755144834518433, 
		 aux loss2: 0.835713803768158, total loss: 1.4975390434265137
<2000th step>
*************************** Test ***************************
time:3m 17s, 2000th Step, Loss: 1.171222448348999, Mean IoU = 20.410%
************************************************************
6th Epoch, 2005th Step, learning rate = 0.009799274819327823 - Loss: 0.6804099082946777, aux loss1: 1.1222416162490845, 
		 aux loss2: 0.7509293556213379, total loss: 1.317454218864441
6th Epoch, 2010th Step, learning rate = 0.009798773690150354 - Loss: 0.8605623245239258, aux loss1: 1.29581880569458, 
		 aux loss2: 0.9755289554595947, total loss: 1.6395195722579956
6th Epoch, 2015th Step, learning rate = 0.009798272558125225 - Loss: 0.6349378228187561, aux loss1: 1.0249544382095337, 
		 aux loss2: 0.7105138301849365, total loss: 1.2266297340393066
6th Epoch, 2020th Step, learning rate = 0.009797771423252263 - Loss: 0.7877233028411865, aux loss1: 1.273738980293274, 
		 aux loss2: 0.8767368793487549, total loss: 1.5205397605895996
6th Epoch, 2025th Step, learning rate = 0.00979727028553129 - Loss: 0.8160716891288757, aux loss1: 1.2828730344772339, 
		 aux loss2: 0.9190757870674133, total loss: 1.5685639381408691
6th Epoch, 2030th Step, learning rate = 0.009796769144962124 - Loss: 0.757083535194397, aux loss1: 1.2508803606033325, 
		 aux loss2: 0.8463231921195984, total loss: 1.470876932144165
6th Epoch, 2035th Step, learning rate = 0.009796268001544591 - Loss: 0.7696349620819092, aux loss1: 1.2884939908981323, 
		 aux loss2: 0.8721728920936584, total loss: 1.5050524473190308
6th Epoch, 2040th Step, learning rate = 0.00979576685527851 - Loss: 0.7584192156791687, aux loss1: 1.1929848194122314, 
		 aux loss2: 0.8577158451080322, total loss: 1.45940101146698
6th Epoch, 2045th Step, learning rate = 0.009795265706163705 - Loss: 0.6558745503425598, aux loss1: 1.0927631855010986, 
		 aux loss2: 0.7188635468482971, total loss: 1.2712489366531372
6th Epoch, 2050th Step, learning rate = 0.009794764554199996 - Loss: 0.6533495187759399, aux loss1: 1.2675871849060059, 
		 aux loss2: 0.790983259677887, total loss: 1.3500189781188965
6th Epoch, 2055th Step, learning rate = 0.009794263399387207 - Loss: 1.036155343055725, aux loss1: 1.4797271490097046, 
		 aux loss2: 1.1183849573135376, total loss: 1.9274274110794067
6th Epoch, 2060th Step, learning rate = 0.009793762241725158 - Loss: 0.8127881288528442, aux loss1: 1.238105058670044, 
		 aux loss2: 0.9002252221107483, total loss: 1.5443097352981567
6th Epoch, 2065th Step, learning rate = 0.00979326108121367 - Loss: 0.7056388258934021, aux loss1: 1.1512224674224854, 
		 aux loss2: 0.7829484343528748, total loss: 1.3641849756240845
6th Epoch, 2070th Step, learning rate = 0.009792759917852568 - Loss: 0.7938319444656372, aux loss1: 1.2364625930786133, 
		 aux loss2: 0.8841360807418823, total loss: 1.5184252262115479
6th Epoch, 2075th Step, learning rate = 0.00979225875164167 - Loss: 0.6333341598510742, aux loss1: 1.061366319656372, 
		 aux loss2: 0.7159919142723083, total loss: 1.2381408214569092
6th Epoch, 2080th Step, learning rate = 0.009791757582580803 - Loss: 0.7620115876197815, aux loss1: 1.2414613962173462, 
		 aux loss2: 0.8546341061592102, total loss: 1.4763035774230957
6th Epoch, 2085th Step, learning rate = 0.009791256410669783 - Loss: 0.6128122210502625, aux loss1: 1.047957420349121, 
		 aux loss2: 0.683275580406189, total loss: 1.200509786605835
6th Epoch, 2090th Step, learning rate = 0.009790755235908433 - Loss: 0.8496845960617065, aux loss1: 1.2997313737869263, 
		 aux loss2: 0.9841211438179016, total loss: 1.633252501487732
6th Epoch, 2095th Step, learning rate = 0.009790254058296578 - Loss: 0.8596700429916382, aux loss1: 1.3116862773895264, 
		 aux loss2: 0.9558227062225342, total loss: 1.6355050802230835
6th Epoch, 2100th Step, learning rate = 0.009789752877834037 - Loss: 0.7455587387084961, aux loss1: 1.2088466882705688, 
		 aux loss2: 0.8226400017738342, total loss: 1.4372687339782715
<2100th step>
*************************** Test ***************************
time:3m 15s, 2100th Step, Loss: 1.0234768390655518, Mean IoU = 22.175%
************************************************************
6th Epoch, 2105th Step, learning rate = 0.00978925169452063 - Loss: 0.6233019828796387, aux loss1: 1.0147857666015625, 
		 aux loss2: 0.6843059659004211, total loss: 1.2014601230621338
6th Epoch, 2110th Step, learning rate = 0.009788750508356184 - Loss: 0.7333158254623413, aux loss1: 1.1657500267028809, 
		 aux loss2: 0.8265825510025024, total loss: 1.4136738777160645
6th Epoch, 2115th Step, learning rate = 0.009788249319340515 - Loss: 0.9868015050888062, aux loss1: 1.420438289642334, 
		 aux loss2: 1.049316644668579, total loss: 1.8326597213745117
6th Epoch, 2120th Step, learning rate = 0.009787748127473447 - Loss: 0.8544847369194031, aux loss1: 1.304039716720581, 
		 aux loss2: 0.9415789246559143, total loss: 1.622328281402588
6th Epoch, 2125th Step, learning rate = 0.009787246932754802 - Loss: 0.6066049337387085, aux loss1: 1.0092031955718994, 
		 aux loss2: 0.6972029805183411, total loss: 1.1882470846176147
6th Epoch, 2130th Step, learning rate = 0.0097867457351844 - Loss: 0.7546496987342834, aux loss1: 1.2460614442825317, 
		 aux loss2: 0.8672472834587097, total loss: 1.4753670692443848
6th Epoch, 2135th Step, learning rate = 0.009786244534762064 - Loss: 0.9887835383415222, aux loss1: 1.3621151447296143, 
		 aux loss2: 1.092556118965149, total loss: 1.8344405889511108
6th Epoch, 2140th Step, learning rate = 0.009785743331487615 - Loss: 0.6509534120559692, aux loss1: 1.0409470796585083, 
		 aux loss2: 0.7173939347267151, total loss: 1.2501951456069946
6th Epoch, 2145th Step, learning rate = 0.009785242125360872 - Loss: 0.6671450138092041, aux loss1: 1.0755720138549805, 
		 aux loss2: 0.7615610361099243, total loss: 1.2944411039352417
6th Epoch, 2150th Step, learning rate = 0.009784740916381662 - Loss: 0.8307923078536987, aux loss1: 1.295305848121643, 
		 aux loss2: 0.8829143047332764, total loss: 1.572549819946289
6th Epoch, 2155th Step, learning rate = 0.0097842397045498 - Loss: 0.6734840273857117, aux loss1: 1.0667465925216675, 
		 aux loss2: 0.7434831857681274, total loss: 1.2909013032913208
6th Epoch, 2160th Step, learning rate = 0.009783738489865112 - Loss: 0.7773067355155945, aux loss1: 1.3007960319519043, 
		 aux loss2: 0.8968249559402466, total loss: 1.5262755155563354
6th Epoch, 2165th Step, learning rate = 0.00978323727232742 - Loss: 0.7949103116989136, aux loss1: 1.2239140272140503, 
		 aux loss2: 0.8950216174125671, total loss: 1.5200932025909424
6th Epoch, 2170th Step, learning rate = 0.00978273605193654 - Loss: 0.7845283150672913, aux loss1: 1.2471433877944946, 
		 aux loss2: 0.8803262114524841, total loss: 1.510801911354065
6th Epoch, 2175th Step, learning rate = 0.009782234828692298 - Loss: 0.746516764163971, aux loss1: 1.2247835397720337, 
		 aux loss2: 0.8372879028320312, total loss: 1.4488669633865356
6th Epoch, 2180th Step, learning rate = 0.009781733602594513 - Loss: 0.7604146003723145, aux loss1: 1.314164161682129, 
		 aux loss2: 0.873212456703186, total loss: 1.5039488077163696
6th Epoch, 2185th Step, learning rate = 0.00978123237364301 - Loss: 0.6951310038566589, aux loss1: 1.1263433694839478, 
		 aux loss2: 0.8034942150115967, total loss: 1.3544317483901978
6th Epoch, 2190th Step, learning rate = 0.009780731141837605 - Loss: 0.6686645746231079, aux loss1: 1.2290091514587402, 
		 aux loss2: 0.7758745551109314, total loss: 1.3477171659469604
6th Epoch, 2195th Step, learning rate = 0.009780229907178122 - Loss: 0.8387719392776489, aux loss1: 1.4300495386123657, 
		 aux loss2: 0.9974036812782288, total loss: 1.666748285293579
6th Epoch, 2200th Step, learning rate = 0.009779728669664381 - Loss: 0.6369496583938599, aux loss1: 1.074608325958252, 
		 aux loss2: 0.7134583592414856, total loss: 1.2447154521942139
<2200th step>
*************************** Test ***************************
time:3m 16s, 2200th Step, Loss: 1.1773021221160889, Mean IoU = 19.868%
************************************************************
6th Epoch, 2205th Step, learning rate = 0.009779227429296206 - Loss: 0.6949412822723389, aux loss1: 1.1637132167816162, 
		 aux loss2: 0.7894933223724365, total loss: 1.3598525524139404
6th Epoch, 2210th Step, learning rate = 0.009778726186073415 - Loss: 0.6749643683433533, aux loss1: 1.0939894914627075, 
		 aux loss2: 0.7729201316833496, total loss: 1.3123292922973633
6th Epoch, 2215th Step, learning rate = 0.009778224939995831 - Loss: 0.6878728866577148, aux loss1: 1.1005289554595947, 
		 aux loss2: 0.7913711667060852, total loss: 1.3345800638198853
6th Epoch, 2220th Step, learning rate = 0.009777723691063275 - Loss: 0.678737461566925, aux loss1: 1.0632938146591187, 
		 aux loss2: 0.7755309343338013, total loss: 1.3079379796981812
6th Epoch, 2225th Step, learning rate = 0.009777222439275568 - Loss: 0.6696695685386658, aux loss1: 1.0926241874694824, 
		 aux loss2: 0.7452582716941833, total loss: 1.2955601215362549
7th Epoch, 2230th Step, learning rate = 0.009776721184632528 - Loss: 0.8930982351303101, aux loss1: 1.3794243335723877, 
		 aux loss2: 1.0113831758499146, total loss: 1.71147882938385
7th Epoch, 2235th Step, learning rate = 0.009776219927133982 - Loss: 0.7295295596122742, aux loss1: 1.2026903629302979, 
		 aux loss2: 0.8351055979728699, total loss: 1.4243788719177246
7th Epoch, 2240th Step, learning rate = 0.009775718666779747 - Loss: 0.8687174320220947, aux loss1: 1.2154054641723633, 
		 aux loss2: 0.9148008823394775, total loss: 1.599259376525879
7th Epoch, 2245th Step, learning rate = 0.009775217403569644 - Loss: 0.6842803955078125, aux loss1: 1.1027982234954834, 
		 aux loss2: 0.7495473623275757, total loss: 1.3149389028549194
7th Epoch, 2250th Step, learning rate = 0.009774716137503496 - Loss: 0.5998212099075317, aux loss1: 1.044488787651062, 
		 aux loss2: 0.6717364192008972, total loss: 1.1818623542785645
7th Epoch, 2255th Step, learning rate = 0.009774214868581122 - Loss: 0.6422991752624512, aux loss1: 1.097109079360962, 
		 aux loss2: 0.7432880401611328, total loss: 1.268747091293335
7th Epoch, 2260th Step, learning rate = 0.009773713596802345 - Loss: 0.8731998801231384, aux loss1: 1.2714980840682983, 
		 aux loss2: 0.9524319171905518, total loss: 1.6356220245361328
7th Epoch, 2265th Step, learning rate = 0.009773212322166984 - Loss: 0.7384130954742432, aux loss1: 1.1174418926239014, 
		 aux loss2: 0.8181838393211365, total loss: 1.4009191989898682
7th Epoch, 2270th Step, learning rate = 0.009772711044674861 - Loss: 0.7871962785720825, aux loss1: 1.2931315898895264, 
		 aux loss2: 0.8804599046707153, total loss: 1.5273196697235107
7th Epoch, 2275th Step, learning rate = 0.009772209764325798 - Loss: 0.9283338785171509, aux loss1: 1.3630772829055786, 
		 aux loss2: 1.064736008644104, total loss: 1.7631515264511108
7th Epoch, 2280th Step, learning rate = 0.009771708481119613 - Loss: 0.7989702224731445, aux loss1: 1.2499749660491943, 
		 aux loss2: 0.9284440279006958, total loss: 1.5453402996063232
7th Epoch, 2285th Step, learning rate = 0.00977120719505613 - Loss: 0.6528550982475281, aux loss1: 1.1045387983322144, 
		 aux loss2: 0.7472553253173828, total loss: 1.2831188440322876
7th Epoch, 2290th Step, learning rate = 0.009770705906135166 - Loss: 0.7620339393615723, aux loss1: 1.2651525735855103, 
		 aux loss2: 0.8255332112312317, total loss: 1.4717930555343628
7th Epoch, 2295th Step, learning rate = 0.009770204614356546 - Loss: 0.7502122521400452, aux loss1: 1.2271015644073486, 
		 aux loss2: 0.8455092906951904, total loss: 1.4565465450286865
7th Epoch, 2300th Step, learning rate = 0.009769703319720088 - Loss: 0.6315644979476929, aux loss1: 1.0416128635406494, 
		 aux loss2: 0.7229579091072083, total loss: 1.233231544494629
<2300th step>
*************************** Test ***************************
time:3m 17s, 2300th Step, Loss: 1.0321506261825562, Mean IoU = 21.628%
************************************************************
7th Epoch, 2305th Step, learning rate = 0.009769202022225613 - Loss: 0.7157769203186035, aux loss1: 1.151360034942627, 
		 aux loss2: 0.8195838332176208, total loss: 1.3890184164047241
7th Epoch, 2310th Step, learning rate = 0.009768700721872945 - Loss: 1.0312246084213257, aux loss1: 1.5260225534439087, 
		 aux loss2: 1.1402997970581055, total loss: 1.9451513290405273
7th Epoch, 2315th Step, learning rate = 0.0097681994186619 - Loss: 0.6822115778923035, aux loss1: 1.0926313400268555, 
		 aux loss2: 0.7633175849914551, total loss: 1.3153280019760132
7th Epoch, 2320th Step, learning rate = 0.009767698112592302 - Loss: 0.6756300926208496, aux loss1: 1.1493476629257202, 
		 aux loss2: 0.7619410157203674, total loss: 1.3252108097076416
7th Epoch, 2325th Step, learning rate = 0.00976719680366397 - Loss: 1.0111745595932007, aux loss1: 1.4617806673049927, 
		 aux loss2: 1.0970373153686523, total loss: 1.888523817062378
7th Epoch, 2330th Step, learning rate = 0.009766695491876724 - Loss: 0.7451649904251099, aux loss1: 1.1619855165481567, 
		 aux loss2: 0.8270905017852783, total loss: 1.424596905708313
7th Epoch, 2335th Step, learning rate = 0.009766194177230387 - Loss: 0.7498711347579956, aux loss1: 1.198738932609558, 
		 aux loss2: 0.8622267246246338, total loss: 1.4543834924697876
7th Epoch, 2340th Step, learning rate = 0.009765692859724779 - Loss: 0.6390839219093323, aux loss1: 1.0973440408706665, 
		 aux loss2: 0.7278478145599365, total loss: 1.259426236152649
7th Epoch, 2345th Step, learning rate = 0.00976519153935972 - Loss: 0.7097446322441101, aux loss1: 1.1519373655319214, 
		 aux loss2: 0.8109084367752075, total loss: 1.3796892166137695
7th Epoch, 2350th Step, learning rate = 0.00976469021613503 - Loss: 0.6873454451560974, aux loss1: 1.1296610832214355, 
		 aux loss2: 0.7786993384361267, total loss: 1.3377234935760498
7th Epoch, 2355th Step, learning rate = 0.00976418889005053 - Loss: 0.9267818927764893, aux loss1: 1.4610456228256226, 
		 aux loss2: 1.0837458372116089, total loss: 1.7985939979553223
7th Epoch, 2360th Step, learning rate = 0.00976368756110604 - Loss: 0.6784893274307251, aux loss1: 1.1686946153640747, 
		 aux loss2: 0.7757443785667419, total loss: 1.339395523071289
7th Epoch, 2365th Step, learning rate = 0.009763186229301384 - Loss: 0.6497275233268738, aux loss1: 1.0557103157043457, 
		 aux loss2: 0.7565069198608398, total loss: 1.2690434455871582
7th Epoch, 2370th Step, learning rate = 0.009762684894636378 - Loss: 0.6533066034317017, aux loss1: 1.142259955406189, 
		 aux loss2: 0.7919971942901611, total loss: 1.3127834796905518
7th Epoch, 2375th Step, learning rate = 0.009762183557110844 - Loss: 0.7558257579803467, aux loss1: 1.2793819904327393, 
		 aux loss2: 0.8561133742332458, total loss: 1.4820857048034668
7th Epoch, 2380th Step, learning rate = 0.009761682216724602 - Loss: 0.819907546043396, aux loss1: 1.323652744293213, 
		 aux loss2: 0.9309764504432678, total loss: 1.589393973350525
7th Epoch, 2385th Step, learning rate = 0.009761180873477476 - Loss: 0.9013914465904236, aux loss1: 1.4002950191497803, 
		 aux loss2: 1.0049808025360107, total loss: 1.7234723567962646
7th Epoch, 2390th Step, learning rate = 0.00976067952736928 - Loss: 0.855472207069397, aux loss1: 1.3088642358779907, 
		 aux loss2: 0.9457852840423584, total loss: 1.6264456510543823
7th Epoch, 2395th Step, learning rate = 0.00976017817839984 - Loss: 0.6272300481796265, aux loss1: 1.1230087280273438, 
		 aux loss2: 0.7196043729782104, total loss: 1.2519744634628296
7th Epoch, 2400th Step, learning rate = 0.009759676826568975 - Loss: 0.6305558681488037, aux loss1: 1.1321296691894531, 
		 aux loss2: 0.7271472215652466, total loss: 1.2610536813735962
<2400th step>
*************************** Test ***************************
time:3m 14s, 2400th Step, Loss: 0.9923446774482727, Mean IoU = 23.210%
************************************************************
7th Epoch, 2405th Step, learning rate = 0.009759175471876503 - Loss: 0.8232753872871399, aux loss1: 1.2603317499160767, 
		 aux loss2: 0.930986762046814, total loss: 1.5737695693969727
7th Epoch, 2410th Step, learning rate = 0.009758674114322246 - Loss: 0.6981831789016724, aux loss1: 1.1405078172683716, 
		 aux loss2: 0.7626389265060425, total loss: 1.3453911542892456
7th Epoch, 2415th Step, learning rate = 0.009758172753906025 - Loss: 0.8170439004898071, aux loss1: 1.2488306760787964, 
		 aux loss2: 0.9327867031097412, total loss: 1.5648077726364136
7th Epoch, 2420th Step, learning rate = 0.009757671390627661 - Loss: 0.6912988424301147, aux loss1: 1.115606665611267, 
		 aux loss2: 0.7900290489196777, total loss: 1.3419924974441528
7th Epoch, 2425th Step, learning rate = 0.00975717002448697 - Loss: 0.6098493933677673, aux loss1: 1.0261917114257812, 
		 aux loss2: 0.7052019238471985, total loss: 1.1997876167297363
7th Epoch, 2430th Step, learning rate = 0.009756668655483776 - Loss: 0.6971715092658997, aux loss1: 1.1590602397918701, 
		 aux loss2: 0.7766772508621216, total loss: 1.355560541152954
7th Epoch, 2435th Step, learning rate = 0.009756167283617898 - Loss: 0.6680530905723572, aux loss1: 1.1577820777893066, 
		 aux loss2: 0.7726895809173584, total loss: 1.3244636058807373
7th Epoch, 2440th Step, learning rate = 0.009755665908889157 - Loss: 0.583387017250061, aux loss1: 1.0875210762023926, 
		 aux loss2: 0.692931592464447, total loss: 1.1868159770965576
7th Epoch, 2445th Step, learning rate = 0.009755164531297373 - Loss: 0.6465592384338379, aux loss1: 1.0835455656051636, 
		 aux loss2: 0.7377821803092957, total loss: 1.2667357921600342
7th Epoch, 2450th Step, learning rate = 0.009754663150842363 - Loss: 0.9185283780097961, aux loss1: 1.402312159538269, 
		 aux loss2: 1.0346932411193848, total loss: 1.7530994415283203
7th Epoch, 2455th Step, learning rate = 0.009754161767523953 - Loss: 0.652037501335144, aux loss1: 1.0871020555496216, 
		 aux loss2: 0.7699143290519714, total loss: 1.286133885383606
7th Epoch, 2460th Step, learning rate = 0.009753660381341959 - Loss: 0.6430580615997314, aux loss1: 1.1051478385925293, 
		 aux loss2: 0.7162955403327942, total loss: 1.2611206769943237
7th Epoch, 2465th Step, learning rate = 0.009753158992296201 - Loss: 0.7199690937995911, aux loss1: 1.2196917533874512, 
		 aux loss2: 0.8175799250602722, total loss: 1.412908673286438
7th Epoch, 2470th Step, learning rate = 0.009752657600386502 - Loss: 0.723734974861145, aux loss1: 1.168945074081421, 
		 aux loss2: 0.8228988647460938, total loss: 1.4035780429840088
7th Epoch, 2475th Step, learning rate = 0.00975215620561268 - Loss: 0.7340798377990723, aux loss1: 1.2747007608413696, 
		 aux loss2: 0.8926211595535278, total loss: 1.4735386371612549
7th Epoch, 2480th Step, learning rate = 0.009751654807974554 - Loss: 0.9967505931854248, aux loss1: 1.4506419897079468, 
		 aux loss2: 1.0927143096923828, total loss: 1.869028925895691
7th Epoch, 2485th Step, learning rate = 0.009751153407471945 - Loss: 0.8546337485313416, aux loss1: 1.2849419116973877, 
		 aux loss2: 0.9490343332290649, total loss: 1.6197301149368286
7th Epoch, 2490th Step, learning rate = 0.009750652004104675 - Loss: 0.791404664516449, aux loss1: 1.2498127222061157, 
		 aux loss2: 0.88821941614151, total loss: 1.5216362476348877
7th Epoch, 2495th Step, learning rate = 0.00975015059787256 - Loss: 0.7747711539268494, aux loss1: 1.1749863624572754, 
		 aux loss2: 0.8612654805183411, total loss: 1.471773386001587
7th Epoch, 2500th Step, learning rate = 0.009749649188775423 - Loss: 0.8425763249397278, aux loss1: 1.3180618286132812, 
		 aux loss2: 0.9448766708374023, total loss: 1.61594557762146
<2500th step>
*************************** Test ***************************
time:3m 13s, 2500th Step, Loss: 0.8937913775444031, Mean IoU = 25.097%
************************************************************
7th Epoch, 2505th Step, learning rate = 0.009749147776813084 - Loss: 0.679824709892273, aux loss1: 1.2707433700561523, 
		 aux loss2: 0.8088486790657043, total loss: 1.384587287902832
7th Epoch, 2510th Step, learning rate = 0.00974864636198536 - Loss: 0.8321624994277954, aux loss1: 1.261507511138916, 
		 aux loss2: 0.9054813981056213, total loss: 1.5728073120117188
7th Epoch, 2515th Step, learning rate = 0.009748144944292074 - Loss: 0.8300198912620544, aux loss1: 1.3791800737380981, 
		 aux loss2: 0.9551694393157959, total loss: 1.625841736793518
7th Epoch, 2520th Step, learning rate = 0.009747643523733043 - Loss: 0.6744705438613892, aux loss1: 1.1436790227890015, 
		 aux loss2: 0.7885876297950745, total loss: 1.3330093622207642
7th Epoch, 2525th Step, learning rate = 0.009747142100308092 - Loss: 1.0402398109436035, aux loss1: 1.4766610860824585, 
		 aux loss2: 1.10795259475708, total loss: 1.9264192581176758
7th Epoch, 2530th Step, learning rate = 0.009746640674017034 - Loss: 0.6405053734779358, aux loss1: 1.1477305889129639, 
		 aux loss2: 0.7483012676239014, total loss: 1.2841451168060303
7th Epoch, 2535th Step, learning rate = 0.009746139244859692 - Loss: 0.7146826982498169, aux loss1: 1.2670183181762695, 
		 aux loss2: 0.7910990715026855, total loss: 1.411227822303772
7th Epoch, 2540th Step, learning rate = 0.009745637812835887 - Loss: 0.5605247020721436, aux loss1: 0.9730329513549805, 
		 aux loss2: 0.6507800221443176, total loss: 1.1127467155456543
7th Epoch, 2545th Step, learning rate = 0.009745136377945437 - Loss: 0.7503818869590759, aux loss1: 1.1623437404632568, 
		 aux loss2: 0.8783634901046753, total loss: 1.4504305124282837
7th Epoch, 2550th Step, learning rate = 0.009744634940188164 - Loss: 0.5201812386512756, aux loss1: 0.8889454007148743, 
		 aux loss2: 0.5665100812911987, total loss: 1.013468861579895
7th Epoch, 2555th Step, learning rate = 0.009744133499563882 - Loss: 0.6660405397415161, aux loss1: 1.1257925033569336, 
		 aux loss2: 0.7410682439804077, total loss: 1.3002057075500488
7th Epoch, 2560th Step, learning rate = 0.009743632056072416 - Loss: 0.8284304141998291, aux loss1: 1.2507696151733398, 
		 aux loss2: 0.912898063659668, total loss: 1.568820595741272
7th Epoch, 2565th Step, learning rate = 0.009743130609713586 - Loss: 0.855867862701416, aux loss1: 1.3020331859588623, 
		 aux loss2: 0.9480613470077515, total loss: 1.6257023811340332
7th Epoch, 2570th Step, learning rate = 0.009742629160487208 - Loss: 0.7115106582641602, aux loss1: 1.1224005222320557, 
		 aux loss2: 0.7990606427192688, total loss: 1.367855191230774
7th Epoch, 2575th Step, learning rate = 0.009742127708393104 - Loss: 0.8899602890014648, aux loss1: 1.2303581237792969, 
		 aux loss2: 0.9506047964096069, total loss: 1.6393096446990967
7th Epoch, 2580th Step, learning rate = 0.009741626253431095 - Loss: 0.7382846474647522, aux loss1: 1.2488799095153809, 
		 aux loss2: 0.8680373430252075, total loss: 1.4601635932922363
7th Epoch, 2585th Step, learning rate = 0.009741124795600997 - Loss: 0.678622305393219, aux loss1: 1.1449898481369019, 
		 aux loss2: 0.7767245769500732, total loss: 1.3328090906143188
7th Epoch, 2590th Step, learning rate = 0.00974062333490263 - Loss: 0.7569093704223633, aux loss1: 1.168921709060669, 
		 aux loss2: 0.84695965051651, total loss: 1.4463697671890259
7th Epoch, 2595th Step, learning rate = 0.009740121871335817 - Loss: 0.9955209493637085, aux loss1: 1.4240350723266602, 
		 aux loss2: 1.0989187955856323, total loss: 1.8622990846633911
8th Epoch, 2600th Step, learning rate = 0.009739620404900375 - Loss: 0.7008847594261169, aux loss1: 1.1685212850570679, 
		 aux loss2: 0.8047868013381958, total loss: 1.3733558654785156
<2600th step>
*************************** Test ***************************
time:3m 15s, 2600th Step, Loss: 0.8678654432296753, Mean IoU = 26.213%
************************************************************
8th Epoch, 2605th Step, learning rate = 0.009739118935596121 - Loss: 0.7252618074417114, aux loss1: 1.1273515224456787, 
		 aux loss2: 0.7990637421607971, total loss: 1.3830927610397339
8th Epoch, 2610th Step, learning rate = 0.009738617463422878 - Loss: 0.7807117104530334, aux loss1: 1.197651982307434, 
		 aux loss2: 0.8795359134674072, total loss: 1.4918216466903687
8th Epoch, 2615th Step, learning rate = 0.009738115988380466 - Loss: 0.5339711308479309, aux loss1: 0.9499911069869995, 
		 aux loss2: 0.6068589687347412, total loss: 1.0617120265960693
8th Epoch, 2620th Step, learning rate = 0.009737614510468702 - Loss: 0.6792311072349548, aux loss1: 1.2111483812332153, 
		 aux loss2: 0.757435142993927, total loss: 1.3455497026443481
8th Epoch, 2625th Step, learning rate = 0.009737113029687407 - Loss: 0.8288060426712036, aux loss1: 1.2995966672897339, 
		 aux loss2: 0.9060447812080383, total loss: 1.581102967262268
8th Epoch, 2630th Step, learning rate = 0.009736611546036401 - Loss: 0.655789315700531, aux loss1: 1.086626648902893, 
		 aux loss2: 0.7404165267944336, total loss: 1.2779439687728882
8th Epoch, 2635th Step, learning rate = 0.009736110059515501 - Loss: 0.5705878138542175, aux loss1: 0.9552479386329651, 
		 aux loss2: 0.6574357748031616, total loss: 1.1201364994049072
8th Epoch, 2640th Step, learning rate = 0.009735608570124527 - Loss: 0.6056700944900513, aux loss1: 1.004776120185852, 
		 aux loss2: 0.6847189664840698, total loss: 1.1809905767440796
8th Epoch, 2645th Step, learning rate = 0.009735107077863297 - Loss: 0.6072376370429993, aux loss1: 1.0406683683395386, 
		 aux loss2: 0.7135055065155029, total loss: 1.2048403024673462
8th Epoch, 2650th Step, learning rate = 0.009734605582731634 - Loss: 0.6226177215576172, aux loss1: 1.028709888458252, 
		 aux loss2: 0.7039722204208374, total loss: 1.2128195762634277
8th Epoch, 2655th Step, learning rate = 0.009734104084729356 - Loss: 0.5824352502822876, aux loss1: 1.0176886320114136, 
		 aux loss2: 0.6640356183052063, total loss: 1.1533560752868652
8th Epoch, 2660th Step, learning rate = 0.00973360258385628 - Loss: 0.7776278853416443, aux loss1: 1.249052882194519, 
		 aux loss2: 0.8995293974876404, total loss: 1.512155532836914
8th Epoch, 2665th Step, learning rate = 0.009733101080112229 - Loss: 0.5257701873779297, aux loss1: 0.9633108973503113, 
		 aux loss2: 0.6006733179092407, total loss: 1.055032730102539
8th Epoch, 2670th Step, learning rate = 0.009732599573497017 - Loss: 0.8374226093292236, aux loss1: 1.3767338991165161, 
		 aux loss2: 0.9541705250740051, total loss: 1.6321109533309937
8th Epoch, 2675th Step, learning rate = 0.009732098064010467 - Loss: 0.5390943288803101, aux loss1: 1.0520401000976562, 
		 aux loss2: 0.629135012626648, total loss: 1.1063604354858398
8th Epoch, 2680th Step, learning rate = 0.009731596551652398 - Loss: 0.6197007894515991, aux loss1: 1.0443317890167236, 
		 aux loss2: 0.7147476077079773, total loss: 1.2188993692398071
8th Epoch, 2685th Step, learning rate = 0.009731095036422627 - Loss: 0.8850353360176086, aux loss1: 1.3315520286560059, 
		 aux loss2: 0.9958555102348328, total loss: 1.6828432083129883
8th Epoch, 2690th Step, learning rate = 0.009730593518320977 - Loss: 0.7504728436470032, aux loss1: 1.1670202016830444, 
		 aux loss2: 0.8302051424980164, total loss: 1.4326609373092651
8th Epoch, 2695th Step, learning rate = 0.009730091997347262 - Loss: 0.6037201285362244, aux loss1: 1.0870553255081177, 
		 aux loss2: 0.6912553906440735, total loss: 1.206338882446289
8th Epoch, 2700th Step, learning rate = 0.009729590473501306 - Loss: 0.6186719536781311, aux loss1: 1.056549310684204, 
		 aux loss2: 0.6895257830619812, total loss: 1.2114471197128296
<2700th step>
*************************** Test ***************************
time:3m 15s, 2700th Step, Loss: 0.9798470735549927, Mean IoU = 23.373%
************************************************************
8th Epoch, 2705th Step, learning rate = 0.009729088946782923 - Loss: 0.5873963236808777, aux loss1: 0.9524189233779907, 
		 aux loss2: 0.6185595393180847, total loss: 1.120545744895935
8th Epoch, 2710th Step, learning rate = 0.009728587417191936 - Loss: 0.6844863295555115, aux loss1: 1.1906213760375977, 
		 aux loss2: 0.7808830738067627, total loss: 1.354025959968567
8th Epoch, 2715th Step, learning rate = 0.009728085884728163 - Loss: 0.7752381563186646, aux loss1: 1.2227240800857544, 
		 aux loss2: 0.850386381149292, total loss: 1.4822099208831787
8th Epoch, 2720th Step, learning rate = 0.009727584349391423 - Loss: 0.6063485145568848, aux loss1: 1.0383820533752441, 
		 aux loss2: 0.685927152633667, total loss: 1.1922340393066406
8th Epoch, 2725th Step, learning rate = 0.009727082811181535 - Loss: 0.8267005085945129, aux loss1: 1.3911676406860352, 
		 aux loss2: 0.8984249234199524, total loss: 1.6034208536148071
8th Epoch, 2730th Step, learning rate = 0.009726581270098317 - Loss: 0.8993963003158569, aux loss1: 1.4385759830474854, 
		 aux loss2: 0.9924500584602356, total loss: 1.7279491424560547
8th Epoch, 2735th Step, learning rate = 0.009726079726141588 - Loss: 0.6751957535743713, aux loss1: 1.2153024673461914, 
		 aux loss2: 0.7746422290802002, total loss: 1.3496434688568115
8th Epoch, 2740th Step, learning rate = 0.009725578179311167 - Loss: 0.5693811178207397, aux loss1: 1.0146600008010864, 
		 aux loss2: 0.6577408313751221, total loss: 1.1368753910064697
8th Epoch, 2745th Step, learning rate = 0.009725076629606874 - Loss: 0.6001786589622498, aux loss1: 1.0822876691818237, 
		 aux loss2: 0.6872615814208984, total loss: 1.1997696161270142
8th Epoch, 2750th Step, learning rate = 0.009724575077028529 - Loss: 0.5947121977806091, aux loss1: 1.0888792276382446, 
		 aux loss2: 0.6732738614082336, total loss: 1.190685510635376
8th Epoch, 2755th Step, learning rate = 0.009724073521575945 - Loss: 0.743191123008728, aux loss1: 1.2469249963760376, 
		 aux loss2: 0.8735932111740112, total loss: 1.4667057991027832
8th Epoch, 2760th Step, learning rate = 0.009723571963248948 - Loss: 0.7731847763061523, aux loss1: 1.2313069105148315, 
		 aux loss2: 0.9117690324783325, total loss: 1.5072845220565796
8th Epoch, 2765th Step, learning rate = 0.009723070402047352 - Loss: 0.6221107244491577, aux loss1: 1.0630466938018799, 
		 aux loss2: 0.7097492218017578, total loss: 1.2249244451522827
8th Epoch, 2770th Step, learning rate = 0.009722568837970978 - Loss: 0.927604615688324, aux loss1: 1.3751320838928223, 
		 aux loss2: 0.9889289736747742, total loss: 1.7357158660888672
8th Epoch, 2775th Step, learning rate = 0.009722067271019643 - Loss: 0.6299372315406799, aux loss1: 1.0907443761825562, 
		 aux loss2: 0.7022396922111511, total loss: 1.2380564212799072
8th Epoch, 2780th Step, learning rate = 0.00972156570119317 - Loss: 0.5944564938545227, aux loss1: 1.0554375648498535, 
		 aux loss2: 0.6836045980453491, total loss: 1.1845295429229736
8th Epoch, 2785th Step, learning rate = 0.00972106412849137 - Loss: 0.7020810842514038, aux loss1: 1.1977424621582031, 
		 aux loss2: 0.7858862280845642, total loss: 1.375758409500122
8th Epoch, 2790th Step, learning rate = 0.009720562552914069 - Loss: 0.7105328440666199, aux loss1: 1.1327179670333862, 
		 aux loss2: 0.7739124894142151, total loss: 1.3599133491516113
8th Epoch, 2795th Step, learning rate = 0.009720060974461082 - Loss: 0.7362856268882751, aux loss1: 1.1939201354980469, 
		 aux loss2: 0.8316258788108826, total loss: 1.427112102508545
8th Epoch, 2800th Step, learning rate = 0.009719559393132227 - Loss: 0.6704077124595642, aux loss1: 1.20012366771698, 
		 aux loss2: 0.7658518552780151, total loss: 1.3367855548858643
<2800th step>
*************************** Test ***************************
time:3m 10s, 2800th Step, Loss: 1.0952268838882446, Mean IoU = 20.615%
************************************************************
8th Epoch, 2805th Step, learning rate = 0.009719057808927326 - Loss: 0.8232364654541016, aux loss1: 1.3920711278915405, 
		 aux loss2: 0.950201690196991, total loss: 1.6209385395050049
8th Epoch, 2810th Step, learning rate = 0.009718556221846194 - Loss: 0.6475228667259216, aux loss1: 1.0871399641036987, 
		 aux loss2: 0.7234776616096497, total loss: 1.2630559206008911
8th Epoch, 2815th Step, learning rate = 0.009718054631888653 - Loss: 0.6885010004043579, aux loss1: 1.1726001501083374, 
		 aux loss2: 0.7785781621932983, total loss: 1.3517123460769653
8th Epoch, 2820th Step, learning rate = 0.009717553039054519 - Loss: 0.6233821511268616, aux loss1: 1.0510351657867432, 
		 aux loss2: 0.693841814994812, total loss: 1.2162294387817383
8th Epoch, 2825th Step, learning rate = 0.009717051443343611 - Loss: 0.6492975354194641, aux loss1: 1.142231822013855, 
		 aux loss2: 0.7293418645858765, total loss: 1.2837038040161133
8th Epoch, 2830th Step, learning rate = 0.00971654984475575 - Loss: 0.7176932096481323, aux loss1: 1.1942689418792725, 
		 aux loss2: 0.8287105560302734, total loss: 1.4074580669403076
8th Epoch, 2835th Step, learning rate = 0.009716048243290748 - Loss: 0.7358866333961487, aux loss1: 1.2671144008636475, 
		 aux loss2: 0.8406631350517273, total loss: 1.4522862434387207
8th Epoch, 2840th Step, learning rate = 0.00971554663894843 - Loss: 0.9013364315032959, aux loss1: 1.3086117506027222, 
		 aux loss2: 0.9854008555412292, total loss: 1.6880804300308228
8th Epoch, 2845th Step, learning rate = 0.009715045031728611 - Loss: 0.772636890411377, aux loss1: 1.243117094039917, 
		 aux loss2: 0.8760650157928467, total loss: 1.4959981441497803
8th Epoch, 2850th Step, learning rate = 0.009714543421631113 - Loss: 0.9465743899345398, aux loss1: 1.3883423805236816, 
		 aux loss2: 1.0759780406951904, total loss: 1.7934683561325073
8th Epoch, 2855th Step, learning rate = 0.00971404180865575 - Loss: 0.6729192733764648, aux loss1: 1.1429356336593628, 
		 aux loss2: 0.7750914692878723, total loss: 1.3258366584777832
8th Epoch, 2860th Step, learning rate = 0.009713540192802341 - Loss: 1.1318856477737427, aux loss1: 1.5938494205474854, 
		 aux loss2: 1.257193922996521, total loss: 2.112917900085449
8th Epoch, 2865th Step, learning rate = 0.009713038574070708 - Loss: 0.8314787149429321, aux loss1: 1.2813525199890137, 
		 aux loss2: 0.9312300086021423, total loss: 1.588376522064209
8th Epoch, 2870th Step, learning rate = 0.009712536952460667 - Loss: 0.7521470189094543, aux loss1: 1.2470793724060059, 
		 aux loss2: 0.853650689125061, total loss: 1.46773099899292
8th Epoch, 2875th Step, learning rate = 0.009712035327972034 - Loss: 0.6273933053016663, aux loss1: 1.1676783561706543, 
		 aux loss2: 0.7357826232910156, total loss: 1.2720098495483398
8th Epoch, 2880th Step, learning rate = 0.009711533700604631 - Loss: 0.6461626887321472, aux loss1: 1.180983543395996, 
		 aux loss2: 0.7378749847412109, total loss: 1.2956078052520752
8th Epoch, 2885th Step, learning rate = 0.009711032070358276 - Loss: 0.5604081749916077, aux loss1: 1.0840277671813965, 
		 aux loss2: 0.6422519683837891, total loss: 1.142517328262329
8th Epoch, 2890th Step, learning rate = 0.009710530437232785 - Loss: 0.7943462133407593, aux loss1: 1.2231841087341309, 
		 aux loss2: 0.8811272382736206, total loss: 1.5137524604797363
8th Epoch, 2895th Step, learning rate = 0.009710028801227975 - Loss: 1.1130136251449585, aux loss1: 1.5297871828079224, 
		 aux loss2: 1.2003459930419922, total loss: 2.0520882606506348
8th Epoch, 2900th Step, learning rate = 0.009709527162343669 - Loss: 0.7902892827987671, aux loss1: 1.206808090209961, 
		 aux loss2: 0.896665096282959, total loss: 1.5109977722167969
<2900th step>
*************************** Test ***************************
time:3m 13s, 2900th Step, Loss: 1.1259700059890747, Mean IoU = 23.111%
************************************************************
8th Epoch, 2905th Step, learning rate = 0.009709025520579683 - Loss: 0.7435919046401978, aux loss1: 1.235559105873108, 
		 aux loss2: 0.867313027381897, total loss: 1.4611849784851074
8th Epoch, 2910th Step, learning rate = 0.009708523875935833 - Loss: 0.8068833351135254, aux loss1: 1.3931818008422852, 
		 aux loss2: 0.9381201267242432, total loss: 1.600085973739624
8th Epoch, 2915th Step, learning rate = 0.009708022228411939 - Loss: 0.7688699960708618, aux loss1: 1.2370234727859497, 
		 aux loss2: 0.8906866312026978, total loss: 1.4962515830993652
8th Epoch, 2920th Step, learning rate = 0.00970752057800782 - Loss: 0.8271229863166809, aux loss1: 1.2340508699417114, 
		 aux loss2: 0.8815927505493164, total loss: 1.5499753952026367
8th Epoch, 2925th Step, learning rate = 0.009707018924723294 - Loss: 0.7191516757011414, aux loss1: 1.1485165357589722, 
		 aux loss2: 0.8190452456474304, total loss: 1.391324758529663
8th Epoch, 2930th Step, learning rate = 0.009706517268558175 - Loss: 0.7784077525138855, aux loss1: 1.3269767761230469, 
		 aux loss2: 0.8870670199394226, total loss: 1.5313276052474976
8th Epoch, 2935th Step, learning rate = 0.009706015609512286 - Loss: 0.6775520443916321, aux loss1: 1.1491378545761108, 
		 aux loss2: 0.7564191818237305, total loss: 1.3248611688613892
8th Epoch, 2940th Step, learning rate = 0.009705513947585445 - Loss: 0.7759122252464294, aux loss1: 1.1938124895095825, 
		 aux loss2: 0.8740398287773132, total loss: 1.4836719036102295
8th Epoch, 2945th Step, learning rate = 0.009705012282777465 - Loss: 0.7773826122283936, aux loss1: 1.226046085357666, 
		 aux loss2: 0.8704838156700134, total loss: 1.4933899641036987
8th Epoch, 2950th Step, learning rate = 0.00970451061508817 - Loss: 0.5795847773551941, aux loss1: 0.981531023979187, 
		 aux loss2: 0.6583321690559387, total loss: 1.1373769044876099
8th Epoch, 2955th Step, learning rate = 0.009704008944517372 - Loss: 0.9975600838661194, aux loss1: 1.4660232067108154, 
		 aux loss2: 1.0762004852294922, total loss: 1.8678473234176636
8th Epoch, 2960th Step, learning rate = 0.009703507271064895 - Loss: 0.5435605049133301, aux loss1: 0.9887745380401611, 
		 aux loss2: 0.6133427023887634, total loss: 1.0855300426483154
8th Epoch, 2965th Step, learning rate = 0.009703005594730552 - Loss: 0.930966317653656, aux loss1: 1.393564224243164, 
		 aux loss2: 1.016802430152893, total loss: 1.7557566165924072
9th Epoch, 2970th Step, learning rate = 0.009702503915514164 - Loss: 0.5855599641799927, aux loss1: 1.0762264728546143, 
		 aux loss2: 0.6563578248023987, total loss: 1.170971155166626
9th Epoch, 2975th Step, learning rate = 0.009702002233415547 - Loss: 0.638466477394104, aux loss1: 1.1104974746704102, 
		 aux loss2: 0.6967601180076599, total loss: 1.2503197193145752
9th Epoch, 2980th Step, learning rate = 0.00970150054843452 - Loss: 0.6524401307106018, aux loss1: 1.1013418436050415, 
		 aux loss2: 0.7535873651504517, total loss: 1.2842776775360107
9th Epoch, 2985th Step, learning rate = 0.0097009988605709 - Loss: 0.6282699704170227, aux loss1: 1.1414190530776978, 
		 aux loss2: 0.73375403881073, total loss: 1.2641973495483398
9th Epoch, 2990th Step, learning rate = 0.009700497169824504 - Loss: 0.5742553472518921, aux loss1: 1.0598152875900269, 
		 aux loss2: 0.6873698234558105, total loss: 1.1671478748321533
9th Epoch, 2995th Step, learning rate = 0.009699995476195154 - Loss: 0.5550187230110168, aux loss1: 0.9578459858894348, 
		 aux loss2: 0.646684467792511, total loss: 1.1010463237762451
9th Epoch, 3000th Step, learning rate = 0.009699493779682662 - Loss: 0.5649949908256531, aux loss1: 1.0292086601257324, 
		 aux loss2: 0.6263757348060608, total loss: 1.1243078708648682
<3000th step>
*************************** Test ***************************
time:3m 11s, 3000th Step, Loss: 0.7813149690628052, Mean IoU = 26.528%
************************************************************
9th Epoch, 3005th Step, learning rate = 0.009698992080286848 - Loss: 0.7765844464302063, aux loss1: 1.2466126680374146, 
		 aux loss2: 0.8739503622055054, total loss: 1.5001484155654907
9th Epoch, 3010th Step, learning rate = 0.009698490378007532 - Loss: 0.6326943039894104, aux loss1: 1.0914970636367798, 
		 aux loss2: 0.6983874440193176, total loss: 1.2394983768463135
9th Epoch, 3015th Step, learning rate = 0.00969798867284453 - Loss: 0.8896153569221497, aux loss1: 1.3454225063323975, 
		 aux loss2: 1.0341740846633911, total loss: 1.7069118022918701
9th Epoch, 3020th Step, learning rate = 0.009697486964797658 - Loss: 0.7912774085998535, aux loss1: 1.2717500925064087, 
		 aux loss2: 0.8893592953681946, total loss: 1.5285462141036987
9th Epoch, 3025th Step, learning rate = 0.009696985253866737 - Loss: 0.710834264755249, aux loss1: 1.1542330980300903, 
		 aux loss2: 0.7909632325172424, total loss: 1.373489499092102
9th Epoch, 3030th Step, learning rate = 0.009696483540051582 - Loss: 0.5472827553749084, aux loss1: 1.089356541633606, 
		 aux loss2: 0.6379073262214661, total loss: 1.1292526721954346
9th Epoch, 3035th Step, learning rate = 0.009695981823352011 - Loss: 0.5787453055381775, aux loss1: 1.0585250854492188, 
		 aux loss2: 0.680986762046814, total loss: 1.1686975955963135
9th Epoch, 3040th Step, learning rate = 0.009695480103767841 - Loss: 0.6971976161003113, aux loss1: 1.150400161743164, 
		 aux loss2: 0.761650800704956, total loss: 1.346977949142456
9th Epoch, 3045th Step, learning rate = 0.009694978381298892 - Loss: 0.5661280751228333, aux loss1: 1.1305509805679321, 
		 aux loss2: 0.6599558591842651, total loss: 1.1692757606506348
9th Epoch, 3050th Step, learning rate = 0.00969447665594498 - Loss: 0.7565636038780212, aux loss1: 1.2516653537750244, 
		 aux loss2: 0.8530983328819275, total loss: 1.4733026027679443
9th Epoch, 3055th Step, learning rate = 0.00969397492770592 - Loss: 0.6679392457008362, aux loss1: 1.0818707942962646, 
		 aux loss2: 0.7519208192825317, total loss: 1.2932687997817993
9th Epoch, 3060th Step, learning rate = 0.009693473196581535 - Loss: 0.5373733043670654, aux loss1: 0.9497720003128052, 
		 aux loss2: 0.5949342250823975, total loss: 1.0602786540985107
9th Epoch, 3065th Step, learning rate = 0.009692971462571639 - Loss: 1.0204764604568481, aux loss1: 1.4871236085891724, 
		 aux loss2: 1.112102746963501, total loss: 1.911454677581787
9th Epoch, 3070th Step, learning rate = 0.00969246972567605 - Loss: 0.49369508028030396, aux loss1: 1.0275366306304932, 
		 aux loss2: 0.583406925201416, total loss: 1.0353188514709473
9th Epoch, 3075th Step, learning rate = 0.009691967985894582 - Loss: 0.6595407724380493, aux loss1: 1.0923128128051758, 
		 aux loss2: 0.7264190912246704, total loss: 1.2778022289276123
9th Epoch, 3080th Step, learning rate = 0.00969146624322706 - Loss: 0.7446702122688293, aux loss1: 1.2775925397872925, 
		 aux loss2: 0.8502930998802185, total loss: 1.4680652618408203
9th Epoch, 3085th Step, learning rate = 0.009690964497673296 - Loss: 0.741381824016571, aux loss1: 1.2105456590652466, 
		 aux loss2: 0.83302241563797, total loss: 1.4377546310424805
9th Epoch, 3090th Step, learning rate = 0.009690462749233108 - Loss: 0.7166486382484436, aux loss1: 1.1679035425186157, 
		 aux loss2: 0.795569658279419, total loss: 1.3852475881576538
9th Epoch, 3095th Step, learning rate = 0.009689960997906314 - Loss: 0.7912636399269104, aux loss1: 1.2047916650772095, 
		 aux loss2: 0.9199633002281189, total loss: 1.5206865072250366
9th Epoch, 3100th Step, learning rate = 0.00968945924369273 - Loss: 0.5155956745147705, aux loss1: 0.9764937162399292, 
		 aux loss2: 0.5892312526702881, total loss: 1.0442363023757935
<3100th step>
*************************** Test ***************************
time:3m 17s, 3100th Step, Loss: 0.9089709520339966, Mean IoU = 25.616%
************************************************************
9th Epoch, 3105th Step, learning rate = 0.009688957486592178 - Loss: 0.5828091502189636, aux loss1: 1.0297704935073853, 
		 aux loss2: 0.6405541300773621, total loss: 1.147961974143982
9th Epoch, 3110th Step, learning rate = 0.009688455726604468 - Loss: 0.7777197360992432, aux loss1: 1.314168095588684, 
		 aux loss2: 0.8904510736465454, total loss: 1.5281505584716797
9th Epoch, 3115th Step, learning rate = 0.009687953963729422 - Loss: 0.6413127183914185, aux loss1: 0.9840222001075745, 
		 aux loss2: 0.694097101688385, total loss: 1.214158296585083
9th Epoch, 3120th Step, learning rate = 0.009687452197966857 - Loss: 0.6515013575553894, aux loss1: 1.139988899230957, 
		 aux loss2: 0.7554762959480286, total loss: 1.295688509941101
9th Epoch, 3125th Step, learning rate = 0.009686950429316589 - Loss: 0.5783615112304688, aux loss1: 0.9937357902526855, 
		 aux loss2: 0.6445594429969788, total loss: 1.1343060731887817
9th Epoch, 3130th Step, learning rate = 0.009686448657778434 - Loss: 0.7946282625198364, aux loss1: 1.2679438591003418, 
		 aux loss2: 0.8994355797767639, total loss: 1.5347856283187866
9th Epoch, 3135th Step, learning rate = 0.009685946883352212 - Loss: 0.6209614872932434, aux loss1: 1.0720504522323608, 
		 aux loss2: 0.7064129114151001, total loss: 1.2251417636871338
9th Epoch, 3140th Step, learning rate = 0.00968544510603774 - Loss: 0.6676087379455566, aux loss1: 1.2083740234375, 
		 aux loss2: 0.7708264589309692, total loss: 1.338451623916626
9th Epoch, 3145th Step, learning rate = 0.009684943325834833 - Loss: 0.8695230484008789, aux loss1: 1.3790463209152222, 
		 aux loss2: 0.9995250105857849, total loss: 1.6830470561981201
9th Epoch, 3150th Step, learning rate = 0.009684441542743309 - Loss: 0.6471350789070129, aux loss1: 1.1535391807556152, 
		 aux loss2: 0.744404137134552, total loss: 1.2909585237503052
9th Epoch, 3155th Step, learning rate = 0.009683939756762985 - Loss: 0.7052656412124634, aux loss1: 1.3202954530715942, 
		 aux loss2: 0.8059229850769043, total loss: 1.423723578453064
9th Epoch, 3160th Step, learning rate = 0.009683437967893678 - Loss: 0.7854565978050232, aux loss1: 1.3187273740768433, 
		 aux loss2: 0.8949090838432312, total loss: 1.5390385389328003
9th Epoch, 3165th Step, learning rate = 0.009682936176135205 - Loss: 0.6376334428787231, aux loss1: 0.9943743944168091, 
		 aux loss2: 0.7438856959342957, total loss: 1.2335000038146973
9th Epoch, 3170th Step, learning rate = 0.009682434381487384 - Loss: 0.7322626113891602, aux loss1: 1.1671171188354492, 
		 aux loss2: 0.8340458273887634, total loss: 1.4160161018371582
9th Epoch, 3175th Step, learning rate = 0.009681932583950031 - Loss: 0.660348653793335, aux loss1: 1.0948346853256226, 
		 aux loss2: 0.750940203666687, total loss: 1.2891751527786255
9th Epoch, 3180th Step, learning rate = 0.009681430783522965 - Loss: 0.6569651365280151, aux loss1: 1.1058989763259888, 
		 aux loss2: 0.7439917325973511, total loss: 1.2863315343856812
9th Epoch, 3185th Step, learning rate = 0.009680928980205998 - Loss: 0.5395146608352661, aux loss1: 1.0877680778503418, 
		 aux loss2: 0.6479329466819763, total loss: 1.1250182390213013
9th Epoch, 3190th Step, learning rate = 0.00968042717399895 - Loss: 0.7323168516159058, aux loss1: 1.299147367477417, 
		 aux loss2: 0.8306154608726501, total loss: 1.454307198524475
9th Epoch, 3195th Step, learning rate = 0.00967992536490164 - Loss: 0.6483469009399414, aux loss1: 1.1590924263000488, 
		 aux loss2: 0.7744084596633911, total loss: 1.3058381080627441
9th Epoch, 3200th Step, learning rate = 0.009679423552913883 - Loss: 0.6832041144371033, aux loss1: 1.140974998474121, 
		 aux loss2: 0.8052595257759094, total loss: 1.3476004600524902
<3200th step>
*************************** Test ***************************
time:3m 14s, 3200th Step, Loss: 0.9315670728683472, Mean IoU = 24.844%
************************************************************
9th Epoch, 3205th Step, learning rate = 0.009678921738035494 - Loss: 0.41384604573249817, aux loss1: 0.7600350379943848, 
		 aux loss2: 0.49748700857162476, total loss: 0.840851366519928
9th Epoch, 3210th Step, learning rate = 0.00967841992026629 - Loss: 0.586411714553833, aux loss1: 0.9641842842102051, 
		 aux loss2: 0.6489275097846985, total loss: 1.1352379322052002
9th Epoch, 3215th Step, learning rate = 0.009677918099606093 - Loss: 0.6286430358886719, aux loss1: 1.0474684238433838, 
		 aux loss2: 0.6949788928031921, total loss: 1.2208751440048218
9th Epoch, 3220th Step, learning rate = 0.009677416276054713 - Loss: 0.7210590243339539, aux loss1: 1.1667184829711914, 
		 aux loss2: 0.7852403521537781, total loss: 1.3851706981658936
9th Epoch, 3225th Step, learning rate = 0.009676914449611973 - Loss: 0.7765982747077942, aux loss1: 1.3398730754852295, 
		 aux loss2: 0.8859901428222656, total loss: 1.5329563617706299
9th Epoch, 3230th Step, learning rate = 0.009676412620277684 - Loss: 0.8492234945297241, aux loss1: 1.3195912837982178, 
		 aux loss2: 0.9423938393592834, total loss: 1.622058391571045
9th Epoch, 3235th Step, learning rate = 0.009675910788051665 - Loss: 0.8713282346725464, aux loss1: 1.356915831565857, 
		 aux loss2: 1.036427617073059, total loss: 1.6929740905761719
9th Epoch, 3240th Step, learning rate = 0.009675408952933734 - Loss: 0.7009791731834412, aux loss1: 1.1530410051345825, 
		 aux loss2: 0.7670657634735107, total loss: 1.3537178039550781
9th Epoch, 3245th Step, learning rate = 0.009674907114923706 - Loss: 0.7141028046607971, aux loss1: 1.2041680812835693, 
		 aux loss2: 0.787036120891571, total loss: 1.3901677131652832
9th Epoch, 3250th Step, learning rate = 0.0096744052740214 - Loss: 0.6206768751144409, aux loss1: 1.0738862752914429, 
		 aux loss2: 0.696613073348999, total loss: 1.2214879989624023
9th Epoch, 3255th Step, learning rate = 0.00967390343022663 - Loss: 0.6165715456008911, aux loss1: 1.1235663890838623, 
		 aux loss2: 0.6990072131156921, total loss: 1.2332444190979004
9th Epoch, 3260th Step, learning rate = 0.009673401583539212 - Loss: 0.7572523355484009, aux loss1: 1.3492858409881592, 
		 aux loss2: 0.858909547328949, total loss: 1.5056018829345703
9th Epoch, 3265th Step, learning rate = 0.009672899733958965 - Loss: 0.5818234086036682, aux loss1: 0.9839047193527222, 
		 aux loss2: 0.6491021513938904, total loss: 1.1366357803344727
9th Epoch, 3270th Step, learning rate = 0.009672397881485705 - Loss: 0.6604788303375244, aux loss1: 1.161566972732544, 
		 aux loss2: 0.7598875164985657, total loss: 1.312903881072998
9th Epoch, 3275th Step, learning rate = 0.009671896026119248 - Loss: 0.5786552429199219, aux loss1: 1.0661065578460693, 
		 aux loss2: 0.6892521381378174, total loss: 1.1741881370544434
9th Epoch, 3280th Step, learning rate = 0.00967139416785941 - Loss: 0.6775849461555481, aux loss1: 1.1865887641906738, 
		 aux loss2: 0.7632850408554077, total loss: 1.338875651359558
9th Epoch, 3285th Step, learning rate = 0.00967089230670601 - Loss: 0.681942343711853, aux loss1: 1.1438605785369873, 
		 aux loss2: 0.7811799049377441, total loss: 1.337572455406189
9th Epoch, 3290th Step, learning rate = 0.00967039044265886 - Loss: 0.7597638964653015, aux loss1: 1.1808600425720215, 
		 aux loss2: 0.8350579738616943, total loss: 1.4480451345443726
9th Epoch, 3295th Step, learning rate = 0.00966988857571778 - Loss: 1.0281380414962769, aux loss1: 1.4509481191635132, 
		 aux loss2: 1.1120682954788208, total loss: 1.908249855041504
9th Epoch, 3300th Step, learning rate = 0.009669386705882589 - Loss: 0.7106838822364807, aux loss1: 1.2243990898132324, 
		 aux loss2: 0.835762083530426, total loss: 1.4123084545135498
<3300th step>
*************************** Test ***************************
time:3m 13s, 3300th Step, Loss: 0.8718768954277039, Mean IoU = 27.431%
************************************************************
9th Epoch, 3305th Step, learning rate = 0.009668884833153096 - Loss: 0.6687166690826416, aux loss1: 1.206284523010254, 
		 aux loss2: 0.7651718258857727, total loss: 1.3366707563400269
9th Epoch, 3310th Step, learning rate = 0.009668382957529123 - Loss: 0.598376989364624, aux loss1: 1.0918738842010498, 
		 aux loss2: 0.679487407207489, total loss: 1.1977341175079346
9th Epoch, 3315th Step, learning rate = 0.009667881079010484 - Loss: 0.6904881596565247, aux loss1: 1.102715253829956, 
		 aux loss2: 0.7780205011367798, total loss: 1.3325109481811523
9th Epoch, 3320th Step, learning rate = 0.009667379197596996 - Loss: 0.7386335134506226, aux loss1: 1.16365647315979, 
		 aux loss2: 0.8460768461227417, total loss: 1.4261611700057983
9th Epoch, 3325th Step, learning rate = 0.009666877313288476 - Loss: 0.7172425985336304, aux loss1: 1.1218500137329102, 
		 aux loss2: 0.8023287653923035, total loss: 1.3747291564941406
9th Epoch, 3330th Step, learning rate = 0.009666375426084738 - Loss: 0.599949300289154, aux loss1: 1.101754903793335, 
		 aux loss2: 0.6773818731307983, total loss: 1.2014285326004028
9th Epoch, 3335th Step, learning rate = 0.009665873535985602 - Loss: 0.7340073585510254, aux loss1: 1.2536870241165161, 
		 aux loss2: 0.8584511280059814, total loss: 1.4534939527511597
10th Epoch, 3340th Step, learning rate = 0.009665371642990882 - Loss: 0.9475516676902771, aux loss1: 1.3373839855194092, 
		 aux loss2: 1.029202938079834, total loss: 1.7604480981826782
10th Epoch, 3345th Step, learning rate = 0.009664869747100392 - Loss: 0.5480117797851562, aux loss1: 1.052889108657837, 
		 aux loss2: 0.6318438053131104, total loss: 1.1166160106658936
10th Epoch, 3350th Step, learning rate = 0.009664367848313952 - Loss: 0.8016193509101868, aux loss1: 1.2290936708450317, 
		 aux loss2: 0.8819279670715332, total loss: 1.5231186151504517
10th Epoch, 3355th Step, learning rate = 0.009663865946631378 - Loss: 0.7675833106040955, aux loss1: 1.309885025024414, 
		 aux loss2: 0.8520135879516602, total loss: 1.5013542175292969
10th Epoch, 3360th Step, learning rate = 0.009663364042052484 - Loss: 0.5838398933410645, aux loss1: 1.019836187362671, 
		 aux loss2: 0.6782490611076355, total loss: 1.16109037399292
10th Epoch, 3365th Step, learning rate = 0.009662862134577087 - Loss: 0.6561293005943298, aux loss1: 1.1151665449142456, 
		 aux loss2: 0.7382751703262329, total loss: 1.2859892845153809
10th Epoch, 3370th Step, learning rate = 0.009662360224205004 - Loss: 0.6887806057929993, aux loss1: 1.1997219324111938, 
		 aux loss2: 0.7803617715835571, total loss: 1.360841989517212
10th Epoch, 3375th Step, learning rate = 0.009661858310936048 - Loss: 0.6340155601501465, aux loss1: 1.1177345514297485, 
		 aux loss2: 0.716770350933075, total loss: 1.2560440301895142
10th Epoch, 3380th Step, learning rate = 0.009661356394770039 - Loss: 0.6370591521263123, aux loss1: 1.0268951654434204, 
		 aux loss2: 0.7111560702323914, total loss: 1.2295901775360107
10th Epoch, 3385th Step, learning rate = 0.00966085447570679 - Loss: 0.8135761022567749, aux loss1: 1.2699458599090576, 
		 aux loss2: 0.924946129322052, total loss: 1.5645382404327393
10th Epoch, 3390th Step, learning rate = 0.00966035255374612 - Loss: 0.5907711982727051, aux loss1: 1.0659464597702026, 
		 aux loss2: 0.7036356925964355, total loss: 1.192009449005127
10th Epoch, 3395th Step, learning rate = 0.009659850628887844 - Loss: 0.7371798753738403, aux loss1: 1.3135327100753784, 
		 aux loss2: 0.839170515537262, total loss: 1.4669078588485718
10th Epoch, 3400th Step, learning rate = 0.009659348701131776 - Loss: 0.5869925618171692, aux loss1: 1.0451595783233643, 
		 aux loss2: 0.6760289072990417, total loss: 1.1709520816802979
<3400th step>
*************************** Test ***************************
time:3m 11s, 3400th Step, Loss: 0.8349553942680359, Mean IoU = 26.008%
************************************************************
10th Epoch, 3405th Step, learning rate = 0.009658846770477734 - Loss: 0.5042117238044739, aux loss1: 0.9815570712089539, 
		 aux loss2: 0.601382315158844, total loss: 1.039231777191162
10th Epoch, 3410th Step, learning rate = 0.009658344836925533 - Loss: 0.5518807768821716, aux loss1: 0.9870931506156921, 
		 aux loss2: 0.6432836651802063, total loss: 1.105322241783142
10th Epoch, 3415th Step, learning rate = 0.00965784290047499 - Loss: 0.6610440611839294, aux loss1: 1.090939998626709, 
		 aux loss2: 0.7459975481033325, total loss: 1.2867250442504883
10th Epoch, 3420th Step, learning rate = 0.009657340961125919 - Loss: 0.7596932649612427, aux loss1: 1.1974164247512817, 
		 aux loss2: 0.8540918231010437, total loss: 1.4605549573898315
10th Epoch, 3425th Step, learning rate = 0.009656839018878137 - Loss: 0.7456166744232178, aux loss1: 1.2970696687698364, 
		 aux loss2: 0.8194233179092407, total loss: 1.4625070095062256
10th Epoch, 3430th Step, learning rate = 0.009656337073731461 - Loss: 0.7238774299621582, aux loss1: 1.2050564289093018, 
		 aux loss2: 0.8425701260566711, total loss: 1.4224224090576172
10th Epoch, 3435th Step, learning rate = 0.009655835125685705 - Loss: 0.5138463973999023, aux loss1: 1.0312165021896362, 
		 aux loss2: 0.6068530678749084, total loss: 1.0659525394439697
10th Epoch, 3440th Step, learning rate = 0.009655333174740684 - Loss: 0.6692858338356018, aux loss1: 1.3179664611816406, 
		 aux loss2: 0.7523497939109802, total loss: 1.365615725517273
10th Epoch, 3445th Step, learning rate = 0.009654831220896219 - Loss: 0.5601668357849121, aux loss1: 0.9927456378936768, 
		 aux loss2: 0.6460700035095215, total loss: 1.116418480873108
10th Epoch, 3450th Step, learning rate = 0.009654329264152118 - Loss: 0.6319200396537781, aux loss1: 1.0817928314208984, 
		 aux loss2: 0.7367421388626099, total loss: 1.2511547803878784
10th Epoch, 3455th Step, learning rate = 0.009653827304508202 - Loss: 0.6601809859275818, aux loss1: 1.047531008720398, 
		 aux loss2: 0.7130820155143738, total loss: 1.2596731185913086
10th Epoch, 3460th Step, learning rate = 0.009653325341964286 - Loss: 0.7639379501342773, aux loss1: 1.268058180809021, 
		 aux loss2: 0.891386091709137, total loss: 1.5009098052978516
10th Epoch, 3465th Step, learning rate = 0.009652823376520186 - Loss: 0.7552803754806519, aux loss1: 1.2424753904342651, 
		 aux loss2: 0.8575446009635925, total loss: 1.4710408449172974
10th Epoch, 3470th Step, learning rate = 0.009652321408175716 - Loss: 0.7041894197463989, aux loss1: 1.100712776184082, 
		 aux loss2: 0.7820394039154053, total loss: 1.3472191095352173
10th Epoch, 3475th Step, learning rate = 0.009651819436930692 - Loss: 0.7200670838356018, aux loss1: 1.1780216693878174, 
		 aux loss2: 0.7974491715431213, total loss: 1.3924531936645508
10th Epoch, 3480th Step, learning rate = 0.009651317462784931 - Loss: 1.0252412557601929, aux loss1: 1.4990653991699219, 
		 aux loss2: 1.1834187507629395, total loss: 1.9483284950256348
10th Epoch, 3485th Step, learning rate = 0.009650815485738247 - Loss: 0.609486997127533, aux loss1: 1.1967692375183105, 
		 aux loss2: 0.7192879915237427, total loss: 1.2562329769134521
10th Epoch, 3490th Step, learning rate = 0.009650313505790455 - Loss: 0.6626679301261902, aux loss1: 1.1797947883605957, 
		 aux loss2: 0.7698916792869568, total loss: 1.3245630264282227
10th Epoch, 3495th Step, learning rate = 0.009649811522941375 - Loss: 1.0767408609390259, aux loss1: 1.5388177633285522, 
		 aux loss2: 1.1464476585388184, total loss: 1.9969652891159058
10th Epoch, 3500th Step, learning rate = 0.009649309537190816 - Loss: 0.7541568875312805, aux loss1: 1.358412504196167, 
		 aux loss2: 0.8718827366828918, total loss: 1.5104337930679321
<3500th step>
*************************** Test ***************************
time:3m 12s, 3500th Step, Loss: 0.8597811460494995, Mean IoU = 25.289%
************************************************************
10th Epoch, 3505th Step, learning rate = 0.009648807548538599 - Loss: 0.8919292688369751, aux loss1: 1.4628714323043823, 
		 aux loss2: 1.0309163331985474, total loss: 1.7431572675704956
10th Epoch, 3510th Step, learning rate = 0.009648305556984536 - Loss: 0.6275221705436707, aux loss1: 1.0912797451019287, 
		 aux loss2: 0.7300940752029419, total loss: 1.246943712234497
10th Epoch, 3515th Step, learning rate = 0.009647803562528447 - Loss: 0.6633065342903137, aux loss1: 1.2320504188537598, 
		 aux loss2: 0.7745153903961182, total loss: 1.3427278995513916
10th Epoch, 3520th Step, learning rate = 0.009647301565170142 - Loss: 0.5953364372253418, aux loss1: 1.0556416511535645, 
		 aux loss2: 0.6878220438957214, total loss: 1.1871577501296997
10th Epoch, 3525th Step, learning rate = 0.009646799564909438 - Loss: 0.6305139660835266, aux loss1: 1.061628818511963, 
		 aux loss2: 0.6930825710296631, total loss: 1.2262356281280518
10th Epoch, 3530th Step, learning rate = 0.00964629756174615 - Loss: 0.7399161458015442, aux loss1: 1.2077451944351196, 
		 aux loss2: 0.8521835803985596, total loss: 1.4431132078170776
10th Epoch, 3535th Step, learning rate = 0.009645795555680098 - Loss: 0.8109387755393982, aux loss1: 1.3646479845046997, 
		 aux loss2: 0.9241405129432678, total loss: 1.589989423751831
10th Epoch, 3540th Step, learning rate = 0.00964529354671109 - Loss: 0.6145651936531067, aux loss1: 1.1186081171035767, 
		 aux loss2: 0.740393877029419, total loss: 1.246305227279663
10th Epoch, 3545th Step, learning rate = 0.009644791534838949 - Loss: 0.6419349908828735, aux loss1: 1.1414755582809448, 
		 aux loss2: 0.7397823333740234, total loss: 1.2802906036376953
10th Epoch, 3550th Step, learning rate = 0.009644289520063486 - Loss: 0.7381262183189392, aux loss1: 1.205209732055664, 
		 aux loss2: 0.8270094990730286, total loss: 1.430492877960205
10th Epoch, 3555th Step, learning rate = 0.009643787502384513 - Loss: 0.7213073372840881, aux loss1: 1.1474285125732422, 
		 aux loss2: 0.8122202754020691, total loss: 1.3904240131378174
10th Epoch, 3560th Step, learning rate = 0.009643285481801852 - Loss: 0.6040858030319214, aux loss1: 1.1086760759353638, 
		 aux loss2: 0.6872795820236206, total loss: 1.2116005420684814
10th Epoch, 3565th Step, learning rate = 0.009642783458315315 - Loss: 0.6477928161621094, aux loss1: 1.1507160663604736, 
		 aux loss2: 0.7601423263549805, total loss: 1.2970645427703857
10th Epoch, 3570th Step, learning rate = 0.009642281431924717 - Loss: 0.4942116439342499, aux loss1: 1.068253993988037, 
		 aux loss2: 0.5941821932792664, total loss: 1.0523607730865479
10th Epoch, 3575th Step, learning rate = 0.009641779402629875 - Loss: 0.7117233872413635, aux loss1: 1.1468908786773682, 
		 aux loss2: 0.8184425830841064, total loss: 1.3831677436828613
10th Epoch, 3580th Step, learning rate = 0.009641277370430601 - Loss: 0.7344281077384949, aux loss1: 1.228583574295044, 
		 aux loss2: 0.814998984336853, total loss: 1.4290028810501099
10th Epoch, 3585th Step, learning rate = 0.009640775335326713 - Loss: 0.5926735997200012, aux loss1: 1.0676008462905884, 
		 aux loss2: 0.7014392614364624, total loss: 1.1935296058654785
10th Epoch, 3590th Step, learning rate = 0.009640273297318026 - Loss: 0.7439211010932922, aux loss1: 1.2133429050445557, 
		 aux loss2: 0.8556321263313293, total loss: 1.4501768350601196
10th Epoch, 3595th Step, learning rate = 0.009639771256404351 - Loss: 0.8426879644393921, aux loss1: 1.4112845659255981, 
		 aux loss2: 0.9503645896911621, total loss: 1.646219253540039
10th Epoch, 3600th Step, learning rate = 0.009639269212585509 - Loss: 0.830241322517395, aux loss1: 1.4369479417800903, 
		 aux loss2: 0.9740579724311829, total loss: 1.6509488821029663
<3600th step>
*************************** Test ***************************
time:3m 11s, 3600th Step, Loss: 0.7908425331115723, Mean IoU = 27.111%
************************************************************
10th Epoch, 3605th Step, learning rate = 0.009638767165861314 - Loss: 0.6351106762886047, aux loss1: 1.0487712621688843, 
		 aux loss2: 0.6947305798530579, total loss: 1.227634310722351
10th Epoch, 3610th Step, learning rate = 0.009638265116231576 - Loss: 0.6961225867271423, aux loss1: 1.1362181901931763, 
		 aux loss2: 0.7694253921508789, total loss: 1.344758152961731
10th Epoch, 3615th Step, learning rate = 0.009637763063696115 - Loss: 0.6683761477470398, aux loss1: 1.1428302526474, 
		 aux loss2: 0.7573177218437195, total loss: 1.3141523599624634
10th Epoch, 3620th Step, learning rate = 0.009637261008254744 - Loss: 0.6675610542297363, aux loss1: 1.154102087020874, 
		 aux loss2: 0.7589044570922852, total loss: 1.3173534870147705
10th Epoch, 3625th Step, learning rate = 0.00963675894990728 - Loss: 0.6027731895446777, aux loss1: 1.0449614524841309, 
		 aux loss2: 0.6795414686203003, total loss: 1.1880782842636108
10th Epoch, 3630th Step, learning rate = 0.009636256888653535 - Loss: 0.8143817186355591, aux loss1: 1.3554327487945557, 
		 aux loss2: 0.9103243350982666, total loss: 1.5851413011550903
10th Epoch, 3635th Step, learning rate = 0.009635754824493326 - Loss: 0.6214479207992554, aux loss1: 1.0637423992156982, 
		 aux loss2: 0.6917904615402222, total loss: 1.2172868251800537
10th Epoch, 3640th Step, learning rate = 0.009635252757426467 - Loss: 0.5878928303718567, aux loss1: 1.077318787574768, 
		 aux loss2: 0.6809154748916626, total loss: 1.1834546327590942
10th Epoch, 3645th Step, learning rate = 0.009634750687452773 - Loss: 0.9365386962890625, aux loss1: 1.4685426950454712, 
		 aux loss2: 1.020363450050354, total loss: 1.7852469682693481
10th Epoch, 3650th Step, learning rate = 0.009634248614572058 - Loss: 0.6765230298042297, aux loss1: 1.1519074440002441, 
		 aux loss2: 0.8062615394592285, total loss: 1.3445998430252075
10th Epoch, 3655th Step, learning rate = 0.00963374653878414 - Loss: 0.724966824054718, aux loss1: 1.2180745601654053, 
		 aux loss2: 0.8313916325569153, total loss: 1.4229459762573242
10th Epoch, 3660th Step, learning rate = 0.00963324446008883 - Loss: 0.7237582206726074, aux loss1: 1.0890703201293945, 
		 aux loss2: 0.768949568271637, total loss: 1.3580591678619385
10th Epoch, 3665th Step, learning rate = 0.009632742378485945 - Loss: 0.5852386355400085, aux loss1: 1.0716325044631958, 
		 aux loss2: 0.6694647669792175, total loss: 1.1745142936706543
10th Epoch, 3670th Step, learning rate = 0.0096322402939753 - Loss: 0.5435497760772705, aux loss1: 1.0089364051818848, 
		 aux loss2: 0.6262080669403076, total loss: 1.0967140197753906
10th Epoch, 3675th Step, learning rate = 0.009631738206556707 - Loss: 0.7022730708122253, aux loss1: 1.2480530738830566, 
		 aux loss2: 0.8107500076293945, total loss: 1.400989055633545
10th Epoch, 3680th Step, learning rate = 0.009631236116229984 - Loss: 0.6641685962677002, aux loss1: 1.124934196472168, 
		 aux loss2: 0.755258321762085, total loss: 1.3037521839141846
10th Epoch, 3685th Step, learning rate = 0.009630734022994943 - Loss: 0.7100640535354614, aux loss1: 1.1674996614456177, 
		 aux loss2: 0.8075554966926575, total loss: 1.3833361864089966
10th Epoch, 3690th Step, learning rate = 0.009630231926851402 - Loss: 0.6232371926307678, aux loss1: 1.1363004446029663, 
		 aux loss2: 0.7132401466369629, total loss: 1.2494233846664429
10th Epoch, 3695th Step, learning rate = 0.009629729827799173 - Loss: 0.5932603478431702, aux loss1: 1.073959231376648, 
		 aux loss2: 0.6825497150421143, total loss: 1.1884679794311523
10th Epoch, 3700th Step, learning rate = 0.00962922772583807 - Loss: 0.6248222589492798, aux loss1: 1.0604699850082397, 
		 aux loss2: 0.6823073625564575, total loss: 1.2158862352371216
<3700th step>
*************************** Test ***************************
time:3m 13s, 3700th Step, Loss: 1.0038293600082397, Mean IoU = 23.820%
************************************************************
10th Epoch, 3705th Step, learning rate = 0.00962872562096791 - Loss: 0.6597056984901428, aux loss1: 1.0585776567459106, 
		 aux loss2: 0.7291775345802307, total loss: 1.2689499855041504
10th Epoch, 3710th Step, learning rate = 0.009628223513188507 - Loss: 0.5037850737571716, aux loss1: 0.99997878074646, 
		 aux loss2: 0.612859845161438, total loss: 1.0489226579666138
11th Epoch, 3715th Step, learning rate = 0.009627721402499676 - Loss: 0.7455586791038513, aux loss1: 1.2146016359329224, 
		 aux loss2: 0.8560439944267273, total loss: 1.4523568153381348
11th Epoch, 3720th Step, learning rate = 0.009627219288901229 - Loss: 0.505094051361084, aux loss1: 1.0033308267593384, 
		 aux loss2: 0.5930085778236389, total loss: 1.0432968139648438
11th Epoch, 3725th Step, learning rate = 0.009626717172392982 - Loss: 0.6146064400672913, aux loss1: 1.12456476688385, 
		 aux loss2: 0.7325626015663147, total loss: 1.245000958442688
11th Epoch, 3730th Step, learning rate = 0.009626215052974752 - Loss: 0.8024618625640869, aux loss1: 1.3471165895462036, 
		 aux loss2: 0.9283245801925659, total loss: 1.5779266357421875
11th Epoch, 3735th Step, learning rate = 0.009625712930646348 - Loss: 0.5605258941650391, aux loss1: 0.9490001201629639, 
		 aux loss2: 0.6258528232574463, total loss: 1.0955671072006226
11th Epoch, 3740th Step, learning rate = 0.00962521080540759 - Loss: 0.5962831377983093, aux loss1: 1.0558080673217773, 
		 aux loss2: 0.6770586371421814, total loss: 1.1838489770889282
11th Epoch, 3745th Step, learning rate = 0.009624708677258289 - Loss: 0.5373206734657288, aux loss1: 1.0466209650039673, 
		 aux loss2: 0.6406123638153076, total loss: 1.1075519323349
11th Epoch, 3750th Step, learning rate = 0.009624206546198262 - Loss: 0.7283391356468201, aux loss1: 1.2273293733596802, 
		 aux loss2: 0.8298973441123962, total loss: 1.4284968376159668
11th Epoch, 3755th Step, learning rate = 0.00962370441222732 - Loss: 0.6704564690589905, aux loss1: 1.1628296375274658, 
		 aux loss2: 0.7661848068237305, total loss: 1.3257793188095093
11th Epoch, 3760th Step, learning rate = 0.00962320227534528 - Loss: 0.637742280960083, aux loss1: 1.1044046878814697, 
		 aux loss2: 0.7163128852844238, total loss: 1.2555888891220093
11th Epoch, 3765th Step, learning rate = 0.009622700135551955 - Loss: 0.804021954536438, aux loss1: 1.2620770931243896, 
		 aux loss2: 0.8751790523529053, total loss: 1.5327167510986328
11th Epoch, 3770th Step, learning rate = 0.009622197992847161 - Loss: 0.7573840022087097, aux loss1: 1.256042718887329, 
		 aux loss2: 0.8734137415885925, total loss: 1.4835623502731323
11th Epoch, 3775th Step, learning rate = 0.00962169584723071 - Loss: 0.6394713521003723, aux loss1: 1.1119413375854492, 
		 aux loss2: 0.7356173992156982, total loss: 1.2673007249832153
11th Epoch, 3780th Step, learning rate = 0.009621193698702417 - Loss: 0.592334508895874, aux loss1: 1.058181881904602, 
		 aux loss2: 0.6785680055618286, total loss: 1.1812162399291992
11th Epoch, 3785th Step, learning rate = 0.0096206915472621 - Loss: 0.5643783807754517, aux loss1: 1.0058236122131348, 
		 aux loss2: 0.6484578847885132, total loss: 1.1255086660385132
11th Epoch, 3790th Step, learning rate = 0.009620189392909565 - Loss: 0.6681428551673889, aux loss1: 1.1462361812591553, 
		 aux loss2: 0.7561337351799011, total loss: 1.314467191696167
11th Epoch, 3795th Step, learning rate = 0.009619687235644636 - Loss: 0.6335259079933167, aux loss1: 1.0787080526351929, 
		 aux loss2: 0.7268376350402832, total loss: 1.247873306274414
11th Epoch, 3800th Step, learning rate = 0.00961918507546712 - Loss: 0.564515233039856, aux loss1: 1.0216056108474731, 
		 aux loss2: 0.6633427739143372, total loss: 1.1363340616226196
<3800th step>
*************************** Test ***************************
time:3m 16s, 3800th Step, Loss: 1.0303819179534912, Mean IoU = 24.651%
************************************************************
11th Epoch, 3805th Step, learning rate = 0.009618682912376834 - Loss: 0.4167335629463196, aux loss1: 0.8748579621315002, 
		 aux loss2: 0.4813387393951416, total loss: 0.8717265129089355
11th Epoch, 3810th Step, learning rate = 0.00961818074637359 - Loss: 0.49944111704826355, aux loss1: 0.9138296842575073, 
		 aux loss2: 0.5806658864021301, total loss: 1.0058563947677612
11th Epoch, 3815th Step, learning rate = 0.009617678577457205 - Loss: 0.4976070523262024, aux loss1: 1.062449336051941, 
		 aux loss2: 0.5839087963104248, total loss: 1.0499054193496704
11th Epoch, 3820th Step, learning rate = 0.009617176405627493 - Loss: 0.5517587661743164, aux loss1: 1.0286017656326294, 
		 aux loss2: 0.6480203866958618, total loss: 1.1195474863052368
11th Epoch, 3825th Step, learning rate = 0.009616674230884265 - Loss: 0.5773918032646179, aux loss1: 1.034372329711914, 
		 aux loss2: 0.6770393252372742, total loss: 1.1585192680358887
11th Epoch, 3830th Step, learning rate = 0.009616172053227338 - Loss: 0.731663703918457, aux loss1: 1.1822752952575684, 
		 aux loss2: 0.8026908040046692, total loss: 1.4074225425720215
11th Epoch, 3835th Step, learning rate = 0.009615669872656525 - Loss: 0.5405909419059753, aux loss1: 0.959010660648346, 
		 aux loss2: 0.615496814250946, total loss: 1.0744929313659668
11th Epoch, 3840th Step, learning rate = 0.00961516768917164 - Loss: 0.607197105884552, aux loss1: 1.2093223333358765, 
		 aux loss2: 0.709513783454895, total loss: 1.253799319267273
11th Epoch, 3845th Step, learning rate = 0.009614665502772497 - Loss: 0.5381844639778137, aux loss1: 1.0173091888427734, 
		 aux loss2: 0.6084319949150085, total loss: 1.0867500305175781
11th Epoch, 3850th Step, learning rate = 0.009614163313458908 - Loss: 0.6523476839065552, aux loss1: 1.1433278322219849, 
		 aux loss2: 0.767113447189331, total loss: 1.3021914958953857
11th Epoch, 3855th Step, learning rate = 0.009613661121230693 - Loss: 0.5935500264167786, aux loss1: 0.9887481331825256, 
		 aux loss2: 0.6637549996376038, total loss: 1.1556764841079712
11th Epoch, 3860th Step, learning rate = 0.009613158926087658 - Loss: 0.6547650098800659, aux loss1: 1.1146564483642578, 
		 aux loss2: 0.755392849445343, total loss: 1.2913191318511963
11th Epoch, 3865th Step, learning rate = 0.009612656728029623 - Loss: 0.7297900319099426, aux loss1: 1.2839267253875732, 
		 aux loss2: 0.834838330745697, total loss: 1.4489034414291382
11th Epoch, 3870th Step, learning rate = 0.009612154527056398 - Loss: 0.726035475730896, aux loss1: 1.158308744430542, 
		 aux loss2: 0.8082181215286255, total loss: 1.396815299987793
11th Epoch, 3875th Step, learning rate = 0.0096116523231678 - Loss: 0.5458774566650391, aux loss1: 1.0382758378982544, 
		 aux loss2: 0.6212968826293945, total loss: 1.1058789491653442
11th Epoch, 3880th Step, learning rate = 0.00961115011636364 - Loss: 0.6975585222244263, aux loss1: 1.1596826314926147, 
		 aux loss2: 0.7883554697036743, total loss: 1.3608055114746094
11th Epoch, 3885th Step, learning rate = 0.009610647906643732 - Loss: 0.8313911557197571, aux loss1: 1.3677653074264526, 
		 aux loss2: 0.9278894662857056, total loss: 1.6128766536712646
11th Epoch, 3890th Step, learning rate = 0.009610145694007892 - Loss: 0.6029128432273865, aux loss1: 1.041657567024231, 
		 aux loss2: 0.6759877800941467, total loss: 1.185805320739746
11th Epoch, 3895th Step, learning rate = 0.009609643478455932 - Loss: 0.6114476323127747, aux loss1: 1.1622594594955444, 
		 aux loss2: 0.7255091667175293, total loss: 1.2503291368484497
11th Epoch, 3900th Step, learning rate = 0.009609141259987667 - Loss: 0.9432045817375183, aux loss1: 1.4526183605194092, 
		 aux loss2: 1.0578285455703735, total loss: 1.802121639251709
<3900th step>
*************************** Test ***************************
time:3m 15s, 3900th Step, Loss: 0.8649457693099976, Mean IoU = 26.997%
************************************************************
11th Epoch, 3905th Step, learning rate = 0.00960863903860291 - Loss: 0.7166843414306641, aux loss1: 1.2269587516784668, 
		 aux loss2: 0.8024742007255554, total loss: 1.40576171875
11th Epoch, 3910th Step, learning rate = 0.009608136814301475 - Loss: 0.4581192135810852, aux loss1: 0.9422504305839539, 
		 aux loss2: 0.5444315075874329, total loss: 0.9585669636726379
11th Epoch, 3915th Step, learning rate = 0.009607634587083176 - Loss: 0.4543457627296448, aux loss1: 1.0332763195037842, 
		 aux loss2: 0.5272976756095886, total loss: 0.9752477407455444
11th Epoch, 3920th Step, learning rate = 0.009607132356947823 - Loss: 0.6567373871803284, aux loss1: 1.1812317371368408, 
		 aux loss2: 0.7745928764343262, total loss: 1.32094407081604
11th Epoch, 3925th Step, learning rate = 0.009606630123895234 - Loss: 0.8590375781059265, aux loss1: 1.2974718809127808, 
		 aux loss2: 0.9622713923454285, total loss: 1.6331876516342163
11th Epoch, 3930th Step, learning rate = 0.009606127887925222 - Loss: 0.6537110209465027, aux loss1: 1.1582072973251343, 
		 aux loss2: 0.7296848297119141, total loss: 1.2930471897125244
11th Epoch, 3935th Step, learning rate = 0.0096056256490376 - Loss: 0.7161756753921509, aux loss1: 1.376429796218872, 
		 aux loss2: 0.8404998183250427, total loss: 1.4653046131134033
11th Epoch, 3940th Step, learning rate = 0.009605123407232179 - Loss: 0.766054093837738, aux loss1: 1.2371901273727417, 
		 aux loss2: 0.8732646703720093, total loss: 1.4865169525146484
11th Epoch, 3945th Step, learning rate = 0.009604621162508776 - Loss: 0.6249924302101135, aux loss1: 1.0315349102020264, 
		 aux loss2: 0.704117476940155, total loss: 1.2160998582839966
11th Epoch, 3950th Step, learning rate = 0.009604118914867205 - Loss: 0.7797017097473145, aux loss1: 1.2782845497131348, 
		 aux loss2: 0.8864829540252686, total loss: 1.5177801847457886
11th Epoch, 3955th Step, learning rate = 0.009603616664307276 - Loss: 0.6999099850654602, aux loss1: 1.2130485773086548, 
		 aux loss2: 0.8199980854988098, total loss: 1.3918237686157227
11th Epoch, 3960th Step, learning rate = 0.009603114410828804 - Loss: 0.6364220380783081, aux loss1: 1.1124509572982788, 
		 aux loss2: 0.6895992159843445, total loss: 1.2459969520568848
11th Epoch, 3965th Step, learning rate = 0.009602612154431605 - Loss: 0.6518402695655823, aux loss1: 1.241000771522522, 
		 aux loss2: 0.7594398260116577, total loss: 1.3279163837432861
11th Epoch, 3970th Step, learning rate = 0.009602109895115488 - Loss: 0.6462966203689575, aux loss1: 1.1580032110214233, 
		 aux loss2: 0.7347591519355774, total loss: 1.2876012325286865
11th Epoch, 3975th Step, learning rate = 0.009601607632880269 - Loss: 0.5174206495285034, aux loss1: 0.9489180445671082, 
		 aux loss2: 0.6047674417495728, total loss: 1.0440030097961426
11th Epoch, 3980th Step, learning rate = 0.00960110536772576 - Loss: 0.5751798152923584, aux loss1: 1.0670669078826904, 
		 aux loss2: 0.670448899269104, total loss: 1.1634794473648071
11th Epoch, 3985th Step, learning rate = 0.009600603099651777 - Loss: 0.5307282209396362, aux loss1: 1.0206619501113892, 
		 aux loss2: 0.6038760542869568, total loss: 1.0784772634506226
11th Epoch, 3990th Step, learning rate = 0.00960010082865813 - Loss: 0.7345327138900757, aux loss1: 1.2509686946868896, 
		 aux loss2: 0.8282907605171204, total loss: 1.4411396980285645
11th Epoch, 3995th Step, learning rate = 0.009599598554744635 - Loss: 0.6058349609375, aux loss1: 1.0644046068191528, 
		 aux loss2: 0.6743766665458679, total loss: 1.1949070692062378
11th Epoch, 4000th Step, learning rate = 0.009599096277911104 - Loss: 0.5636410117149353, aux loss1: 0.9156661033630371, 
		 aux loss2: 0.6093511581420898, total loss: 1.0820813179016113
<4000th step>
*************************** Test ***************************
time:3m 20s, 4000th Step, Loss: 0.7607237696647644, Mean IoU = 29.180%
************************************************************
11th Epoch, 4005th Step, learning rate = 0.00959859399815735 - Loss: 0.6423216462135315, aux loss1: 1.0974441766738892, 
		 aux loss2: 0.734013020992279, total loss: 1.265160083770752
11th Epoch, 4010th Step, learning rate = 0.009598091715483186 - Loss: 0.5822463035583496, aux loss1: 0.9932869076728821, 
		 aux loss2: 0.6567149758338928, total loss: 1.142918348312378
11th Epoch, 4015th Step, learning rate = 0.009597589429888425 - Loss: 0.8065582513809204, aux loss1: 1.304182529449463, 
		 aux loss2: 0.9188580513000488, total loss: 1.5653562545776367
11th Epoch, 4020th Step, learning rate = 0.009597087141372883 - Loss: 0.5901660919189453, aux loss1: 1.0458571910858154, 
		 aux loss2: 0.6713414788246155, total loss: 1.1724598407745361
11th Epoch, 4025th Step, learning rate = 0.009596584849936371 - Loss: 0.8667421340942383, aux loss1: 1.3221185207366943, 
		 aux loss2: 0.9467483758926392, total loss: 1.6420769691467285
11th Epoch, 4030th Step, learning rate = 0.009596082555578702 - Loss: 0.6582955718040466, aux loss1: 1.1685681343078613, 
		 aux loss2: 0.7730354070663452, total loss: 1.318080186843872
11th Epoch, 4035th Step, learning rate = 0.009595580258299688 - Loss: 0.7164090275764465, aux loss1: 1.163884162902832, 
		 aux loss2: 0.7858936190605164, total loss: 1.3799316883087158
11th Epoch, 4040th Step, learning rate = 0.009595077958099146 - Loss: 0.6131433844566345, aux loss1: 1.0505115985870361, 
		 aux loss2: 0.6891979575157166, total loss: 1.203976035118103
11th Epoch, 4045th Step, learning rate = 0.009594575654976885 - Loss: 0.6187440752983093, aux loss1: 1.1534255743026733, 
		 aux loss2: 0.7200121879577637, total loss: 1.2527766227722168
11th Epoch, 4050th Step, learning rate = 0.00959407334893272 - Loss: 0.8243368864059448, aux loss1: 1.355723261833191, 
		 aux loss2: 0.9297069907188416, total loss: 1.6029366254806519
11th Epoch, 4055th Step, learning rate = 0.009593571039966463 - Loss: 0.5383049845695496, aux loss1: 1.0097657442092896, 
		 aux loss2: 0.6279928684234619, total loss: 1.0924317836761475
11th Epoch, 4060th Step, learning rate = 0.009593068728077928 - Loss: 0.5738232731819153, aux loss1: 1.025068759918213, 
		 aux loss2: 0.6420618891716003, total loss: 1.1381686925888062
11th Epoch, 4065th Step, learning rate = 0.009592566413266928 - Loss: 0.5436837077140808, aux loss1: 1.0183565616607666, 
		 aux loss2: 0.6103751063346863, total loss: 1.0933407545089722
11th Epoch, 4070th Step, learning rate = 0.009592064095533273 - Loss: 0.6533483266830444, aux loss1: 1.1522492170333862, 
		 aux loss2: 0.7208994626998901, total loss: 1.2873828411102295
11th Epoch, 4075th Step, learning rate = 0.009591561774876783 - Loss: 0.5212782025337219, aux loss1: 1.0139762163162231, 
		 aux loss2: 0.6025571823120117, total loss: 1.0664938688278198
11th Epoch, 4080th Step, learning rate = 0.009591059451297264 - Loss: 0.4896920919418335, aux loss1: 0.9963036775588989, 
		 aux loss2: 0.5883791446685791, total loss: 1.0239348411560059
12th Epoch, 4085th Step, learning rate = 0.009590557124794532 - Loss: 0.7768809199333191, aux loss1: 1.3470840454101562, 
		 aux loss2: 0.8808788657188416, total loss: 1.5333577394485474
12th Epoch, 4090th Step, learning rate = 0.009590054795368399 - Loss: 0.5088996887207031, aux loss1: 1.0508606433868408, 
		 aux loss2: 0.6180315613746643, total loss: 1.0713704824447632
12th Epoch, 4095th Step, learning rate = 0.009589552463018677 - Loss: 0.4341827929019928, aux loss1: 0.8796331286430359, 
		 aux loss2: 0.5157955288887024, total loss: 0.9043909311294556
12th Epoch, 4100th Step, learning rate = 0.00958905012774518 - Loss: 0.7055987119674683, aux loss1: 1.1536298990249634, 
		 aux loss2: 0.8015301823616028, total loss: 1.3722997903823853
<4100th step>
*************************** Test ***************************
time:3m 13s, 4100th Step, Loss: 0.7249218225479126, Mean IoU = 28.956%
************************************************************
12th Epoch, 4105th Step, learning rate = 0.00958854778954772 - Loss: 0.6409167647361755, aux loss1: 1.1542129516601562, 
		 aux loss2: 0.7284019589424133, total loss: 1.2785414457321167
12th Epoch, 4110th Step, learning rate = 0.009588045448426112 - Loss: 0.5371801257133484, aux loss1: 0.959537923336029, 
		 aux loss2: 0.608995795249939, total loss: 1.068639874458313
12th Epoch, 4115th Step, learning rate = 0.009587543104380168 - Loss: 0.5816925168037415, aux loss1: 1.0724061727523804, 
		 aux loss2: 0.694259762763977, total loss: 1.1811182498931885
12th Epoch, 4120th Step, learning rate = 0.009587040757409697 - Loss: 0.5754401087760925, aux loss1: 1.0743756294250488, 
		 aux loss2: 0.6699218153953552, total loss: 1.1657215356826782
12th Epoch, 4125th Step, learning rate = 0.009586538407514517 - Loss: 0.7491918206214905, aux loss1: 1.1889864206314087, 
		 aux loss2: 0.8249298334121704, total loss: 1.4358596801757812
12th Epoch, 4130th Step, learning rate = 0.009586036054694437 - Loss: 0.8070719242095947, aux loss1: 1.2306392192840576, 
		 aux loss2: 0.882705807685852, total loss: 1.529345989227295
12th Epoch, 4135th Step, learning rate = 0.009585533698949272 - Loss: 0.7954748868942261, aux loss1: 1.3204054832458496, 
		 aux loss2: 0.873150110244751, total loss: 1.5408565998077393
12th Epoch, 4140th Step, learning rate = 0.009585031340278832 - Loss: 0.6597199440002441, aux loss1: 1.1309384107589722, 
		 aux loss2: 0.7571737170219421, total loss: 1.3018710613250732
12th Epoch, 4145th Step, learning rate = 0.009584528978682933 - Loss: 0.558437168598175, aux loss1: 0.9851873517036438, 
		 aux loss2: 0.6197280883789062, total loss: 1.1018846035003662
12th Epoch, 4150th Step, learning rate = 0.009584026614161384 - Loss: 0.8145186901092529, aux loss1: 1.3264693021774292, 
		 aux loss2: 0.9330277442932129, total loss: 1.5856707096099854
12th Epoch, 4155th Step, learning rate = 0.009583524246714001 - Loss: 0.7150604724884033, aux loss1: 1.314122200012207, 
		 aux loss2: 0.8213924765586853, total loss: 1.4378541707992554
12th Epoch, 4160th Step, learning rate = 0.009583021876340594 - Loss: 0.6700496673583984, aux loss1: 1.1766002178192139, 
		 aux loss2: 0.7736717462539673, total loss: 1.332498550415039
12th Epoch, 4165th Step, learning rate = 0.009582519503040976 - Loss: 0.6826021671295166, aux loss1: 1.2161728143692017, 
		 aux loss2: 0.7840502858161926, total loss: 1.3610740900039673
12th Epoch, 4170th Step, learning rate = 0.00958201712681496 - Loss: 0.6703442335128784, aux loss1: 1.104874849319458, 
		 aux loss2: 0.7394912838935852, total loss: 1.2976032495498657
12th Epoch, 4175th Step, learning rate = 0.009581514747662358 - Loss: 0.5436596274375916, aux loss1: 1.039263129234314, 
		 aux loss2: 0.6586223840713501, total loss: 1.1188875436782837
12th Epoch, 4180th Step, learning rate = 0.009581012365582986 - Loss: 0.4974218010902405, aux loss1: 0.9583389163017273, 
		 aux loss2: 0.5705879926681519, total loss: 1.0131586790084839
12th Epoch, 4185th Step, learning rate = 0.009580509980576649 - Loss: 0.5274052619934082, aux loss1: 1.036253571510315, 
		 aux loss2: 0.6252577304840088, total loss: 1.0883843898773193
12th Epoch, 4190th Step, learning rate = 0.009580007592643165 - Loss: 0.6344114542007446, aux loss1: 1.112334966659546, 
		 aux loss2: 0.7310026288032532, total loss: 1.2605130672454834
12th Epoch, 4195th Step, learning rate = 0.009579505201782346 - Loss: 0.6405483484268188, aux loss1: 1.0601383447647095, 
		 aux loss2: 0.7020470499992371, total loss: 1.2394087314605713
12th Epoch, 4200th Step, learning rate = 0.009579002807994003 - Loss: 0.6792830228805542, aux loss1: 1.2837759256362915, 
		 aux loss2: 0.7973219752311707, total loss: 1.3833446502685547
<4200th step>
*************************** Test ***************************
time:3m 14s, 4200th Step, Loss: 0.8019251823425293, Mean IoU = 27.278%
************************************************************
12th Epoch, 4205th Step, learning rate = 0.009578500411277948 - Loss: 0.5837910771369934, aux loss1: 1.0622082948684692, 
		 aux loss2: 0.687929093837738, total loss: 1.1776251792907715
12th Epoch, 4210th Step, learning rate = 0.009577998011633995 - Loss: 0.578059196472168, aux loss1: 1.099773645401001, 
		 aux loss2: 0.6722678542137146, total loss: 1.17689847946167
12th Epoch, 4215th Step, learning rate = 0.009577495609061955 - Loss: 0.7143433690071106, aux loss1: 1.1360511779785156, 
		 aux loss2: 0.8260987997055054, total loss: 1.3855983018875122
12th Epoch, 4220th Step, learning rate = 0.00957699320356164 - Loss: 0.5713308453559875, aux loss1: 1.0663057565689087, 
		 aux loss2: 0.6677415370941162, total loss: 1.1583192348480225
12th Epoch, 4225th Step, learning rate = 0.009576490795132864 - Loss: 0.601426362991333, aux loss1: 1.0282368659973145, 
		 aux loss2: 0.6653144359588623, total loss: 1.176023244857788
12th Epoch, 4230th Step, learning rate = 0.009575988383775437 - Loss: 0.5134627223014832, aux loss1: 0.9434248208999634, 
		 aux loss2: 0.5994234085083008, total loss: 1.0362595319747925
12th Epoch, 4235th Step, learning rate = 0.009575485969489175 - Loss: 0.8501707315444946, aux loss1: 1.3070013523101807, 
		 aux loss2: 0.9540234208106995, total loss: 1.6238806247711182
12th Epoch, 4240th Step, learning rate = 0.009574983552273883 - Loss: 0.6378201246261597, aux loss1: 1.1262164115905762, 
		 aux loss2: 0.7223901152610779, total loss: 1.2646410465240479
12th Epoch, 4245th Step, learning rate = 0.00957448113212938 - Loss: 0.5788499116897583, aux loss1: 1.031307578086853, 
		 aux loss2: 0.6597809195518494, total loss: 1.152154564857483
12th Epoch, 4250th Step, learning rate = 0.009573978709055476 - Loss: 0.7406137585639954, aux loss1: 1.27082359790802, 
		 aux loss2: 0.8426774144172668, total loss: 1.458931803703308
12th Epoch, 4255th Step, learning rate = 0.009573476283051982 - Loss: 0.5984974503517151, aux loss1: 1.2577584981918335, 
		 aux loss2: 0.7148222327232361, total loss: 1.2617539167404175
12th Epoch, 4260th Step, learning rate = 0.009572973854118712 - Loss: 0.8074657320976257, aux loss1: 1.294819712638855, 
		 aux loss2: 0.8834688067436218, total loss: 1.5492992401123047
12th Epoch, 4265th Step, learning rate = 0.009572471422255476 - Loss: 0.5745671987533569, aux loss1: 1.0596576929092407, 
		 aux loss2: 0.6725229620933533, total loss: 1.1614737510681152
12th Epoch, 4270th Step, learning rate = 0.009571968987462088 - Loss: 0.5646620988845825, aux loss1: 1.076634407043457, 
		 aux loss2: 0.6538326740264893, total loss: 1.1491854190826416
12th Epoch, 4275th Step, learning rate = 0.009571466549738358 - Loss: 0.7106688618659973, aux loss1: 1.1913361549377441, 
		 aux loss2: 0.8221858143806458, total loss: 1.3969440460205078
12th Epoch, 4280th Step, learning rate = 0.009570964109084099 - Loss: 0.559032142162323, aux loss1: 0.9418909549713135, 
		 aux loss2: 0.6148934364318848, total loss: 1.0875568389892578
12th Epoch, 4285th Step, learning rate = 0.009570461665499123 - Loss: 0.6054851412773132, aux loss1: 1.152584433555603, 
		 aux loss2: 0.6753597855567932, total loss: 1.2214043140411377
12th Epoch, 4290th Step, learning rate = 0.009569959218983244 - Loss: 0.5695141553878784, aux loss1: 1.1211439371109009, 
		 aux loss2: 0.6646130084991455, total loss: 1.17170250415802
12th Epoch, 4295th Step, learning rate = 0.00956945676953627 - Loss: 0.5850444436073303, aux loss1: 1.0139628648757935, 
		 aux loss2: 0.6551709175109863, total loss: 1.1513017416000366
12th Epoch, 4300th Step, learning rate = 0.009568954317158014 - Loss: 0.6660246849060059, aux loss1: 1.1945793628692627, 
		 aux loss2: 0.7576223015785217, total loss: 1.327447533607483
<4300th step>
*************************** Test ***************************
time:3m 17s, 4300th Step, Loss: 0.7626333236694336, Mean IoU = 29.874%
************************************************************
12th Epoch, 4305th Step, learning rate = 0.009568451861848291 - Loss: 0.6191390752792358, aux loss1: 1.0831066370010376, 
		 aux loss2: 0.7004609704017639, total loss: 1.2242554426193237
12th Epoch, 4310th Step, learning rate = 0.009567949403606911 - Loss: 0.7532334327697754, aux loss1: 1.2266509532928467, 
		 aux loss2: 0.8484709858894348, total loss: 1.4606170654296875
12th Epoch, 4315th Step, learning rate = 0.009567446942433682 - Loss: 0.5255788564682007, aux loss1: 1.0196943283081055, 
		 aux loss2: 0.6324309706687927, total loss: 1.0844595432281494
12th Epoch, 4320th Step, learning rate = 0.009566944478328421 - Loss: 0.4957277774810791, aux loss1: 1.010707974433899, 
		 aux loss2: 0.614113986492157, total loss: 1.0445858240127563
12th Epoch, 4325th Step, learning rate = 0.009566442011290938 - Loss: 0.5820973515510559, aux loss1: 0.9739028811454773, 
		 aux loss2: 0.6347848773002625, total loss: 1.1281821727752686
12th Epoch, 4330th Step, learning rate = 0.009565939541321044 - Loss: 0.5011971592903137, aux loss1: 0.9770412445068359, 
		 aux loss2: 0.5721991658210754, total loss: 1.0231891870498657
12th Epoch, 4335th Step, learning rate = 0.009565437068418552 - Loss: 0.7162693738937378, aux loss1: 1.1805590391159058, 
		 aux loss2: 0.8143795728683472, total loss: 1.3961889743804932
12th Epoch, 4340th Step, learning rate = 0.009564934592583275 - Loss: 0.5486385226249695, aux loss1: 1.0408375263214111, 
		 aux loss2: 0.6362079381942749, total loss: 1.1153730154037476
12th Epoch, 4345th Step, learning rate = 0.009564432113815021 - Loss: 0.6958069801330566, aux loss1: 1.211260437965393, 
		 aux loss2: 0.7905052900314331, total loss: 1.3753873109817505
12th Epoch, 4350th Step, learning rate = 0.009563929632113603 - Loss: 0.7556964159011841, aux loss1: 1.3420181274414062, 
		 aux loss2: 0.8668899536132812, total loss: 1.5050578117370605
12th Epoch, 4355th Step, learning rate = 0.009563427147478832 - Loss: 0.614111602306366, aux loss1: 1.1854069232940674, 
		 aux loss2: 0.7031855583190918, total loss: 1.2510079145431519
12th Epoch, 4360th Step, learning rate = 0.009562924659910524 - Loss: 0.6525973081588745, aux loss1: 1.148639440536499, 
		 aux loss2: 0.7454034686088562, total loss: 1.2953505516052246
12th Epoch, 4365th Step, learning rate = 0.009562422169408486 - Loss: 0.4327826499938965, aux loss1: 0.9059582352638245, 
		 aux loss2: 0.5158542990684509, total loss: 0.9109119176864624
12th Epoch, 4370th Step, learning rate = 0.00956191967597253 - Loss: 0.5218965411186218, aux loss1: 0.9988974928855896, 
		 aux loss2: 0.6320885419845581, total loss: 1.0744012594223022
12th Epoch, 4375th Step, learning rate = 0.00956141717960247 - Loss: 0.531829833984375, aux loss1: 1.017669677734375, 
		 aux loss2: 0.606122612953186, total loss: 1.0795798301696777
12th Epoch, 4380th Step, learning rate = 0.009560914680298115 - Loss: 0.6467204093933105, aux loss1: 1.1963293552398682, 
		 aux loss2: 0.766753613948822, total loss: 1.3123207092285156
12th Epoch, 4385th Step, learning rate = 0.009560412178059278 - Loss: 0.6635040640830994, aux loss1: 1.0733637809753418, 
		 aux loss2: 0.7338606119155884, total loss: 1.279057502746582
12th Epoch, 4390th Step, learning rate = 0.00955990967288577 - Loss: 0.5632888078689575, aux loss1: 1.026439905166626, 
		 aux loss2: 0.6492981910705566, total loss: 1.1309400796890259
12th Epoch, 4395th Step, learning rate = 0.009559407164777402 - Loss: 0.7038867473602295, aux loss1: 1.0884673595428467, 
		 aux loss2: 0.7785125970840454, total loss: 1.3418320417404175
12th Epoch, 4400th Step, learning rate = 0.009558904653733987 - Loss: 0.637876033782959, aux loss1: 1.0769661664962769, 
		 aux loss2: 0.7110210061073303, total loss: 1.245374321937561
<4400th step>
*************************** Test ***************************
time:3m 16s, 4400th Step, Loss: 0.8807512521743774, Mean IoU = 26.490%
************************************************************
12th Epoch, 4405th Step, learning rate = 0.009558402139755335 - Loss: 0.4679546058177948, aux loss1: 0.8547387719154358, 
		 aux loss2: 0.5290384292602539, total loss: 0.935991644859314
12th Epoch, 4410th Step, learning rate = 0.009557899622841258 - Loss: 0.6580847501754761, aux loss1: 1.056257963180542, 
		 aux loss2: 0.7223583459854126, total loss: 1.2639055252075195
12th Epoch, 4415th Step, learning rate = 0.009557397102991567 - Loss: 0.6279940009117126, aux loss1: 1.0549250841140747, 
		 aux loss2: 0.7036367058753967, total loss: 1.225926160812378
12th Epoch, 4420th Step, learning rate = 0.009556894580206072 - Loss: 0.5994951725006104, aux loss1: 1.1238086223602295, 
		 aux loss2: 0.6616568565368652, total loss: 1.2013005018234253
12th Epoch, 4425th Step, learning rate = 0.009556392054484587 - Loss: 0.5081371068954468, aux loss1: 0.9389011263847351, 
		 aux loss2: 0.5927190780639648, total loss: 1.0268950462341309
12th Epoch, 4430th Step, learning rate = 0.009555889525826922 - Loss: 0.6483871340751648, aux loss1: 1.1249579191207886, 
		 aux loss2: 0.7415368556976318, total loss: 1.28248929977417
12th Epoch, 4435th Step, learning rate = 0.00955538699423289 - Loss: 0.7994855642318726, aux loss1: 1.2282779216766357, 
		 aux loss2: 0.8765427470207214, total loss: 1.5185861587524414
12th Epoch, 4440th Step, learning rate = 0.009554884459702298 - Loss: 0.5253425240516663, aux loss1: 0.9749181866645813, 
		 aux loss2: 0.6274819374084473, total loss: 1.0688107013702393
12th Epoch, 4445th Step, learning rate = 0.009554381922234961 - Loss: 0.4701826870441437, aux loss1: 0.975321352481842, 
		 aux loss2: 0.5418223142623901, total loss: 0.9795080423355103
12th Epoch, 4450th Step, learning rate = 0.00955387938183069 - Loss: 0.5516488552093506, aux loss1: 1.0411328077316284, 
		 aux loss2: 0.624671995639801, total loss: 1.1138575077056885
13th Epoch, 4455th Step, learning rate = 0.009553376838489294 - Loss: 0.6737856268882751, aux loss1: 1.1283057928085327, 
		 aux loss2: 0.7736860513687134, total loss: 1.3217518329620361
13th Epoch, 4460th Step, learning rate = 0.009552874292210587 - Loss: 0.4698650538921356, aux loss1: 0.9723957180976868, 
		 aux loss2: 0.5672990083694458, total loss: 0.9885033965110779
13th Epoch, 4465th Step, learning rate = 0.009552371742994377 - Loss: 0.6021148562431335, aux loss1: 1.1720831394195557, 
		 aux loss2: 0.7123644351959229, total loss: 1.2386856079101562
13th Epoch, 4470th Step, learning rate = 0.009551869190840476 - Loss: 0.677567720413208, aux loss1: 1.1463425159454346, 
		 aux loss2: 0.7596656680107117, total loss: 1.3253368139266968
13th Epoch, 4475th Step, learning rate = 0.009551366635748695 - Loss: 0.688926100730896, aux loss1: 1.1399277448654175, 
		 aux loss2: 0.7785791754722595, total loss: 1.3423360586166382
13th Epoch, 4480th Step, learning rate = 0.00955086407771885 - Loss: 0.4914086163043976, aux loss1: 0.9652016758918762, 
		 aux loss2: 0.5842999815940857, total loss: 1.0146890878677368
13th Epoch, 4485th Step, learning rate = 0.009550361516750745 - Loss: 0.6014626622200012, aux loss1: 1.1313526630401611, 
		 aux loss2: 0.7012731432914734, total loss: 1.2213777303695679
13th Epoch, 4490th Step, learning rate = 0.009549858952844194 - Loss: 0.7225223183631897, aux loss1: 1.3373124599456787, 
		 aux loss2: 0.8051499724388123, total loss: 1.445776104927063
13th Epoch, 4495th Step, learning rate = 0.009549356385999009 - Loss: 1.0512218475341797, aux loss1: 1.5662213563919067, 
		 aux loss2: 1.1639680862426758, total loss: 1.986675500869751
13th Epoch, 4500th Step, learning rate = 0.009548853816214998 - Loss: 0.5156409740447998, aux loss1: 1.0532379150390625, 
		 aux loss2: 0.6097899675369263, total loss: 1.0755283832550049
<4500th step>
*************************** Test ***************************
time:3m 16s, 4500th Step, Loss: 0.9226096272468567, Mean IoU = 26.673%
************************************************************
13th Epoch, 4505th Step, learning rate = 0.009548351243491975 - Loss: 0.7597016096115112, aux loss1: 1.2043964862823486, 
		 aux loss2: 0.830909788608551, total loss: 1.453384518623352
13th Epoch, 4510th Step, learning rate = 0.00954784866782975 - Loss: 0.6057556867599487, aux loss1: 1.1546374559402466, 
		 aux loss2: 0.6629509329795837, total loss: 1.217327356338501
13th Epoch, 4515th Step, learning rate = 0.009547346089228134 - Loss: 0.5309649705886841, aux loss1: 0.9470364451408386, 
		 aux loss2: 0.6020402312278748, total loss: 1.055891990661621
13th Epoch, 4520th Step, learning rate = 0.009546843507686937 - Loss: 0.6668863296508789, aux loss1: 1.2718507051467896, 
		 aux loss2: 0.766381025314331, total loss: 1.3549939393997192
13th Epoch, 4525th Step, learning rate = 0.009546340923205969 - Loss: 0.5645152926445007, aux loss1: 1.105522871017456, 
		 aux loss2: 0.6704666018486023, total loss: 1.1643588542938232
13th Epoch, 4530th Step, learning rate = 0.009545838335785043 - Loss: 0.42224931716918945, aux loss1: 0.8818256258964539, 
		 aux loss2: 0.49905723333358765, total loss: 0.8864198923110962
13th Epoch, 4535th Step, learning rate = 0.00954533574542397 - Loss: 0.5814043283462524, aux loss1: 1.0524204969406128, 
		 aux loss2: 0.6837596297264099, total loss: 1.170634388923645
13th Epoch, 4540th Step, learning rate = 0.00954483315212256 - Loss: 0.9768067002296448, aux loss1: 1.5516188144683838, 
		 aux loss2: 1.0975223779678345, total loss: 1.8813012838363647
13th Epoch, 4545th Step, learning rate = 0.009544330555880623 - Loss: 0.5825356245040894, aux loss1: 1.0713361501693726, 
		 aux loss2: 0.6708835959434509, total loss: 1.1722899675369263
13th Epoch, 4550th Step, learning rate = 0.009543827956697969 - Loss: 0.47188714146614075, aux loss1: 0.9147082567214966, 
		 aux loss2: 0.5501688122749329, total loss: 0.9663671255111694
13th Epoch, 4555th Step, learning rate = 0.009543325354574412 - Loss: 0.507892906665802, aux loss1: 1.005344033241272, 
		 aux loss2: 0.5987629890441895, total loss: 1.0490013360977173
13th Epoch, 4560th Step, learning rate = 0.009542822749509761 - Loss: 0.44453001022338867, aux loss1: 0.8447166085243225, 
		 aux loss2: 0.5116807222366333, total loss: 0.9026172757148743
13th Epoch, 4565th Step, learning rate = 0.009542320141503826 - Loss: 0.7028316855430603, aux loss1: 1.2553225755691528, 
		 aux loss2: 0.8374686241149902, total loss: 1.4144158363342285
13th Epoch, 4570th Step, learning rate = 0.009541817530556416 - Loss: 0.6670776605606079, aux loss1: 1.1629728078842163, 
		 aux loss2: 0.7593745589256287, total loss: 1.3197193145751953
13th Epoch, 4575th Step, learning rate = 0.009541314916667347 - Loss: 0.5242263078689575, aux loss1: 1.0478935241699219, 
		 aux loss2: 0.620920717716217, total loss: 1.0869626998901367
13th Epoch, 4580th Step, learning rate = 0.009540812299836424 - Loss: 0.5980216264724731, aux loss1: 1.1453988552093506, 
		 aux loss2: 0.6815098524093628, total loss: 1.214245319366455
13th Epoch, 4585th Step, learning rate = 0.00954030968006346 - Loss: 0.6054226160049438, aux loss1: 1.0732353925704956, 
		 aux loss2: 0.696735680103302, total loss: 1.206087589263916
13th Epoch, 4590th Step, learning rate = 0.009539807057348266 - Loss: 0.5415523052215576, aux loss1: 1.0717908143997192, 
		 aux loss2: 0.6229117512702942, total loss: 1.11225426197052
13th Epoch, 4595th Step, learning rate = 0.009539304431690652 - Loss: 0.7860240936279297, aux loss1: 1.2687913179397583, 
		 aux loss2: 0.8692495226860046, total loss: 1.5143613815307617
13th Epoch, 4600th Step, learning rate = 0.009538801803090429 - Loss: 0.5557828545570374, aux loss1: 0.9773095846176147, 
		 aux loss2: 0.6119006276130676, total loss: 1.0937360525131226
<4600th step>
*************************** Test ***************************
time:3m 14s, 4600th Step, Loss: 0.837857723236084, Mean IoU = 25.792%
************************************************************
13th Epoch, 4605th Step, learning rate = 0.009538299171547405 - Loss: 0.7621082663536072, aux loss1: 1.2133371829986572, 
		 aux loss2: 0.8405873775482178, total loss: 1.4623442888259888
13th Epoch, 4610th Step, learning rate = 0.009537796537061395 - Loss: 0.6297821998596191, aux loss1: 1.1127653121948242, 
		 aux loss2: 0.7187967300415039, total loss: 1.2511305809020996
13th Epoch, 4615th Step, learning rate = 0.009537293899632206 - Loss: 0.48621630668640137, aux loss1: 0.9399473071098328, 
		 aux loss2: 0.5846644639968872, total loss: 1.0020662546157837
13th Epoch, 4620th Step, learning rate = 0.009536791259259648 - Loss: 0.6175006628036499, aux loss1: 1.0963131189346313, 
		 aux loss2: 0.7214808464050293, total loss: 1.2349870204925537
13th Epoch, 4625th Step, learning rate = 0.009536288615943534 - Loss: 0.7402184009552002, aux loss1: 1.2232182025909424, 
		 aux loss2: 0.831937313079834, total loss: 1.4399588108062744
13th Epoch, 4630th Step, learning rate = 0.009535785969683675 - Loss: 0.625227153301239, aux loss1: 1.1313782930374146, 
		 aux loss2: 0.7007420659065247, total loss: 1.2449374198913574
13th Epoch, 4635th Step, learning rate = 0.009535283320479876 - Loss: 0.43923816084861755, aux loss1: 0.897018551826477, 
		 aux loss2: 0.49145254492759705, total loss: 0.904924750328064
13th Epoch, 4640th Step, learning rate = 0.009534780668331952 - Loss: 0.5365579724311829, aux loss1: 1.0183923244476318, 
		 aux loss2: 0.6252388954162598, total loss: 1.092171311378479
13th Epoch, 4645th Step, learning rate = 0.009534278013239712 - Loss: 0.5346437096595764, aux loss1: 1.06252121925354, 
		 aux loss2: 0.6166286468505859, total loss: 1.1000515222549438
13th Epoch, 4650th Step, learning rate = 0.009533775355202967 - Loss: 0.5576990842819214, aux loss1: 1.0505750179290771, 
		 aux loss2: 0.6580567955970764, total loss: 1.136094331741333
13th Epoch, 4655th Step, learning rate = 0.009533272694221525 - Loss: 0.6834375858306885, aux loss1: 1.2477527856826782, 
		 aux loss2: 0.8078790307044983, total loss: 1.3809150457382202
13th Epoch, 4660th Step, learning rate = 0.0095327700302952 - Loss: 0.7368549704551697, aux loss1: 1.202323079109192, 
		 aux loss2: 0.852980375289917, total loss: 1.438744068145752
13th Epoch, 4665th Step, learning rate = 0.009532267363423799 - Loss: 0.5703656077384949, aux loss1: 1.1059859991073608, 
		 aux loss2: 0.6942303776741028, total loss: 1.1798535585403442
13th Epoch, 4670th Step, learning rate = 0.009531764693607132 - Loss: 0.7813276052474976, aux loss1: 1.2847951650619507, 
		 aux loss2: 0.8698954582214355, total loss: 1.5147243738174438
13th Epoch, 4675th Step, learning rate = 0.009531262020845012 - Loss: 0.5738091468811035, aux loss1: 1.1286938190460205, 
		 aux loss2: 0.6917657256126404, total loss: 1.1891236305236816
13th Epoch, 4680th Step, learning rate = 0.009530759345137247 - Loss: 0.6114034652709961, aux loss1: 1.1091899871826172, 
		 aux loss2: 0.71543949842453, total loss: 1.230336308479309
13th Epoch, 4685th Step, learning rate = 0.009530256666483647 - Loss: 0.5994210243225098, aux loss1: 1.0651814937591553, 
		 aux loss2: 0.6687610745429993, total loss: 1.186479926109314
13th Epoch, 4690th Step, learning rate = 0.009529753984884023 - Loss: 0.5100008845329285, aux loss1: 1.1267402172088623, 
		 aux loss2: 0.6268693804740906, total loss: 1.0987707376480103
13th Epoch, 4695th Step, learning rate = 0.009529251300338184 - Loss: 0.5451381802558899, aux loss1: 1.0841144323349, 
		 aux loss2: 0.6354227662086487, total loss: 1.1245416402816772
13th Epoch, 4700th Step, learning rate = 0.009528748612845942 - Loss: 0.6444135904312134, aux loss1: 1.2025630474090576, 
		 aux loss2: 0.7451657652854919, total loss: 1.3032488822937012
<4700th step>
*************************** Test ***************************
time:3m 14s, 4700th Step, Loss: 0.7654436826705933, Mean IoU = 28.860%
************************************************************
13th Epoch, 4705th Step, learning rate = 0.009528245922407107 - Loss: 0.5154733657836914, aux loss1: 0.9044352173805237, 
		 aux loss2: 0.5836927890777588, total loss: 1.0202810764312744
13th Epoch, 4710th Step, learning rate = 0.009527743229021486 - Loss: 0.6321559548377991, aux loss1: 1.1143282651901245, 
		 aux loss2: 0.6966369152069092, total loss: 1.2451092004776
13th Epoch, 4715th Step, learning rate = 0.00952724053268889 - Loss: 0.5869720578193665, aux loss1: 1.1309175491333008, 
		 aux loss2: 0.655316174030304, total loss: 1.1883738040924072
13th Epoch, 4720th Step, learning rate = 0.009526737833409132 - Loss: 0.5336863398551941, aux loss1: 0.9972058534622192, 
		 aux loss2: 0.6171574592590332, total loss: 1.0797110795974731
13th Epoch, 4725th Step, learning rate = 0.009526235131182018 - Loss: 0.7241595387458801, aux loss1: 1.2337223291397095, 
		 aux loss2: 0.8073469996452332, total loss: 1.4172149896621704
13th Epoch, 4730th Step, learning rate = 0.00952573242600736 - Loss: 0.48103848099708557, aux loss1: 0.932346522808075, 
		 aux loss2: 0.554092288017273, total loss: 0.9823793172836304
13th Epoch, 4735th Step, learning rate = 0.009525229717884968 - Loss: 0.5891369581222534, aux loss1: 1.0264241695404053, 
		 aux loss2: 0.6731760501861572, total loss: 1.166334629058838
13th Epoch, 4740th Step, learning rate = 0.009524727006814651 - Loss: 0.7265385389328003, aux loss1: 1.283110499382019, 
		 aux loss2: 0.8480084538459778, total loss: 1.4506750106811523
13th Epoch, 4745th Step, learning rate = 0.009524224292796219 - Loss: 0.6142511963844299, aux loss1: 1.0881472826004028, 
		 aux loss2: 0.7024720311164856, total loss: 1.221684217453003
13th Epoch, 4750th Step, learning rate = 0.009523721575829482 - Loss: 0.7038436532020569, aux loss1: 1.1291825771331787, 
		 aux loss2: 0.7928738594055176, total loss: 1.3597480058670044
13th Epoch, 4755th Step, learning rate = 0.009523218855914251 - Loss: 0.6096587777137756, aux loss1: 1.1111387014389038, 
		 aux loss2: 0.7072634696960449, total loss: 1.2259058952331543
13th Epoch, 4760th Step, learning rate = 0.009522716133050332 - Loss: 0.5993948578834534, aux loss1: 1.0520100593566895, 
		 aux loss2: 0.6774046421051025, total loss: 1.1859596967697144
13th Epoch, 4765th Step, learning rate = 0.009522213407237539 - Loss: 0.6925334930419922, aux loss1: 1.1611047983169556, 
		 aux loss2: 0.7969979643821716, total loss: 1.3596642017364502
13th Epoch, 4770th Step, learning rate = 0.00952171067847568 - Loss: 1.1595187187194824, aux loss1: 1.6935210227966309, 
		 aux loss2: 1.2674251794815063, total loss: 2.1745452880859375
13th Epoch, 4775th Step, learning rate = 0.009521207946764565 - Loss: 0.8263345956802368, aux loss1: 1.4329484701156616, 
		 aux loss2: 0.9163309931755066, total loss: 1.6227515935897827
13th Epoch, 4780th Step, learning rate = 0.009520705212104 - Loss: 0.5547405481338501, aux loss1: 1.0378247499465942, 
		 aux loss2: 0.6455716490745544, total loss: 1.124316692352295
13th Epoch, 4785th Step, learning rate = 0.0095202024744938 - Loss: 0.6611220240592957, aux loss1: 1.2969439029693604, 
		 aux loss2: 0.77326500415802, total loss: 1.3595112562179565
13th Epoch, 4790th Step, learning rate = 0.009519699733933774 - Loss: 0.5486410856246948, aux loss1: 1.073799729347229, 
		 aux loss2: 0.6379307508468628, total loss: 1.1259533166885376
13th Epoch, 4795th Step, learning rate = 0.00951919699042373 - Loss: 0.6576039791107178, aux loss1: 1.190004587173462, 
		 aux loss2: 0.7245720624923706, total loss: 1.3044342994689941
13th Epoch, 4800th Step, learning rate = 0.009518694243963476 - Loss: 0.5664251446723938, aux loss1: 1.0524460077285767, 
		 aux loss2: 0.6439883708953857, total loss: 1.139754295349121
<4800th step>
*************************** Test ***************************
time:3m 16s, 4800th Step, Loss: 0.7466326951980591, Mean IoU = 30.295%
************************************************************
13th Epoch, 4805th Step, learning rate = 0.009518191494552825 - Loss: 0.4436505436897278, aux loss1: 0.893968403339386, 
		 aux loss2: 0.5203812718391418, total loss: 0.9199936389923096
13th Epoch, 4810th Step, learning rate = 0.009517688742191584 - Loss: 0.7165185213088989, aux loss1: 1.1790711879730225, 
		 aux loss2: 0.8229979872703552, total loss: 1.3994390964508057
13th Epoch, 4815th Step, learning rate = 0.009517185986879563 - Loss: 0.5212138891220093, aux loss1: 1.0228925943374634, 
		 aux loss2: 0.6329778432846069, total loss: 1.081272840499878
13th Epoch, 4820th Step, learning rate = 0.009516683228616573 - Loss: 0.5305610299110413, aux loss1: 1.001945972442627, 
		 aux loss2: 0.6271058320999146, total loss: 1.0819871425628662
14th Epoch, 4825th Step, learning rate = 0.009516180467402421 - Loss: 0.4748690724372864, aux loss1: 0.9619659781455994, 
		 aux loss2: 0.5560475587844849, total loss: 0.9858778715133667
14th Epoch, 4830th Step, learning rate = 0.009515677703236919 - Loss: 0.5328211188316345, aux loss1: 1.0555144548416138, 
		 aux loss2: 0.6261340975761414, total loss: 1.0999290943145752
14th Epoch, 4835th Step, learning rate = 0.009515174936119876 - Loss: 0.5188311338424683, aux loss1: 1.000459909439087, 
		 aux loss2: 0.6071583032608032, total loss: 1.0618324279785156
14th Epoch, 4840th Step, learning rate = 0.009514672166051097 - Loss: 0.5865067839622498, aux loss1: 1.1193584203720093, 
		 aux loss2: 0.6892009377479553, total loss: 1.1979947090148926
14th Epoch, 4845th Step, learning rate = 0.009514169393030398 - Loss: 0.5876671075820923, aux loss1: 1.0964689254760742, 
		 aux loss2: 0.6882855892181396, total loss: 1.1919220685958862
14th Epoch, 4850th Step, learning rate = 0.009513666617057584 - Loss: 0.4929767847061157, aux loss1: 0.99676513671875, 
		 aux loss2: 0.578318178653717, total loss: 1.0233336687088013
14th Epoch, 4855th Step, learning rate = 0.009513163838132464 - Loss: 0.4104336202144623, aux loss1: 0.8547201156616211, 
		 aux loss2: 0.48544415831565857, total loss: 0.8610273599624634
14th Epoch, 4860th Step, learning rate = 0.009512661056254852 - Loss: 0.4231398105621338, aux loss1: 0.9000210762023926, 
		 aux loss2: 0.5002133846282959, total loss: 0.8932314515113831
14th Epoch, 4865th Step, learning rate = 0.009512158271424553 - Loss: 0.7117801308631897, aux loss1: 1.2531157732009888, 
		 aux loss2: 0.8136184215545654, total loss: 1.4131622314453125
14th Epoch, 4870th Step, learning rate = 0.009511655483641376 - Loss: 0.47648289799690247, aux loss1: 0.9655842185020447, 
		 aux loss2: 0.549799382686615, total loss: 0.9860779047012329
14th Epoch, 4875th Step, learning rate = 0.009511152692905131 - Loss: 0.6039177775382996, aux loss1: 1.162278413772583, 
		 aux loss2: 0.7005723714828491, total loss: 1.232830286026001
14th Epoch, 4880th Step, learning rate = 0.00951064989921563 - Loss: 0.4286709427833557, aux loss1: 0.8843222260475159, 
		 aux loss2: 0.5110127925872803, total loss: 0.8983727097511292
14th Epoch, 4885th Step, learning rate = 0.009510147102572681 - Loss: 0.7682040929794312, aux loss1: 1.2482798099517822, 
		 aux loss2: 0.8254250884056091, total loss: 1.4728580713272095
14th Epoch, 4890th Step, learning rate = 0.00950964430297609 - Loss: 0.5771176815032959, aux loss1: 1.0262336730957031, 
		 aux loss2: 0.6560583114624023, total loss: 1.1474111080169678
14th Epoch, 4895th Step, learning rate = 0.009509141500425668 - Loss: 0.8349983096122742, aux loss1: 1.3430896997451782, 
		 aux loss2: 0.9607981443405151, total loss: 1.6222445964813232
14th Epoch, 4900th Step, learning rate = 0.009508638694921226 - Loss: 0.6151260733604431, aux loss1: 1.0978879928588867, 
		 aux loss2: 0.7100563645362854, total loss: 1.2285150289535522
<4900th step>
*************************** Test ***************************
time:3m 14s, 4900th Step, Loss: 0.7418525218963623, Mean IoU = 30.653%
************************************************************
14th Epoch, 4905th Step, learning rate = 0.00950813588646257 - Loss: 0.6252474188804626, aux loss1: 1.198681116104126, 
		 aux loss2: 0.7470823526382446, total loss: 1.2836847305297852
14th Epoch, 4910th Step, learning rate = 0.00950763307504951 - Loss: 0.44138655066490173, aux loss1: 0.9318776726722717, 
		 aux loss2: 0.5377790927886963, total loss: 0.9360615015029907
14th Epoch, 4915th Step, learning rate = 0.009507130260681855 - Loss: 0.5253041386604309, aux loss1: 0.946178138256073, 
		 aux loss2: 0.6056385636329651, total loss: 1.0514130592346191
14th Epoch, 4920th Step, learning rate = 0.009506627443359417 - Loss: 0.5081014633178711, aux loss1: 0.940470814704895, 
		 aux loss2: 0.5791535377502441, total loss: 1.0219041109085083
14th Epoch, 4925th Step, learning rate = 0.009506124623082 - Loss: 0.7070196270942688, aux loss1: 1.2326583862304688, 
		 aux loss2: 0.8112785220146179, total loss: 1.4013285636901855
14th Epoch, 4930th Step, learning rate = 0.009505621799849418 - Loss: 0.7375606894493103, aux loss1: 1.2150709629058838, 
		 aux loss2: 0.8070610761642456, total loss: 1.4249064922332764
14th Epoch, 4935th Step, learning rate = 0.009505118973661476 - Loss: 0.834502100944519, aux loss1: 1.354897141456604, 
		 aux loss2: 0.9073079824447632, total loss: 1.6038944721221924
14th Epoch, 4940th Step, learning rate = 0.009504616144517985 - Loss: 0.6106237173080444, aux loss1: 1.0523558855056763, 
		 aux loss2: 0.7029651999473572, total loss: 1.2075165510177612
14th Epoch, 4945th Step, learning rate = 0.009504113312418752 - Loss: 0.5507074594497681, aux loss1: 0.987677812576294, 
		 aux loss2: 0.6244129538536072, total loss: 1.096776008605957
14th Epoch, 4950th Step, learning rate = 0.009503610477363587 - Loss: 0.6533768177032471, aux loss1: 1.0534050464630127, 
		 aux loss2: 0.7328988909721375, total loss: 1.2625579833984375
14th Epoch, 4955th Step, learning rate = 0.009503107639352302 - Loss: 0.4473656117916107, aux loss1: 0.8950819969177246, 
		 aux loss2: 0.5131763815879822, total loss: 0.9211608171463013
14th Epoch, 4960th Step, learning rate = 0.0095026047983847 - Loss: 0.8572337627410889, aux loss1: 1.2735188007354736, 
		 aux loss2: 0.9237124919891357, total loss: 1.6087744235992432
14th Epoch, 4965th Step, learning rate = 0.009502101954460593 - Loss: 0.4668371081352234, aux loss1: 0.8904715776443481, 
		 aux loss2: 0.5524153113365173, total loss: 0.9549447298049927
14th Epoch, 4970th Step, learning rate = 0.00950159910757979 - Loss: 0.5344574451446533, aux loss1: 1.014859914779663, 
		 aux loss2: 0.6078067421913147, total loss: 1.082038164138794
14th Epoch, 4975th Step, learning rate = 0.009501096257742097 - Loss: 0.5025044679641724, aux loss1: 1.0336920022964478, 
		 aux loss2: 0.5965179204940796, total loss: 1.0512192249298096
14th Epoch, 4980th Step, learning rate = 0.009500593404947326 - Loss: 0.4921166002750397, aux loss1: 1.0044361352920532, 
		 aux loss2: 0.5882263779640198, total loss: 1.028738021850586
14th Epoch, 4985th Step, learning rate = 0.009500090549195286 - Loss: 0.5142278671264648, aux loss1: 0.9733120203018188, 
		 aux loss2: 0.5988702774047852, total loss: 1.0457695722579956
14th Epoch, 4990th Step, learning rate = 0.009499587690485783 - Loss: 0.5704476833343506, aux loss1: 1.0735788345336914, 
		 aux loss2: 0.6658523678779602, total loss: 1.1588623523712158
14th Epoch, 4995th Step, learning rate = 0.009499084828818628 - Loss: 0.651508629322052, aux loss1: 1.0838172435760498, 
		 aux loss2: 0.7189361453056335, total loss: 1.264228343963623
14th Epoch, 5000th Step, learning rate = 0.009498581964193625 - Loss: 0.9135416150093079, aux loss1: 1.4358835220336914, 
		 aux loss2: 0.9877901077270508, total loss: 1.7394227981567383
<5000th step>
*************************** Test ***************************
time:3m 14s, 5000th Step, Loss: 0.7767857909202576, Mean IoU = 30.144%
************************************************************
14th Epoch, 5005th Step, learning rate = 0.00949807909661059 - Loss: 0.5456191897392273, aux loss1: 0.9989640116691589, 
		 aux loss2: 0.6450023055076599, total loss: 1.1033093929290771
14th Epoch, 5010th Step, learning rate = 0.009497576226069325 - Loss: 0.5654063820838928, aux loss1: 1.0166735649108887, 
		 aux loss2: 0.6531587243080139, total loss: 1.1316719055175781
14th Epoch, 5015th Step, learning rate = 0.009497073352569644 - Loss: 0.6418811678886414, aux loss1: 1.0375484228134155, 
		 aux loss2: 0.7275237441062927, total loss: 1.2441552877426147
14th Epoch, 5020th Step, learning rate = 0.00949657047611135 - Loss: 0.4187069833278656, aux loss1: 0.9151141047477722, 
		 aux loss2: 0.5133237838745117, total loss: 0.8985707759857178
14th Epoch, 5025th Step, learning rate = 0.009496067596694255 - Loss: 0.6213876605033875, aux loss1: 1.169135570526123, 
		 aux loss2: 0.7229748368263245, total loss: 1.2613182067871094
14th Epoch, 5030th Step, learning rate = 0.009495564714318169 - Loss: 0.5754169225692749, aux loss1: 1.1593735218048096, 
		 aux loss2: 0.6911266446113586, total loss: 1.1996796131134033
14th Epoch, 5035th Step, learning rate = 0.009495061828982895 - Loss: 0.5912836194038391, aux loss1: 1.0865066051483154, 
		 aux loss2: 0.6879631876945496, total loss: 1.1924209594726562
14th Epoch, 5040th Step, learning rate = 0.009494558940688246 - Loss: 0.5570473670959473, aux loss1: 1.0761644840240479, 
		 aux loss2: 0.6187475919723511, total loss: 1.127395749092102
14th Epoch, 5045th Step, learning rate = 0.00949405604943403 - Loss: 0.48792365193367004, aux loss1: 0.9425497651100159, 
		 aux loss2: 0.5808916687965393, total loss: 1.0030453205108643
14th Epoch, 5050th Step, learning rate = 0.009493553155220052 - Loss: 0.5175164341926575, aux loss1: 0.980326235294342, 
		 aux loss2: 0.5986625552177429, total loss: 1.051079273223877
14th Epoch, 5055th Step, learning rate = 0.009493050258046126 - Loss: 0.6661613583564758, aux loss1: 1.2690986394882202, 
		 aux loss2: 0.7886443734169006, total loss: 1.3623487949371338
14th Epoch, 5060th Step, learning rate = 0.009492547357912056 - Loss: 0.5082842111587524, aux loss1: 0.9922837615013123, 
		 aux loss2: 0.6043438911437988, total loss: 1.047706961631775
14th Epoch, 5065th Step, learning rate = 0.00949204445481765 - Loss: 0.5574520826339722, aux loss1: 1.022292137145996, 
		 aux loss2: 0.6503873467445374, total loss: 1.124294638633728
14th Epoch, 5070th Step, learning rate = 0.00949154154876272 - Loss: 0.6396450996398926, aux loss1: 1.2589843273162842, 
		 aux loss2: 0.7600545883178711, total loss: 1.3213622570037842
14th Epoch, 5075th Step, learning rate = 0.009491038639747072 - Loss: 0.505450427532196, aux loss1: 0.9896807670593262, 
		 aux loss2: 0.5960242748260498, total loss: 1.0407644510269165
14th Epoch, 5080th Step, learning rate = 0.009490535727770514 - Loss: 0.8129292130470276, aux loss1: 1.3112221956253052, 
		 aux loss2: 0.8828791975975037, total loss: 1.5594475269317627
14th Epoch, 5085th Step, learning rate = 0.009490032812832854 - Loss: 0.5798962116241455, aux loss1: 1.0954447984695435, 
		 aux loss2: 0.7010112404823303, total loss: 1.188934087753296
14th Epoch, 5090th Step, learning rate = 0.009489529894933901 - Loss: 0.5341302752494812, aux loss1: 0.9706514477729797, 
		 aux loss2: 0.6439130306243896, total loss: 1.0828909873962402
14th Epoch, 5095th Step, learning rate = 0.009489026974073464 - Loss: 0.6887118220329285, aux loss1: 1.175188660621643, 
		 aux loss2: 0.7938650846481323, total loss: 1.3588144779205322
14th Epoch, 5100th Step, learning rate = 0.00948852405025135 - Loss: 0.8004767894744873, aux loss1: 1.235859751701355, 
		 aux loss2: 0.853065550327301, total loss: 1.5124609470367432
<5100th step>
*************************** Test ***************************
time:3m 14s, 5100th Step, Loss: 0.7563151121139526, Mean IoU = 29.123%
************************************************************
14th Epoch, 5105th Step, learning rate = 0.009488021123467366 - Loss: 0.5539152026176453, aux loss1: 1.073859691619873, 
		 aux loss2: 0.6641685366630554, total loss: 1.1417405605316162
14th Epoch, 5110th Step, learning rate = 0.009487518193721322 - Loss: 0.6551146507263184, aux loss1: 1.1675196886062622, 
		 aux loss2: 0.7627516388893127, total loss: 1.3104712963104248
14th Epoch, 5115th Step, learning rate = 0.009487015261013027 - Loss: 0.7294095754623413, aux loss1: 1.2915489673614502, 
		 aux loss2: 0.8307405710220337, total loss: 1.449170470237732
14th Epoch, 5120th Step, learning rate = 0.009486512325342285 - Loss: 0.5781367421150208, aux loss1: 1.0871555805206299, 
		 aux loss2: 0.673326313495636, total loss: 1.1736139059066772
14th Epoch, 5125th Step, learning rate = 0.009486009386708908 - Loss: 0.7268772721290588, aux loss1: 1.2113306522369385, 
		 aux loss2: 0.8325904607772827, total loss: 1.4233126640319824
14th Epoch, 5130th Step, learning rate = 0.009485506445112703 - Loss: 0.7120797038078308, aux loss1: 1.2564377784729004, 
		 aux loss2: 0.8105953931808472, total loss: 1.4132492542266846
14th Epoch, 5135th Step, learning rate = 0.009485003500553478 - Loss: 0.8570958971977234, aux loss1: 1.5081045627593994, 
		 aux loss2: 0.9742110967636108, total loss: 1.6992117166519165
14th Epoch, 5140th Step, learning rate = 0.00948450055303104 - Loss: 0.4668341875076294, aux loss1: 1.0223734378814697, 
		 aux loss2: 0.5562431812286377, total loss: 0.9960435032844543
14th Epoch, 5145th Step, learning rate = 0.009483997602545197 - Loss: 0.7587701678276062, aux loss1: 1.1753935813903809, 
		 aux loss2: 0.8238394260406494, total loss: 1.4409239292144775
14th Epoch, 5150th Step, learning rate = 0.009483494649095757 - Loss: 0.7807801961898804, aux loss1: 1.2861602306365967, 
		 aux loss2: 0.8887432217597961, total loss: 1.522125482559204
14th Epoch, 5155th Step, learning rate = 0.00948299169268253 - Loss: 0.6023751497268677, aux loss1: 1.0631177425384521, 
		 aux loss2: 0.6779849529266357, total loss: 1.1925044059753418
14th Epoch, 5160th Step, learning rate = 0.009482488733305322 - Loss: 0.5986736416816711, aux loss1: 1.0686613321304321, 
		 aux loss2: 0.6864111423492432, total loss: 1.1938365697860718
14th Epoch, 5165th Step, learning rate = 0.009481985770963939 - Loss: 0.6504953503608704, aux loss1: 1.14336097240448, 
		 aux loss2: 0.7560486793518066, total loss: 1.2959232330322266
14th Epoch, 5170th Step, learning rate = 0.009481482805658194 - Loss: 0.712044894695282, aux loss1: 1.114274501800537, 
		 aux loss2: 0.752688467502594, total loss: 1.347402572631836
14th Epoch, 5175th Step, learning rate = 0.009480979837387889 - Loss: 0.46722617745399475, aux loss1: 0.9077650904655457, 
		 aux loss2: 0.5510182976722717, total loss: 0.9599630236625671
14th Epoch, 5180th Step, learning rate = 0.009480476866152835 - Loss: 0.6528034806251526, aux loss1: 1.1020864248275757, 
		 aux loss2: 0.733658492565155, total loss: 1.276892900466919
14th Epoch, 5185th Step, learning rate = 0.00947997389195284 - Loss: 0.5262846946716309, aux loss1: 1.064848780632019, 
		 aux loss2: 0.6257398128509521, total loss: 1.0960352420806885
14th Epoch, 5190th Step, learning rate = 0.009479470914787711 - Loss: 0.5519127249717712, aux loss1: 0.9681751132011414, 
		 aux loss2: 0.600792407989502, total loss: 1.0826822519302368
15th Epoch, 5195th Step, learning rate = 0.009478967934657256 - Loss: 0.5936233997344971, aux loss1: 1.077364206314087, 
		 aux loss2: 0.6864767670631409, total loss: 1.1914234161376953
15th Epoch, 5200th Step, learning rate = 0.009478464951561282 - Loss: 0.8200565576553345, aux loss1: 1.361716389656067, 
		 aux loss2: 0.9503270983695984, total loss: 1.6087024211883545
<5200th step>
*************************** Test ***************************
time:3m 14s, 5200th Step, Loss: 0.7204461693763733, Mean IoU = 31.208%
************************************************************
15th Epoch, 5205th Step, learning rate = 0.009477961965499597 - Loss: 0.525542140007019, aux loss1: 1.0232592821121216, 
		 aux loss2: 0.6366307735443115, total loss: 1.087172269821167
15th Epoch, 5210th Step, learning rate = 0.009477458976472009 - Loss: 0.6433482766151428, aux loss1: 1.2125129699707031, 
		 aux loss2: 0.7452731728553772, total loss: 1.3052115440368652
15th Epoch, 5215th Step, learning rate = 0.009476955984478326 - Loss: 0.597690999507904, aux loss1: 1.070685625076294, 
		 aux loss2: 0.6969128251075745, total loss: 1.1976618766784668
15th Epoch, 5220th Step, learning rate = 0.00947645298951835 - Loss: 0.7423177361488342, aux loss1: 1.160776972770691, 
		 aux loss2: 0.8121564388275146, total loss: 1.415413498878479
15th Epoch, 5225th Step, learning rate = 0.0094759499915919 - Loss: 0.43322572112083435, aux loss1: 0.912934422492981, 
		 aux loss2: 0.5215994119644165, total loss: 0.9157458543777466
15th Epoch, 5230th Step, learning rate = 0.009475446990698773 - Loss: 0.6133596301078796, aux loss1: 1.0570307970046997, 
		 aux loss2: 0.7279945015907288, total loss: 1.221666693687439
15th Epoch, 5235th Step, learning rate = 0.009474943986838782 - Loss: 0.7086214423179626, aux loss1: 1.2031227350234985, 
		 aux loss2: 0.7821803689002991, total loss: 1.3824304342269897
15th Epoch, 5240th Step, learning rate = 0.009474440980011734 - Loss: 0.4599507749080658, aux loss1: 0.9097288846969604, 
		 aux loss2: 0.5215817093849182, total loss: 0.9415021538734436
15th Epoch, 5245th Step, learning rate = 0.009473937970217434 - Loss: 0.7350964546203613, aux loss1: 1.1725388765335083, 
		 aux loss2: 0.816484272480011, total loss: 1.413451910018921
15th Epoch, 5250th Step, learning rate = 0.00947343495745569 - Loss: 0.7064977288246155, aux loss1: 1.315692663192749, 
		 aux loss2: 0.8126854300498962, total loss: 1.4262797832489014
15th Epoch, 5255th Step, learning rate = 0.009472931941726312 - Loss: 0.677381694316864, aux loss1: 1.2148486375808716, 
		 aux loss2: 0.7535425424575806, total loss: 1.343253254890442
15th Epoch, 5260th Step, learning rate = 0.009472428923029106 - Loss: 0.5712181329727173, aux loss1: 1.116031289100647, 
		 aux loss2: 0.6668649315834045, total loss: 1.1727735996246338
15th Epoch, 5265th Step, learning rate = 0.009471925901363878 - Loss: 0.5837459564208984, aux loss1: 1.1232435703277588, 
		 aux loss2: 0.6742749810218811, total loss: 1.1904289722442627
15th Epoch, 5270th Step, learning rate = 0.009471422876730437 - Loss: 0.5093191266059875, aux loss1: 0.9881168007850647, 
		 aux loss2: 0.5812009572982788, total loss: 1.0382345914840698
15th Epoch, 5275th Step, learning rate = 0.009470919849128588 - Loss: 0.552486002445221, aux loss1: 0.995701253414154, 
		 aux loss2: 0.6387916207313538, total loss: 1.106713056564331
15th Epoch, 5280th Step, learning rate = 0.009470416818558144 - Loss: 0.5276399254798889, aux loss1: 1.050154447555542, 
		 aux loss2: 0.6222423315048218, total loss: 1.091583251953125
15th Epoch, 5285th Step, learning rate = 0.009469913785018904 - Loss: 0.5732383131980896, aux loss1: 1.1108516454696655, 
		 aux loss2: 0.6824550032615662, total loss: 1.1794757843017578
15th Epoch, 5290th Step, learning rate = 0.009469410748510682 - Loss: 0.4755062460899353, aux loss1: 0.9516021013259888, 
		 aux loss2: 0.5782705545425415, total loss: 0.9922951459884644
15th Epoch, 5295th Step, learning rate = 0.009468907709033284 - Loss: 0.6218363046646118, aux loss1: 1.1871520280838013, 
		 aux loss2: 0.7116016149520874, total loss: 1.262622594833374
15th Epoch, 5300th Step, learning rate = 0.009468404666586513 - Loss: 0.6028568744659424, aux loss1: 1.1152126789093018, 
		 aux loss2: 0.6958752274513245, total loss: 1.2157708406448364
<5300th step>
*************************** Test ***************************
time:3m 14s, 5300th Step, Loss: 0.7418192028999329, Mean IoU = 31.212%
************************************************************
15th Epoch, 5305th Step, learning rate = 0.00946790162117018 - Loss: 0.4921334385871887, aux loss1: 1.0180127620697021, 
		 aux loss2: 0.5947938561439514, total loss: 1.0354547500610352
15th Epoch, 5310th Step, learning rate = 0.009467398572784093 - Loss: 0.5761680603027344, aux loss1: 1.0520886182785034, 
		 aux loss2: 0.6513261198997498, total loss: 1.15232515335083
15th Epoch, 5315th Step, learning rate = 0.009466895521428056 - Loss: 0.5806742906570435, aux loss1: 0.989188551902771, 
		 aux loss2: 0.6421069502830505, total loss: 1.134273648262024
15th Epoch, 5320th Step, learning rate = 0.009466392467101879 - Loss: 0.5911539196968079, aux loss1: 1.0965160131454468, 
		 aux loss2: 0.6819995641708374, total loss: 1.192908525466919
15th Epoch, 5325th Step, learning rate = 0.009465889409805367 - Loss: 0.5317978858947754, aux loss1: 0.9433361291885376, 
		 aux loss2: 0.6299468278884888, total loss: 1.0667774677276611
15th Epoch, 5330th Step, learning rate = 0.009465386349538328 - Loss: 0.6746079921722412, aux loss1: 1.2613266706466675, 
		 aux loss2: 0.8084170818328857, total loss: 1.3763729333877563
15th Epoch, 5335th Step, learning rate = 0.009464883286300569 - Loss: 0.4942210912704468, aux loss1: 0.9648571610450745, 
		 aux loss2: 0.5751897096633911, total loss: 1.01375412940979
15th Epoch, 5340th Step, learning rate = 0.009464380220091896 - Loss: 0.5932950377464294, aux loss1: 1.0924261808395386, 
		 aux loss2: 0.6833234429359436, total loss: 1.1943522691726685
15th Epoch, 5345th Step, learning rate = 0.009463877150912117 - Loss: 0.47829195857048035, aux loss1: 0.9533639550209045, 
		 aux loss2: 0.5567423701286316, total loss: 0.9869981408119202
15th Epoch, 5350th Step, learning rate = 0.00946337407876104 - Loss: 0.5279217958450317, aux loss1: 1.0912070274353027, 
		 aux loss2: 0.6098320484161377, total loss: 1.0992166996002197
15th Epoch, 5355th Step, learning rate = 0.00946287100363847 - Loss: 0.6433646082878113, aux loss1: 1.1084911823272705, 
		 aux loss2: 0.7399400472640991, total loss: 1.271888017654419
15th Epoch, 5360th Step, learning rate = 0.009462367925544213 - Loss: 0.46068644523620605, aux loss1: 0.925561249256134, 
		 aux loss2: 0.5518548488616943, total loss: 0.9590967297554016
15th Epoch, 5365th Step, learning rate = 0.009461864844478082 - Loss: 0.5654911994934082, aux loss1: 1.11073899269104, 
		 aux loss2: 0.6640914678573608, total loss: 1.1643494367599487
15th Epoch, 5370th Step, learning rate = 0.009461361760439876 - Loss: 0.5801174640655518, aux loss1: 1.1688451766967773, 
		 aux loss2: 0.6705755591392517, total loss: 1.1990011930465698
15th Epoch, 5375th Step, learning rate = 0.009460858673429405 - Loss: 0.4886665940284729, aux loss1: 0.9804071187973022, 
		 aux loss2: 0.5725801587104797, total loss: 1.0118207931518555
15th Epoch, 5380th Step, learning rate = 0.009460355583446475 - Loss: 0.4670248031616211, aux loss1: 0.9537215232849121, 
		 aux loss2: 0.5561949610710144, total loss: 0.9756192564964294
15th Epoch, 5385th Step, learning rate = 0.009459852490490897 - Loss: 0.5788136124610901, aux loss1: 1.1043293476104736, 
		 aux loss2: 0.6688671708106995, total loss: 1.177659273147583
15th Epoch, 5390th Step, learning rate = 0.009459349394562474 - Loss: 0.4903044104576111, aux loss1: 1.0235015153884888, 
		 aux loss2: 0.5922736525535583, total loss: 1.034264326095581
15th Epoch, 5395th Step, learning rate = 0.009458846295661013 - Loss: 0.5140420794487, aux loss1: 0.9090185761451721, 
		 aux loss2: 0.5647880434989929, total loss: 1.0126628875732422
15th Epoch, 5400th Step, learning rate = 0.009458343193786321 - Loss: 0.689842700958252, aux loss1: 1.1939406394958496, 
		 aux loss2: 0.7850775718688965, total loss: 1.3620558977127075
<5400th step>
*************************** Test ***************************
time:3m 14s, 5400th Step, Loss: 0.9076749086380005, Mean IoU = 28.340%
************************************************************
15th Epoch, 5405th Step, learning rate = 0.009457840088938206 - Loss: 0.7523792386054993, aux loss1: 1.2402124404907227, 
		 aux loss2: 0.8280209898948669, total loss: 1.4556515216827393
15th Epoch, 5410th Step, learning rate = 0.009457336981116473 - Loss: 0.5742748975753784, aux loss1: 1.1281652450561523, 
		 aux loss2: 0.6597236394882202, total loss: 1.1766139268875122
15th Epoch, 5415th Step, learning rate = 0.009456833870320928 - Loss: 0.5412447452545166, aux loss1: 1.0593332052230835, 
		 aux loss2: 0.6292006969451904, total loss: 1.1107250452041626
15th Epoch, 5420th Step, learning rate = 0.00945633075655138 - Loss: 0.6346555948257446, aux loss1: 1.1926813125610352, 
		 aux loss2: 0.732530415058136, total loss: 1.2854721546173096
15th Epoch, 5425th Step, learning rate = 0.009455827639807634 - Loss: 0.5556263327598572, aux loss1: 0.9618194699287415, 
		 aux loss2: 0.6333489418029785, total loss: 1.0975117683410645
15th Epoch, 5430th Step, learning rate = 0.009455324520089497 - Loss: 0.6199327111244202, aux loss1: 1.0913631916046143, 
		 aux loss2: 0.7290277481079102, total loss: 1.2389527559280396
15th Epoch, 5435th Step, learning rate = 0.009454821397396776 - Loss: 0.5929527878761292, aux loss1: 1.1237744092941284, 
		 aux loss2: 0.7216335535049438, total loss: 1.2187385559082031
15th Epoch, 5440th Step, learning rate = 0.009454318271729278 - Loss: 0.6231155395507812, aux loss1: 1.0534651279449463, 
		 aux loss2: 0.7067345380783081, total loss: 1.221848964691162
15th Epoch, 5445th Step, learning rate = 0.009453815143086805 - Loss: 0.6113315224647522, aux loss1: 1.0759886503219604, 
		 aux loss2: 0.6911675333976746, total loss: 1.2105951309204102
15th Epoch, 5450th Step, learning rate = 0.009453312011469171 - Loss: 0.5762519240379333, aux loss1: 1.109792947769165, 
		 aux loss2: 0.6881831884384155, total loss: 1.1844631433486938
15th Epoch, 5455th Step, learning rate = 0.009452808876876178 - Loss: 0.5276174545288086, aux loss1: 0.9787819385528564, 
		 aux loss2: 0.6003705263137817, total loss: 1.061400294303894
15th Epoch, 5460th Step, learning rate = 0.009452305739307632 - Loss: 0.4374169707298279, aux loss1: 0.8610530495643616, 
		 aux loss2: 0.5147949457168579, total loss: 0.9016509056091309
15th Epoch, 5465th Step, learning rate = 0.00945180259876334 - Loss: 0.4426388144493103, aux loss1: 0.8634065985679626, 
		 aux loss2: 0.5101540684700012, total loss: 0.905722439289093
15th Epoch, 5470th Step, learning rate = 0.00945129945524311 - Loss: 0.6129570603370667, aux loss1: 1.1271027326583862, 
		 aux loss2: 0.6960225701332092, total loss: 1.229496955871582
15th Epoch, 5475th Step, learning rate = 0.009450796308746748 - Loss: 0.5523771047592163, aux loss1: 1.070268154144287, 
		 aux loss2: 0.6373016238212585, total loss: 1.12837815284729
15th Epoch, 5480th Step, learning rate = 0.009450293159274058 - Loss: 0.6981120705604553, aux loss1: 1.2510371208190918, 
		 aux loss2: 0.7886932492256165, total loss: 1.3889005184173584
15th Epoch, 5485th Step, learning rate = 0.009449790006824848 - Loss: 0.550618052482605, aux loss1: 0.9960159659385681, 
		 aux loss2: 0.6077355742454529, total loss: 1.0925170183181763
15th Epoch, 5490th Step, learning rate = 0.009449286851398925 - Loss: 0.4553554952144623, aux loss1: 0.8769925832748413, 
		 aux loss2: 0.5598831176757812, total loss: 0.9424065351486206
15th Epoch, 5495th Step, learning rate = 0.009448783692996093 - Loss: 0.5056944489479065, aux loss1: 0.9611607789993286, 
		 aux loss2: 0.5918986797332764, total loss: 1.0308021306991577
15th Epoch, 5500th Step, learning rate = 0.00944828053161616 - Loss: 0.4993760585784912, aux loss1: 1.0346966981887817, 
		 aux loss2: 0.5838332772254944, total loss: 1.0433183908462524
<5500th step>
*************************** Test ***************************
time:3m 16s, 5500th Step, Loss: 0.6810367107391357, Mean IoU = 30.840%
************************************************************
15th Epoch, 5505th Step, learning rate = 0.009447777367258933 - Loss: 0.707761824131012, aux loss1: 1.2977464199066162, 
		 aux loss2: 0.8060283064842224, total loss: 1.419497013092041
15th Epoch, 5510th Step, learning rate = 0.009447274199924218 - Loss: 0.6611056327819824, aux loss1: 1.203783631324768, 
		 aux loss2: 0.7566958069801331, total loss: 1.3249191045761108
15th Epoch, 5515th Step, learning rate = 0.009446771029611818 - Loss: 0.5556703805923462, aux loss1: 0.9969247579574585, 
		 aux loss2: 0.6357224583625793, total loss: 1.1090368032455444
15th Epoch, 5520th Step, learning rate = 0.009446267856321543 - Loss: 0.6471668481826782, aux loss1: 1.0855607986450195, 
		 aux loss2: 0.7257283329963684, total loss: 1.2631263732910156
15th Epoch, 5525th Step, learning rate = 0.009445764680053197 - Loss: 0.6283869743347168, aux loss1: 1.3574620485305786, 
		 aux loss2: 0.7891483306884766, total loss: 1.3512849807739258
15th Epoch, 5530th Step, learning rate = 0.009445261500806587 - Loss: 0.7168869972229004, aux loss1: 1.105299949645996, 
		 aux loss2: 0.7770373821258545, total loss: 1.359291911125183
15th Epoch, 5535th Step, learning rate = 0.009444758318581518 - Loss: 0.7121731638908386, aux loss1: 1.256151795387268, 
		 aux loss2: 0.8096407651901245, total loss: 1.4128750562667847
15th Epoch, 5540th Step, learning rate = 0.009444255133377797 - Loss: 0.4153159260749817, aux loss1: 0.914965033531189, 
		 aux loss2: 0.4961191415786743, total loss: 0.8882530927658081
15th Epoch, 5545th Step, learning rate = 0.00944375194519523 - Loss: 0.6323128938674927, aux loss1: 1.113747239112854, 
		 aux loss2: 0.7115808129310608, total loss: 1.25106942653656
15th Epoch, 5550th Step, learning rate = 0.009443248754033623 - Loss: 0.5128614902496338, aux loss1: 0.9743380546569824, 
		 aux loss2: 0.5873676538467407, total loss: 1.0401099920272827
15th Epoch, 5555th Step, learning rate = 0.009442745559892782 - Loss: 0.6181448698043823, aux loss1: 1.0997811555862427, 
		 aux loss2: 0.7158752679824829, total loss: 1.2344293594360352
15th Epoch, 5560th Step, learning rate = 0.009442242362772512 - Loss: 0.5194128751754761, aux loss1: 1.046106219291687, 
		 aux loss2: 0.6020947694778442, total loss: 1.074082612991333
15th Epoch, 5565th Step, learning rate = 0.00944173916267262 - Loss: 0.4901408553123474, aux loss1: 0.9741770029067993, 
		 aux loss2: 0.5765931606292725, total loss: 1.013031244277954
16th Epoch, 5570th Step, learning rate = 0.009441235959592911 - Loss: 0.6423875093460083, aux loss1: 1.2134625911712646, 
		 aux loss2: 0.7342812418937683, total loss: 1.3001388311386108
16th Epoch, 5575th Step, learning rate = 0.009440732753533193 - Loss: 0.7619321942329407, aux loss1: 1.309995412826538, 
		 aux loss2: 0.875623881816864, total loss: 1.5051803588867188
16th Epoch, 5580th Step, learning rate = 0.00944022954449327 - Loss: 0.6006569266319275, aux loss1: 1.065125584602356, 
		 aux loss2: 0.6584725379943848, total loss: 1.1835836172103882
16th Epoch, 5585th Step, learning rate = 0.00943972633247295 - Loss: 0.6612459421157837, aux loss1: 1.1093372106552124, 
		 aux loss2: 0.7519721984863281, total loss: 1.2948360443115234
16th Epoch, 5590th Step, learning rate = 0.009439223117472034 - Loss: 0.6637265682220459, aux loss1: 1.141684651374817, 
		 aux loss2: 0.7174906134605408, total loss: 1.293228268623352
16th Epoch, 5595th Step, learning rate = 0.009438719899490331 - Loss: 0.5434660911560059, aux loss1: 1.0270483493804932, 
		 aux loss2: 0.6132015585899353, total loss: 1.0968612432479858
16th Epoch, 5600th Step, learning rate = 0.009438216678527648 - Loss: 0.8124213814735413, aux loss1: 1.2678102254867554, 
		 aux loss2: 0.8826709985733032, total loss: 1.545832872390747
<5600th step>
*************************** Test ***************************
time:3m 17s, 5600th Step, Loss: 1.1372839212417603, Mean IoU = 23.410%
************************************************************
16th Epoch, 5605th Step, learning rate = 0.009437713454583788 - Loss: 0.47078844904899597, aux loss1: 0.8332769274711609, 
		 aux loss2: 0.5354342460632324, total loss: 0.9349452257156372
16th Epoch, 5610th Step, learning rate = 0.009437210227658558 - Loss: 0.42863360047340393, aux loss1: 0.8842006325721741, 
		 aux loss2: 0.5064286589622498, total loss: 0.8964652419090271
16th Epoch, 5615th Step, learning rate = 0.009436706997751764 - Loss: 0.48465412855148315, aux loss1: 0.9186478853225708, 
		 aux loss2: 0.5484824776649475, total loss: 0.9796415567398071
16th Epoch, 5620th Step, learning rate = 0.009436203764863213 - Loss: 0.6346387267112732, aux loss1: 1.0720160007476807, 
		 aux loss2: 0.7181656360626221, total loss: 1.2435097694396973
16th Epoch, 5625th Step, learning rate = 0.009435700528992709 - Loss: 0.4941772222518921, aux loss1: 0.9443157911300659, 
		 aux loss2: 0.5843933820724487, total loss: 1.0112292766571045
16th Epoch, 5630th Step, learning rate = 0.009435197290140055 - Loss: 0.5996061563491821, aux loss1: 1.043121576309204, 
		 aux loss2: 0.6797614097595215, total loss: 1.184447169303894
16th Epoch, 5635th Step, learning rate = 0.009434694048305062 - Loss: 0.5867805480957031, aux loss1: 0.9608358144760132, 
		 aux loss2: 0.6404798626899719, total loss: 1.131223201751709
16th Epoch, 5640th Step, learning rate = 0.009434190803487532 - Loss: 0.5240548253059387, aux loss1: 0.9941666722297668, 
		 aux loss2: 0.6168913245201111, total loss: 1.0690613985061646
16th Epoch, 5645th Step, learning rate = 0.009433687555687272 - Loss: 0.5726215839385986, aux loss1: 1.0612144470214844, 
		 aux loss2: 0.6735129952430725, total loss: 1.1603912115097046
16th Epoch, 5650th Step, learning rate = 0.009433184304904084 - Loss: 0.6057034134864807, aux loss1: 1.1248557567596436, 
		 aux loss2: 0.6958924531936646, total loss: 1.2215172052383423
16th Epoch, 5655th Step, learning rate = 0.00943268105113778 - Loss: 0.48162758350372314, aux loss1: 0.9708142876625061, 
		 aux loss2: 0.5734006762504578, total loss: 1.0022320747375488
16th Epoch, 5660th Step, learning rate = 0.009432177794388161 - Loss: 0.6021861433982849, aux loss1: 1.0939230918884277, 
		 aux loss2: 0.6827439665794373, total loss: 1.203460693359375
16th Epoch, 5665th Step, learning rate = 0.009431674534655031 - Loss: 0.5034173727035522, aux loss1: 0.9711458683013916, 
		 aux loss2: 0.5706341862678528, total loss: 1.0230149030685425
16th Epoch, 5670th Step, learning rate = 0.0094311712719382 - Loss: 0.6761882901191711, aux loss1: 1.2698907852172852, 
		 aux loss2: 0.7873751521110535, total loss: 1.3721057176589966
16th Epoch, 5675th Step, learning rate = 0.00943066800623747 - Loss: 0.4778049886226654, aux loss1: 0.947853684425354, 
		 aux loss2: 0.5622147917747498, total loss: 0.9870470762252808
16th Epoch, 5680th Step, learning rate = 0.009430164737552649 - Loss: 0.6318996548652649, aux loss1: 1.2080448865890503, 
		 aux loss2: 0.7687098383903503, total loss: 1.3017970323562622
16th Epoch, 5685th Step, learning rate = 0.00942966146588354 - Loss: 0.7227105498313904, aux loss1: 1.2108486890792847, 
		 aux loss2: 0.7922197580337524, total loss: 1.402853012084961
16th Epoch, 5690th Step, learning rate = 0.00942915819122995 - Loss: 0.6704189777374268, aux loss1: 1.187229037284851, 
		 aux loss2: 0.7733617424964905, total loss: 1.3359324932098389
16th Epoch, 5695th Step, learning rate = 0.009428654913591681 - Loss: 0.67095947265625, aux loss1: 1.165215253829956, 
		 aux loss2: 0.7852290272712708, total loss: 1.334615707397461
16th Epoch, 5700th Step, learning rate = 0.009428151632968543 - Loss: 0.48024532198905945, aux loss1: 0.9472910165786743, 
		 aux loss2: 0.5521154403686523, total loss: 0.985278844833374
<5700th step>
*************************** Test ***************************
time:3m 16s, 5700th Step, Loss: 0.6772172451019287, Mean IoU = 32.557%
************************************************************
16th Epoch, 5705th Step, learning rate = 0.00942764834936034 - Loss: 0.7177636623382568, aux loss1: 1.2409074306488037, 
		 aux loss2: 0.8017404675483704, total loss: 1.4107321500778198
16th Epoch, 5710th Step, learning rate = 0.009427145062766875 - Loss: 0.4247157871723175, aux loss1: 0.8346137404441833, 
		 aux loss2: 0.48063409328460693, total loss: 0.8673535585403442
16th Epoch, 5715th Step, learning rate = 0.009426641773187954 - Loss: 0.42880168557167053, aux loss1: 0.8885135650634766, 
		 aux loss2: 0.5019780397415161, total loss: 0.8961470127105713
16th Epoch, 5720th Step, learning rate = 0.009426138480623384 - Loss: 0.5606802105903625, aux loss1: 1.0558514595031738, 
		 aux loss2: 0.6244169473648071, total loss: 1.1272025108337402
16th Epoch, 5725th Step, learning rate = 0.009425635185072967 - Loss: 0.7202051281929016, aux loss1: 1.1521670818328857, 
		 aux loss2: 0.8109509944915771, total loss: 1.3902356624603271
16th Epoch, 5730th Step, learning rate = 0.00942513188653651 - Loss: 0.521657407283783, aux loss1: 1.0131186246871948, 
		 aux loss2: 0.6261605620384216, total loss: 1.0760571956634521
16th Epoch, 5735th Step, learning rate = 0.00942462858501382 - Loss: 0.46354109048843384, aux loss1: 0.8619012832641602, 
		 aux loss2: 0.5367584228515625, total loss: 0.9368148446083069
16th Epoch, 5740th Step, learning rate = 0.0094241252805047 - Loss: 0.5820609331130981, aux loss1: 1.0700384378433228, 
		 aux loss2: 0.6765735745429993, total loss: 1.1737018823623657
16th Epoch, 5745th Step, learning rate = 0.009423621973008955 - Loss: 0.5000987648963928, aux loss1: 0.9346699714660645, 
		 aux loss2: 0.5814183354377747, total loss: 1.0130671262741089
16th Epoch, 5750th Step, learning rate = 0.009423118662526389 - Loss: 0.5059998631477356, aux loss1: 0.9322255849838257, 
		 aux loss2: 0.5815354585647583, total loss: 1.0182816982269287
16th Epoch, 5755th Step, learning rate = 0.009422615349056808 - Loss: 0.6405598521232605, aux loss1: 1.1113405227661133, 
		 aux loss2: 0.7280873656272888, total loss: 1.2651969194412231
16th Epoch, 5760th Step, learning rate = 0.009422112032600018 - Loss: 0.5323113799095154, aux loss1: 1.040292739868164, 
		 aux loss2: 0.6204252243041992, total loss: 1.092569351196289
16th Epoch, 5765th Step, learning rate = 0.009421608713155826 - Loss: 0.6861159801483154, aux loss1: 1.1749533414840698, 
		 aux loss2: 0.799761950969696, total loss: 1.3585067987442017
16th Epoch, 5770th Step, learning rate = 0.00942110539072403 - Loss: 0.7033756375312805, aux loss1: 1.1555984020233154, 
		 aux loss2: 0.7781122326850891, total loss: 1.361299991607666
16th Epoch, 5775th Step, learning rate = 0.009420602065304443 - Loss: 0.5416601300239563, aux loss1: 1.0027751922607422, 
		 aux loss2: 0.6203228831291199, total loss: 1.090621829032898
16th Epoch, 5780th Step, learning rate = 0.009420098736896863 - Loss: 0.6117859482765198, aux loss1: 1.1608620882034302, 
		 aux loss2: 0.7242566347122192, total loss: 1.2497472763061523
16th Epoch, 5785th Step, learning rate = 0.009419595405501099 - Loss: 0.4905114769935608, aux loss1: 0.9896979928016663, 
		 aux loss2: 0.5945590734481812, total loss: 1.0252444744110107
16th Epoch, 5790th Step, learning rate = 0.009419092071116955 - Loss: 0.5016598105430603, aux loss1: 1.0808511972427368, 
		 aux loss2: 0.6004451513290405, total loss: 1.0660933256149292
16th Epoch, 5795th Step, learning rate = 0.009418588733744236 - Loss: 0.5045676827430725, aux loss1: 1.059927225112915, 
		 aux loss2: 0.5859473347663879, total loss: 1.056924819946289
16th Epoch, 5800th Step, learning rate = 0.009418085393382744 - Loss: 0.7609764933586121, aux loss1: 1.4662033319473267, 
		 aux loss2: 0.923540472984314, total loss: 1.5702537298202515
<5800th step>
*************************** Test ***************************
time:3m 15s, 5800th Step, Loss: 0.7791155576705933, Mean IoU = 31.697%
************************************************************
16th Epoch, 5805th Step, learning rate = 0.009417582050032288 - Loss: 0.58036208152771, aux loss1: 1.1320664882659912, 
		 aux loss2: 0.6538205742835999, total loss: 1.181510329246521
16th Epoch, 5810th Step, learning rate = 0.00941707870369267 - Loss: 0.45713335275650024, aux loss1: 0.9955925345420837, 
		 aux loss2: 0.5282503962516785, total loss: 0.9671112298965454
16th Epoch, 5815th Step, learning rate = 0.009416575354363696 - Loss: 0.5058899521827698, aux loss1: 1.0049632787704468, 
		 aux loss2: 0.6054552793502808, total loss: 1.0495610237121582
16th Epoch, 5820th Step, learning rate = 0.00941607200204517 - Loss: 0.5183024406433105, aux loss1: 1.0318547487258911, 
		 aux loss2: 0.606888473033905, total loss: 1.070614218711853
16th Epoch, 5825th Step, learning rate = 0.009415568646736898 - Loss: 0.5926212072372437, aux loss1: 1.1451740264892578, 
		 aux loss2: 0.690092921257019, total loss: 1.2122106552124023
16th Epoch, 5830th Step, learning rate = 0.009415065288438683 - Loss: 0.4233250319957733, aux loss1: 0.8355086445808411, 
		 aux loss2: 0.49094241857528687, total loss: 0.8703545928001404
16th Epoch, 5835th Step, learning rate = 0.00941456192715033 - Loss: 0.5864827036857605, aux loss1: 1.0554239749908447, 
		 aux loss2: 0.6684808135032654, total loss: 1.1705021858215332
16th Epoch, 5840th Step, learning rate = 0.009414058562871645 - Loss: 0.5487766265869141, aux loss1: 1.0489522218704224, 
		 aux loss2: 0.6302733421325684, total loss: 1.1155717372894287
16th Epoch, 5845th Step, learning rate = 0.009413555195602429 - Loss: 0.4891239404678345, aux loss1: 0.9706951975822449, 
		 aux loss2: 0.5680633187294006, total loss: 1.0075578689575195
16th Epoch, 5850th Step, learning rate = 0.009413051825342491 - Loss: 0.5427332520484924, aux loss1: 1.0187747478485107, 
		 aux loss2: 0.6260527968406677, total loss: 1.0987868309020996
16th Epoch, 5855th Step, learning rate = 0.009412548452091633 - Loss: 0.8317468762397766, aux loss1: 1.3447719812393188, 
		 aux loss2: 0.9337537288665771, total loss: 1.608680009841919
16th Epoch, 5860th Step, learning rate = 0.009412045075849659 - Loss: 0.6743552684783936, aux loss1: 1.1375418901443481, 
		 aux loss2: 0.7854724526405334, total loss: 1.3298068046569824
16th Epoch, 5865th Step, learning rate = 0.009411541696616375 - Loss: 0.4013744294643402, aux loss1: 0.7739837169647217, 
		 aux loss2: 0.4611784517765045, total loss: 0.8180409073829651
16th Epoch, 5870th Step, learning rate = 0.009411038314391586 - Loss: 0.6651051044464111, aux loss1: 1.2267563343048096, 
		 aux loss2: 0.7727105021476746, total loss: 1.3422162532806396
16th Epoch, 5875th Step, learning rate = 0.009410534929175094 - Loss: 0.5166497826576233, aux loss1: 1.0308611392974854, 
		 aux loss2: 0.585160493850708, total loss: 1.0599722862243652
16th Epoch, 5880th Step, learning rate = 0.009410031540966705 - Loss: 0.5742524266242981, aux loss1: 1.1683770418167114, 
		 aux loss2: 0.6911182403564453, total loss: 1.2012128829956055
16th Epoch, 5885th Step, learning rate = 0.009409528149766224 - Loss: 0.5968822836875916, aux loss1: 1.1540404558181763, 
		 aux loss2: 0.7028619050979614, total loss: 1.2242392301559448
16th Epoch, 5890th Step, learning rate = 0.009409024755573453 - Loss: 0.6996008157730103, aux loss1: 1.226850986480713, 
		 aux loss2: 0.7768140435218811, total loss: 1.3783817291259766
16th Epoch, 5895th Step, learning rate = 0.009408521358388199 - Loss: 0.5619992613792419, aux loss1: 1.1482757329940796, 
		 aux loss2: 0.6654695868492126, total loss: 1.1726698875427246
16th Epoch, 5900th Step, learning rate = 0.009408017958210264 - Loss: 0.6035396456718445, aux loss1: 1.0672216415405273, 
		 aux loss2: 0.6652641296386719, total loss: 1.1898118257522583
<5900th step>
*************************** Test ***************************
time:3m 13s, 5900th Step, Loss: 0.7031742334365845, Mean IoU = 30.671%
************************************************************
16th Epoch, 5905th Step, learning rate = 0.009407514555039454 - Loss: 0.5136227607727051, aux loss1: 0.9613001346588135, 
		 aux loss2: 0.5861717462539673, total loss: 1.036481499671936
16th Epoch, 5910th Step, learning rate = 0.009407011148875573 - Loss: 0.5704451203346252, aux loss1: 1.0966485738754272, 
		 aux loss2: 0.6742268800735474, total loss: 1.1691304445266724
16th Epoch, 5915th Step, learning rate = 0.009406507739718425 - Loss: 0.5070725083351135, aux loss1: 0.9430986046791077, 
		 aux loss2: 0.5718063116073608, total loss: 1.0187246799468994
16th Epoch, 5920th Step, learning rate = 0.009406004327567814 - Loss: 0.5477697849273682, aux loss1: 1.1000895500183105, 
		 aux loss2: 0.648949146270752, total loss: 1.137376308441162
16th Epoch, 5925th Step, learning rate = 0.009405500912423545 - Loss: 0.49674665927886963, aux loss1: 1.0509065389633179, 
		 aux loss2: 0.5854902863502502, total loss: 1.0462146997451782
16th Epoch, 5930th Step, learning rate = 0.00940499749428542 - Loss: 0.6163729429244995, aux loss1: 1.165050983428955, 
		 aux loss2: 0.7195897698402405, total loss: 1.253724217414856
16th Epoch, 5935th Step, learning rate = 0.009404494073153245 - Loss: 0.5615904331207275, aux loss1: 1.0221683979034424, 
		 aux loss2: 0.6447386145591736, total loss: 1.1261364221572876
17th Epoch, 5940th Step, learning rate = 0.009403990649026823 - Loss: 0.5689778327941895, aux loss1: 1.0589919090270996, 
		 aux loss2: 0.6513689160346985, total loss: 1.1472229957580566
17th Epoch, 5945th Step, learning rate = 0.009403487221905961 - Loss: 0.5613038539886475, aux loss1: 1.0627262592315674, 
		 aux loss2: 0.6504873037338257, total loss: 1.1403166055679321
17th Epoch, 5950th Step, learning rate = 0.00940298379179046 - Loss: 0.6112304329872131, aux loss1: 1.1356228590011597, 
		 aux loss2: 0.7167881727218628, total loss: 1.2386325597763062
17th Epoch, 5955th Step, learning rate = 0.009402480358680123 - Loss: 0.5410200953483582, aux loss1: 1.0559959411621094, 
		 aux loss2: 0.6295759677886963, total loss: 1.1096493005752563
17th Epoch, 5960th Step, learning rate = 0.009401976922574759 - Loss: 0.5436838865280151, aux loss1: 0.9891438484191895, 
		 aux loss2: 0.636293888092041, total loss: 1.0949445962905884
17th Epoch, 5965th Step, learning rate = 0.009401473483474167 - Loss: 0.5442426800727844, aux loss1: 1.0332865715026855, 
		 aux loss2: 0.6470652222633362, total loss: 1.1130547523498535
17th Epoch, 5970th Step, learning rate = 0.009400970041378152 - Loss: 0.48612913489341736, aux loss1: 0.9260255098342896, 
		 aux loss2: 0.5549707412719727, total loss: 0.9859250783920288
17th Epoch, 5975th Step, learning rate = 0.009400466596286522 - Loss: 0.526543378829956, aux loss1: 1.1002253293991089, 
		 aux loss2: 0.6281281113624573, total loss: 1.1078622341156006
17th Epoch, 5980th Step, learning rate = 0.009399963148199074 - Loss: 0.4331461489200592, aux loss1: 0.9511566162109375, 
		 aux loss2: 0.5237485766410828, total loss: 0.9279925227165222
17th Epoch, 5985th Step, learning rate = 0.009399459697115616 - Loss: 0.4291467070579529, aux loss1: 0.8961122632026672, 
		 aux loss2: 0.5114348530769348, total loss: 0.9025543332099915
17th Epoch, 5990th Step, learning rate = 0.009398956243035952 - Loss: 0.5947263240814209, aux loss1: 1.1394845247268677, 
		 aux loss2: 0.691480278968811, total loss: 1.2131638526916504
17th Epoch, 5995th Step, learning rate = 0.009398452785959887 - Loss: 0.5775838494300842, aux loss1: 1.1640466451644897, 
		 aux loss2: 0.6778598427772522, total loss: 1.197941780090332
17th Epoch, 6000th Step, learning rate = 0.009397949325887223 - Loss: 0.5501357316970825, aux loss1: 1.0620753765106201, 
		 aux loss2: 0.6613295674324036, total loss: 1.13329017162323
<6000th step>
*************************** Test ***************************
time:3m 14s, 6000th Step, Loss: 0.6963634490966797, Mean IoU = 30.660%
************************************************************
17th Epoch, 6005th Step, learning rate = 0.009397445862817762 - Loss: 0.6896175742149353, aux loss1: 1.1744251251220703, 
		 aux loss2: 0.7146965861320496, total loss: 1.3278237581253052
17th Epoch, 6010th Step, learning rate = 0.00939694239675131 - Loss: 0.4443371295928955, aux loss1: 0.929086446762085, 
		 aux loss2: 0.5244314670562744, total loss: 0.9328356981277466
17th Epoch, 6015th Step, learning rate = 0.009396438927687673 - Loss: 0.6670042872428894, aux loss1: 1.1397989988327026, 
		 aux loss2: 0.7578858733177185, total loss: 1.3120983839035034
17th Epoch, 6020th Step, learning rate = 0.00939593545562665 - Loss: 0.4985015094280243, aux loss1: 0.9243223667144775, 
		 aux loss2: 0.5738568902015686, total loss: 1.0053409337997437
17th Epoch, 6025th Step, learning rate = 0.009395431980568048 - Loss: 0.5984330773353577, aux loss1: 1.093129277229309, 
		 aux loss2: 0.7013633251190186, total loss: 1.2069171667099
17th Epoch, 6030th Step, learning rate = 0.00939492850251167 - Loss: 0.40331345796585083, aux loss1: 0.912037193775177, 
		 aux loss2: 0.48937007784843445, total loss: 0.8726726174354553
17th Epoch, 6035th Step, learning rate = 0.009394425021457316 - Loss: 0.5532270073890686, aux loss1: 1.0568881034851074, 
		 aux loss2: 0.6469267010688782, total loss: 1.1290640830993652
17th Epoch, 6040th Step, learning rate = 0.009393921537404796 - Loss: 0.46254363656044006, aux loss1: 1.102799415588379, 
		 aux loss2: 0.5655227303504944, total loss: 1.019592523574829
17th Epoch, 6045th Step, learning rate = 0.009393418050353907 - Loss: 0.6035386323928833, aux loss1: 1.0687869787216187, 
		 aux loss2: 0.6715448498725891, total loss: 1.1927926540374756
17th Epoch, 6050th Step, learning rate = 0.00939291456030446 - Loss: 0.7797751426696777, aux loss1: 1.2625627517700195, 
		 aux loss2: 0.8565930128097534, total loss: 1.5011811256408691
17th Epoch, 6055th Step, learning rate = 0.009392411067256252 - Loss: 0.5779310464859009, aux loss1: 1.0434768199920654, 
		 aux loss2: 0.6624411344528198, total loss: 1.1559505462646484
17th Epoch, 6060th Step, learning rate = 0.00939190757120909 - Loss: 0.4486028850078583, aux loss1: 0.9115390181541443, 
		 aux loss2: 0.5149023532867432, total loss: 0.9280255436897278
17th Epoch, 6065th Step, learning rate = 0.009391404072162777 - Loss: 0.445975661277771, aux loss1: 0.8879388570785522, 
		 aux loss2: 0.5252106785774231, total loss: 0.9224416017532349
17th Epoch, 6070th Step, learning rate = 0.009390900570117114 - Loss: 0.8620970845222473, aux loss1: 1.4362075328826904, 
		 aux loss2: 1.0016738176345825, total loss: 1.6936289072036743
17th Epoch, 6075th Step, learning rate = 0.009390397065071908 - Loss: 0.5358625054359436, aux loss1: 0.9860969185829163, 
		 aux loss2: 0.6198329329490662, total loss: 1.0796247720718384
17th Epoch, 6080th Step, learning rate = 0.00938989355702696 - Loss: 0.5295848846435547, aux loss1: 1.025831937789917, 
		 aux loss2: 0.6286235451698303, total loss: 1.0887839794158936
17th Epoch, 6085th Step, learning rate = 0.009389390045982075 - Loss: 0.5216991305351257, aux loss1: 1.005713701248169, 
		 aux loss2: 0.6046523451805115, total loss: 1.0652742385864258
17th Epoch, 6090th Step, learning rate = 0.009388886531937056 - Loss: 0.6211775541305542, aux loss1: 1.1248281002044678, 
		 aux loss2: 0.7282600402832031, total loss: 1.2499300241470337
17th Epoch, 6095th Step, learning rate = 0.009388383014891706 - Loss: 0.6255689263343811, aux loss1: 1.194766640663147, 
		 aux loss2: 0.7461596131324768, total loss: 1.2824627161026
17th Epoch, 6100th Step, learning rate = 0.009387879494845828 - Loss: 0.44237956404685974, aux loss1: 0.9662832021713257, 
		 aux loss2: 0.5180783271789551, total loss: 0.939495861530304
<6100th step>
*************************** Test ***************************
time:3m 15s, 6100th Step, Loss: 0.8145869374275208, Mean IoU = 30.320%
************************************************************
17th Epoch, 6105th Step, learning rate = 0.009387375971799226 - Loss: 0.5017216205596924, aux loss1: 0.9959065914154053, 
		 aux loss2: 0.578120231628418, total loss: 1.031741738319397
17th Epoch, 6110th Step, learning rate = 0.009386872445751702 - Loss: 0.46423959732055664, aux loss1: 0.9748106002807617, 
		 aux loss2: 0.5652799606323242, total loss: 0.9827947616577148
17th Epoch, 6115th Step, learning rate = 0.00938636891670306 - Loss: 0.6510821580886841, aux loss1: 1.1053006649017334, 
		 aux loss2: 0.7500479817390442, total loss: 1.282691478729248
17th Epoch, 6120th Step, learning rate = 0.009385865384653105 - Loss: 0.4857572317123413, aux loss1: 1.038718581199646, 
		 aux loss2: 0.5754882097244263, total loss: 1.0275681018829346
17th Epoch, 6125th Step, learning rate = 0.009385361849601637 - Loss: 0.5687722563743591, aux loss1: 1.0272397994995117, 
		 aux loss2: 0.6803597211837769, total loss: 1.1490881443023682
17th Epoch, 6130th Step, learning rate = 0.009384858311548462 - Loss: 0.6160597205162048, aux loss1: 1.1057604551315308, 
		 aux loss2: 0.7005583643913269, total loss: 1.2280112504959106
17th Epoch, 6135th Step, learning rate = 0.00938435477049338 - Loss: 0.580222487449646, aux loss1: 1.0831003189086914, 
		 aux loss2: 0.6560439467430115, total loss: 1.1675701141357422
17th Epoch, 6140th Step, learning rate = 0.009383851226436198 - Loss: 0.7694355249404907, aux loss1: 1.2883087396621704, 
		 aux loss2: 0.8771213889122009, total loss: 1.5067766904830933
17th Epoch, 6145th Step, learning rate = 0.009383347679376717 - Loss: 0.5218284726142883, aux loss1: 1.0139451026916504, 
		 aux loss2: 0.5992394089698792, total loss: 1.065707802772522
17th Epoch, 6150th Step, learning rate = 0.00938284412931474 - Loss: 0.44348782300949097, aux loss1: 0.9000222086906433, 
		 aux loss2: 0.5261960029602051, total loss: 0.9239729642868042
17th Epoch, 6155th Step, learning rate = 0.009382340576250071 - Loss: 0.5138490200042725, aux loss1: 1.007720708847046, 
		 aux loss2: 0.592897891998291, total loss: 1.0533243417739868
17th Epoch, 6160th Step, learning rate = 0.00938183702018251 - Loss: 0.4747093617916107, aux loss1: 1.030002474784851, 
		 aux loss2: 0.5857428312301636, total loss: 1.0180072784423828
17th Epoch, 6165th Step, learning rate = 0.009381333461111864 - Loss: 0.6492403745651245, aux loss1: 1.2411549091339111, 
		 aux loss2: 0.7554610967636108, total loss: 1.323771357536316
17th Epoch, 6170th Step, learning rate = 0.009380829899037935 - Loss: 0.6438010334968567, aux loss1: 1.1588133573532104, 
		 aux loss2: 0.7359138131141663, total loss: 1.2858105897903442
17th Epoch, 6175th Step, learning rate = 0.009380326333960525 - Loss: 0.8055508732795715, aux loss1: 1.2982497215270996, 
		 aux loss2: 0.9006576538085938, total loss: 1.5552889108657837
17th Epoch, 6180th Step, learning rate = 0.009379822765879437 - Loss: 0.5914809107780457, aux loss1: 1.0154553651809692, 
		 aux loss2: 0.6657690405845642, total loss: 1.16242516040802
17th Epoch, 6185th Step, learning rate = 0.009379319194794473 - Loss: 0.4387393593788147, aux loss1: 0.8612701296806335, 
		 aux loss2: 0.5029999017715454, total loss: 0.8983203768730164
17th Epoch, 6190th Step, learning rate = 0.009378815620705437 - Loss: 0.38527798652648926, aux loss1: 0.840313196182251, 
		 aux loss2: 0.4601094126701355, total loss: 0.8214157223701477
17th Epoch, 6195th Step, learning rate = 0.009378312043612134 - Loss: 0.5590016841888428, aux loss1: 1.087174892425537, 
		 aux loss2: 0.6427434682846069, total loss: 1.1422514915466309
17th Epoch, 6200th Step, learning rate = 0.009377808463514364 - Loss: 0.5629730820655823, aux loss1: 1.0349831581115723, 
		 aux loss2: 0.6541218757629395, total loss: 1.1351168155670166
<6200th step>
*************************** Test ***************************
time:3m 12s, 6200th Step, Loss: 0.6766997575759888, Mean IoU = 32.846%
************************************************************
17th Epoch, 6205th Step, learning rate = 0.009377304880411929 - Loss: 0.3965222239494324, aux loss1: 0.8772358894348145, 
		 aux loss2: 0.4825038015842438, total loss: 0.8526945114135742
17th Epoch, 6210th Step, learning rate = 0.009376801294304635 - Loss: 0.7493603825569153, aux loss1: 1.2230852842330933, 
		 aux loss2: 0.8331566452980042, total loss: 1.4495487213134766
17th Epoch, 6215th Step, learning rate = 0.009376297705192283 - Loss: 0.5173699259757996, aux loss1: 1.0360097885131836, 
		 aux loss2: 0.596837043762207, total loss: 1.0669076442718506
17th Epoch, 6220th Step, learning rate = 0.009375794113074674 - Loss: 0.5579122304916382, aux loss1: 1.1405060291290283, 
		 aux loss2: 0.6468864679336548, total loss: 1.1588186025619507
17th Epoch, 6225th Step, learning rate = 0.009375290517951614 - Loss: 0.5029035210609436, aux loss1: 1.032478928565979, 
		 aux loss2: 0.5928047299385071, total loss: 1.0497691631317139
17th Epoch, 6230th Step, learning rate = 0.009374786919822905 - Loss: 0.5873726606369019, aux loss1: 1.0169683694839478, 
		 aux loss2: 0.6821539998054504, total loss: 1.1653248071670532
17th Epoch, 6235th Step, learning rate = 0.009374283318688347 - Loss: 0.4653221070766449, aux loss1: 0.893836498260498, 
		 aux loss2: 0.5424694418907166, total loss: 0.9504608511924744
17th Epoch, 6240th Step, learning rate = 0.009373779714547744 - Loss: 0.5419549942016602, aux loss1: 1.0685975551605225, 
		 aux loss2: 0.6200082898139954, total loss: 1.1105376482009888
17th Epoch, 6245th Step, learning rate = 0.0093732761074009 - Loss: 0.5013625621795654, aux loss1: 0.9811667203903198, 
		 aux loss2: 0.606705904006958, total loss: 1.0383949279785156
17th Epoch, 6250th Step, learning rate = 0.009372772497247618 - Loss: 0.6034306287765503, aux loss1: 1.14161217212677, 
		 aux loss2: 0.6963774561882019, total loss: 1.224465250968933
17th Epoch, 6255th Step, learning rate = 0.009372268884087698 - Loss: 0.7569405436515808, aux loss1: 1.2968050241470337, 
		 aux loss2: 0.851038932800293, total loss: 1.486397624015808
17th Epoch, 6260th Step, learning rate = 0.009371765267920945 - Loss: 0.4457384943962097, aux loss1: 1.02918541431427, 
		 aux loss2: 0.5437279343605042, total loss: 0.9719853401184082
17th Epoch, 6265th Step, learning rate = 0.009371261648747159 - Loss: 0.48166829347610474, aux loss1: 0.9178164005279541, 
		 aux loss2: 0.5394213795661926, total loss: 0.972781777381897
17th Epoch, 6270th Step, learning rate = 0.009370758026566143 - Loss: 0.47747528553009033, aux loss1: 0.9603540301322937, 
		 aux loss2: 0.5424566864967346, total loss: 0.9825641512870789
17th Epoch, 6275th Step, learning rate = 0.009370254401377702 - Loss: 0.4579874873161316, aux loss1: 0.9784414172172546, 
		 aux loss2: 0.5390344858169556, total loss: 0.9671337008476257
17th Epoch, 6280th Step, learning rate = 0.009369750773181636 - Loss: 0.5325586199760437, aux loss1: 1.1517566442489624, 
		 aux loss2: 0.6313188076019287, total loss: 1.130613088607788
17th Epoch, 6285th Step, learning rate = 0.009369247141977748 - Loss: 0.485164076089859, aux loss1: 0.9665403962135315, 
		 aux loss2: 0.5846219658851624, total loss: 1.0089750289916992
17th Epoch, 6290th Step, learning rate = 0.00936874350776584 - Loss: 0.4623723328113556, aux loss1: 1.0638130903244019, 
		 aux loss2: 0.5696842074394226, total loss: 1.0093899965286255
17th Epoch, 6295th Step, learning rate = 0.009368239870545716 - Loss: 0.6799361109733582, aux loss1: 1.1885120868682861, 
		 aux loss2: 0.7914047241210938, total loss: 1.3530516624450684
17th Epoch, 6300th Step, learning rate = 0.009367736230317175 - Loss: 0.5751003623008728, aux loss1: 1.1639065742492676, 
		 aux loss2: 0.6930034160614014, total loss: 1.2014737129211426
<6300th step>
*************************** Test ***************************
time:3m 15s, 6300th Step, Loss: 0.7343178391456604, Mean IoU = 31.739%
************************************************************
17th Epoch, 6305th Step, learning rate = 0.009367232587080025 - Loss: 0.6668280363082886, aux loss1: 1.2471883296966553, 
		 aux loss2: 0.8235843777656555, total loss: 1.3704183101654053
18th Epoch, 6310th Step, learning rate = 0.009366728940834061 - Loss: 0.371674507856369, aux loss1: 0.8448569178581238, 
		 aux loss2: 0.4552624225616455, total loss: 0.8072365522384644
18th Epoch, 6315th Step, learning rate = 0.009366225291579091 - Loss: 0.401548832654953, aux loss1: 0.7784804701805115, 
		 aux loss2: 0.4971556067466736, total loss: 0.8339552283287048
18th Epoch, 6320th Step, learning rate = 0.009365721639314916 - Loss: 0.6693947911262512, aux loss1: 1.0887901782989502, 
		 aux loss2: 0.7639041543006897, total loss: 1.301593542098999
18th Epoch, 6325th Step, learning rate = 0.009365217984041337 - Loss: 0.5118677020072937, aux loss1: 0.9797751307487488, 
		 aux loss2: 0.5911970138549805, total loss: 1.0422790050506592
18th Epoch, 6330th Step, learning rate = 0.009364714325758156 - Loss: 0.5220961570739746, aux loss1: 1.0520023107528687, 
		 aux loss2: 0.6001415848731995, total loss: 1.0777535438537598
18th Epoch, 6335th Step, learning rate = 0.009364210664465177 - Loss: 0.4744824469089508, aux loss1: 0.9061260223388672, 
		 aux loss2: 0.5426216125488281, total loss: 0.9633688926696777
18th Epoch, 6340th Step, learning rate = 0.009363707000162199 - Loss: 0.5160831212997437, aux loss1: 1.1168113946914673, 
		 aux loss2: 0.6247200965881348, total loss: 1.1010146141052246
18th Epoch, 6345th Step, learning rate = 0.009363203332849027 - Loss: 0.38507816195487976, aux loss1: 0.8784679174423218, 
		 aux loss2: 0.4704495668411255, total loss: 0.8367984294891357
18th Epoch, 6350th Step, learning rate = 0.009362699662525464 - Loss: 0.5522047281265259, aux loss1: 1.0797768831253052, 
		 aux loss2: 0.6414674520492554, total loss: 1.1327247619628906
18th Epoch, 6355th Step, learning rate = 0.009362195989191309 - Loss: 0.5028472542762756, aux loss1: 0.956235945224762, 
		 aux loss2: 0.5788903832435608, total loss: 1.021274209022522
18th Epoch, 6360th Step, learning rate = 0.009361692312846363 - Loss: 0.5898540019989014, aux loss1: 1.1666557788848877, 
		 aux loss2: 0.6925011277198792, total loss: 1.2168512344360352
18th Epoch, 6365th Step, learning rate = 0.009361188633490433 - Loss: 0.4102247953414917, aux loss1: 0.8566070795059204, 
		 aux loss2: 0.47912168502807617, total loss: 0.8588556051254272
18th Epoch, 6370th Step, learning rate = 0.009360684951123318 - Loss: 0.428404837846756, aux loss1: 0.8714499473571777, 
		 aux loss2: 0.5002314448356628, total loss: 0.88993239402771
18th Epoch, 6375th Step, learning rate = 0.00936018126574482 - Loss: 0.5522263646125793, aux loss1: 1.0356695652008057, 
		 aux loss2: 0.633273184299469, total loss: 1.1162365674972534
18th Epoch, 6380th Step, learning rate = 0.009359677577354742 - Loss: 0.5705934166908264, aux loss1: 1.1480754613876343, 
		 aux loss2: 0.6754966974258423, total loss: 1.1852147579193115
18th Epoch, 6385th Step, learning rate = 0.009359173885952884 - Loss: 0.6968297958374023, aux loss1: 1.0780951976776123, 
		 aux loss2: 0.7559834122657776, total loss: 1.3226518630981445
18th Epoch, 6390th Step, learning rate = 0.00935867019153905 - Loss: 0.4175100028514862, aux loss1: 0.8884954452514648, 
		 aux loss2: 0.5106143951416016, total loss: 0.8883044123649597
18th Epoch, 6395th Step, learning rate = 0.009358166494113042 - Loss: 0.7042076587677002, aux loss1: 1.2309333086013794, 
		 aux loss2: 0.7984786629676819, total loss: 1.3928791284561157
18th Epoch, 6400th Step, learning rate = 0.009357662793674656 - Loss: 0.5410532355308533, aux loss1: 1.0157647132873535, 
		 aux loss2: 0.6250666379928589, total loss: 1.0958093404769897
<6400th step>
*************************** Test ***************************
time:3m 17s, 6400th Step, Loss: 0.6799194812774658, Mean IoU = 33.384%
************************************************************
18th Epoch, 6405th Step, learning rate = 0.009357159090223702 - Loss: 0.4765254557132721, aux loss1: 0.958713948726654, 
		 aux loss2: 0.5634558796882629, total loss: 0.9895219802856445
18th Epoch, 6410th Step, learning rate = 0.009356655383759979 - Loss: 0.6813414692878723, aux loss1: 1.2342559099197388, 
		 aux loss2: 0.8091793656349182, total loss: 1.3752899169921875
18th Epoch, 6415th Step, learning rate = 0.009356151674283287 - Loss: 0.8934729099273682, aux loss1: 1.3946579694747925, 
		 aux loss2: 1.0216554403305054, total loss: 1.7205325365066528
18th Epoch, 6420th Step, learning rate = 0.00935564796179343 - Loss: 0.5579258799552917, aux loss1: 1.209397315979004, 
		 aux loss2: 0.6775963306427002, total loss: 1.1917836666107178
18th Epoch, 6425th Step, learning rate = 0.009355144246290206 - Loss: 0.6807196140289307, aux loss1: 1.2006787061691284, 
		 aux loss2: 0.7941445112228394, total loss: 1.3585810661315918
18th Epoch, 6430th Step, learning rate = 0.009354640527773421 - Loss: 0.5463570952415466, aux loss1: 1.0215517282485962, 
		 aux loss2: 0.6440737247467041, total loss: 1.1104521751403809
18th Epoch, 6435th Step, learning rate = 0.009354136806242875 - Loss: 0.6732494831085205, aux loss1: 1.1242740154266357, 
		 aux loss2: 0.7690186500549316, total loss: 1.3181390762329102
18th Epoch, 6440th Step, learning rate = 0.009353633081698369 - Loss: 0.5485885739326477, aux loss1: 1.0084311962127686, 
		 aux loss2: 0.6349241137504578, total loss: 1.1050876379013062
18th Epoch, 6445th Step, learning rate = 0.009353129354139707 - Loss: 0.6622886657714844, aux loss1: 1.1375236511230469, 
		 aux loss2: 0.7595381736755371, total loss: 1.3073610067367554
18th Epoch, 6450th Step, learning rate = 0.009352625623566686 - Loss: 0.6533690690994263, aux loss1: 1.2422025203704834, 
		 aux loss2: 0.7666930556297302, total loss: 1.3327070474624634
18th Epoch, 6455th Step, learning rate = 0.009352121889979111 - Loss: 0.5057417750358582, aux loss1: 0.9863592386245728, 
		 aux loss2: 0.5960568785667419, total loss: 1.0400723218917847
18th Epoch, 6460th Step, learning rate = 0.009351618153376786 - Loss: 0.4443100690841675, aux loss1: 0.9251357913017273, 
		 aux loss2: 0.5454654097557068, total loss: 0.9400370121002197
18th Epoch, 6465th Step, learning rate = 0.009351114413759506 - Loss: 0.4329523742198944, aux loss1: 0.8423917293548584, 
		 aux loss2: 0.4929712414741516, total loss: 0.882858395576477
18th Epoch, 6470th Step, learning rate = 0.009350610671127076 - Loss: 1.015415072441101, aux loss1: 1.6568114757537842, 
		 aux loss2: 1.161858081817627, total loss: 1.9772018194198608
18th Epoch, 6475th Step, learning rate = 0.009350106925479298 - Loss: 0.8600339889526367, aux loss1: 1.3653359413146973, 
		 aux loss2: 0.9648693203926086, total loss: 1.6555824279785156
18th Epoch, 6480th Step, learning rate = 0.009349603176815975 - Loss: 0.6114392280578613, aux loss1: 1.1839275360107422, 
		 aux loss2: 0.7126216292381287, total loss: 1.2516660690307617
18th Epoch, 6485th Step, learning rate = 0.009349099425136903 - Loss: 0.4523470997810364, aux loss1: 0.8573253154754639, 
		 aux loss2: 0.5171409845352173, total loss: 0.9164011478424072
18th Epoch, 6490th Step, learning rate = 0.009348595670441889 - Loss: 0.48939231038093567, aux loss1: 0.9718472361564636, 
		 aux loss2: 0.5690875053405762, total loss: 1.008581519126892
18th Epoch, 6495th Step, learning rate = 0.009348091912730729 - Loss: 0.45949849486351013, aux loss1: 0.9415596723556519, 
		 aux loss2: 0.5420095324516296, total loss: 0.9587701559066772
18th Epoch, 6500th Step, learning rate = 0.009347588152003232 - Loss: 0.5486432313919067, aux loss1: 1.0669432878494263, 
		 aux loss2: 0.6479874849319458, total loss: 1.127921223640442
<6500th step>
*************************** Test ***************************
time:3m 14s, 6500th Step, Loss: 0.6701430082321167, Mean IoU = 32.698%
************************************************************
18th Epoch, 6505th Step, learning rate = 0.00934708438825919 - Loss: 0.4555607736110687, aux loss1: 0.9278362989425659, 
		 aux loss2: 0.5366747975349426, total loss: 0.9485815763473511
18th Epoch, 6510th Step, learning rate = 0.009346580621498412 - Loss: 0.6691850423812866, aux loss1: 1.1796305179595947, 
		 aux loss2: 0.7617911696434021, total loss: 1.32779061794281
18th Epoch, 6515th Step, learning rate = 0.009346076851720696 - Loss: 0.49295610189437866, aux loss1: 0.9385674595832825, 
		 aux loss2: 0.5727213621139526, total loss: 1.003614902496338
18th Epoch, 6520th Step, learning rate = 0.009345573078925843 - Loss: 0.568871021270752, aux loss1: 1.0346797704696655, 
		 aux loss2: 0.6650645732879639, total loss: 1.1453008651733398
18th Epoch, 6525th Step, learning rate = 0.009345069303113653 - Loss: 0.5229277610778809, aux loss1: 1.0363940000534058, 
		 aux loss2: 0.6217656135559082, total loss: 1.082552194595337
18th Epoch, 6530th Step, learning rate = 0.00934456552428393 - Loss: 0.5623480677604675, aux loss1: 1.0519291162490845, 
		 aux loss2: 0.6536867022514343, total loss: 1.1394015550613403
18th Epoch, 6535th Step, learning rate = 0.009344061742436474 - Loss: 0.4446668326854706, aux loss1: 0.8415589332580566, 
		 aux loss2: 0.5108136534690857, total loss: 0.9014599323272705
18th Epoch, 6540th Step, learning rate = 0.009343557957571087 - Loss: 0.6140909194946289, aux loss1: 1.136087417602539, 
		 aux loss2: 0.7028949856758118, total loss: 1.2360751628875732
18th Epoch, 6545th Step, learning rate = 0.009343054169687568 - Loss: 0.38983041048049927, aux loss1: 0.9434993267059326, 
		 aux loss2: 0.4690358638763428, total loss: 0.8604946136474609
18th Epoch, 6550th Step, learning rate = 0.00934255037878572 - Loss: 0.41469675302505493, aux loss1: 0.9511362314224243, 
		 aux loss2: 0.4972917139530182, total loss: 0.8989542722702026
18th Epoch, 6555th Step, learning rate = 0.009342046584865345 - Loss: 0.39680033922195435, aux loss1: 0.8953255414962769, 
		 aux loss2: 0.47717520594596863, total loss: 0.8562681078910828
18th Epoch, 6560th Step, learning rate = 0.009341542787926241 - Loss: 0.7142168879508972, aux loss1: 1.268877625465393, 
		 aux loss2: 0.8451433181762695, total loss: 1.4329376220703125
18th Epoch, 6565th Step, learning rate = 0.00934103898796821 - Loss: 0.4701257646083832, aux loss1: 0.9846649765968323, 
		 aux loss2: 0.5728524923324585, total loss: 0.9946662783622742
18th Epoch, 6570th Step, learning rate = 0.009340535184991054 - Loss: 0.5782917737960815, aux loss1: 1.0887254476547241, 
		 aux loss2: 0.671071469783783, total loss: 1.1733380556106567
18th Epoch, 6575th Step, learning rate = 0.009340031378994574 - Loss: 0.6435683369636536, aux loss1: 1.1317229270935059, 
		 aux loss2: 0.7472770810127258, total loss: 1.2819960117340088
18th Epoch, 6580th Step, learning rate = 0.00933952756997857 - Loss: 0.7866515517234802, aux loss1: 1.3786042928695679, 
		 aux loss2: 0.9001725912094116, total loss: 1.5603018999099731
18th Epoch, 6585th Step, learning rate = 0.009339023757942844 - Loss: 0.7074262499809265, aux loss1: 1.2222528457641602, 
		 aux loss2: 0.7979841828346252, total loss: 1.3932958841323853
18th Epoch, 6590th Step, learning rate = 0.009338519942887195 - Loss: 0.6891301870346069, aux loss1: 1.183210015296936, 
		 aux loss2: 0.7867333889007568, total loss: 1.3587864637374878
18th Epoch, 6595th Step, learning rate = 0.009338016124811428 - Loss: 0.5411394238471985, aux loss1: 1.0474597215652466, 
		 aux loss2: 0.6379377245903015, total loss: 1.110552430152893
18th Epoch, 6600th Step, learning rate = 0.009337512303715337 - Loss: 0.5218511819839478, aux loss1: 1.0077497959136963, 
		 aux loss2: 0.6020770072937012, total loss: 1.065006971359253
<6600th step>
*************************** Test ***************************
time:3m 18s, 6600th Step, Loss: 0.6850466132164001, Mean IoU = 32.881%
************************************************************
18th Epoch, 6605th Step, learning rate = 0.009337008479598728 - Loss: 0.45840996503829956, aux loss1: 0.8891873359680176, 
		 aux loss2: 0.5395605564117432, total loss: 0.9409904479980469
18th Epoch, 6610th Step, learning rate = 0.009336504652461403 - Loss: 0.557040274143219, aux loss1: 0.9753835797309875, 
		 aux loss2: 0.6197670698165894, total loss: 1.0975621938705444
18th Epoch, 6615th Step, learning rate = 0.009336000822303158 - Loss: 0.5106363296508789, aux loss1: 0.9601464867591858, 
		 aux loss2: 0.5858307480812073, total loss: 1.0330126285552979
18th Epoch, 6620th Step, learning rate = 0.009335496989123795 - Loss: 0.5963725447654724, aux loss1: 1.1640125513076782, 
		 aux loss2: 0.6757588982582092, total loss: 1.2158799171447754
18th Epoch, 6625th Step, learning rate = 0.009334993152923118 - Loss: 0.5840403437614441, aux loss1: 1.112647533416748, 
		 aux loss2: 0.6798014044761658, total loss: 1.1897552013397217
18th Epoch, 6630th Step, learning rate = 0.009334489313700926 - Loss: 0.5141334533691406, aux loss1: 1.0285097360610962, 
		 aux loss2: 0.6146568655967712, total loss: 1.0685491561889648
18th Epoch, 6635th Step, learning rate = 0.009333985471457017 - Loss: 0.47408074140548706, aux loss1: 0.8937404155731201, 
		 aux loss2: 0.5506168603897095, total loss: 0.9624496102333069
18th Epoch, 6640th Step, learning rate = 0.009333481626191195 - Loss: 0.4815589189529419, aux loss1: 0.8931766152381897, 
		 aux loss2: 0.5798518657684326, total loss: 0.9814527034759521
18th Epoch, 6645th Step, learning rate = 0.00933297777790326 - Loss: 0.49274125695228577, aux loss1: 1.0352275371551514, 
		 aux loss2: 0.5865403413772583, total loss: 1.0379257202148438
18th Epoch, 6650th Step, learning rate = 0.009332473926593012 - Loss: 0.4356103241443634, aux loss1: 0.8665102124214172, 
		 aux loss2: 0.4906060993671417, total loss: 0.89180588722229
18th Epoch, 6655th Step, learning rate = 0.00933197007226025 - Loss: 0.6247921586036682, aux loss1: 1.1043925285339355, 
		 aux loss2: 0.704808235168457, total loss: 1.2380332946777344
18th Epoch, 6660th Step, learning rate = 0.009331466214904776 - Loss: 0.5116361379623413, aux loss1: 0.987006425857544, 
		 aux loss2: 0.5975655913352966, total loss: 1.0467642545700073
18th Epoch, 6665th Step, learning rate = 0.009330962354526393 - Loss: 0.5746814012527466, aux loss1: 1.0648901462554932, 
		 aux loss2: 0.6779719591140747, total loss: 1.165337324142456
18th Epoch, 6670th Step, learning rate = 0.009330458491124898 - Loss: 0.41728416085243225, aux loss1: 0.8380700945854187, 
		 aux loss2: 0.49479711055755615, total loss: 0.8666240572929382
18th Epoch, 6675th Step, learning rate = 0.009329954624700092 - Loss: 0.8277686238288879, aux loss1: 1.2991609573364258, 
		 aux loss2: 0.9269617795944214, total loss: 1.588301658630371
19th Epoch, 6680th Step, learning rate = 0.009329450755251776 - Loss: 0.5402247309684753, aux loss1: 0.9801278114318848, 
		 aux loss2: 0.648777425289154, total loss: 1.0937740802764893
19th Epoch, 6685th Step, learning rate = 0.00932894688277975 - Loss: 0.6150838136672974, aux loss1: 1.326119065284729, 
		 aux loss2: 0.7556637525558472, total loss: 1.3151850700378418
19th Epoch, 6690th Step, learning rate = 0.009328443007283816 - Loss: 0.5231680870056152, aux loss1: 1.033624529838562, 
		 aux loss2: 0.6297037601470947, total loss: 1.0851370096206665
19th Epoch, 6695th Step, learning rate = 0.009327939128763773 - Loss: 0.4629223644733429, aux loss1: 0.9990699887275696, 
		 aux loss2: 0.5557853579521179, total loss: 0.9849574565887451
19th Epoch, 6700th Step, learning rate = 0.00932743524721942 - Loss: 0.4266645610332489, aux loss1: 0.956037163734436, 
		 aux loss2: 0.5216140747070312, total loss: 0.9221213459968567
<6700th step>
*************************** Test ***************************
time:3m 13s, 6700th Step, Loss: 0.7502648830413818, Mean IoU = 30.982%
************************************************************
19th Epoch, 6705th Step, learning rate = 0.00932693136265056 - Loss: 0.5136400461196899, aux loss1: 1.0129038095474243, 
		 aux loss2: 0.6031530499458313, total loss: 1.0587724447250366
19th Epoch, 6710th Step, learning rate = 0.009326427475056994 - Loss: 0.42830291390419006, aux loss1: 0.8626428842544556, 
		 aux loss2: 0.5003840327262878, total loss: 0.8872493505477905
19th Epoch, 6715th Step, learning rate = 0.009325923584438518 - Loss: 0.6696262359619141, aux loss1: 1.1881204843521118, 
		 aux loss2: 0.7663745880126953, total loss: 1.3326122760772705
19th Epoch, 6720th Step, learning rate = 0.009325419690794935 - Loss: 0.4683748781681061, aux loss1: 0.9287285804748535, 
		 aux loss2: 0.5613155961036682, total loss: 0.9715196490287781
19th Epoch, 6725th Step, learning rate = 0.009324915794126046 - Loss: 0.5618093609809875, aux loss1: 1.0565502643585205, 
		 aux loss2: 0.6572704911231995, total loss: 1.1416826248168945
19th Epoch, 6730th Step, learning rate = 0.009324411894431648 - Loss: 0.5701711773872375, aux loss1: 1.0254687070846558, 
		 aux loss2: 0.6538745164871216, total loss: 1.1393616199493408
19th Epoch, 6735th Step, learning rate = 0.009323907991711546 - Loss: 0.4996917247772217, aux loss1: 1.0252692699432373, 
		 aux loss2: 0.5795319676399231, total loss: 1.0390853881835938
19th Epoch, 6740th Step, learning rate = 0.009323404085965535 - Loss: 0.5549852848052979, aux loss1: 1.0264297723770142, 
		 aux loss2: 0.6309587359428406, total loss: 1.1152976751327515
19th Epoch, 6745th Step, learning rate = 0.009322900177193418 - Loss: 0.5262578725814819, aux loss1: 0.9873427748680115, 
		 aux loss2: 0.6267982125282288, total loss: 1.0731799602508545
19th Epoch, 6750th Step, learning rate = 0.009322396265394996 - Loss: 0.36774787306785583, aux loss1: 0.8048295974731445, 
		 aux loss2: 0.4326997697353363, total loss: 0.7822766900062561
19th Epoch, 6755th Step, learning rate = 0.009321892350570066 - Loss: 0.42750874161720276, aux loss1: 0.9009827971458435, 
		 aux loss2: 0.5058000683784485, total loss: 0.900123655796051
19th Epoch, 6760th Step, learning rate = 0.00932138843271843 - Loss: 0.7106026411056519, aux loss1: 1.2162530422210693, 
		 aux loss2: 0.7876639366149902, total loss: 1.3905441761016846
19th Epoch, 6765th Step, learning rate = 0.009320884511839888 - Loss: 0.597137451171875, aux loss1: 1.0946235656738281, 
		 aux loss2: 0.6996946930885315, total loss: 1.2054023742675781
19th Epoch, 6770th Step, learning rate = 0.009320380587934239 - Loss: 0.44473081827163696, aux loss1: 0.9301418662071228, 
		 aux loss2: 0.5245618224143982, total loss: 0.9335981011390686
19th Epoch, 6775th Step, learning rate = 0.009319876661001284 - Loss: 0.7832208871841431, aux loss1: 1.4105452299118042, 
		 aux loss2: 0.9318198561668396, total loss: 1.5791124105453491
19th Epoch, 6780th Step, learning rate = 0.009319372731040823 - Loss: 0.5759490132331848, aux loss1: 1.0213003158569336, 
		 aux loss2: 0.6469034552574158, total loss: 1.141100525856018
19th Epoch, 6785th Step, learning rate = 0.009318868798052656 - Loss: 0.5869055390357971, aux loss1: 1.0785930156707764, 
		 aux loss2: 0.6640775799751282, total loss: 1.176114559173584
19th Epoch, 6790th Step, learning rate = 0.009318364862036582 - Loss: 0.5433525443077087, aux loss1: 1.1149147748947144, 
		 aux loss2: 0.6414266228675842, total loss: 1.1343976259231567
19th Epoch, 6795th Step, learning rate = 0.0093178609229924 - Loss: 0.6184495091438293, aux loss1: 1.0424294471740723, 
		 aux loss2: 0.7115249633789062, total loss: 1.2157883644104004
19th Epoch, 6800th Step, learning rate = 0.009317356980919912 - Loss: 0.6542243361473083, aux loss1: 1.1453074216842651, 
		 aux loss2: 0.7518389225006104, total loss: 1.29855215549469
<6800th step>
*************************** Test ***************************
time:3m 13s, 6800th Step, Loss: 0.9034231901168823, Mean IoU = 27.990%
************************************************************
19th Epoch, 6805th Step, learning rate = 0.009316853035818915 - Loss: 0.5038613677024841, aux loss1: 0.9865517616271973, 
		 aux loss2: 0.5819944739341736, total loss: 1.0326247215270996
19th Epoch, 6810th Step, learning rate = 0.009316349087689213 - Loss: 0.5183289051055908, aux loss1: 1.005993366241455, 
		 aux loss2: 0.6114327907562256, total loss: 1.0647000074386597
19th Epoch, 6815th Step, learning rate = 0.009315845136530602 - Loss: 0.38262882828712463, aux loss1: 0.9310318231582642, 
		 aux loss2: 0.47156986594200134, total loss: 0.8505663871765137
19th Epoch, 6820th Step, learning rate = 0.009315341182342885 - Loss: 0.40864649415016174, aux loss1: 0.8775320649147034, 
		 aux loss2: 0.4916449189186096, total loss: 0.8685640692710876
19th Epoch, 6825th Step, learning rate = 0.00931483722512586 - Loss: 0.46077048778533936, aux loss1: 0.8808738589286804, 
		 aux loss2: 0.5415799617767334, total loss: 0.9416646957397461
19th Epoch, 6830th Step, learning rate = 0.009314333264879324 - Loss: 0.638880729675293, aux loss1: 1.0755634307861328, 
		 aux loss2: 0.7224591970443726, total loss: 1.2505334615707397
19th Epoch, 6835th Step, learning rate = 0.00931382930160308 - Loss: 0.5385187864303589, aux loss1: 1.0487922430038452, 
		 aux loss2: 0.6291375160217285, total loss: 1.104811429977417
19th Epoch, 6840th Step, learning rate = 0.009313325335296928 - Loss: 0.56693035364151, aux loss1: 0.9844464659690857, 
		 aux loss2: 0.6311734318733215, total loss: 1.1147336959838867
19th Epoch, 6845th Step, learning rate = 0.009312821365960665 - Loss: 0.7337779402732849, aux loss1: 1.1788506507873535, 
		 aux loss2: 0.8063545227050781, total loss: 1.4099749326705933
19th Epoch, 6850th Step, learning rate = 0.009312317393594094 - Loss: 0.735117495059967, aux loss1: 1.1917593479156494, 
		 aux loss2: 0.8194422721862793, total loss: 1.4204221963882446
19th Epoch, 6855th Step, learning rate = 0.00931181341819701 - Loss: 0.45543959736824036, aux loss1: 0.9835326671600342, 
		 aux loss2: 0.5584117770195007, total loss: 0.9738640785217285
19th Epoch, 6860th Step, learning rate = 0.009311309439769218 - Loss: 0.49782606959342957, aux loss1: 1.0088292360305786, 
		 aux loss2: 0.5848131775856018, total loss: 1.0344001054763794
19th Epoch, 6865th Step, learning rate = 0.009310805458310513 - Loss: 0.6119225025177002, aux loss1: 1.1548317670822144, 
		 aux loss2: 0.6932973861694336, total loss: 1.2356910705566406
19th Epoch, 6870th Step, learning rate = 0.009310301473820694 - Loss: 0.4961930513381958, aux loss1: 0.9635437726974487, 
		 aux loss2: 0.5793911218643188, total loss: 1.017012596130371
19th Epoch, 6875th Step, learning rate = 0.009309797486299566 - Loss: 0.3881871700286865, aux loss1: 0.8402956128120422, 
		 aux loss2: 0.4655517637729645, total loss: 0.8264965415000916
19th Epoch, 6880th Step, learning rate = 0.009309293495746924 - Loss: 0.4800055921077728, aux loss1: 1.0174133777618408, 
		 aux loss2: 0.5851610898971558, total loss: 1.019294023513794
19th Epoch, 6885th Step, learning rate = 0.009308789502162568 - Loss: 0.4637000858783722, aux loss1: 0.8778437972068787, 
		 aux loss2: 0.5408496260643005, total loss: 0.9433931112289429
19th Epoch, 6890th Step, learning rate = 0.009308285505546297 - Loss: 0.5986104607582092, aux loss1: 1.152551293373108, 
		 aux loss2: 0.7170323729515076, total loss: 1.2311887741088867
19th Epoch, 6895th Step, learning rate = 0.009307781505897913 - Loss: 0.5354581475257874, aux loss1: 0.9809170961380005, 
		 aux loss2: 0.6097499132156372, total loss: 1.0736331939697266
19th Epoch, 6900th Step, learning rate = 0.009307277503217214 - Loss: 0.5155687928199768, aux loss1: 1.032177448272705, 
		 aux loss2: 0.613193690776825, total loss: 1.0704995393753052
<6900th step>
*************************** Test ***************************
time:3m 15s, 6900th Step, Loss: 0.7489540576934814, Mean IoU = 30.523%
************************************************************
19th Epoch, 6905th Step, learning rate = 0.009306773497503997 - Loss: 0.7335343956947327, aux loss1: 1.2197834253311157, 
		 aux loss2: 0.8349148631095886, total loss: 1.4334354400634766
19th Epoch, 6910th Step, learning rate = 0.009306269488758062 - Loss: 0.5043376088142395, aux loss1: 1.0634628534317017, 
		 aux loss2: 0.5889345407485962, total loss: 1.0589503049850464
19th Epoch, 6915th Step, learning rate = 0.009305765476979212 - Loss: 0.5516283512115479, aux loss1: 0.9937981367111206, 
		 aux loss2: 0.6343367695808411, total loss: 1.1035025119781494
19th Epoch, 6920th Step, learning rate = 0.009305261462167242 - Loss: 0.44708430767059326, aux loss1: 0.8643497228622437, 
		 aux loss2: 0.5107038617134094, total loss: 0.910670816898346
19th Epoch, 6925th Step, learning rate = 0.009304757444321951 - Loss: 0.55777907371521, aux loss1: 1.0961859226226807, 
		 aux loss2: 0.6608143448829651, total loss: 1.1509605646133423
19th Epoch, 6930th Step, learning rate = 0.009304253423443144 - Loss: 0.5299594402313232, aux loss1: 0.9842374920845032, 
		 aux loss2: 0.6375012993812561, total loss: 1.0802311897277832
19th Epoch, 6935th Step, learning rate = 0.009303749399530614 - Loss: 0.39865782856941223, aux loss1: 0.898810625076294, 
		 aux loss2: 0.48880594968795776, total loss: 0.8638233542442322
19th Epoch, 6940th Step, learning rate = 0.009303245372584161 - Loss: 0.6907278895378113, aux loss1: 1.3139153718948364, 
		 aux loss2: 0.808388352394104, total loss: 1.4082578420639038
19th Epoch, 6945th Step, learning rate = 0.009302741342603586 - Loss: 0.48763296008110046, aux loss1: 0.9385084509849548, 
		 aux loss2: 0.5526394248008728, total loss: 0.990241289138794
19th Epoch, 6950th Step, learning rate = 0.009302237309588688 - Loss: 0.5793919563293457, aux loss1: 1.0752098560333252, 
		 aux loss2: 0.6790387630462646, total loss: 1.1735703945159912
19th Epoch, 6955th Step, learning rate = 0.009301733273539265 - Loss: 0.6098397970199585, aux loss1: 1.0572223663330078, 
		 aux loss2: 0.6820837259292603, total loss: 1.1998399496078491
19th Epoch, 6960th Step, learning rate = 0.009301229234455116 - Loss: 0.5419252514839172, aux loss1: 1.0921764373779297, 
		 aux loss2: 0.6867859959602356, total loss: 1.1442925930023193
19th Epoch, 6965th Step, learning rate = 0.009300725192336042 - Loss: 0.5239599943161011, aux loss1: 0.9837825894355774, 
		 aux loss2: 0.6053346395492554, total loss: 1.061228632926941
19th Epoch, 6970th Step, learning rate = 0.00930022114718184 - Loss: 0.5418825149536133, aux loss1: 1.013756513595581, 
		 aux loss2: 0.620366632938385, total loss: 1.0941561460494995
19th Epoch, 6975th Step, learning rate = 0.009299717098992308 - Loss: 0.3914109170436859, aux loss1: 0.851093053817749, 
		 aux loss2: 0.4701535701751709, total loss: 0.8348003029823303
19th Epoch, 6980th Step, learning rate = 0.009299213047767247 - Loss: 0.5860490798950195, aux loss1: 1.026043176651001, 
		 aux loss2: 0.6606296896934509, total loss: 1.158113956451416
19th Epoch, 6985th Step, learning rate = 0.009298708993506457 - Loss: 0.5541250705718994, aux loss1: 1.0474005937576294, 
		 aux loss2: 0.6322524547576904, total loss: 1.1212462186813354
19th Epoch, 6990th Step, learning rate = 0.009298204936209734 - Loss: 0.633188009262085, aux loss1: 1.1743465662002563, 
		 aux loss2: 0.7416329979896545, total loss: 1.2821452617645264
19th Epoch, 6995th Step, learning rate = 0.009297700875876875 - Loss: 0.6351842880249023, aux loss1: 1.1731328964233398, 
		 aux loss2: 0.7632728815078735, total loss: 1.2924333810806274
19th Epoch, 7000th Step, learning rate = 0.009297196812507685 - Loss: 0.7152048349380493, aux loss1: 1.2851930856704712, 
		 aux loss2: 0.818286120891571, total loss: 1.4280773401260376
<7000th step>
*************************** Test ***************************
time:3m 13s, 7000th Step, Loss: 0.6876229047775269, Mean IoU = 32.444%
************************************************************
19th Epoch, 7005th Step, learning rate = 0.009296692746101958 - Loss: 0.4549214541912079, aux loss1: 1.051689624786377, 
		 aux loss2: 0.554431676864624, total loss: 0.992201030254364
19th Epoch, 7010th Step, learning rate = 0.009296188676659496 - Loss: 0.5224474668502808, aux loss1: 1.0599855184555054, 
		 aux loss2: 0.6019792556762695, total loss: 1.0812348127365112
19th Epoch, 7015th Step, learning rate = 0.009295684604180095 - Loss: 0.45841825008392334, aux loss1: 0.9855511784553528, 
		 aux loss2: 0.5518511533737183, total loss: 0.974824070930481
19th Epoch, 7020th Step, learning rate = 0.009295180528663556 - Loss: 0.4654691517353058, aux loss1: 1.042307734489441, 
		 aux loss2: 0.5767391920089722, total loss: 1.008857250213623
19th Epoch, 7025th Step, learning rate = 0.009294676450109673 - Loss: 0.4219372570514679, aux loss1: 0.8957204818725586, 
		 aux loss2: 0.4944283068180084, total loss: 0.8884247541427612
19th Epoch, 7030th Step, learning rate = 0.00929417236851825 - Loss: 0.4991970360279083, aux loss1: 0.9743388891220093, 
		 aux loss2: 0.5778117775917053, total loss: 1.0226234197616577
19th Epoch, 7035th Step, learning rate = 0.009293668283889084 - Loss: 0.6259081959724426, aux loss1: 1.1460636854171753, 
		 aux loss2: 0.7367216348648071, total loss: 1.264415979385376
19th Epoch, 7040th Step, learning rate = 0.009293164196221974 - Loss: 0.7956381440162659, aux loss1: 1.4009287357330322, 
		 aux loss2: 0.924606442451477, total loss: 1.5857594013214111
19th Epoch, 7045th Step, learning rate = 0.009292660105516718 - Loss: 0.5103821754455566, aux loss1: 0.9487732648849487, 
		 aux loss2: 0.5910476446151733, total loss: 1.0314332246780396
20th Epoch, 7050th Step, learning rate = 0.009292156011773115 - Loss: 0.7473497986793518, aux loss1: 1.2613581418991089, 
		 aux loss2: 0.8294126987457275, total loss: 1.4575222730636597
20th Epoch, 7055th Step, learning rate = 0.009291651914990961 - Loss: 0.4819861054420471, aux loss1: 1.040323257446289, 
		 aux loss2: 0.5682034492492676, total loss: 1.021364450454712
20th Epoch, 7060th Step, learning rate = 0.009291147815170058 - Loss: 0.4723735451698303, aux loss1: 0.9580318927764893, 
		 aux loss2: 0.5572836995124817, total loss: 0.9826966524124146
20th Epoch, 7065th Step, learning rate = 0.009290643712310203 - Loss: 0.5300328135490417, aux loss1: 1.058379888534546, 
		 aux loss2: 0.6222333312034607, total loss: 1.0964401960372925
20th Epoch, 7070th Step, learning rate = 0.009290139606411193 - Loss: 1.010583519935608, aux loss1: 1.6148834228515625, 
		 aux loss2: 1.1664930582046509, total loss: 1.9616457223892212
20th Epoch, 7075th Step, learning rate = 0.00928963549747283 - Loss: 0.4909892976284027, aux loss1: 1.0267508029937744, 
		 aux loss2: 0.5836743712425232, total loss: 1.0324842929840088
20th Epoch, 7080th Step, learning rate = 0.00928913138549491 - Loss: 0.5398145914077759, aux loss1: 1.0841443538665771, 
		 aux loss2: 0.6276959776878357, total loss: 1.1161363124847412
20th Epoch, 7085th Step, learning rate = 0.009288627270477232 - Loss: 0.4980379641056061, aux loss1: 0.9401271343231201, 
		 aux loss2: 0.5813308358192444, total loss: 1.012608528137207
20th Epoch, 7090th Step, learning rate = 0.009288123152419593 - Loss: 0.45139428973197937, aux loss1: 0.974669873714447, 
		 aux loss2: 0.541340708732605, total loss: 0.9603315591812134
20th Epoch, 7095th Step, learning rate = 0.009287619031321795 - Loss: 0.6020011901855469, aux loss1: 1.066282868385315, 
		 aux loss2: 0.6839979290962219, total loss: 1.195485234260559
20th Epoch, 7100th Step, learning rate = 0.009287114907183631 - Loss: 0.6126214861869812, aux loss1: 1.0813640356063843, 
		 aux loss2: 0.7110990881919861, total loss: 1.2214703559875488
<7100th step>
*************************** Test ***************************
time:3m 16s, 7100th Step, Loss: 0.7814218997955322, Mean IoU = 32.117%
************************************************************
20th Epoch, 7105th Step, learning rate = 0.009286610780004903 - Loss: 0.4971645772457123, aux loss1: 0.9397105574607849, 
		 aux loss2: 0.5800583958625793, total loss: 1.0111011266708374
20th Epoch, 7110th Step, learning rate = 0.00928610664978541 - Loss: 0.5402515530586243, aux loss1: 1.062497615814209, 
		 aux loss2: 0.6437022089958191, total loss: 1.1164817810058594
20th Epoch, 7115th Step, learning rate = 0.009285602516524947 - Loss: 0.6704036593437195, aux loss1: 1.0510282516479492, 
		 aux loss2: 0.7374566197395325, total loss: 1.280694842338562
20th Epoch, 7120th Step, learning rate = 0.009285098380223313 - Loss: 0.44592735171318054, aux loss1: 0.8791198134422302, 
		 aux loss2: 0.5132571458816528, total loss: 0.9149661064147949
20th Epoch, 7125th Step, learning rate = 0.009284594240880309 - Loss: 0.5935168862342834, aux loss1: 1.1394978761672974, 
		 aux loss2: 0.6954452991485596, total loss: 1.2135443687438965
20th Epoch, 7130th Step, learning rate = 0.00928409009849573 - Loss: 0.510427713394165, aux loss1: 0.9489203095436096, 
		 aux loss2: 0.5888791084289551, total loss: 1.0306553840637207
20th Epoch, 7135th Step, learning rate = 0.009283585953069376 - Loss: 0.5383826494216919, aux loss1: 0.9766604900360107, 
		 aux loss2: 0.6373987793922424, total loss: 1.0863404273986816
20th Epoch, 7140th Step, learning rate = 0.009283081804601044 - Loss: 0.5321112275123596, aux loss1: 0.9280875325202942, 
		 aux loss2: 0.6081715822219849, total loss: 1.0538060665130615
20th Epoch, 7145th Step, learning rate = 0.009282577653090533 - Loss: 0.44245684146881104, aux loss1: 0.8627575635910034, 
		 aux loss2: 0.5353171825408936, total loss: 0.9154109954833984
20th Epoch, 7150th Step, learning rate = 0.009282073498537638 - Loss: 0.5085217356681824, aux loss1: 0.9789086580276489, 
		 aux loss2: 0.6035984754562378, total loss: 1.0436336994171143
20th Epoch, 7155th Step, learning rate = 0.009281569340942162 - Loss: 0.5775205492973328, aux loss1: 1.0868504047393799, 
		 aux loss2: 0.6760167479515076, total loss: 1.1739823818206787
20th Epoch, 7160th Step, learning rate = 0.0092810651803039 - Loss: 0.5013487339019775, aux loss1: 0.9198324084281921, 
		 aux loss2: 0.5915416479110718, total loss: 1.0139150619506836
20th Epoch, 7165th Step, learning rate = 0.009280561016622653 - Loss: 0.48082488775253296, aux loss1: 0.916878342628479, 
		 aux loss2: 0.5644034147262573, total loss: 0.9816497564315796
20th Epoch, 7170th Step, learning rate = 0.009280056849898213 - Loss: 0.5915747880935669, aux loss1: 1.1814223527908325, 
		 aux loss2: 0.7063266634941101, total loss: 1.2285321950912476
20th Epoch, 7175th Step, learning rate = 0.00927955268013038 - Loss: 0.6420461535453796, aux loss1: 1.2236695289611816, 
		 aux loss2: 0.7713403701782227, total loss: 1.317683219909668
20th Epoch, 7180th Step, learning rate = 0.009279048507318957 - Loss: 0.48369669914245605, aux loss1: 0.9795361161231995, 
		 aux loss2: 0.5754076242446899, total loss: 1.0077205896377563
20th Epoch, 7185th Step, learning rate = 0.009278544331463738 - Loss: 0.5256699919700623, aux loss1: 1.0587530136108398, 
		 aux loss2: 0.6333819627761841, total loss: 1.0966486930847168
20th Epoch, 7190th Step, learning rate = 0.00927804015256452 - Loss: 0.4771004915237427, aux loss1: 0.8785784840583801, 
		 aux loss2: 0.538025975227356, total loss: 0.9558843970298767
20th Epoch, 7195th Step, learning rate = 0.0092775359706211 - Loss: 0.4684532880783081, aux loss1: 1.0657782554626465, 
		 aux loss2: 0.5608695149421692, total loss: 1.0125346183776855
20th Epoch, 7200th Step, learning rate = 0.009277031785633282 - Loss: 0.7774394750595093, aux loss1: 1.2276109457015991, 
		 aux loss2: 0.8720090985298157, total loss: 1.4945263862609863
<7200th step>
*************************** Test ***************************
time:3m 16s, 7200th Step, Loss: 0.6396799087524414, Mean IoU = 35.010%
************************************************************
20th Epoch, 7205th Step, learning rate = 0.009276527597600857 - Loss: 0.424270898103714, aux loss1: 0.9698584079742432, 
		 aux loss2: 0.5140700936317444, total loss: 0.9208564758300781
20th Epoch, 7210th Step, learning rate = 0.009276023406523625 - Loss: 0.654879093170166, aux loss1: 1.1761376857757568, 
		 aux loss2: 0.7664424777030945, total loss: 1.3142974376678467
20th Epoch, 7215th Step, learning rate = 0.009275519212401384 - Loss: 0.47057604789733887, aux loss1: 0.9061021208763123, 
		 aux loss2: 0.562865138053894, total loss: 0.9675527811050415
20th Epoch, 7220th Step, learning rate = 0.009275015015233933 - Loss: 0.6073716282844543, aux loss1: 1.07611882686615, 
		 aux loss2: 0.6873618364334106, total loss: 1.2051520347595215
20th Epoch, 7225th Step, learning rate = 0.009274510815021068 - Loss: 0.6956044435501099, aux loss1: 1.2449851036071777, 
		 aux loss2: 0.8139187693595886, total loss: 1.3946675062179565
20th Epoch, 7230th Step, learning rate = 0.009274006611762585 - Loss: 0.49498996138572693, aux loss1: 1.0555297136306763, 
		 aux loss2: 0.6140298247337341, total loss: 1.0572607517242432
20th Epoch, 7235th Step, learning rate = 0.009273502405458286 - Loss: 0.5377063751220703, aux loss1: 1.0849895477294922, 
		 aux loss2: 0.6186078190803528, total loss: 1.110646367073059
20th Epoch, 7240th Step, learning rate = 0.009272998196107964 - Loss: 0.6888347268104553, aux loss1: 1.1543151140213013, 
		 aux loss2: 0.7872774004936218, total loss: 1.350040316581726
20th Epoch, 7245th Step, learning rate = 0.009272493983711421 - Loss: 0.6373010277748108, aux loss1: 1.1301705837249756, 
		 aux loss2: 0.7153212428092957, total loss: 1.2624807357788086
20th Epoch, 7250th Step, learning rate = 0.00927198976826845 - Loss: 0.48034369945526123, aux loss1: 0.9441118240356445, 
		 aux loss2: 0.5711479187011719, total loss: 0.9920364022254944
20th Epoch, 7255th Step, learning rate = 0.009271485549778854 - Loss: 0.4776310324668884, aux loss1: 0.9972169995307922, 
		 aux loss2: 0.5567079782485962, total loss: 0.9994792938232422
20th Epoch, 7260th Step, learning rate = 0.009270981328242424 - Loss: 0.6875818371772766, aux loss1: 1.2669124603271484, 
		 aux loss2: 0.7898769974708557, total loss: 1.3836064338684082
20th Epoch, 7265th Step, learning rate = 0.009270477103658963 - Loss: 0.5251556038856506, aux loss1: 0.9546302556991577, 
		 aux loss2: 0.6031221747398376, total loss: 1.0527935028076172
20th Epoch, 7270th Step, learning rate = 0.009269972876028263 - Loss: 0.6202825307846069, aux loss1: 1.1136242151260376, 
		 aux loss2: 0.745028555393219, total loss: 1.2523812055587769
20th Epoch, 7275th Step, learning rate = 0.009269468645350127 - Loss: 0.5354433655738831, aux loss1: 0.9544093012809753, 
		 aux loss2: 0.6108187437057495, total loss: 1.0660936832427979
20th Epoch, 7280th Step, learning rate = 0.00926896441162435 - Loss: 0.5869981050491333, aux loss1: 1.0379328727722168, 
		 aux loss2: 0.6668151021003723, total loss: 1.1651040315628052
20th Epoch, 7285th Step, learning rate = 0.009268460174850729 - Loss: 0.5209190845489502, aux loss1: 1.0931432247161865, 
		 aux loss2: 0.6223299503326416, total loss: 1.0977940559387207
20th Epoch, 7290th Step, learning rate = 0.009267955935029062 - Loss: 0.4421424865722656, aux loss1: 0.9363446235656738, 
		 aux loss2: 0.5257577896118164, total loss: 0.9333490133285522
20th Epoch, 7295th Step, learning rate = 0.009267451692159147 - Loss: 0.5626081228256226, aux loss1: 0.975459635257721, 
		 aux loss2: 0.6174099445343018, total loss: 1.1022100448608398
20th Epoch, 7300th Step, learning rate = 0.009266947446240778 - Loss: 0.48444864153862, aux loss1: 1.0293865203857422, 
		 aux loss2: 0.5875586867332458, total loss: 1.0282881259918213
<7300th step>
*************************** Test ***************************
time:3m 14s, 7300th Step, Loss: 0.6717873811721802, Mean IoU = 32.840%
************************************************************
20th Epoch, 7305th Step, learning rate = 0.009266443197273757 - Loss: 0.5515231490135193, aux loss1: 1.1534922122955322, 
		 aux loss2: 0.6544824242591858, total loss: 1.159363865852356
20th Epoch, 7310th Step, learning rate = 0.009265938945257877 - Loss: 0.44993099570274353, aux loss1: 0.910322904586792, 
		 aux loss2: 0.5251146554946899, total loss: 0.9330737590789795
20th Epoch, 7315th Step, learning rate = 0.009265434690192937 - Loss: 0.5751494765281677, aux loss1: 1.0829380750656128, 
		 aux loss2: 0.6658847332000732, total loss: 1.1663848161697388
20th Epoch, 7320th Step, learning rate = 0.009264930432078735 - Loss: 0.6847003102302551, aux loss1: 1.2689905166625977, 
		 aux loss2: 0.7836415767669678, total loss: 1.3788541555404663
20th Epoch, 7325th Step, learning rate = 0.009264426170915068 - Loss: 0.4640137851238251, aux loss1: 0.8779058456420898, 
		 aux loss2: 0.5207067131996155, total loss: 0.9356682300567627
20th Epoch, 7330th Step, learning rate = 0.00926392190670173 - Loss: 0.5557191371917725, aux loss1: 1.0914158821105957, 
		 aux loss2: 0.6407687664031982, total loss: 1.1394513845443726
20th Epoch, 7335th Step, learning rate = 0.009263417639438522 - Loss: 0.4571836292743683, aux loss1: 0.9790196418762207, 
		 aux loss2: 0.5374482870101929, total loss: 0.9658688306808472
20th Epoch, 7340th Step, learning rate = 0.00926291336912524 - Loss: 0.483466237783432, aux loss1: 0.9982528686523438, 
		 aux loss2: 0.5945609211921692, total loss: 1.0207664966583252
20th Epoch, 7345th Step, learning rate = 0.009262409095761683 - Loss: 0.45769986510276794, aux loss1: 0.903992235660553, 
		 aux loss2: 0.5128389596939087, total loss: 0.9340331554412842
20th Epoch, 7350th Step, learning rate = 0.009261904819347641 - Loss: 0.7393627762794495, aux loss1: 1.4041600227355957, 
		 aux loss2: 0.9206700325012207, total loss: 1.5288788080215454
20th Epoch, 7355th Step, learning rate = 0.009261400539882919 - Loss: 0.40305647253990173, aux loss1: 0.7962015867233276, 
		 aux loss2: 0.48001381754875183, total loss: 0.8339225053787231
20th Epoch, 7360th Step, learning rate = 0.00926089625736731 - Loss: 0.4356856644153595, aux loss1: 1.0077368021011353, 
		 aux loss2: 0.5119620561599731, total loss: 0.9427915215492249
20th Epoch, 7365th Step, learning rate = 0.009260391971800612 - Loss: 0.511231005191803, aux loss1: 0.9565913081169128, 
		 aux loss2: 0.5923110246658325, total loss: 1.035132884979248
20th Epoch, 7370th Step, learning rate = 0.009259887683182621 - Loss: 0.5310291051864624, aux loss1: 1.1402311325073242, 
		 aux loss2: 0.6321103572845459, total loss: 1.1259427070617676
20th Epoch, 7375th Step, learning rate = 0.009259383391513134 - Loss: 0.6278449296951294, aux loss1: 1.1684982776641846, 
		 aux loss2: 0.763755202293396, total loss: 1.2838964462280273
20th Epoch, 7380th Step, learning rate = 0.00925887909679195 - Loss: 0.6956399083137512, aux loss1: 1.2117385864257812, 
		 aux loss2: 0.7874099612236023, total loss: 1.3741254806518555
20th Epoch, 7385th Step, learning rate = 0.009258374799018863 - Loss: 0.3877045214176178, aux loss1: 0.8559894561767578, 
		 aux loss2: 0.4652714729309082, total loss: 0.830609917640686
20th Epoch, 7390th Step, learning rate = 0.009257870498193672 - Loss: 0.7635992765426636, aux loss1: 1.306612253189087, 
		 aux loss2: 0.8715857267379761, total loss: 1.5042171478271484
20th Epoch, 7395th Step, learning rate = 0.009257366194316172 - Loss: 0.4202767312526703, aux loss1: 0.849651575088501, 
		 aux loss2: 0.5021899938583374, total loss: 0.87604820728302
20th Epoch, 7400th Step, learning rate = 0.009256861887386161 - Loss: 0.4945358633995056, aux loss1: 0.9608045816421509, 
		 aux loss2: 0.5594598650932312, total loss: 1.0065611600875854
<7400th step>
*************************** Test ***************************
time:3m 15s, 7400th Step, Loss: 0.6810346245765686, Mean IoU = 31.929%
************************************************************
20th Epoch, 7405th Step, learning rate = 0.009256357577403436 - Loss: 0.4535168707370758, aux loss1: 0.926464855670929, 
		 aux loss2: 0.5304492712020874, total loss: 0.9436360597610474
20th Epoch, 7410th Step, learning rate = 0.009255853264367791 - Loss: 0.630066454410553, aux loss1: 1.1185200214385986, 
		 aux loss2: 0.7263975739479065, total loss: 1.2561814785003662
20th Epoch, 7415th Step, learning rate = 0.009255348948279027 - Loss: 0.4978443682193756, aux loss1: 1.0159296989440918, 
		 aux loss2: 0.5646443963050842, total loss: 1.0284810066223145
20th Epoch, 7420th Step, learning rate = 0.009254844629136935 - Loss: 0.41828063130378723, aux loss1: 0.878044605255127, 
		 aux loss2: 0.4939129650592804, total loss: 0.8792592287063599
21th Epoch, 7425th Step, learning rate = 0.00925434030694132 - Loss: 0.5155102014541626, aux loss1: 0.9326274991035461, 
		 aux loss2: 0.5913332104682922, total loss: 1.0318317413330078
21th Epoch, 7430th Step, learning rate = 0.009253835981691971 - Loss: 0.4953227639198303, aux loss1: 1.1857807636260986, 
		 aux loss2: 0.6216717958450317, total loss: 1.0997257232666016
21th Epoch, 7435th Step, learning rate = 0.009253331653388687 - Loss: 0.5487404465675354, aux loss1: 0.9822671413421631, 
		 aux loss2: 0.6245769262313843, total loss: 1.093251347541809
21th Epoch, 7440th Step, learning rate = 0.009252827322031266 - Loss: 0.48553311824798584, aux loss1: 0.9365127086639404, 
		 aux loss2: 0.5690637826919556, total loss: 0.994112491607666
21th Epoch, 7445th Step, learning rate = 0.009252322987619502 - Loss: 0.5217654705047607, aux loss1: 0.9048205614089966, 
		 aux loss2: 0.595881998538971, total loss: 1.031564474105835
21th Epoch, 7450th Step, learning rate = 0.009251818650153194 - Loss: 0.5525331497192383, aux loss1: 0.9860346913337708, 
		 aux loss2: 0.6138496398925781, total loss: 1.0938835144042969
21th Epoch, 7455th Step, learning rate = 0.009251314309632138 - Loss: 0.47016197443008423, aux loss1: 0.917721688747406, 
		 aux loss2: 0.5554879903793335, total loss: 0.9676737189292908
21th Epoch, 7460th Step, learning rate = 0.009250809966056128 - Loss: 0.4967581629753113, aux loss1: 0.9271422028541565, 
		 aux loss2: 0.569062352180481, total loss: 1.0025256872177124
21th Epoch, 7465th Step, learning rate = 0.009250305619424963 - Loss: 0.6174530982971191, aux loss1: 1.00948965549469, 
		 aux loss2: 0.7130004167556763, total loss: 1.2055001258850098
21th Epoch, 7470th Step, learning rate = 0.00924980126973844 - Loss: 0.5030816197395325, aux loss1: 0.9824403524398804, 
		 aux loss2: 0.607346773147583, total loss: 1.0407525300979614
21th Epoch, 7475th Step, learning rate = 0.009249296916996353 - Loss: 0.4102849066257477, aux loss1: 0.9310999512672424, 
		 aux loss2: 0.48253723978996277, total loss: 0.8826298117637634
21th Epoch, 7480th Step, learning rate = 0.0092487925611985 - Loss: 0.3866361081600189, aux loss1: 0.8082209825515747, 
		 aux loss2: 0.4570099115371704, total loss: 0.8119063973426819
21th Epoch, 7485th Step, learning rate = 0.009248288202344676 - Loss: 0.619436502456665, aux loss1: 1.0959343910217285, 
		 aux loss2: 0.7062734365463257, total loss: 1.2307262420654297
21th Epoch, 7490th Step, learning rate = 0.009247783840434677 - Loss: 0.45130667090415955, aux loss1: 0.8993788361549377, 
		 aux loss2: 0.5175079107284546, total loss: 0.9281235337257385
21th Epoch, 7495th Step, learning rate = 0.009247279475468302 - Loss: 0.67926424741745, aux loss1: 1.2235276699066162, 
		 aux loss2: 0.8058428764343262, total loss: 1.3686597347259521
21th Epoch, 7500th Step, learning rate = 0.009246775107445347 - Loss: 0.4354999363422394, aux loss1: 0.9798794388771057, 
		 aux loss2: 0.5400146245956421, total loss: 0.9454696774482727
<7500th step>
*************************** Test ***************************
time:3m 14s, 7500th Step, Loss: 0.612869143486023, Mean IoU = 34.451%
************************************************************
21th Epoch, 7505th Step, learning rate = 0.009246270736365605 - Loss: 0.4966832101345062, aux loss1: 1.0600866079330444, 
		 aux loss2: 0.6007762551307678, total loss: 1.055019736289978
21th Epoch, 7510th Step, learning rate = 0.009245766362228874 - Loss: 0.569349467754364, aux loss1: 1.0386816263198853, 
		 aux loss2: 0.6476496458053589, total loss: 1.1400138139724731
21th Epoch, 7515th Step, learning rate = 0.00924526198503495 - Loss: 0.4434725344181061, aux loss1: 0.9332345128059387, 
		 aux loss2: 0.5371137261390686, total loss: 0.9382883906364441
21th Epoch, 7520th Step, learning rate = 0.00924475760478363 - Loss: 0.4304109811782837, aux loss1: 0.8565988540649414, 
		 aux loss2: 0.4910353720188141, total loss: 0.8838048577308655
21th Epoch, 7525th Step, learning rate = 0.00924425322147471 - Loss: 0.4802685081958771, aux loss1: 1.010617733001709, 
		 aux loss2: 0.5628179311752319, total loss: 1.0085810422897339
21th Epoch, 7530th Step, learning rate = 0.009243748835107984 - Loss: 0.3892790675163269, aux loss1: 0.8400464057922363, 
		 aux loss2: 0.46888479590415955, total loss: 0.8288469314575195
21th Epoch, 7535th Step, learning rate = 0.00924324444568325 - Loss: 0.5813818573951721, aux loss1: 1.1185795068740845, 
		 aux loss2: 0.7053481936454773, total loss: 1.1990950107574463
21th Epoch, 7540th Step, learning rate = 0.009242740053200306 - Loss: 0.44305476546287537, aux loss1: 0.9334988594055176, 
		 aux loss2: 0.5414746403694153, total loss: 0.939694344997406
21th Epoch, 7545th Step, learning rate = 0.009242235657658944 - Loss: 0.6618881821632385, aux loss1: 1.2465425729751587, 
		 aux loss2: 0.7589263319969177, total loss: 1.3394215106964111
21th Epoch, 7550th Step, learning rate = 0.009241731259058961 - Loss: 0.5564195513725281, aux loss1: 1.0340244770050049, 
		 aux loss2: 0.6465075612068176, total loss: 1.1252299547195435
21th Epoch, 7555th Step, learning rate = 0.009241226857400154 - Loss: 0.3944159746170044, aux loss1: 0.8336963653564453, 
		 aux loss2: 0.4657860994338989, total loss: 0.8308393955230713
21th Epoch, 7560th Step, learning rate = 0.00924072245268232 - Loss: 0.45471131801605225, aux loss1: 0.9161098599433899, 
		 aux loss2: 0.5401161909103394, total loss: 0.9455907344818115
21th Epoch, 7565th Step, learning rate = 0.009240218044905253 - Loss: 0.4375532865524292, aux loss1: 0.9624307751655579, 
		 aux loss2: 0.5668985843658447, total loss: 0.9530419707298279
21th Epoch, 7570th Step, learning rate = 0.009239713634068749 - Loss: 0.5943701863288879, aux loss1: 1.1237822771072388, 
		 aux loss2: 0.7415059208869934, total loss: 1.228107213973999
21th Epoch, 7575th Step, learning rate = 0.009239209220172602 - Loss: 0.4130244553089142, aux loss1: 0.8712841272354126, 
		 aux loss2: 0.4806894361972809, total loss: 0.8666855096817017
21th Epoch, 7580th Step, learning rate = 0.009238704803216615 - Loss: 0.5629360675811768, aux loss1: 0.9492728114128113, 
		 aux loss2: 0.6381120681762695, total loss: 1.1029627323150635
21th Epoch, 7585th Step, learning rate = 0.009238200383200576 - Loss: 0.4579527974128723, aux loss1: 0.9391387701034546, 
		 aux loss2: 0.5588633418083191, total loss: 0.9632397890090942
21th Epoch, 7590th Step, learning rate = 0.009237695960124285 - Loss: 0.6080150008201599, aux loss1: 1.1848434209823608, 
		 aux loss2: 0.698047935962677, total loss: 1.2426872253417969
21th Epoch, 7595th Step, learning rate = 0.009237191533987535 - Loss: 0.48312535881996155, aux loss1: 0.9342605471611023, 
		 aux loss2: 0.5356768369674683, total loss: 0.9776742458343506
21th Epoch, 7600th Step, learning rate = 0.009236687104790123 - Loss: 0.8363544940948486, aux loss1: 1.2365370988845825, 
		 aux loss2: 0.9093911647796631, total loss: 1.5710721015930176
<7600th step>
*************************** Test ***************************
time:3m 15s, 7600th Step, Loss: 0.7086930871009827, Mean IoU = 32.437%
************************************************************
21th Epoch, 7605th Step, learning rate = 0.009236182672531847 - Loss: 0.6007344126701355, aux loss1: 1.2999671697616577, 
		 aux loss2: 0.7414382100105286, total loss: 1.2872998714447021
21th Epoch, 7610th Step, learning rate = 0.009235678237212499 - Loss: 0.48488813638687134, aux loss1: 0.9798583984375, 
		 aux loss2: 0.5909679532051086, total loss: 1.015232801437378
21th Epoch, 7615th Step, learning rate = 0.009235173798831877 - Loss: 0.6208510398864746, aux loss1: 1.1493089199066162, 
		 aux loss2: 0.7128103971481323, total loss: 1.2507679462432861
21th Epoch, 7620th Step, learning rate = 0.009234669357389775 - Loss: 0.4795222878456116, aux loss1: 0.9380689263343811, 
		 aux loss2: 0.5666695237159729, total loss: 0.9876107573509216
21th Epoch, 7625th Step, learning rate = 0.00923416491288599 - Loss: 0.6740871667861938, aux loss1: 1.1551213264465332, 
		 aux loss2: 0.7527698874473572, total loss: 1.3217315673828125
21th Epoch, 7630th Step, learning rate = 0.009233660465320316 - Loss: 0.530603289604187, aux loss1: 1.0842801332473755, 
		 aux loss2: 0.6237574815750122, total loss: 1.1053903102874756
21th Epoch, 7635th Step, learning rate = 0.009233156014692552 - Loss: 0.6412206888198853, aux loss1: 1.2427358627319336, 
		 aux loss2: 0.778860330581665, total loss: 1.3255856037139893
21th Epoch, 7640th Step, learning rate = 0.009232651561002489 - Loss: 0.4557822048664093, aux loss1: 0.8977780342102051, 
		 aux loss2: 0.5578559041023254, total loss: 0.9482580423355103
21th Epoch, 7645th Step, learning rate = 0.009232147104249926 - Loss: 0.5581297278404236, aux loss1: 0.9885164499282837, 
		 aux loss2: 0.6264929175376892, total loss: 1.1052818298339844
21th Epoch, 7650th Step, learning rate = 0.009231642644434657 - Loss: 0.5461435914039612, aux loss1: 1.0832369327545166, 
		 aux loss2: 0.654121994972229, total loss: 1.1327635049819946
21th Epoch, 7655th Step, learning rate = 0.009231138181556478 - Loss: 0.5379288196563721, aux loss1: 1.013372778892517, 
		 aux loss2: 0.622566282749176, total loss: 1.0909671783447266
21th Epoch, 7660th Step, learning rate = 0.009230633715615182 - Loss: 0.5206393003463745, aux loss1: 1.0423046350479126, 
		 aux loss2: 0.6094459295272827, total loss: 1.0771090984344482
21th Epoch, 7665th Step, learning rate = 0.009230129246610569 - Loss: 0.501544177532196, aux loss1: 1.0185316801071167, 
		 aux loss2: 0.608847975730896, total loss: 1.0506428480148315
21th Epoch, 7670th Step, learning rate = 0.00922962477454243 - Loss: 0.6192603707313538, aux loss1: 1.1543810367584229, 
		 aux loss2: 0.7314795851707458, total loss: 1.2581665515899658
21th Epoch, 7675th Step, learning rate = 0.009229120299410561 - Loss: 0.49047186970710754, aux loss1: 0.9464874863624573, 
		 aux loss2: 0.5639621019363403, total loss: 1.0000029802322388
21th Epoch, 7680th Step, learning rate = 0.00922861582121476 - Loss: 0.47679147124290466, aux loss1: 0.9157861471176147, 
		 aux loss2: 0.5738083720207214, total loss: 0.9810506701469421
21th Epoch, 7685th Step, learning rate = 0.009228111339954822 - Loss: 0.4112240970134735, aux loss1: 0.9472812414169312, 
		 aux loss2: 0.5060126185417175, total loss: 0.8978134989738464
21th Epoch, 7690th Step, learning rate = 0.00922760685563054 - Loss: 0.5192898511886597, aux loss1: 0.9963288903236389, 
		 aux loss2: 0.6014588475227356, total loss: 1.058772087097168
21th Epoch, 7695th Step, learning rate = 0.009227102368241709 - Loss: 0.581040620803833, aux loss1: 1.1192243099212646, 
		 aux loss2: 0.7011983394622803, total loss: 1.1972872018814087
21th Epoch, 7700th Step, learning rate = 0.009226597877788125 - Loss: 0.38291314244270325, aux loss1: 0.9317313432693481, 
		 aux loss2: 0.4652513265609741, total loss: 0.8485330939292908
<7700th step>
*************************** Test ***************************
time:3m 19s, 7700th Step, Loss: 0.6649957895278931, Mean IoU = 33.570%
************************************************************
21th Epoch, 7705th Step, learning rate = 0.009226093384269588 - Loss: 0.48062410950660706, aux loss1: 0.896943986415863, 
		 aux loss2: 0.5644525289535522, total loss: 0.9754883646965027
21th Epoch, 7710th Step, learning rate = 0.009225588887685885 - Loss: 0.47509700059890747, aux loss1: 0.9374181032180786, 
		 aux loss2: 0.5389304757118225, total loss: 0.9718946218490601
21th Epoch, 7715th Step, learning rate = 0.009225084388036814 - Loss: 0.41104406118392944, aux loss1: 0.8531091213226318, 
		 aux loss2: 0.49359744787216187, total loss: 0.8644157648086548
21th Epoch, 7720th Step, learning rate = 0.009224579885322173 - Loss: 0.3759986460208893, aux loss1: 0.873647153377533, 
		 aux loss2: 0.46026790142059326, total loss: 0.8222000002861023
21th Epoch, 7725th Step, learning rate = 0.009224075379541756 - Loss: 0.6432358026504517, aux loss1: 1.1911115646362305, 
		 aux loss2: 0.7573105096817017, total loss: 1.3034934997558594
21th Epoch, 7730th Step, learning rate = 0.009223570870695355 - Loss: 0.446156769990921, aux loss1: 0.9441248178482056, 
		 aux loss2: 0.5215855240821838, total loss: 0.9380283951759338
21th Epoch, 7735th Step, learning rate = 0.009223066358782768 - Loss: 0.5415353178977966, aux loss1: 1.0209455490112305, 
		 aux loss2: 0.6269046664237976, total loss: 1.0985808372497559
21th Epoch, 7740th Step, learning rate = 0.009222561843803788 - Loss: 0.540244996547699, aux loss1: 1.021963119506836, 
		 aux loss2: 0.6407915353775024, total loss: 1.1031506061553955
21th Epoch, 7745th Step, learning rate = 0.009222057325758213 - Loss: 0.45686057209968567, aux loss1: 0.9454132318496704, 
		 aux loss2: 0.538923978805542, total loss: 0.9560542106628418
21th Epoch, 7750th Step, learning rate = 0.009221552804645835 - Loss: 0.41755005717277527, aux loss1: 0.8540872931480408, 
		 aux loss2: 0.494702011346817, total loss: 0.8716570734977722
21th Epoch, 7755th Step, learning rate = 0.00922104828046645 - Loss: 0.3920672535896301, aux loss1: 0.8704545497894287, 
		 aux loss2: 0.46510425209999084, total loss: 0.8392453193664551
21th Epoch, 7760th Step, learning rate = 0.009220543753219854 - Loss: 0.5403838157653809, aux loss1: 1.0134822130203247, 
		 aux loss2: 0.6336221098899841, total loss: 1.0978772640228271
21th Epoch, 7765th Step, learning rate = 0.00922003922290584 - Loss: 0.4507296085357666, aux loss1: 0.8457257151603699, 
		 aux loss2: 0.5303178429603577, total loss: 0.9165744781494141
21th Epoch, 7770th Step, learning rate = 0.009219534689524203 - Loss: 0.42025625705718994, aux loss1: 0.9088059067726135, 
		 aux loss2: 0.517466127872467, total loss: 0.8998844623565674
21th Epoch, 7775th Step, learning rate = 0.009219030153074742 - Loss: 0.5668509602546692, aux loss1: 1.1686869859695435, 
		 aux loss2: 0.6685035228729248, total loss: 1.1848585605621338
21th Epoch, 7780th Step, learning rate = 0.009218525613557243 - Loss: 0.5646405220031738, aux loss1: 1.218516230583191, 
		 aux loss2: 0.6728496551513672, total loss: 1.1993352174758911
21th Epoch, 7785th Step, learning rate = 0.00921802107097151 - Loss: 0.4943773150444031, aux loss1: 0.9844635725021362, 
		 aux loss2: 0.6063926815986633, total loss: 1.0322734117507935
21th Epoch, 7790th Step, learning rate = 0.009217516525317332 - Loss: 0.5883588194847107, aux loss1: 1.1012344360351562, 
		 aux loss2: 0.683935284614563, total loss: 1.1923032999038696
22th Epoch, 7795th Step, learning rate = 0.009217011976594506 - Loss: 0.5600929856300354, aux loss1: 1.0815703868865967, 
		 aux loss2: 0.6469221711158752, total loss: 1.1433329582214355
22th Epoch, 7800th Step, learning rate = 0.009216507424802825 - Loss: 0.8123142719268799, aux loss1: 1.354400396347046, 
		 aux loss2: 0.9267878532409668, total loss: 1.5893495082855225
<7800th step>
*************************** Test ***************************
time:3m 13s, 7800th Step, Loss: 0.6956953406333923, Mean IoU = 34.665%
************************************************************
22th Epoch, 7805th Step, learning rate = 0.009216002869942086 - Loss: 0.5035598874092102, aux loss1: 0.9679865837097168, 
		 aux loss2: 0.5969771146774292, total loss: 1.03274667263031
22th Epoch, 7810th Step, learning rate = 0.009215498312012084 - Loss: 0.6055951714515686, aux loss1: 1.1071933507919312, 
		 aux loss2: 0.7147688865661621, total loss: 1.2236607074737549
22th Epoch, 7815th Step, learning rate = 0.00921499375101261 - Loss: 0.4030410349369049, aux loss1: 0.8923746943473816, 
		 aux loss2: 0.5259356498718262, total loss: 0.8811277151107788
22th Epoch, 7820th Step, learning rate = 0.00921448918694346 - Loss: 0.49432289600372314, aux loss1: 0.9481588006019592, 
		 aux loss2: 0.575008749961853, total loss: 1.0087740421295166
22th Epoch, 7825th Step, learning rate = 0.009213984619804431 - Loss: 0.40909409523010254, aux loss1: 0.8078057169914246, 
		 aux loss2: 0.47107815742492676, total loss: 0.839867115020752
22th Epoch, 7830th Step, learning rate = 0.009213480049595315 - Loss: 0.5918340086936951, aux loss1: 0.979459822177887, 
		 aux loss2: 0.6534473299980164, total loss: 1.1470508575439453
22th Epoch, 7835th Step, learning rate = 0.009212975476315907 - Loss: 0.5863534212112427, aux loss1: 1.1247944831848145, 
		 aux loss2: 0.6871568560600281, total loss: 1.1986545324325562
22th Epoch, 7840th Step, learning rate = 0.009212470899966003 - Loss: 0.5571175217628479, aux loss1: 1.0637078285217285, 
		 aux loss2: 0.6468378305435181, total loss: 1.1349650621414185
22th Epoch, 7845th Step, learning rate = 0.009211966320545396 - Loss: 0.4108484387397766, aux loss1: 0.8892011046409607, 
		 aux loss2: 0.5080747008323669, total loss: 0.8808386921882629
22th Epoch, 7850th Step, learning rate = 0.009211461738053879 - Loss: 0.4308064877986908, aux loss1: 0.8821321725845337, 
		 aux loss2: 0.5329232811927795, total loss: 0.9086154699325562
22th Epoch, 7855th Step, learning rate = 0.009210957152491248 - Loss: 0.5897822976112366, aux loss1: 1.046852707862854, 
		 aux loss2: 0.6907018423080444, total loss: 1.1801189184188843
22th Epoch, 7860th Step, learning rate = 0.009210452563857299 - Loss: 0.459334135055542, aux loss1: 0.9628150463104248, 
		 aux loss2: 0.5408456325531006, total loss: 0.9645169377326965
22th Epoch, 7865th Step, learning rate = 0.009209947972151824 - Loss: 0.4145727753639221, aux loss1: 0.8958899974822998, 
		 aux loss2: 0.5031086206436157, total loss: 0.8845832347869873
22th Epoch, 7870th Step, learning rate = 0.009209443377374617 - Loss: 0.42866241931915283, aux loss1: 0.9298519492149353, 
		 aux loss2: 0.5195680856704712, total loss: 0.9154452085494995
22th Epoch, 7875th Step, learning rate = 0.009208938779525475 - Loss: 0.5093390941619873, aux loss1: 0.9387724995613098, 
		 aux loss2: 0.5870558619499207, total loss: 1.025793194770813
22th Epoch, 7880th Step, learning rate = 0.009208434178604188 - Loss: 0.4719068109989166, aux loss1: 1.1046791076660156, 
		 aux loss2: 0.5781102776527405, total loss: 1.0345546007156372
22th Epoch, 7885th Step, learning rate = 0.009207929574610557 - Loss: 0.5343655943870544, aux loss1: 1.0534844398498535, 
		 aux loss2: 0.6260853409767151, total loss: 1.1008450984954834
22th Epoch, 7890th Step, learning rate = 0.00920742496754437 - Loss: 0.5425369739532471, aux loss1: 0.973509669303894, 
		 aux loss2: 0.5993084907531738, total loss: 1.0743132829666138
22th Epoch, 7895th Step, learning rate = 0.009206920357405423 - Loss: 0.4907611608505249, aux loss1: 0.9735704064369202, 
		 aux loss2: 0.5706908106803894, total loss: 1.011108636856079
22th Epoch, 7900th Step, learning rate = 0.009206415744193511 - Loss: 0.5570134520530701, aux loss1: 1.1056404113769531, 
		 aux loss2: 0.6797081828117371, total loss: 1.1605888605117798
<7900th step>
*************************** Test ***************************
time:3m 16s, 7900th Step, Loss: 0.6978964805603027, Mean IoU = 34.203%
************************************************************
22th Epoch, 7905th Step, learning rate = 0.009205911127908428 - Loss: 0.7656263709068298, aux loss1: 1.3151434659957886, 
		 aux loss2: 0.8731774091720581, total loss: 1.509440302848816
22th Epoch, 7910th Step, learning rate = 0.009205406508549965 - Loss: 0.5159626603126526, aux loss1: 1.0193812847137451, 
		 aux loss2: 0.6007500886917114, total loss: 1.0620770454406738
22th Epoch, 7915th Step, learning rate = 0.009204901886117922 - Loss: 0.6539714932441711, aux loss1: 1.2389999628067017, 
		 aux loss2: 0.7807714939117432, total loss: 1.337980031967163
22th Epoch, 7920th Step, learning rate = 0.009204397260612089 - Loss: 0.4550197124481201, aux loss1: 0.9182980060577393, 
		 aux loss2: 0.5313880443572998, total loss: 0.9430643916130066
22th Epoch, 7925th Step, learning rate = 0.00920389263203226 - Loss: 0.5916679501533508, aux loss1: 1.150762915611267, 
		 aux loss2: 0.7059659361839294, total loss: 1.2192832231521606
22th Epoch, 7930th Step, learning rate = 0.00920338800037823 - Loss: 0.550170361995697, aux loss1: 0.9904555678367615, 
		 aux loss2: 0.6398435235023499, total loss: 1.1032445430755615
22th Epoch, 7935th Step, learning rate = 0.009202883365649792 - Loss: 0.43034520745277405, aux loss1: 0.9082493185997009, 
		 aux loss2: 0.5219810009002686, total loss: 0.9116123914718628
22th Epoch, 7940th Step, learning rate = 0.009202378727846744 - Loss: 0.6761561036109924, aux loss1: 1.21638023853302, 
		 aux loss2: 0.7798067927360535, total loss: 1.3529930114746094
22th Epoch, 7945th Step, learning rate = 0.009201874086968874 - Loss: 0.5667793154716492, aux loss1: 1.1104512214660645, 
		 aux loss2: 0.6508874297142029, total loss: 1.1602696180343628
22th Epoch, 7950th Step, learning rate = 0.009201369443015977 - Loss: 0.564513623714447, aux loss1: 1.073310375213623, 
		 aux loss2: 0.6550371646881104, total loss: 1.1485216617584229
22th Epoch, 7955th Step, learning rate = 0.009200864795987852 - Loss: 0.6588106751441956, aux loss1: 1.1964350938796997, 
		 aux loss2: 0.7950000762939453, total loss: 1.3357412815093994
22th Epoch, 7960th Step, learning rate = 0.009200360145884288 - Loss: 0.49805957078933716, aux loss1: 0.9436856508255005, 
		 aux loss2: 0.5874001383781433, total loss: 1.0161253213882446
22th Epoch, 7965th Step, learning rate = 0.00919985549270508 - Loss: 0.5512956976890564, aux loss1: 1.0397865772247314, 
		 aux loss2: 0.6413652300834656, total loss: 1.119777798652649
22th Epoch, 7970th Step, learning rate = 0.009199350836450024 - Loss: 0.5826975107192993, aux loss1: 1.1460579633712769, 
		 aux loss2: 0.6789124011993408, total loss: 1.1980798244476318
22th Epoch, 7975th Step, learning rate = 0.00919884617711891 - Loss: 0.3549550473690033, aux loss1: 0.7642164826393127, 
		 aux loss2: 0.4306669533252716, total loss: 0.7564867734909058
22th Epoch, 7980th Step, learning rate = 0.009198341514711533 - Loss: 0.6126924753189087, aux loss1: 1.045823097229004, 
		 aux loss2: 0.7061903476715088, total loss: 1.2089155912399292
22th Epoch, 7985th Step, learning rate = 0.009197836849227687 - Loss: 0.476093590259552, aux loss1: 0.928129255771637, 
		 aux loss2: 0.5662869215011597, total loss: 0.9810470938682556
22th Epoch, 7990th Step, learning rate = 0.009197332180667166 - Loss: 0.47478169202804565, aux loss1: 0.9608513116836548, 
		 aux loss2: 0.5610342025756836, total loss: 0.9874507784843445
22th Epoch, 7995th Step, learning rate = 0.009196827509029764 - Loss: 0.46079522371292114, aux loss1: 0.9829935431480408, 
		 aux loss2: 0.5584237575531006, total loss: 0.9790627956390381
22th Epoch, 8000th Step, learning rate = 0.009196322834315275 - Loss: 0.4736163318157196, aux loss1: 0.9617467522621155, 
		 aux loss2: 0.5701152682304382, total loss: 0.9901865124702454
<8000th step>
*************************** Test ***************************
time:3m 17s, 8000th Step, Loss: 0.6198611855506897, Mean IoU = 35.577%
************************************************************
22th Epoch, 8005th Step, learning rate = 0.009195818156523488 - Loss: 0.4359755516052246, aux loss1: 0.8569803237915039, 
		 aux loss2: 0.49643614888191223, total loss: 0.8916441798210144
22th Epoch, 8010th Step, learning rate = 0.009195313475654205 - Loss: 0.45736509561538696, aux loss1: 0.9436920881271362, 
		 aux loss2: 0.5368732810020447, total loss: 0.9552220702171326
22th Epoch, 8015th Step, learning rate = 0.009194808791707212 - Loss: 0.5042052865028381, aux loss1: 0.97697913646698, 
		 aux loss2: 0.5913338661193848, total loss: 1.0338325500488281
22th Epoch, 8020th Step, learning rate = 0.009194304104682307 - Loss: 0.4529697597026825, aux loss1: 0.9565619230270386, 
		 aux loss2: 0.5553880333900452, total loss: 0.9620935916900635
22th Epoch, 8025th Step, learning rate = 0.009193799414579283 - Loss: 0.43371689319610596, aux loss1: 1.034512996673584, 
		 aux loss2: 0.5549523830413818, total loss: 0.9660516977310181
22th Epoch, 8030th Step, learning rate = 0.00919329472139793 - Loss: 0.46963897347450256, aux loss1: 0.878372311592102, 
		 aux loss2: 0.5517429709434509, total loss: 0.9538478851318359
22th Epoch, 8035th Step, learning rate = 0.009192790025138045 - Loss: 0.5397522449493408, aux loss1: 1.08775794506073, 
		 aux loss2: 0.6658316254615784, total loss: 1.132412314414978
22th Epoch, 8040th Step, learning rate = 0.009192285325799418 - Loss: 0.5229129195213318, aux loss1: 0.9838755130767822, 
		 aux loss2: 0.5935030579566956, total loss: 1.0554767847061157
22th Epoch, 8045th Step, learning rate = 0.00919178062338185 - Loss: 0.41487744450569153, aux loss1: 0.9167027473449707, 
		 aux loss2: 0.49277830123901367, total loss: 0.8869995474815369
22th Epoch, 8050th Step, learning rate = 0.009191275917885124 - Loss: 0.41503527760505676, aux loss1: 0.9029552340507507, 
		 aux loss2: 0.4947510361671448, total loss: 0.8838222622871399
22th Epoch, 8055th Step, learning rate = 0.009190771209309041 - Loss: 0.4945170283317566, aux loss1: 0.9527351260185242, 
		 aux loss2: 0.5628386735916138, total loss: 1.005473017692566
22th Epoch, 8060th Step, learning rate = 0.00919026649765339 - Loss: 0.5663948655128479, aux loss1: 1.0468803644180298, 
		 aux loss2: 0.6693969964981079, total loss: 1.148217797279358
22th Epoch, 8065th Step, learning rate = 0.009189761782917968 - Loss: 0.501494824886322, aux loss1: 1.0343663692474365, 
		 aux loss2: 0.5980382561683655, total loss: 1.0510200262069702
22th Epoch, 8070th Step, learning rate = 0.009189257065102565 - Loss: 0.4400976896286011, aux loss1: 0.8995554447174072, 
		 aux loss2: 0.5212029814720154, total loss: 0.9184455275535583
22th Epoch, 8075th Step, learning rate = 0.009188752344206975 - Loss: 0.5663025975227356, aux loss1: 1.0932157039642334, 
		 aux loss2: 0.6511058807373047, total loss: 1.1547096967697144
22th Epoch, 8080th Step, learning rate = 0.009188247620230993 - Loss: 0.40453028678894043, aux loss1: 0.8768728971481323, 
		 aux loss2: 0.4917023181915283, total loss: 0.8642730712890625
22th Epoch, 8085th Step, learning rate = 0.00918774289317441 - Loss: 0.6582979559898376, aux loss1: 1.170055866241455, 
		 aux loss2: 0.7546495199203491, total loss: 1.3111746311187744
22th Epoch, 8090th Step, learning rate = 0.00918723816303702 - Loss: 0.5752414464950562, aux loss1: 1.080060362815857, 
		 aux loss2: 0.6662647724151611, total loss: 1.1657655239105225
22th Epoch, 8095th Step, learning rate = 0.009186733429818617 - Loss: 0.5105664134025574, aux loss1: 0.9494976997375488, 
		 aux loss2: 0.6181308031082153, total loss: 1.042668104171753
22th Epoch, 8100th Step, learning rate = 0.009186228693518995 - Loss: 0.5190553665161133, aux loss1: 1.0124415159225464, 
		 aux loss2: 0.604131281375885, total loss: 1.064440369606018
<8100th step>
*************************** Test ***************************
time:3m 16s, 8100th Step, Loss: 0.7006241679191589, Mean IoU = 32.319%
************************************************************
22th Epoch, 8105th Step, learning rate = 0.009185723954137942 - Loss: 0.6851227879524231, aux loss1: 1.1486520767211914, 
		 aux loss2: 0.7682644724845886, total loss: 1.337024211883545
22th Epoch, 8110th Step, learning rate = 0.009185219211675255 - Loss: 0.4500073492527008, aux loss1: 0.8675142526626587, 
		 aux loss2: 0.5323479771614075, total loss: 0.9232008457183838
22th Epoch, 8115th Step, learning rate = 0.009184714466130728 - Loss: 0.5334279537200928, aux loss1: 1.005192756652832, 
		 aux loss2: 0.6178915500640869, total loss: 1.0821423530578613
22th Epoch, 8120th Step, learning rate = 0.009184209717504152 - Loss: 0.4902454614639282, aux loss1: 1.0227489471435547, 
		 aux loss2: 0.5934674143791199, total loss: 1.0344570875167847
22th Epoch, 8125th Step, learning rate = 0.009183704965795321 - Loss: 0.483897864818573, aux loss1: 0.9143953919410706, 
		 aux loss2: 0.5692940950393677, total loss: 0.9859341382980347
22th Epoch, 8130th Step, learning rate = 0.009183200211004026 - Loss: 0.6309201121330261, aux loss1: 1.215621829032898, 
		 aux loss2: 0.7404757142066956, total loss: 1.2917969226837158
22th Epoch, 8135th Step, learning rate = 0.009182695453130064 - Loss: 0.42892855405807495, aux loss1: 0.8626711964607239, 
		 aux loss2: 0.4918110966682434, total loss: 0.8844543695449829
22th Epoch, 8140th Step, learning rate = 0.009182190692173221 - Loss: 0.5403243899345398, aux loss1: 1.0646357536315918, 
		 aux loss2: 0.6331369280815125, total loss: 1.1129698753356934
22th Epoch, 8145th Step, learning rate = 0.009181685928133296 - Loss: 0.6711110472679138, aux loss1: 1.2162582874298096, 
		 aux loss2: 0.7652410864830017, total loss: 1.3420850038528442
22th Epoch, 8150th Step, learning rate = 0.009181181161010082 - Loss: 0.4793911576271057, aux loss1: 0.8668946623802185, 
		 aux loss2: 0.5500402450561523, total loss: 0.9594756960868835
22th Epoch, 8155th Step, learning rate = 0.009180676390803368 - Loss: 0.4288080632686615, aux loss1: 0.8524993062019348, 
		 aux loss2: 0.5033984780311584, total loss: 0.8859172463417053
22th Epoch, 8160th Step, learning rate = 0.009180171617512948 - Loss: 0.5177359580993652, aux loss1: 0.9319220185279846, 
		 aux loss2: 0.5974689722061157, total loss: 1.0363001823425293
23th Epoch, 8165th Step, learning rate = 0.009179666841138615 - Loss: 0.4566100239753723, aux loss1: 0.9089755415916443, 
		 aux loss2: 0.533889651298523, total loss: 0.9428585767745972
23th Epoch, 8170th Step, learning rate = 0.009179162061680164 - Loss: 0.4286443293094635, aux loss1: 0.8842570185661316, 
		 aux loss2: 0.533493161201477, total loss: 0.9073187112808228
23th Epoch, 8175th Step, learning rate = 0.009178657279137385 - Loss: 0.5921614170074463, aux loss1: 1.0331263542175293, 
		 aux loss2: 0.6758780479431152, total loss: 1.1724505424499512
23th Epoch, 8180th Step, learning rate = 0.00917815249351007 - Loss: 0.44818222522735596, aux loss1: 0.8584302663803101, 
		 aux loss2: 0.5475720167160034, total loss: 0.9247401356697083
23th Epoch, 8185th Step, learning rate = 0.009177647704798014 - Loss: 0.5412512421607971, aux loss1: 1.0306681394577026, 
		 aux loss2: 0.6310571432113647, total loss: 1.102874517440796
23th Epoch, 8190th Step, learning rate = 0.009177142913001009 - Loss: 0.4481291174888611, aux loss1: 0.9935237765312195, 
		 aux loss2: 0.5469449162483215, total loss: 0.9649642109870911
23th Epoch, 8195th Step, learning rate = 0.009176638118118847 - Loss: 0.3464028537273407, aux loss1: 0.7838869094848633, 
		 aux loss2: 0.4202188551425934, total loss: 0.7496564984321594
23th Epoch, 8200th Step, learning rate = 0.009176133320151322 - Loss: 0.5934881567955017, aux loss1: 1.0557209253311157, 
		 aux loss2: 0.6942163109779358, total loss: 1.1878910064697266
<8200th step>
*************************** Test ***************************
time:3m 10s, 8200th Step, Loss: 0.6492815613746643, Mean IoU = 33.572%
************************************************************
23th Epoch, 8205th Step, learning rate = 0.009175628519098224 - Loss: 0.5387279987335205, aux loss1: 1.0337275266647339, 
		 aux loss2: 0.618125319480896, total loss: 1.096096396446228
23th Epoch, 8210th Step, learning rate = 0.009175123714959347 - Loss: 0.5000325441360474, aux loss1: 0.9360462427139282, 
		 aux loss2: 0.5753614902496338, total loss: 1.0109909772872925
23th Epoch, 8215th Step, learning rate = 0.009174618907734484 - Loss: 0.5062175393104553, aux loss1: 1.0112406015396118, 
		 aux loss2: 0.6179178357124329, total loss: 1.056756854057312
23th Epoch, 8220th Step, learning rate = 0.009174114097423426 - Loss: 0.4168418347835541, aux loss1: 0.9036800265312195, 
		 aux loss2: 0.5030412673950195, total loss: 0.8891623616218567
23th Epoch, 8225th Step, learning rate = 0.009173609284025967 - Loss: 0.43754342198371887, aux loss1: 0.9150369763374329, 
		 aux loss2: 0.5164253115653992, total loss: 0.9186246395111084
23th Epoch, 8230th Step, learning rate = 0.009173104467541899 - Loss: 0.4428911507129669, aux loss1: 0.8899049162864685, 
		 aux loss2: 0.5309478044509888, total loss: 0.9222418069839478
23th Epoch, 8235th Step, learning rate = 0.009172599647971014 - Loss: 0.4618852138519287, aux loss1: 1.0227491855621338, 
		 aux loss2: 0.5728805065155029, total loss: 0.9978622198104858
23th Epoch, 8240th Step, learning rate = 0.009172094825313103 - Loss: 0.7058383226394653, aux loss1: 1.3128198385238647, 
		 aux loss2: 0.8329275250434875, total loss: 1.432855248451233
23th Epoch, 8245th Step, learning rate = 0.009171589999567962 - Loss: 0.42597970366477966, aux loss1: 0.963701605796814, 
		 aux loss2: 0.5239961743354797, total loss: 0.9246886372566223
23th Epoch, 8250th Step, learning rate = 0.00917108517073538 - Loss: 0.4762146770954132, aux loss1: 0.9345026016235352, 
		 aux loss2: 0.5469704270362854, total loss: 0.9753535985946655
23th Epoch, 8255th Step, learning rate = 0.00917058033881515 - Loss: 0.43307065963745117, aux loss1: 0.8516761660575867, 
		 aux loss2: 0.5253229141235352, total loss: 0.8987026214599609
23th Epoch, 8260th Step, learning rate = 0.009170075503807067 - Loss: 0.5418447852134705, aux loss1: 1.072589635848999, 
		 aux loss2: 0.6195380091667175, total loss: 1.1114369630813599
23th Epoch, 8265th Step, learning rate = 0.00916957066571092 - Loss: 0.5102150440216064, aux loss1: 0.9856444597244263, 
		 aux loss2: 0.5877817869186401, total loss: 1.0410211086273193
23th Epoch, 8270th Step, learning rate = 0.009169065824526501 - Loss: 0.4517979621887207, aux loss1: 1.0020339488983154, 
		 aux loss2: 0.5455434918403625, total loss: 0.9706255197525024
23th Epoch, 8275th Step, learning rate = 0.009168560980253605 - Loss: 0.5822097659111023, aux loss1: 1.1238408088684082, 
		 aux loss2: 0.6843569874763489, total loss: 1.1931047439575195
23th Epoch, 8280th Step, learning rate = 0.009168056132892021 - Loss: 0.6141407489776611, aux loss1: 1.152401089668274, 
		 aux loss2: 0.7456265091896057, total loss: 1.2581117153167725
23th Epoch, 8285th Step, learning rate = 0.009167551282441542 - Loss: 0.45788252353668213, aux loss1: 0.9423543214797974, 
		 aux loss2: 0.5402079224586487, total loss: 0.9566720128059387
23th Epoch, 8290th Step, learning rate = 0.009167046428901962 - Loss: 0.3696008622646332, aux loss1: 0.8112484216690063, 
		 aux loss2: 0.46960172057151794, total loss: 0.8008161187171936
23th Epoch, 8295th Step, learning rate = 0.009166541572273071 - Loss: 0.764376699924469, aux loss1: 1.3016632795333862, 
		 aux loss2: 0.8719428181648254, total loss: 1.5036529302597046
23th Epoch, 8300th Step, learning rate = 0.009166036712554662 - Loss: 0.44086137413978577, aux loss1: 0.9189406633377075, 
		 aux loss2: 0.5242689251899719, total loss: 0.9262511134147644
<8300th step>
*************************** Test ***************************
time:3m 17s, 8300th Step, Loss: 0.7543352246284485, Mean IoU = 32.982%
************************************************************
23th Epoch, 8305th Step, learning rate = 0.009165531849746526 - Loss: 0.4020349681377411, aux loss1: 0.7895911335945129, 
		 aux loss2: 0.4744599759578705, total loss: 0.8286963105201721
23th Epoch, 8310th Step, learning rate = 0.009165026983848457 - Loss: 0.448368638753891, aux loss1: 0.9960619211196899, 
		 aux loss2: 0.5488899350166321, total loss: 0.9667432308197021
23th Epoch, 8315th Step, learning rate = 0.009164522114860246 - Loss: 0.4526321589946747, aux loss1: 0.897593080997467, 
		 aux loss2: 0.5305907726287842, total loss: 0.9341464042663574
23th Epoch, 8320th Step, learning rate = 0.009164017242781684 - Loss: 0.49110525846481323, aux loss1: 1.0707390308380127, 
		 aux loss2: 0.6247228384017944, total loss: 1.06221604347229
23th Epoch, 8325th Step, learning rate = 0.009163512367612562 - Loss: 0.5976191163063049, aux loss1: 1.0544753074645996, 
		 aux loss2: 0.6885954141616821, total loss: 1.1893998384475708
23th Epoch, 8330th Step, learning rate = 0.009163007489352677 - Loss: 0.5367322564125061, aux loss1: 1.0880483388900757, 
		 aux loss2: 0.6263801455497742, total loss: 1.1136988401412964
23th Epoch, 8335th Step, learning rate = 0.009162502608001815 - Loss: 0.4271196126937866, aux loss1: 0.9561859965324402, 
		 aux loss2: 0.5298162698745728, total loss: 0.9259019494056702
23th Epoch, 8340th Step, learning rate = 0.009161997723559771 - Loss: 0.7619448900222778, aux loss1: 1.2303311824798584, 
		 aux loss2: 0.8506416082382202, total loss: 1.4713009595870972
23th Epoch, 8345th Step, learning rate = 0.009161492836026333 - Loss: 0.42295190691947937, aux loss1: 0.8588423132896423, 
		 aux loss2: 0.5080248117446899, total loss: 0.8838145136833191
23th Epoch, 8350th Step, learning rate = 0.0091609879454013 - Loss: 0.39913660287857056, aux loss1: 0.9035083651542664, 
		 aux loss2: 0.49006715416908264, total loss: 0.8662160038948059
23th Epoch, 8355th Step, learning rate = 0.009160483051684458 - Loss: 0.43897032737731934, aux loss1: 0.9325397610664368, 
		 aux loss2: 0.5316970944404602, total loss: 0.93141108751297
23th Epoch, 8360th Step, learning rate = 0.0091599781548756 - Loss: 0.42637869715690613, aux loss1: 0.9490641951560974, 
		 aux loss2: 0.5039929151535034, total loss: 0.9126951098442078
23th Epoch, 8365th Step, learning rate = 0.009159473254974517 - Loss: 0.37574517726898193, aux loss1: 0.8269327878952026, 
		 aux loss2: 0.4576564431190491, total loss: 0.8068876266479492
23th Epoch, 8370th Step, learning rate = 0.009158968351981002 - Loss: 0.49390387535095215, aux loss1: 1.0194040536880493, 
		 aux loss2: 0.5783987045288086, total loss: 1.0310845375061035
23th Epoch, 8375th Step, learning rate = 0.009158463445894847 - Loss: 0.4230947196483612, aux loss1: 0.8451014161109924, 
		 aux loss2: 0.4912751615047455, total loss: 0.8731352090835571
23th Epoch, 8380th Step, learning rate = 0.009157958536715841 - Loss: 0.45873695611953735, aux loss1: 0.9963524341583252, 
		 aux loss2: 0.5865777134895325, total loss: 0.9922738075256348
23th Epoch, 8385th Step, learning rate = 0.00915745362444378 - Loss: 0.570747435092926, aux loss1: 1.087418794631958, 
		 aux loss2: 0.6848868131637573, total loss: 1.1709277629852295
23th Epoch, 8390th Step, learning rate = 0.00915694870907845 - Loss: 0.6094779372215271, aux loss1: 1.2125028371810913, 
		 aux loss2: 0.7541728615760803, total loss: 1.2748979330062866
23th Epoch, 8395th Step, learning rate = 0.009156443790619648 - Loss: 0.975362241268158, aux loss1: 1.5109748840332031, 
		 aux loss2: 1.1168657541275024, total loss: 1.8754010200500488
23th Epoch, 8400th Step, learning rate = 0.009155938869067161 - Loss: 0.4505894184112549, aux loss1: 0.9082589745521545, 
		 aux loss2: 0.5382646322250366, total loss: 0.9383730292320251
<8400th step>
*************************** Test ***************************
time:3m 16s, 8400th Step, Loss: 0.7485359311103821, Mean IoU = 32.004%
************************************************************
23th Epoch, 8405th Step, learning rate = 0.009155433944420784 - Loss: 0.5518579483032227, aux loss1: 0.9465028047561646, 
		 aux loss2: 0.602465033531189, total loss: 1.0767948627471924
23th Epoch, 8410th Step, learning rate = 0.009154929016680306 - Loss: 0.5845482349395752, aux loss1: 1.1196434497833252, 
		 aux loss2: 0.6624330878257751, total loss: 1.1854145526885986
23th Epoch, 8415th Step, learning rate = 0.00915442408584552 - Loss: 0.5553070902824402, aux loss1: 1.0144002437591553, 
		 aux loss2: 0.6322409510612488, total loss: 1.1125235557556152
23th Epoch, 8420th Step, learning rate = 0.009153919151916216 - Loss: 0.5739285349845886, aux loss1: 1.0537179708480835, 
		 aux loss2: 0.6925857663154602, total loss: 1.1670782566070557
23th Epoch, 8425th Step, learning rate = 0.009153414214892188 - Loss: 0.40132007002830505, aux loss1: 0.8371044397354126, 
		 aux loss2: 0.4723688066005707, total loss: 0.8413989543914795
23th Epoch, 8430th Step, learning rate = 0.009152909274773222 - Loss: 0.5240601301193237, aux loss1: 1.1114038228988647, 
		 aux loss2: 0.6407831311225891, total loss: 1.1137945652008057
23th Epoch, 8435th Step, learning rate = 0.009152404331559115 - Loss: 0.47999876737594604, aux loss1: 0.9048667550086975, 
		 aux loss2: 0.5473227500915527, total loss: 0.970387876033783
23th Epoch, 8440th Step, learning rate = 0.009151899385249657 - Loss: 0.4297391474246979, aux loss1: 0.9143165349960327, 
		 aux loss2: 0.5333700180053711, total loss: 0.9173821210861206
23th Epoch, 8445th Step, learning rate = 0.009151394435844637 - Loss: 0.435516893863678, aux loss1: 0.9251336455345154, 
		 aux loss2: 0.5113058686256409, total loss: 0.9175794124603271
23th Epoch, 8450th Step, learning rate = 0.009150889483343846 - Loss: 0.6339104771614075, aux loss1: 1.1238914728164673, 
		 aux loss2: 0.7709745168685913, total loss: 1.2794677019119263
23th Epoch, 8455th Step, learning rate = 0.00915038452774708 - Loss: 0.44816288352012634, aux loss1: 0.8905702233314514, 
		 aux loss2: 0.5120403170585632, total loss: 0.9201500415802002
23th Epoch, 8460th Step, learning rate = 0.009149879569054125 - Loss: 0.5370139479637146, aux loss1: 1.0685845613479614, 
		 aux loss2: 0.619636595249176, total loss: 1.1054439544677734
23th Epoch, 8465th Step, learning rate = 0.009149374607264775 - Loss: 0.4521687924861908, aux loss1: 0.8719455599784851, 
		 aux loss2: 0.5300775170326233, total loss: 0.9257835149765015
23th Epoch, 8470th Step, learning rate = 0.009148869642378819 - Loss: 0.5864099264144897, aux loss1: 0.9915758371353149, 
		 aux loss2: 0.6477857828140259, total loss: 1.1429970264434814
23th Epoch, 8475th Step, learning rate = 0.00914836467439605 - Loss: 0.5754541158676147, aux loss1: 1.1009749174118042, 
		 aux loss2: 0.6684487462043762, total loss: 1.1731261014938354
23th Epoch, 8480th Step, learning rate = 0.009147859703316259 - Loss: 0.37429386377334595, aux loss1: 0.8268085718154907, 
		 aux loss2: 0.4559844732284546, total loss: 0.804730236530304
23th Epoch, 8485th Step, learning rate = 0.009147354729139235 - Loss: 0.6467816829681396, aux loss1: 1.1363483667373657, 
		 aux loss2: 0.7483218312263489, total loss: 1.2870149612426758
23th Epoch, 8490th Step, learning rate = 0.00914684975186477 - Loss: 0.4414575695991516, aux loss1: 0.8782078623771667, 
		 aux loss2: 0.5239788889884949, total loss: 0.914511501789093
23th Epoch, 8495th Step, learning rate = 0.009146344771492659 - Loss: 0.39346882700920105, aux loss1: 0.9418531060218811, 
		 aux loss2: 0.48669543862342834, total loss: 0.8707029819488525
23th Epoch, 8500th Step, learning rate = 0.009145839788022688 - Loss: 0.5081900358200073, aux loss1: 0.9282885789871216, 
		 aux loss2: 0.5670219659805298, total loss: 1.0134854316711426
<8500th step>
*************************** Test ***************************
time:3m 16s, 8500th Step, Loss: 0.6380845904350281, Mean IoU = 35.343%
************************************************************
23th Epoch, 8505th Step, learning rate = 0.009145334801454647 - Loss: 0.40832579135894775, aux loss1: 0.870964765548706, 
		 aux loss2: 0.4865815341472626, total loss: 0.8642479181289673
23th Epoch, 8510th Step, learning rate = 0.009144829811788333 - Loss: 0.4395144283771515, aux loss1: 0.981768012046814, 
		 aux loss2: 0.5313071608543396, total loss: 0.946567714214325
23th Epoch, 8515th Step, learning rate = 0.00914432481902353 - Loss: 0.485483318567276, aux loss1: 1.1167008876800537, 
		 aux loss2: 0.5943931341171265, total loss: 1.0582507848739624
23th Epoch, 8520th Step, learning rate = 0.009143819823160034 - Loss: 0.6356809735298157, aux loss1: 1.0816705226898193, 
		 aux loss2: 0.7412731051445007, total loss: 1.256691336631775
23th Epoch, 8525th Step, learning rate = 0.009143314824197633 - Loss: 0.525880753993988, aux loss1: 1.0498844385147095, 
		 aux loss2: 0.6129307746887207, total loss: 1.0860183238983154
23th Epoch, 8530th Step, learning rate = 0.00914280982213612 - Loss: 0.540908694267273, aux loss1: 1.0813058614730835, 
		 aux loss2: 0.6250287294387817, total loss: 1.1153119802474976
24th Epoch, 8535th Step, learning rate = 0.009142304816975281 - Loss: 0.4378054141998291, aux loss1: 0.8911014199256897, 
		 aux loss2: 0.509482741355896, total loss: 0.9089289307594299
24th Epoch, 8540th Step, learning rate = 0.009141799808714914 - Loss: 0.49274465441703796, aux loss1: 0.9533953666687012, 
		 aux loss2: 0.5846202969551086, total loss: 1.0126113891601562
24th Epoch, 8545th Step, learning rate = 0.009141294797354803 - Loss: 0.4721807539463043, aux loss1: 0.9381333589553833, 
		 aux loss2: 0.573296308517456, total loss: 0.9829392433166504
24th Epoch, 8550th Step, learning rate = 0.009140789782894745 - Loss: 0.6422502398490906, aux loss1: 1.121754765510559, 
		 aux loss2: 0.745446503162384, total loss: 1.2769553661346436
24th Epoch, 8555th Step, learning rate = 0.009140284765334525 - Loss: 0.6588004231452942, aux loss1: 1.1609704494476318, 
		 aux loss2: 0.7568811178207397, total loss: 1.3098440170288086
24th Epoch, 8560th Step, learning rate = 0.009139779744673936 - Loss: 0.5089481472969055, aux loss1: 0.9162814617156982, 
		 aux loss2: 0.5718291997909546, total loss: 1.0125643014907837
24th Epoch, 8565th Step, learning rate = 0.00913927472091277 - Loss: 0.42177510261535645, aux loss1: 0.8526549339294434, 
		 aux loss2: 0.5075664520263672, total loss: 0.8805981874465942
24th Epoch, 8570th Step, learning rate = 0.009138769694050815 - Loss: 0.6274709105491638, aux loss1: 1.2070523500442505, 
		 aux loss2: 0.7445028424263, total loss: 1.287387728691101
24th Epoch, 8575th Step, learning rate = 0.009138264664087863 - Loss: 0.5023062229156494, aux loss1: 0.9736534953117371, 
		 aux loss2: 0.6066846251487732, total loss: 1.0370761156082153
24th Epoch, 8580th Step, learning rate = 0.009137759631023704 - Loss: 0.4942876994609833, aux loss1: 1.0016570091247559, 
		 aux loss2: 0.6009730696678162, total loss: 1.035174012184143
24th Epoch, 8585th Step, learning rate = 0.00913725459485813 - Loss: 0.5531308650970459, aux loss1: 1.1545644998550415, 
		 aux loss2: 0.6901856064796448, total loss: 1.175574541091919
24th Epoch, 8590th Step, learning rate = 0.009136749555590929 - Loss: 0.680311381816864, aux loss1: 1.1907329559326172, 
		 aux loss2: 0.7891624569892883, total loss: 1.3531962633132935
24th Epoch, 8595th Step, learning rate = 0.009136244513221894 - Loss: 0.41803455352783203, aux loss1: 0.8821896910667419, 
		 aux loss2: 0.5098642706871033, total loss: 0.8866371512413025
24th Epoch, 8600th Step, learning rate = 0.009135739467750812 - Loss: 0.42368990182876587, aux loss1: 0.8259516358375549, 
		 aux loss2: 0.5048692226409912, total loss: 0.8734230995178223
<8600th step>
*************************** Test ***************************
time:3m 14s, 8600th Step, Loss: 0.6134259700775146, Mean IoU = 33.241%
************************************************************
24th Epoch, 8605th Step, learning rate = 0.009135234419177476 - Loss: 0.48615556955337524, aux loss1: 1.0322515964508057, 
		 aux loss2: 0.5772368907928467, total loss: 1.0267258882522583
24th Epoch, 8610th Step, learning rate = 0.009134729367501678 - Loss: 0.38056090474128723, aux loss1: 0.8096473217010498, 
		 aux loss2: 0.45717278122901917, total loss: 0.8063242435455322
24th Epoch, 8615th Step, learning rate = 0.009134224312723205 - Loss: 0.4020192325115204, aux loss1: 0.8937472105026245, 
		 aux loss2: 0.4867520034313202, total loss: 0.8648442029953003
24th Epoch, 8620th Step, learning rate = 0.00913371925484185 - Loss: 0.46150246262550354, aux loss1: 0.921886146068573, 
		 aux loss2: 0.5382093787193298, total loss: 0.9533520936965942
24th Epoch, 8625th Step, learning rate = 0.0091332141938574 - Loss: 0.4617239534854889, aux loss1: 0.9478442668914795, 
		 aux loss2: 0.5574225783348083, total loss: 0.9690462946891785
24th Epoch, 8630th Step, learning rate = 0.009132709129769647 - Loss: 0.3805302679538727, aux loss1: 0.7995445728302002, 
		 aux loss2: 0.4497823715209961, total loss: 0.8003065586090088
24th Epoch, 8635th Step, learning rate = 0.009132204062578383 - Loss: 0.6551244854927063, aux loss1: 1.1289095878601074, 
		 aux loss2: 0.7744441032409668, total loss: 1.303575038909912
24th Epoch, 8640th Step, learning rate = 0.009131698992283397 - Loss: 0.4597465395927429, aux loss1: 0.9377583265304565, 
		 aux loss2: 0.5538538098335266, total loss: 0.9626156091690063
24th Epoch, 8645th Step, learning rate = 0.009131193918884476 - Loss: 0.5283392071723938, aux loss1: 1.0396461486816406, 
		 aux loss2: 0.6444938778877258, total loss: 1.098030686378479
24th Epoch, 8650th Step, learning rate = 0.009130688842381414 - Loss: 0.4850836992263794, aux loss1: 0.9600604176521301, 
		 aux loss2: 0.576442539691925, total loss: 1.003678798675537
24th Epoch, 8655th Step, learning rate = 0.009130183762774002 - Loss: 0.4019342362880707, aux loss1: 0.8781833052635193, 
		 aux loss2: 0.4932555556297302, total loss: 0.8626914620399475
24th Epoch, 8660th Step, learning rate = 0.009129678680062026 - Loss: 0.6836477518081665, aux loss1: 1.1013809442520142, 
		 aux loss2: 0.7694226503372192, total loss: 1.3218311071395874
24th Epoch, 8665th Step, learning rate = 0.009129173594245279 - Loss: 0.5143988132476807, aux loss1: 1.0488580465316772, 
		 aux loss2: 0.6202283501625061, total loss: 1.0771476030349731
24th Epoch, 8670th Step, learning rate = 0.009128668505323552 - Loss: 0.5387979745864868, aux loss1: 1.0163568258285522, 
		 aux loss2: 0.63239586353302, total loss: 1.096663475036621
24th Epoch, 8675th Step, learning rate = 0.009128163413296631 - Loss: 0.5055898427963257, aux loss1: 1.0001635551452637, 
		 aux loss2: 0.629235565662384, total loss: 1.0573331117630005
24th Epoch, 8680th Step, learning rate = 0.00912765831816431 - Loss: 0.6700105667114258, aux loss1: 1.090498685836792, 
		 aux loss2: 0.7457389235496521, total loss: 1.295455813407898
24th Epoch, 8685th Step, learning rate = 0.009127153219926375 - Loss: 0.4488966166973114, aux loss1: 0.8936500549316406, 
		 aux loss2: 0.5295975804328918, total loss: 0.9288306832313538
24th Epoch, 8690th Step, learning rate = 0.00912664811858262 - Loss: 0.35829147696495056, aux loss1: 0.7495318055152893, 
		 aux loss2: 0.4181669354438782, total loss: 0.7504178285598755
24th Epoch, 8695th Step, learning rate = 0.009126143014132834 - Loss: 0.5882665514945984, aux loss1: 1.0923891067504883, 
		 aux loss2: 0.6940252780914307, total loss: 1.1935935020446777
24th Epoch, 8700th Step, learning rate = 0.009125637906576804 - Loss: 0.3355156481266022, aux loss1: 0.7933283448219299, 
		 aux loss2: 0.3955415189266205, total loss: 0.7317307591438293
<8700th step>
*************************** Test ***************************
time:3m 16s, 8700th Step, Loss: 0.6328968405723572, Mean IoU = 35.209%
************************************************************
24th Epoch, 8705th Step, learning rate = 0.009125132795914322 - Loss: 0.4576653838157654, aux loss1: 0.9196067452430725, 
		 aux loss2: 0.5528496503829956, total loss: 0.9546872973442078
24th Epoch, 8710th Step, learning rate = 0.009124627682145179 - Loss: 0.42746061086654663, aux loss1: 0.8778954148292542, 
		 aux loss2: 0.4965422451496124, total loss: 0.8894461989402771
24th Epoch, 8715th Step, learning rate = 0.009124122565269163 - Loss: 0.5867001414299011, aux loss1: 1.0066994428634644, 
		 aux loss2: 0.6682597994804382, total loss: 1.1560139656066895
24th Epoch, 8720th Step, learning rate = 0.009123617445286064 - Loss: 0.5308101177215576, aux loss1: 0.9382284879684448, 
		 aux loss2: 0.6176407933235168, total loss: 1.0593349933624268
24th Epoch, 8725th Step, learning rate = 0.009123112322195672 - Loss: 0.4692830443382263, aux loss1: 1.0042903423309326, 
		 aux loss2: 0.5687305331230164, total loss: 0.9980623722076416
24th Epoch, 8730th Step, learning rate = 0.009122607195997778 - Loss: 0.41483187675476074, aux loss1: 0.9464194774627686, 
		 aux loss2: 0.4966167211532593, total loss: 0.8974044322967529
24th Epoch, 8735th Step, learning rate = 0.009122102066692171 - Loss: 0.4152078330516815, aux loss1: 0.8813581466674805, 
		 aux loss2: 0.5117659568786621, total loss: 0.8843216300010681
24th Epoch, 8740th Step, learning rate = 0.009121596934278638 - Loss: 0.35532745718955994, aux loss1: 0.7907000184059143, 
		 aux loss2: 0.42540058493614197, total loss: 0.762697696685791
24th Epoch, 8745th Step, learning rate = 0.009121091798756972 - Loss: 0.5428906083106995, aux loss1: 1.063040018081665, 
		 aux loss2: 0.658669114112854, total loss: 1.1252702474594116
24th Epoch, 8750th Step, learning rate = 0.009120586660126962 - Loss: 0.48324480652809143, aux loss1: 0.9605472087860107, 
		 aux loss2: 0.5764821171760559, total loss: 1.0020017623901367
24th Epoch, 8755th Step, learning rate = 0.009120081518388395 - Loss: 0.5922276973724365, aux loss1: 1.0450595617294312, 
		 aux loss2: 0.6874917149543762, total loss: 1.1807422637939453
24th Epoch, 8760th Step, learning rate = 0.009119576373541065 - Loss: 0.5218189358711243, aux loss1: 1.018445611000061, 
		 aux loss2: 0.6176367998123169, total loss: 1.0744073390960693
24th Epoch, 8765th Step, learning rate = 0.009119071225584757 - Loss: 0.8759955763816833, aux loss1: 1.485266089439392, 
		 aux loss2: 1.0096631050109863, total loss: 1.7254406213760376
24th Epoch, 8770th Step, learning rate = 0.009118566074519264 - Loss: 0.6555479168891907, aux loss1: 1.3036906719207764, 
		 aux loss2: 0.7801440954208374, total loss: 1.3587127923965454
24th Epoch, 8775th Step, learning rate = 0.009118060920344373 - Loss: 0.6779308915138245, aux loss1: 1.1950404644012451, 
		 aux loss2: 0.7801316380500793, total loss: 1.3484957218170166
24th Epoch, 8780th Step, learning rate = 0.009117555763059875 - Loss: 0.5563346743583679, aux loss1: 1.0341283082962036, 
		 aux loss2: 0.6535152792930603, total loss: 1.1279792785644531
24th Epoch, 8785th Step, learning rate = 0.00911705060266556 - Loss: 0.4256296753883362, aux loss1: 1.0443185567855835, 
		 aux loss2: 0.5510284900665283, total loss: 0.9593366384506226
24th Epoch, 8790th Step, learning rate = 0.009116545439161216 - Loss: 0.498334139585495, aux loss1: 0.9411922693252563, 
		 aux loss2: 0.607244074344635, total loss: 1.0235894918441772
24th Epoch, 8795th Step, learning rate = 0.00911604027254663 - Loss: 0.4520094692707062, aux loss1: 0.9243963956832886, 
		 aux loss2: 0.5360652208328247, total loss: 0.9437544941902161
24th Epoch, 8800th Step, learning rate = 0.009115535102821598 - Loss: 0.574015736579895, aux loss1: 1.0632951259613037, 
		 aux loss2: 0.7103284597396851, total loss: 1.177135705947876
<8800th step>
*************************** Test ***************************
time:3m 17s, 8800th Step, Loss: 1.1262929439544678, Mean IoU = 29.033%
************************************************************
24th Epoch, 8805th Step, learning rate = 0.009115029929985904 - Loss: 0.3870820105075836, aux loss1: 0.8093920350074768, 
		 aux loss2: 0.47470250725746155, total loss: 0.8197806477546692
24th Epoch, 8810th Step, learning rate = 0.009114524754039338 - Loss: 0.5161173343658447, aux loss1: 1.0599178075790405, 
		 aux loss2: 0.633940577507019, total loss: 1.0876688957214355
24th Epoch, 8815th Step, learning rate = 0.009114019574981692 - Loss: 0.4948965311050415, aux loss1: 0.9358924627304077, 
		 aux loss2: 0.5779105424880981, total loss: 1.0068285465240479
24th Epoch, 8820th Step, learning rate = 0.00911351439281275 - Loss: 0.5146295428276062, aux loss1: 1.0433839559555054, 
		 aux loss2: 0.6137985587120056, total loss: 1.0731641054153442
24th Epoch, 8825th Step, learning rate = 0.009113009207532307 - Loss: 0.5034665465354919, aux loss1: 1.083688735961914, 
		 aux loss2: 0.6186596155166626, total loss: 1.076037049293518
24th Epoch, 8830th Step, learning rate = 0.009112504019140148 - Loss: 0.6605265140533447, aux loss1: 1.1935372352600098, 
		 aux loss2: 0.7660064697265625, total loss: 1.3249902725219727
24th Epoch, 8835th Step, learning rate = 0.009111998827636065 - Loss: 0.7214264273643494, aux loss1: 1.2768728733062744, 
		 aux loss2: 0.8426725268363953, total loss: 1.4415574073791504
24th Epoch, 8840th Step, learning rate = 0.009111493633019845 - Loss: 0.45062896609306335, aux loss1: 0.9459015727043152, 
		 aux loss2: 0.549580454826355, total loss: 0.9542316198348999
24th Epoch, 8845th Step, learning rate = 0.009110988435291277 - Loss: 0.5116841197013855, aux loss1: 0.9983004331588745, 
		 aux loss2: 0.586713433265686, total loss: 1.045859694480896
24th Epoch, 8850th Step, learning rate = 0.009110483234450153 - Loss: 0.5333495140075684, aux loss1: 0.9727970361709595, 
		 aux loss2: 0.6250309348106384, total loss: 1.0752010345458984
24th Epoch, 8855th Step, learning rate = 0.00910997803049626 - Loss: 0.35509270429611206, aux loss1: 0.8368551135063171, 
		 aux loss2: 0.4296300709247589, total loss: 0.7780013084411621
24th Epoch, 8860th Step, learning rate = 0.009109472823429386 - Loss: 0.6583350896835327, aux loss1: 1.1944283246994019, 
		 aux loss2: 0.7715657353401184, total loss: 1.3252898454666138
24th Epoch, 8865th Step, learning rate = 0.00910896761324932 - Loss: 0.45405662059783936, aux loss1: 0.9930257797241211, 
		 aux loss2: 0.541812539100647, total loss: 0.9686893224716187
24th Epoch, 8870th Step, learning rate = 0.009108462399955854 - Loss: 0.5064864158630371, aux loss1: 0.9950532913208008, 
		 aux loss2: 0.6076701879501343, total loss: 1.0480705499649048
24th Epoch, 8875th Step, learning rate = 0.009107957183548775 - Loss: 0.460332453250885, aux loss1: 0.9225428700447083, 
		 aux loss2: 0.530616819858551, total loss: 0.9493420720100403
24th Epoch, 8880th Step, learning rate = 0.00910745196402787 - Loss: 0.5475460290908813, aux loss1: 0.9505935907363892, 
		 aux loss2: 0.6457422971725464, total loss: 1.0910210609436035
24th Epoch, 8885th Step, learning rate = 0.009106946741392933 - Loss: 0.42154660820961, aux loss1: 0.8442772626876831, 
		 aux loss2: 0.4879392385482788, total loss: 0.8700055480003357
24th Epoch, 8890th Step, learning rate = 0.009106441515643748 - Loss: 0.6158429384231567, aux loss1: 1.0333391427993774, 
		 aux loss2: 0.6985563635826111, total loss: 1.2052671909332275
24th Epoch, 8895th Step, learning rate = 0.009105936286780105 - Loss: 0.5914585590362549, aux loss1: 1.0506993532180786, 
		 aux loss2: 0.6720337867736816, total loss: 1.175481915473938
24th Epoch, 8900th Step, learning rate = 0.009105431054801792 - Loss: 0.5134149789810181, aux loss1: 1.0210487842559814, 
		 aux loss2: 0.5932756662368774, total loss: 1.0570398569107056
<8900th step>
*************************** Test ***************************
time:3m 13s, 8900th Step, Loss: 0.7071795463562012, Mean IoU = 31.789%
************************************************************
25th Epoch, 8905th Step, learning rate = 0.0091049258197086 - Loss: 0.48741334676742554, aux loss1: 0.9948550462722778, 
		 aux loss2: 0.5831878185272217, total loss: 1.0191450119018555
25th Epoch, 8910th Step, learning rate = 0.009104420581500319 - Loss: 0.5893645286560059, aux loss1: 1.0800490379333496, 
		 aux loss2: 0.6684532761573792, total loss: 1.1807606220245361
25th Epoch, 8915th Step, learning rate = 0.009103915340176731 - Loss: 0.471359521150589, aux loss1: 0.9213951230049133, 
		 aux loss2: 0.5371743440628052, total loss: 0.9626477956771851
25th Epoch, 8920th Step, learning rate = 0.009103410095737632 - Loss: 0.663683295249939, aux loss1: 1.191103219985962, 
		 aux loss2: 0.7953565716743469, total loss: 1.3391568660736084
25th Epoch, 8925th Step, learning rate = 0.009102904848182809 - Loss: 0.4808683693408966, aux loss1: 0.8914356231689453, 
		 aux loss2: 0.5530874133110046, total loss: 0.9695340394973755
25th Epoch, 8930th Step, learning rate = 0.009102399597512047 - Loss: 0.4418315291404724, aux loss1: 1.0028358697891235, 
		 aux loss2: 0.5646007061004639, total loss: 0.9685226082801819
25th Epoch, 8935th Step, learning rate = 0.009101894343725138 - Loss: 0.4512481093406677, aux loss1: 1.0284744501113892, 
		 aux loss2: 0.558857798576355, total loss: 0.9833335280418396
25th Epoch, 8940th Step, learning rate = 0.009101389086821869 - Loss: 0.4838572144508362, aux loss1: 0.9939507246017456, 
		 aux loss2: 0.5868266820907593, total loss: 1.0167731046676636
25th Epoch, 8945th Step, learning rate = 0.00910088382680203 - Loss: 0.39112353324890137, aux loss1: 0.8432818055152893, 
		 aux loss2: 0.4881784915924072, total loss: 0.8393794298171997
25th Epoch, 8950th Step, learning rate = 0.009100378563665409 - Loss: 0.537151038646698, aux loss1: 1.1109799146652222, 
		 aux loss2: 0.6626607179641724, total loss: 1.1355092525482178
25th Epoch, 8955th Step, learning rate = 0.009099873297411793 - Loss: 0.4611508846282959, aux loss1: 0.9328188896179199, 
		 aux loss2: 0.5474875569343567, total loss: 0.9599916338920593
25th Epoch, 8960th Step, learning rate = 0.009099368028040972 - Loss: 0.421924352645874, aux loss1: 0.8936590552330017, 
		 aux loss2: 0.5072737336158752, total loss: 0.8929315805435181
25th Epoch, 8965th Step, learning rate = 0.009098862755552734 - Loss: 0.5315033197402954, aux loss1: 1.2009214162826538, 
		 aux loss2: 0.650402843952179, total loss: 1.151940941810608
25th Epoch, 8970th Step, learning rate = 0.009098357479946868 - Loss: 0.43945881724357605, aux loss1: 0.948001503944397, 
		 aux loss2: 0.5391390323638916, total loss: 0.9395149350166321
25th Epoch, 8975th Step, learning rate = 0.009097852201223163 - Loss: 0.4441196024417877, aux loss1: 0.8445241451263428, 
		 aux loss2: 0.5187091827392578, total loss: 0.9049605131149292
25th Epoch, 8980th Step, learning rate = 0.009097346919381405 - Loss: 0.5089028477668762, aux loss1: 0.9940953254699707, 
		 aux loss2: 0.5978174209594727, total loss: 1.0462584495544434
25th Epoch, 8985th Step, learning rate = 0.009096841634421383 - Loss: 0.3741741478443146, aux loss1: 0.9264262914657593, 
		 aux loss2: 0.4788348376750946, total loss: 0.8436359763145447
25th Epoch, 8990th Step, learning rate = 0.009096336346342887 - Loss: 0.5629854202270508, aux loss1: 1.0234482288360596, 
		 aux loss2: 0.6539831757545471, total loss: 1.1316132545471191
25th Epoch, 8995th Step, learning rate = 0.009095831055145704 - Loss: 0.43599411845207214, aux loss1: 0.8746612668037415, 
		 aux loss2: 0.519822895526886, total loss: 0.90632164478302
25th Epoch, 9000th Step, learning rate = 0.009095325760829623 - Loss: 0.4681791365146637, aux loss1: 0.9716677069664001, 
		 aux loss2: 0.5526986122131348, total loss: 0.9807589054107666
<9000th step>
*************************** Test ***************************
time:3m 15s, 9000th Step, Loss: 0.7391005754470825, Mean IoU = 33.866%
************************************************************
25th Epoch, 9005th Step, learning rate = 0.00909482046339443 - Loss: 0.4041542410850525, aux loss1: 0.9102218747138977, 
		 aux loss2: 0.4752683639526367, total loss: 0.8673281669616699
25th Epoch, 9010th Step, learning rate = 0.009094315162839916 - Loss: 0.4275333881378174, aux loss1: 0.8474633097648621, 
		 aux loss2: 0.5128846764564514, total loss: 0.8869262337684631
25th Epoch, 9015th Step, learning rate = 0.009093809859165868 - Loss: 0.6388304233551025, aux loss1: 1.3132845163345337, 
		 aux loss2: 0.7858701944351196, total loss: 1.3471639156341553
25th Epoch, 9020th Step, learning rate = 0.009093304552372073 - Loss: 0.46856167912483215, aux loss1: 0.9074974656105042, 
		 aux loss2: 0.5570048689842224, total loss: 0.9636129140853882
25th Epoch, 9025th Step, learning rate = 0.009092799242458321 - Loss: 0.5198801159858704, aux loss1: 0.9595790505409241, 
		 aux loss2: 0.6146209836006165, total loss: 1.0536022186279297
25th Epoch, 9030th Step, learning rate = 0.0090922939294244 - Loss: 0.39322325587272644, aux loss1: 0.8750824332237244, 
		 aux loss2: 0.46138182282447815, total loss: 0.8403007388114929
25th Epoch, 9035th Step, learning rate = 0.009091788613270098 - Loss: 0.48750069737434387, aux loss1: 0.9833992123603821, 
		 aux loss2: 0.5879113674163818, total loss: 1.017685055732727
25th Epoch, 9040th Step, learning rate = 0.0090912832939952 - Loss: 0.41250666975975037, aux loss1: 0.8945790529251099, 
		 aux loss2: 0.5210003852844238, total loss: 0.8892805576324463
25th Epoch, 9045th Step, learning rate = 0.009090777971599498 - Loss: 0.5747494697570801, aux loss1: 0.9549087285995483, 
		 aux loss2: 0.665084183216095, total loss: 1.1272557973861694
25th Epoch, 9050th Step, learning rate = 0.00909027264608278 - Loss: 0.5607551336288452, aux loss1: 1.058122158050537, 
		 aux loss2: 0.67960125207901, total loss: 1.1500322818756104
25th Epoch, 9055th Step, learning rate = 0.00908976731744483 - Loss: 0.43745890259742737, aux loss1: 0.9656599164009094, 
		 aux loss2: 0.5142275094985962, total loss: 0.9328478574752808
25th Epoch, 9060th Step, learning rate = 0.009089261985685437 - Loss: 0.6398854851722717, aux loss1: 1.1823813915252686, 
		 aux loss2: 0.7466046214103699, total loss: 1.2932417392730713
25th Epoch, 9065th Step, learning rate = 0.009088756650804393 - Loss: 0.4951312839984894, aux loss1: 0.970141589641571, 
		 aux loss2: 0.5875391364097595, total loss: 1.0211894512176514
25th Epoch, 9070th Step, learning rate = 0.009088251312801483 - Loss: 0.42915770411491394, aux loss1: 0.8852062821388245, 
		 aux loss2: 0.49782174825668335, total loss: 0.8938482999801636
25th Epoch, 9075th Step, learning rate = 0.009087745971676494 - Loss: 0.5960559844970703, aux loss1: 0.9905627369880676, 
		 aux loss2: 0.6759473085403442, total loss: 1.1636037826538086
25th Epoch, 9080th Step, learning rate = 0.009087240627429214 - Loss: 0.8270347118377686, aux loss1: 1.2668967247009277, 
		 aux loss2: 0.9087600708007812, total loss: 1.5706077814102173
25th Epoch, 9085th Step, learning rate = 0.00908673528005943 - Loss: 0.5012843608856201, aux loss1: 1.008554220199585, 
		 aux loss2: 0.6030401587486267, total loss: 1.0450667142868042
25th Epoch, 9090th Step, learning rate = 0.009086229929566937 - Loss: 0.4824415147304535, aux loss1: 0.9353126287460327, 
		 aux loss2: 0.5620187520980835, total loss: 0.9878427982330322
25th Epoch, 9095th Step, learning rate = 0.009085724575951512 - Loss: 0.37802135944366455, aux loss1: 0.8532593846321106, 
		 aux loss2: 0.4546557664871216, total loss: 0.8158615231513977
25th Epoch, 9100th Step, learning rate = 0.009085219219212948 - Loss: 0.41508907079696655, aux loss1: 0.8741817474365234, 
		 aux loss2: 0.50082927942276, total loss: 0.8776752948760986
<9100th step>
*************************** Test ***************************
time:3m 11s, 9100th Step, Loss: 0.6400684118270874, Mean IoU = 35.496%
************************************************************
25th Epoch, 9105th Step, learning rate = 0.009084713859351034 - Loss: 0.45642510056495667, aux loss1: 0.9169577956199646, 
		 aux loss2: 0.5408517718315125, total loss: 0.947853147983551
25th Epoch, 9110th Step, learning rate = 0.009084208496365556 - Loss: 0.5924931764602661, aux loss1: 0.9796991944313049, 
		 aux loss2: 0.6700836420059204, total loss: 1.154436469078064
25th Epoch, 9115th Step, learning rate = 0.0090837031302563 - Loss: 0.45736369490623474, aux loss1: 0.9944685101509094, 
		 aux loss2: 0.5568524599075317, total loss: 0.978445291519165
25th Epoch, 9120th Step, learning rate = 0.009083197761023057 - Loss: 0.3652627468109131, aux loss1: 0.7939457893371582, 
		 aux loss2: 0.43287038803100586, total loss: 0.7765946388244629
25th Epoch, 9125th Step, learning rate = 0.009082692388665612 - Loss: 0.6951112151145935, aux loss1: 1.2258514165878296, 
		 aux loss2: 0.7992383241653442, total loss: 1.3825620412826538
25th Epoch, 9130th Step, learning rate = 0.009082187013183753 - Loss: 0.4477322995662689, aux loss1: 0.9754505157470703, 
		 aux loss2: 0.54863041639328, total loss: 0.9598196744918823
25th Epoch, 9135th Step, learning rate = 0.009081681634577267 - Loss: 0.46687325835227966, aux loss1: 0.9481573104858398, 
		 aux loss2: 0.5741702318191528, total loss: 0.9809885621070862
25th Epoch, 9140th Step, learning rate = 0.009081176252845944 - Loss: 0.5371455550193787, aux loss1: 1.0635390281677246, 
		 aux loss2: 0.6407561302185059, total loss: 1.1125097274780273
25th Epoch, 9145th Step, learning rate = 0.009080670867989568 - Loss: 0.44324791431427, aux loss1: 0.9703750014305115, 
		 aux loss2: 0.5265838503837585, total loss: 0.9449939727783203
25th Epoch, 9150th Step, learning rate = 0.009080165480007929 - Loss: 0.4993323087692261, aux loss1: 0.9598671197891235, 
		 aux loss2: 0.5888184309005737, total loss: 1.0228198766708374
25th Epoch, 9155th Step, learning rate = 0.009079660088900814 - Loss: 0.35306107997894287, aux loss1: 0.8546360731124878, 
		 aux loss2: 0.43807095289230347, total loss: 0.7846802473068237
25th Epoch, 9160th Step, learning rate = 0.00907915469466801 - Loss: 0.5255858302116394, aux loss1: 0.9633389711380005, 
		 aux loss2: 0.5871403813362122, total loss: 1.0494437217712402
25th Epoch, 9165th Step, learning rate = 0.009078649297309303 - Loss: 0.3633926510810852, aux loss1: 0.74885493516922, 
		 aux loss2: 0.4420022964477539, total loss: 0.7648500800132751
25th Epoch, 9170th Step, learning rate = 0.009078143896824481 - Loss: 0.5742717981338501, aux loss1: 1.0769457817077637, 
		 aux loss2: 0.6829769015312195, total loss: 1.170546293258667
25th Epoch, 9175th Step, learning rate = 0.009077638493213335 - Loss: 0.44653835892677307, aux loss1: 0.8208372592926025, 
		 aux loss2: 0.5236464142799377, total loss: 0.9022481441497803
25th Epoch, 9180th Step, learning rate = 0.009077133086475645 - Loss: 0.5075029730796814, aux loss1: 0.9735879898071289, 
		 aux loss2: 0.5978735089302063, total loss: 1.0387288331985474
25th Epoch, 9185th Step, learning rate = 0.009076627676611205 - Loss: 0.6040453910827637, aux loss1: 1.182599663734436, 
		 aux loss2: 0.7135717272758484, total loss: 1.2442539930343628
25th Epoch, 9190th Step, learning rate = 0.009076122263619799 - Loss: 0.39905256032943726, aux loss1: 0.8894630670547485, 
		 aux loss2: 0.46821704506874084, total loss: 0.8531783819198608
25th Epoch, 9195th Step, learning rate = 0.009075616847501215 - Loss: 0.5003746151924133, aux loss1: 1.070879578590393, 
		 aux loss2: 0.6277742981910706, total loss: 1.0727481842041016
25th Epoch, 9200th Step, learning rate = 0.00907511142825524 - Loss: 0.41632336378097534, aux loss1: 0.8990463018417358, 
		 aux loss2: 0.5049974918365479, total loss: 0.88803631067276
<9200th step>
*************************** Test ***************************
time:3m 19s, 9200th Step, Loss: 0.7186038494110107, Mean IoU = 34.367%
************************************************************
25th Epoch, 9205th Step, learning rate = 0.00907460600588166 - Loss: 0.4628821909427643, aux loss1: 0.9470027089118958, 
		 aux loss2: 0.5562840700149536, total loss: 0.9694966673851013
25th Epoch, 9210th Step, learning rate = 0.009074100580380263 - Loss: 0.46629613637924194, aux loss1: 0.9231985211372375, 
		 aux loss2: 0.5480793714523315, total loss: 0.9624874591827393
25th Epoch, 9215th Step, learning rate = 0.009073595151750838 - Loss: 0.719525158405304, aux loss1: 1.3923442363739014, 
		 aux loss2: 0.8436017036437988, total loss: 1.4746692180633545
25th Epoch, 9220th Step, learning rate = 0.009073089719993169 - Loss: 0.39585232734680176, aux loss1: 0.8466280698776245, 
		 aux loss2: 0.5030229091644287, total loss: 0.8510499596595764
25th Epoch, 9225th Step, learning rate = 0.009072584285107044 - Loss: 0.44938182830810547, aux loss1: 0.9073522090911865, 
		 aux loss2: 0.5391845703125, total loss: 0.9372613430023193
25th Epoch, 9230th Step, learning rate = 0.009072078847092251 - Loss: 0.44608306884765625, aux loss1: 0.9267688393592834, 
		 aux loss2: 0.551293671131134, total loss: 0.9446311593055725
25th Epoch, 9235th Step, learning rate = 0.009071573405948575 - Loss: 0.7200555801391602, aux loss1: 1.2887696027755737, 
		 aux loss2: 0.8540351390838623, total loss: 1.4483006000518799
25th Epoch, 9240th Step, learning rate = 0.009071067961675804 - Loss: 0.5763384699821472, aux loss1: 0.9214867949485779, 
		 aux loss2: 0.6517089605331421, total loss: 1.1134681701660156
25th Epoch, 9245th Step, learning rate = 0.009070562514273725 - Loss: 0.5335443615913391, aux loss1: 0.988731324672699, 
		 aux loss2: 0.616009533405304, total loss: 1.0765676498413086
25th Epoch, 9250th Step, learning rate = 0.009070057063742127 - Loss: 0.5425543785095215, aux loss1: 0.9707185626029968, 
		 aux loss2: 0.6195036172866821, total loss: 1.081571340560913
25th Epoch, 9255th Step, learning rate = 0.009069551610080792 - Loss: 0.42323005199432373, aux loss1: 0.8172011375427246, 
		 aux loss2: 0.5018354058265686, total loss: 0.8691245317459106
25th Epoch, 9260th Step, learning rate = 0.00906904615328951 - Loss: 0.47769859433174133, aux loss1: 0.9864780902862549, 
		 aux loss2: 0.5894819498062134, total loss: 1.0094348192214966
25th Epoch, 9265th Step, learning rate = 0.009068540693368068 - Loss: 0.5433699488639832, aux loss1: 0.9929779767990112, 
		 aux loss2: 0.6393507122993469, total loss: 1.097003698348999
25th Epoch, 9270th Step, learning rate = 0.009068035230316253 - Loss: 0.6240479350090027, aux loss1: 1.052230715751648, 
		 aux loss2: 0.7218539714813232, total loss: 1.2284587621688843
25th Epoch, 9275th Step, learning rate = 0.009067529764133848 - Loss: 0.4963175058364868, aux loss1: 0.9427258968353271, 
		 aux loss2: 0.5997774004936218, total loss: 1.0190463066101074
26th Epoch, 9280th Step, learning rate = 0.009067024294820644 - Loss: 0.6660284996032715, aux loss1: 1.1976351737976074, 
		 aux loss2: 0.8056614398956299, total loss: 1.3475836515426636
26th Epoch, 9285th Step, learning rate = 0.009066518822376425 - Loss: 0.5713778734207153, aux loss1: 1.0068219900131226, 
		 aux loss2: 0.6764563322067261, total loss: 1.1440069675445557
26th Epoch, 9290th Step, learning rate = 0.00906601334680098 - Loss: 0.4723955988883972, aux loss1: 0.9033858776092529, 
		 aux loss2: 0.5464789271354675, total loss: 0.9620029330253601
26th Epoch, 9295th Step, learning rate = 0.009065507868094094 - Loss: 0.35289058089256287, aux loss1: 0.8255984783172607, 
		 aux loss2: 0.44195356965065, total loss: 0.7773515582084656
26th Epoch, 9300th Step, learning rate = 0.009065002386255554 - Loss: 0.4887988567352295, aux loss1: 0.8979213833808899, 
		 aux loss2: 0.5720583200454712, total loss: 0.9869985580444336
<9300th step>
*************************** Test ***************************
time:3m 13s, 9300th Step, Loss: 0.6107211709022522, Mean IoU = 35.288%
************************************************************
26th Epoch, 9305th Step, learning rate = 0.009064496901285147 - Loss: 0.5129014849662781, aux loss1: 1.053385615348816, 
		 aux loss2: 0.6072571873664856, total loss: 1.0718200206756592
26th Epoch, 9310th Step, learning rate = 0.009063991413182659 - Loss: 0.35844460129737854, aux loss1: 0.7580065131187439, 
		 aux loss2: 0.44138815999031067, total loss: 0.762401819229126
26th Epoch, 9315th Step, learning rate = 0.009063485921947875 - Loss: 0.5052066445350647, aux loss1: 0.9957038760185242, 
		 aux loss2: 0.5962828397750854, total loss: 1.0424309968948364
26th Epoch, 9320th Step, learning rate = 0.009062980427580586 - Loss: 0.37859129905700684, aux loss1: 0.8136199712753296, 
		 aux loss2: 0.4696980118751526, total loss: 0.8105565309524536
26th Epoch, 9325th Step, learning rate = 0.009062474930080573 - Loss: 0.6748346090316772, aux loss1: 1.1022353172302246, 
		 aux loss2: 0.781104564666748, total loss: 1.3179470300674438
26th Epoch, 9330th Step, learning rate = 0.009061969429447626 - Loss: 0.5703519582748413, aux loss1: 1.1381771564483643, 
		 aux loss2: 0.6790485382080078, total loss: 1.1834245920181274
26th Epoch, 9335th Step, learning rate = 0.00906146392568153 - Loss: 0.556836724281311, aux loss1: 1.0455983877182007, 
		 aux loss2: 0.6490606069564819, total loss: 1.1301405429840088
26th Epoch, 9340th Step, learning rate = 0.009060958418782072 - Loss: 0.5392348766326904, aux loss1: 0.966433584690094, 
		 aux loss2: 0.5929920673370361, total loss: 1.0663617849349976
26th Epoch, 9345th Step, learning rate = 0.009060452908749038 - Loss: 0.5540984869003296, aux loss1: 1.083558440208435, 
		 aux loss2: 0.6675801873207092, total loss: 1.146198034286499
26th Epoch, 9350th Step, learning rate = 0.009059947395582215 - Loss: 0.36847761273384094, aux loss1: 0.8200430274009705, 
		 aux loss2: 0.45226964354515076, total loss: 0.7953983545303345
26th Epoch, 9355th Step, learning rate = 0.009059441879281389 - Loss: 0.38462063670158386, aux loss1: 0.8203341364860535, 
		 aux loss2: 0.4430568814277649, total loss: 0.80794358253479
26th Epoch, 9360th Step, learning rate = 0.009058936359846346 - Loss: 0.4753354787826538, aux loss1: 0.9477201104164124, 
		 aux loss2: 0.5744233727455139, total loss: 0.9894208908081055
26th Epoch, 9365th Step, learning rate = 0.00905843083727687 - Loss: 0.38506370782852173, aux loss1: 0.7738223075866699, 
		 aux loss2: 0.46412816643714905, total loss: 0.8028616905212402
26th Epoch, 9370th Step, learning rate = 0.009057925311572752 - Loss: 0.6513007879257202, aux loss1: 1.2529635429382324, 
		 aux loss2: 0.7947684526443481, total loss: 1.345097303390503
26th Epoch, 9375th Step, learning rate = 0.009057419782733774 - Loss: 0.46370503306388855, aux loss1: 0.8929260969161987, 
		 aux loss2: 0.5488138794898987, total loss: 0.951108455657959
26th Epoch, 9380th Step, learning rate = 0.009056914250759723 - Loss: 0.4049884080886841, aux loss1: 0.8689195513725281, 
		 aux loss2: 0.49579545855522156, total loss: 0.8639824986457825
26th Epoch, 9385th Step, learning rate = 0.009056408715650386 - Loss: 0.5011813640594482, aux loss1: 1.0144233703613281, 
		 aux loss2: 0.6108471751213074, total loss: 1.0498472452163696
26th Epoch, 9390th Step, learning rate = 0.009055903177405551 - Loss: 0.686120331287384, aux loss1: 1.2278928756713867, 
		 aux loss2: 0.8034196496009827, total loss: 1.3758560419082642
26th Epoch, 9395th Step, learning rate = 0.009055397636025002 - Loss: 0.39785680174827576, aux loss1: 0.8699001669883728, 
		 aux loss2: 0.4745487570762634, total loss: 0.848646342754364
26th Epoch, 9400th Step, learning rate = 0.009054892091508523 - Loss: 0.46297699213027954, aux loss1: 0.9615378379821777, 
		 aux loss2: 0.5583645105361938, total loss: 0.9747841954231262
<9400th step>
*************************** Test ***************************
time:3m 14s, 9400th Step, Loss: 0.6761387586593628, Mean IoU = 35.530%
************************************************************
26th Epoch, 9405th Step, learning rate = 0.009054386543855902 - Loss: 0.37426894903182983, aux loss1: 0.8802509903907776, 
		 aux loss2: 0.449236661195755, total loss: 0.8180389404296875
26th Epoch, 9410th Step, learning rate = 0.009053880993066926 - Loss: 0.3944762945175171, aux loss1: 0.7925426959991455, 
		 aux loss2: 0.4628128707408905, total loss: 0.8173642754554749
26th Epoch, 9415th Step, learning rate = 0.00905337543914138 - Loss: 0.3965926766395569, aux loss1: 0.8581809997558594, 
		 aux loss2: 0.4673156440258026, total loss: 0.8409732580184937
26th Epoch, 9420th Step, learning rate = 0.00905286988207905 - Loss: 0.49773746728897095, aux loss1: 1.0401531457901, 
		 aux loss2: 0.6039896607398987, total loss: 1.0513793230056763
26th Epoch, 9425th Step, learning rate = 0.009052364321879723 - Loss: 0.5565577745437622, aux loss1: 1.0784715414047241, 
		 aux loss2: 0.6358277201652527, total loss: 1.1344302892684937
26th Epoch, 9430th Step, learning rate = 0.00905185875854318 - Loss: 0.44661054015159607, aux loss1: 0.9178467988967896, 
		 aux loss2: 0.5361276865005493, total loss: 0.9364156723022461
26th Epoch, 9435th Step, learning rate = 0.009051353192069215 - Loss: 0.6216289401054382, aux loss1: 1.0598145723342896, 
		 aux loss2: 0.6960470080375671, total loss: 1.2179920673370361
26th Epoch, 9440th Step, learning rate = 0.009050847622457605 - Loss: 0.43052181601524353, aux loss1: 0.886289656162262, 
		 aux loss2: 0.5141750574111938, total loss: 0.9020787477493286
26th Epoch, 9445th Step, learning rate = 0.009050342049708142 - Loss: 0.47589120268821716, aux loss1: 1.0179890394210815, 
		 aux loss2: 0.5915926694869995, total loss: 1.0179250240325928
26th Epoch, 9450th Step, learning rate = 0.009049836473820612 - Loss: 0.4764522612094879, aux loss1: 0.9963937401771545, 
		 aux loss2: 0.5624637603759766, total loss: 1.000355839729309
26th Epoch, 9455th Step, learning rate = 0.009049330894794795 - Loss: 0.6182058453559875, aux loss1: 1.2096623182296753, 
		 aux loss2: 0.7497252821922302, total loss: 1.2809946537017822
26th Epoch, 9460th Step, learning rate = 0.009048825312630482 - Loss: 0.6674267649650574, aux loss1: 1.1266789436340332, 
		 aux loss2: 0.7463120222091675, total loss: 1.303955316543579
26th Epoch, 9465th Step, learning rate = 0.009048319727327458 - Loss: 0.47584813833236694, aux loss1: 0.9323066473007202, 
		 aux loss2: 0.5660591125488281, total loss: 0.9819637537002563
26th Epoch, 9470th Step, learning rate = 0.009047814138885505 - Loss: 0.5815487504005432, aux loss1: 1.1181434392929077, 
		 aux loss2: 0.6987091898918152, total loss: 1.1964755058288574
26th Epoch, 9475th Step, learning rate = 0.009047308547304412 - Loss: 0.3503732979297638, aux loss1: 0.8081053495407104, 
		 aux loss2: 0.42841243743896484, total loss: 0.7641698718070984
26th Epoch, 9480th Step, learning rate = 0.009046802952583966 - Loss: 0.4046992063522339, aux loss1: 0.8547574281692505, 
		 aux loss2: 0.48642900586128235, total loss: 0.8556980490684509
26th Epoch, 9485th Step, learning rate = 0.009046297354723948 - Loss: 0.42248648405075073, aux loss1: 0.8564750552177429, 
		 aux loss2: 0.4923435151576996, total loss: 0.8763664960861206
26th Epoch, 9490th Step, learning rate = 0.009045791753724148 - Loss: 0.4834878742694855, aux loss1: 0.9977560043334961, 
		 aux loss2: 0.57513827085495, total loss: 1.012869954109192
26th Epoch, 9495th Step, learning rate = 0.009045286149584346 - Loss: 0.40535470843315125, aux loss1: 0.9079392552375793, 
		 aux loss2: 0.4796677827835083, total loss: 0.8696036338806152
26th Epoch, 9500th Step, learning rate = 0.009044780542304336 - Loss: 0.4283253252506256, aux loss1: 0.8777705430984497, 
		 aux loss2: 0.5244012475013733, total loss: 0.9014169573783875
<9500th step>
*************************** Test ***************************
time:3m 16s, 9500th Step, Loss: 0.6246567964553833, Mean IoU = 34.735%
************************************************************
26th Epoch, 9505th Step, learning rate = 0.009044274931883893 - Loss: 0.5115886330604553, aux loss1: 0.9765682816505432, 
		 aux loss2: 0.5955941081047058, total loss: 1.0427967309951782
26th Epoch, 9510th Step, learning rate = 0.009043769318322811 - Loss: 0.4453045427799225, aux loss1: 0.8437871336936951, 
		 aux loss2: 0.5117129683494568, total loss: 0.9031258821487427
26th Epoch, 9515th Step, learning rate = 0.00904326370162087 - Loss: 0.42985910177230835, aux loss1: 0.9335153102874756, 
		 aux loss2: 0.5369158387184143, total loss: 0.9246800541877747
26th Epoch, 9520th Step, learning rate = 0.00904275808177786 - Loss: 0.41777363419532776, aux loss1: 0.902059018611908, 
		 aux loss2: 0.5171491503715515, total loss: 0.8952509760856628
26th Epoch, 9525th Step, learning rate = 0.009042252458793565 - Loss: 0.5680344104766846, aux loss1: 1.0870904922485352, 
		 aux loss2: 0.6781315803527832, total loss: 1.1654142141342163
26th Epoch, 9530th Step, learning rate = 0.009041746832667766 - Loss: 0.5060649514198303, aux loss1: 1.1098878383636475, 
		 aux loss2: 0.627507746219635, total loss: 1.0900344848632812
26th Epoch, 9535th Step, learning rate = 0.009041241203400252 - Loss: 0.471877783536911, aux loss1: 0.9541314244270325, 
		 aux loss2: 0.5803260803222656, total loss: 0.9902476072311401
26th Epoch, 9540th Step, learning rate = 0.009040735570990808 - Loss: 0.4666404724121094, aux loss1: 0.8978504538536072, 
		 aux loss2: 0.557106077671051, total loss: 0.9588381052017212
26th Epoch, 9545th Step, learning rate = 0.00904022993543922 - Loss: 0.45026832818984985, aux loss1: 0.9059910178184509, 
		 aux loss2: 0.5388315320014954, total loss: 0.9375982880592346
26th Epoch, 9550th Step, learning rate = 0.009039724296745271 - Loss: 0.4465978443622589, aux loss1: 0.954493522644043, 
		 aux loss2: 0.5491383671760559, total loss: 0.9526012539863586
26th Epoch, 9555th Step, learning rate = 0.009039218654908747 - Loss: 0.7760130167007446, aux loss1: 1.3658784627914429, 
		 aux loss2: 0.9262511134147644, total loss: 1.5562770366668701
26th Epoch, 9560th Step, learning rate = 0.009038713009929434 - Loss: 0.44361698627471924, aux loss1: 0.8749780058860779, 
		 aux loss2: 0.5087135434150696, total loss: 0.909595787525177
26th Epoch, 9565th Step, learning rate = 0.009038207361807117 - Loss: 0.4506992995738983, aux loss1: 0.8733844757080078, 
		 aux loss2: 0.5377693772315979, total loss: 0.9278224110603333
26th Epoch, 9570th Step, learning rate = 0.00903770171054158 - Loss: 0.4160619378089905, aux loss1: 0.8509369492530823, 
		 aux loss2: 0.5037651658058167, total loss: 0.8728491067886353
26th Epoch, 9575th Step, learning rate = 0.00903719605613261 - Loss: 0.4845227599143982, aux loss1: 0.9508767127990723, 
		 aux loss2: 0.5770278573036194, total loss: 1.0005968809127808
26th Epoch, 9580th Step, learning rate = 0.00903669039857999 - Loss: 0.6061287522315979, aux loss1: 1.1765315532684326, 
		 aux loss2: 0.7503997087478638, total loss: 1.25924813747406
26th Epoch, 9585th Step, learning rate = 0.009036184737883505 - Loss: 0.5569615364074707, aux loss1: 1.2239362001419067, 
		 aux loss2: 0.6972863078117371, total loss: 1.2030569314956665
26th Epoch, 9590th Step, learning rate = 0.009035679074042942 - Loss: 0.6124781370162964, aux loss1: 1.0802894830703735, 
		 aux loss2: 0.7101530432701111, total loss: 1.2206262350082397
26th Epoch, 9595th Step, learning rate = 0.009035173407058084 - Loss: 0.49120575189590454, aux loss1: 0.97126305103302, 
		 aux loss2: 0.5908330082893372, total loss: 1.0189179182052612
26th Epoch, 9600th Step, learning rate = 0.009034667736928717 - Loss: 0.3890990614891052, aux loss1: 0.8715709447860718, 
		 aux loss2: 0.45877745747566223, total loss: 0.8340814113616943
<9600th step>
*************************** Test ***************************
time:3m 14s, 9600th Step, Loss: 0.6179882287979126, Mean IoU = 35.622%
************************************************************
26th Epoch, 9605th Step, learning rate = 0.009034162063654625 - Loss: 0.4529888927936554, aux loss1: 0.9222647547721863, 
		 aux loss2: 0.5437950491905212, total loss: 0.9471863508224487
26th Epoch, 9610th Step, learning rate = 0.009033656387235594 - Loss: 0.4376835823059082, aux loss1: 0.9197864532470703, 
		 aux loss2: 0.5177627205848694, total loss: 0.920724630355835
26th Epoch, 9615th Step, learning rate = 0.009033150707671408 - Loss: 0.4192635715007782, aux loss1: 0.864236056804657, 
		 aux loss2: 0.5029600858688354, total loss: 0.8797184228897095
26th Epoch, 9620th Step, learning rate = 0.00903264502496185 - Loss: 0.6701448559761047, aux loss1: 1.1436299085617065, 
		 aux loss2: 0.7816925048828125, total loss: 1.3259109258651733
26th Epoch, 9625th Step, learning rate = 0.009032139339106708 - Loss: 0.6368513703346252, aux loss1: 1.1758421659469604, 
		 aux loss2: 0.7473034262657166, total loss: 1.2885253429412842
26th Epoch, 9630th Step, learning rate = 0.009031633650105767 - Loss: 0.43004050850868225, aux loss1: 0.9494719505310059, 
		 aux loss2: 0.53167325258255, total loss: 0.9275514483451843
26th Epoch, 9635th Step, learning rate = 0.00903112795795881 - Loss: 0.3832302987575531, aux loss1: 0.88341224193573, 
		 aux loss2: 0.46311068534851074, total loss: 0.8334982395172119
26th Epoch, 9640th Step, learning rate = 0.00903062226266562 - Loss: 0.5054506659507751, aux loss1: 0.9302725791931152, 
		 aux loss2: 0.5700245499610901, total loss: 1.0125422477722168
26th Epoch, 9645th Step, learning rate = 0.009030116564225985 - Loss: 0.6329852342605591, aux loss1: 1.1192820072174072, 
		 aux loss2: 0.7183671593666077, total loss: 1.2561167478561401
27th Epoch, 9650th Step, learning rate = 0.009029610862639688 - Loss: 0.6387391686439514, aux loss1: 1.1078064441680908, 
		 aux loss2: 0.7377023100852966, total loss: 1.2661620378494263
27th Epoch, 9655th Step, learning rate = 0.009029105157906513 - Loss: 0.3860078752040863, aux loss1: 0.8753176331520081, 
		 aux loss2: 0.4652053415775299, total loss: 0.8346853256225586
27th Epoch, 9660th Step, learning rate = 0.009028599450026247 - Loss: 0.408668577671051, aux loss1: 0.8338906764984131, 
		 aux loss2: 0.4808802604675293, total loss: 0.8511878848075867
27th Epoch, 9665th Step, learning rate = 0.009028093738998672 - Loss: 0.4536818861961365, aux loss1: 0.8939386010169983, 
		 aux loss2: 0.5305037498474121, total loss: 0.9340649843215942
27th Epoch, 9670th Step, learning rate = 0.009027588024823573 - Loss: 0.36805349588394165, aux loss1: 0.8443059921264648, 
		 aux loss2: 0.450341135263443, total loss: 0.8014817237854004
27th Epoch, 9675th Step, learning rate = 0.009027082307500735 - Loss: 0.5176562666893005, aux loss1: 1.023592233657837, 
		 aux loss2: 0.6295768618583679, total loss: 1.0765647888183594
27th Epoch, 9680th Step, learning rate = 0.009026576587029945 - Loss: 0.6360650062561035, aux loss1: 1.1127047538757324, 
		 aux loss2: 0.7355436086654663, total loss: 1.2640938758850098
27th Epoch, 9685th Step, learning rate = 0.00902607086341098 - Loss: 0.4653313159942627, aux loss1: 0.9510369300842285, 
		 aux loss2: 0.552668035030365, total loss: 0.9717096090316772
27th Epoch, 9690th Step, learning rate = 0.009025565136643633 - Loss: 0.45416077971458435, aux loss1: 0.9270578026771545, 
		 aux loss2: 0.5562142133712769, total loss: 0.9547637701034546
27th Epoch, 9695th Step, learning rate = 0.009025059406727685 - Loss: 0.4676644504070282, aux loss1: 0.9250767827033997, 
		 aux loss2: 0.559167742729187, total loss: 0.9688546061515808
27th Epoch, 9700th Step, learning rate = 0.009024553673662918 - Loss: 0.4442228674888611, aux loss1: 0.9775409698486328, 
		 aux loss2: 0.5379049181938171, total loss: 0.9526471495628357
<9700th step>
*************************** Test ***************************
time:3m 14s, 9700th Step, Loss: 0.8184669613838196, Mean IoU = 34.244%
************************************************************
27th Epoch, 9705th Step, learning rate = 0.00902404793744912 - Loss: 0.4425032138824463, aux loss1: 0.902580738067627, 
		 aux loss2: 0.5062010288238525, total loss: 0.9157578945159912
27th Epoch, 9710th Step, learning rate = 0.009023542198086073 - Loss: 0.4602515697479248, aux loss1: 0.945473313331604, 
		 aux loss2: 0.5586466789245605, total loss: 0.9673522710800171
27th Epoch, 9715th Step, learning rate = 0.009023036455573561 - Loss: 0.35834404826164246, aux loss1: 0.8508550524711609, 
		 aux loss2: 0.4512925446033478, total loss: 0.7941176295280457
27th Epoch, 9720th Step, learning rate = 0.009022530709911372 - Loss: 0.4947156310081482, aux loss1: 1.006606101989746, 
		 aux loss2: 0.6069219708442688, total loss: 1.0394662618637085
27th Epoch, 9725th Step, learning rate = 0.009022024961099285 - Loss: 0.41390690207481384, aux loss1: 0.9162547588348389, 
		 aux loss2: 0.5145153403282166, total loss: 0.8945894837379456
27th Epoch, 9730th Step, learning rate = 0.009021519209137087 - Loss: 0.40149012207984924, aux loss1: 0.8965491652488708, 
		 aux loss2: 0.4871383011341095, total loss: 0.8653101921081543
27th Epoch, 9735th Step, learning rate = 0.009021013454024562 - Loss: 0.4638785421848297, aux loss1: 0.8525112867355347, 
		 aux loss2: 0.5207714438438416, total loss: 0.9279404878616333
27th Epoch, 9740th Step, learning rate = 0.009020507695761494 - Loss: 0.35727742314338684, aux loss1: 0.7239688634872437, 
		 aux loss2: 0.4074843227863312, total loss: 0.7374618053436279
27th Epoch, 9745th Step, learning rate = 0.009020001934347667 - Loss: 0.59760582447052, aux loss1: 1.0637593269348145, 
		 aux loss2: 0.6917670369148254, total loss: 1.1934404373168945
27th Epoch, 9750th Step, learning rate = 0.009019496169782863 - Loss: 0.628372311592102, aux loss1: 1.240370750427246, 
		 aux loss2: 0.7527033090591431, total loss: 1.3015648126602173
27th Epoch, 9755th Step, learning rate = 0.00901899040206687 - Loss: 0.5028055906295776, aux loss1: 1.1064906120300293, 
		 aux loss2: 0.6124853491783142, total loss: 1.079746961593628
27th Epoch, 9760th Step, learning rate = 0.009018484631199471 - Loss: 0.41547852754592896, aux loss1: 0.8614001870155334, 
		 aux loss2: 0.5128162503242493, total loss: 0.8790251016616821
27th Epoch, 9765th Step, learning rate = 0.009017978857180448 - Loss: 0.528255820274353, aux loss1: 1.0051146745681763, 
		 aux loss2: 0.640028178691864, total loss: 1.0858014822006226
27th Epoch, 9770th Step, learning rate = 0.009017473080009587 - Loss: 0.5469926595687866, aux loss1: 0.9919388890266418, 
		 aux loss2: 0.6355293393135071, total loss: 1.0987861156463623
27th Epoch, 9775th Step, learning rate = 0.009016967299686669 - Loss: 0.6401368975639343, aux loss1: 1.0998561382293701, 
		 aux loss2: 0.698494553565979, total loss: 1.249491572380066
27th Epoch, 9780th Step, learning rate = 0.009016461516211481 - Loss: 0.5444015264511108, aux loss1: 1.0645962953567505, 
		 aux loss2: 0.6541932821273804, total loss: 1.125457763671875
27th Epoch, 9785th Step, learning rate = 0.009015955729583807 - Loss: 0.4936716556549072, aux loss1: 0.9967630505561829, 
		 aux loss2: 0.6227729320526123, total loss: 1.0418097972869873
27th Epoch, 9790th Step, learning rate = 0.009015449939803428 - Loss: 0.39111778140068054, aux loss1: 0.8408635258674622, 
		 aux loss2: 0.48028841614723206, total loss: 0.8354921936988831
27th Epoch, 9795th Step, learning rate = 0.00901494414687013 - Loss: 0.6623006463050842, aux loss1: 1.1365281343460083, 
		 aux loss2: 0.7722520232200623, total loss: 1.3121598958969116
27th Epoch, 9800th Step, learning rate = 0.009014438350783695 - Loss: 0.40139448642730713, aux loss1: 0.8630632162094116, 
		 aux loss2: 0.48667842149734497, total loss: 0.8549848794937134
<9800th step>
*************************** Test ***************************
time:3m 14s, 9800th Step, Loss: 0.6475091576576233, Mean IoU = 34.584%
************************************************************
27th Epoch, 9805th Step, learning rate = 0.00901393255154391 - Loss: 0.5045965313911438, aux loss1: 1.0251835584640503, 
		 aux loss2: 0.6203958988189697, total loss: 1.0603100061416626
27th Epoch, 9810th Step, learning rate = 0.009013426749150556 - Loss: 0.34693393111228943, aux loss1: 0.7635425925254822, 
		 aux loss2: 0.4301764667034149, total loss: 0.7480672597885132
27th Epoch, 9815th Step, learning rate = 0.009012920943603417 - Loss: 0.3136540949344635, aux loss1: 0.7296844720840454, 
		 aux loss2: 0.3997598886489868, total loss: 0.6924633979797363
27th Epoch, 9820th Step, learning rate = 0.009012415134902276 - Loss: 0.39576956629753113, aux loss1: 0.8578478097915649, 
		 aux loss2: 0.5106630325317383, total loss: 0.8573891520500183
27th Epoch, 9825th Step, learning rate = 0.009011909323046921 - Loss: 0.4273207187652588, aux loss1: 0.9299734830856323, 
		 aux loss2: 0.5168058276176453, total loss: 0.9130350947380066
27th Epoch, 9830th Step, learning rate = 0.00901140350803713 - Loss: 0.4865942597389221, aux loss1: 0.9928296804428101, 
		 aux loss2: 0.5775917172431946, total loss: 1.0154798030853271
27th Epoch, 9835th Step, learning rate = 0.009010897689872689 - Loss: 0.6091514825820923, aux loss1: 1.0470529794692993, 
		 aux loss2: 0.6960222721099854, total loss: 1.2016762495040894
27th Epoch, 9840th Step, learning rate = 0.009010391868553383 - Loss: 0.4567151665687561, aux loss1: 0.8950589895248413, 
		 aux loss2: 0.5266462564468384, total loss: 0.935891330242157
27th Epoch, 9845th Step, learning rate = 0.009009886044078992 - Loss: 0.3834594190120697, aux loss1: 0.8420858979225159, 
		 aux loss2: 0.4734688401222229, total loss: 0.8254727721214294
27th Epoch, 9850th Step, learning rate = 0.009009380216449302 - Loss: 0.43383803963661194, aux loss1: 0.9699020981788635, 
		 aux loss2: 0.5311437249183655, total loss: 0.9372661709785461
27th Epoch, 9855th Step, learning rate = 0.009008874385664096 - Loss: 0.39779892563819885, aux loss1: 0.9334322214126587, 
		 aux loss2: 0.505343496799469, total loss: 0.8799660205841064
27th Epoch, 9860th Step, learning rate = 0.00900836855172316 - Loss: 0.6934584975242615, aux loss1: 1.1220347881317139, 
		 aux loss2: 0.780389130115509, total loss: 1.3422245979309082
27th Epoch, 9865th Step, learning rate = 0.009007862714626272 - Loss: 0.5791361927986145, aux loss1: 1.0426546335220337, 
		 aux loss2: 0.6477167010307312, total loss: 1.1510193347930908
27th Epoch, 9870th Step, learning rate = 0.009007356874373219 - Loss: 0.40971630811691284, aux loss1: 0.9977989792823792, 
		 aux loss2: 0.5328490734100342, total loss: 0.9221956729888916
27th Epoch, 9875th Step, learning rate = 0.009006851030963783 - Loss: 0.33994224667549133, aux loss1: 0.8538262248039246, 
		 aux loss2: 0.42283332347869873, total loss: 0.765223503112793
27th Epoch, 9880th Step, learning rate = 0.009006345184397751 - Loss: 0.4472857415676117, aux loss1: 0.906278133392334, 
		 aux loss2: 0.5083779096603394, total loss: 0.9225203990936279
27th Epoch, 9885th Step, learning rate = 0.0090058393346749 - Loss: 0.40346911549568176, aux loss1: 0.8876607418060303, 
		 aux loss2: 0.5025443434715271, total loss: 0.870785117149353
27th Epoch, 9890th Step, learning rate = 0.009005333481795018 - Loss: 0.412811279296875, aux loss1: 0.8833492994308472, 
		 aux loss2: 0.5116767883300781, total loss: 0.8824868202209473
27th Epoch, 9895th Step, learning rate = 0.009004827625757888 - Loss: 0.3702118694782257, aux loss1: 0.8176458477973938, 
		 aux loss2: 0.4563479721546173, total loss: 0.7980448007583618
27th Epoch, 9900th Step, learning rate = 0.00900432176656329 - Loss: 0.3907456398010254, aux loss1: 0.8096070289611816, 
		 aux loss2: 0.45101168751716614, total loss: 0.8140324354171753
<9900th step>
*************************** Test ***************************
time:3m 17s, 9900th Step, Loss: 0.7192898392677307, Mean IoU = 34.470%
************************************************************
27th Epoch, 9905th Step, learning rate = 0.009003815904211008 - Loss: 0.5139500498771667, aux loss1: 1.126513957977295, 
		 aux loss2: 0.6373116970062256, total loss: 1.1068289279937744
27th Epoch, 9910th Step, learning rate = 0.00900331003870083 - Loss: 0.4074409306049347, aux loss1: 0.9093940258026123, 
		 aux loss2: 0.5013501048088074, total loss: 0.8807991743087769
27th Epoch, 9915th Step, learning rate = 0.009002804170032535 - Loss: 0.448839008808136, aux loss1: 0.9706917405128479, 
		 aux loss2: 0.5487021803855896, total loss: 0.9595273733139038
27th Epoch, 9920th Step, learning rate = 0.009002298298205905 - Loss: 0.6430556774139404, aux loss1: 1.1955095529556274, 
		 aux loss2: 0.7582233548164368, total loss: 1.3049979209899902
27th Epoch, 9925th Step, learning rate = 0.009001792423220726 - Loss: 0.5171880125999451, aux loss1: 1.0599302053451538, 
		 aux loss2: 0.6488940715789795, total loss: 1.0947246551513672
27th Epoch, 9930th Step, learning rate = 0.009001286545076778 - Loss: 0.5545915365219116, aux loss1: 1.0533397197723389, 
		 aux loss2: 0.6461169719696045, total loss: 1.129040241241455
27th Epoch, 9935th Step, learning rate = 0.009000780663773848 - Loss: 0.36900171637535095, aux loss1: 0.8683720827102661, 
		 aux loss2: 0.4746705889701843, total loss: 0.819381594657898
27th Epoch, 9940th Step, learning rate = 0.009000274779311715 - Loss: 0.3067399263381958, aux loss1: 0.85517817735672, 
		 aux loss2: 0.4082243740558624, total loss: 0.7265831232070923
27th Epoch, 9945th Step, learning rate = 0.008999768891690166 - Loss: 0.433095246553421, aux loss1: 0.9287192821502686, 
		 aux loss2: 0.5369627475738525, total loss: 0.926496148109436
27th Epoch, 9950th Step, learning rate = 0.00899926300090898 - Loss: 0.6571545004844666, aux loss1: 1.2428443431854248, 
		 aux loss2: 0.7909243702888489, total loss: 1.3463776111602783
27th Epoch, 9955th Step, learning rate = 0.008998757106967943 - Loss: 0.40252137184143066, aux loss1: 0.8697509765625, 
		 aux loss2: 0.47512203454971313, total loss: 0.8534954786300659
27th Epoch, 9960th Step, learning rate = 0.008998251209866834 - Loss: 0.46308887004852295, aux loss1: 1.1315275430679321, 
		 aux loss2: 0.5838638544082642, total loss: 1.036092758178711
27th Epoch, 9965th Step, learning rate = 0.008997745309605442 - Loss: 0.31848758459091187, aux loss1: 0.6965876817703247, 
		 aux loss2: 0.36439406871795654, total loss: 0.6732215285301208
27th Epoch, 9970th Step, learning rate = 0.008997239406183544 - Loss: 0.38642987608909607, aux loss1: 0.8669472932815552, 
		 aux loss2: 0.46402204036712646, total loss: 0.8321228623390198
27th Epoch, 9975th Step, learning rate = 0.008996733499600925 - Loss: 0.4503851532936096, aux loss1: 0.9838356375694275, 
		 aux loss2: 0.5370362997055054, total loss: 0.9603503942489624
27th Epoch, 9980th Step, learning rate = 0.008996227589857367 - Loss: 0.43773385882377625, aux loss1: 0.9051163792610168, 
		 aux loss2: 0.5210673213005066, total loss: 0.9176957607269287
27th Epoch, 9985th Step, learning rate = 0.008995721676952657 - Loss: 0.527290940284729, aux loss1: 1.1369019746780396, 
		 aux loss2: 0.6876137852668762, total loss: 1.1434071063995361
27th Epoch, 9990th Step, learning rate = 0.00899521576088657 - Loss: 0.415732741355896, aux loss1: 0.9033714532852173, 
		 aux loss2: 0.49346476793289185, total loss: 0.8841301202774048
27th Epoch, 9995th Step, learning rate = 0.008994709841658895 - Loss: 0.5160373449325562, aux loss1: 0.9228084683418274, 
		 aux loss2: 0.5748643279075623, total loss: 1.0228257179260254
27th Epoch, 10000th Step, learning rate = 0.008994203919269413 - Loss: 0.5095087289810181, aux loss1: 0.9887192845344543, 
		 aux loss2: 0.5937337875366211, total loss: 1.043618083000183
<10000th step>
*************************** Test ***************************
time:3m 13s, 10000th Step, Loss: 0.6236855387687683, Mean IoU = 36.335%
************************************************************
27th Epoch, 10005th Step, learning rate = 0.008993697993717905 - Loss: 0.5404816269874573, aux loss1: 0.9856959581375122, 
		 aux loss2: 0.6282989382743835, total loss: 1.087510108947754
27th Epoch, 10010th Step, learning rate = 0.008993192065004155 - Loss: 0.5929591059684753, aux loss1: 1.1122270822525024, 
		 aux loss2: 0.6940489411354065, total loss: 1.2042468786239624
27th Epoch, 10015th Step, learning rate = 0.008992686133127946 - Loss: 0.5377628207206726, aux loss1: 1.0449458360671997, 
		 aux loss2: 0.6447629928588867, total loss: 1.109151840209961
28th Epoch, 10020th Step, learning rate = 0.00899218019808906 - Loss: 0.5052757263183594, aux loss1: 1.0189932584762573, 
		 aux loss2: 0.63227778673172, total loss: 1.0638848543167114
28th Epoch, 10025th Step, learning rate = 0.008991674259887278 - Loss: 0.5362241864204407, aux loss1: 1.0212293863296509, 
		 aux loss2: 0.6325688362121582, total loss: 1.0956205129623413
28th Epoch, 10030th Step, learning rate = 0.008991168318522385 - Loss: 0.3428966701030731, aux loss1: 0.7836250066757202, 
		 aux loss2: 0.4086417555809021, total loss: 0.7414408922195435
28th Epoch, 10035th Step, learning rate = 0.008990662373994162 - Loss: 0.4841359853744507, aux loss1: 0.8787954449653625, 
		 aux loss2: 0.5625975728034973, total loss: 0.972813606262207
28th Epoch, 10040th Step, learning rate = 0.008990156426302392 - Loss: 0.52629154920578, aux loss1: 0.9740554690361023, 
		 aux loss2: 0.6192397475242615, total loss: 1.0662040710449219
28th Epoch, 10045th Step, learning rate = 0.008989650475446857 - Loss: 0.6960358023643494, aux loss1: 1.2523860931396484, 
		 aux loss2: 0.8049893975257874, total loss: 1.393747329711914
28th Epoch, 10050th Step, learning rate = 0.00898914452142734 - Loss: 0.5081738233566284, aux loss1: 1.0440411567687988, 
		 aux loss2: 0.607718825340271, total loss: 1.0644737482070923
28th Epoch, 10055th Step, learning rate = 0.00898863856424362 - Loss: 0.5203660726547241, aux loss1: 0.9917763471603394, 
		 aux loss2: 0.6053014397621155, total loss: 1.060019612312317
28th Epoch, 10060th Step, learning rate = 0.008988132603895485 - Loss: 0.542922854423523, aux loss1: 1.0621784925460815, 
		 aux loss2: 0.6706765294075012, total loss: 1.1298470497131348
28th Epoch, 10065th Step, learning rate = 0.008987626640382716 - Loss: 0.41301459074020386, aux loss1: 0.954553484916687, 
		 aux loss2: 0.5363573431968689, total loss: 0.9139235615730286
28th Epoch, 10070th Step, learning rate = 0.008987120673705091 - Loss: 0.42356446385383606, aux loss1: 0.9049870371818542, 
		 aux loss2: 0.49452072381973267, total loss: 0.8928688764572144
28th Epoch, 10075th Step, learning rate = 0.008986614703862396 - Loss: 0.4000745117664337, aux loss1: 0.8231289386749268, 
		 aux loss2: 0.4865555465221405, total loss: 0.8416354060173035
28th Epoch, 10080th Step, learning rate = 0.008986108730854411 - Loss: 0.547248363494873, aux loss1: 1.1327381134033203, 
		 aux loss2: 0.7005903720855713, total loss: 1.1673059463500977
28th Epoch, 10085th Step, learning rate = 0.00898560275468092 - Loss: 0.41320058703422546, aux loss1: 0.9958882331848145, 
		 aux loss2: 0.519561231136322, total loss: 0.919791579246521
28th Epoch, 10090th Step, learning rate = 0.008985096775341705 - Loss: 0.48315829038619995, aux loss1: 0.9829961061477661, 
		 aux loss2: 0.590829074382782, total loss: 1.0143886804580688
28th Epoch, 10095th Step, learning rate = 0.008984590792836547 - Loss: 0.41049978137016296, aux loss1: 0.8718533515930176, 
		 aux loss2: 0.4940547049045563, total loss: 0.869677722454071
28th Epoch, 10100th Step, learning rate = 0.008984084807165229 - Loss: 0.568604052066803, aux loss1: 1.0838866233825684, 
		 aux loss2: 0.6897215247154236, total loss: 1.1696586608886719
<10100th step>
*************************** Test ***************************
time:3m 16s, 10100th Step, Loss: 0.6360958814620972, Mean IoU = 36.844%
************************************************************
28th Epoch, 10105th Step, learning rate = 0.008983578818327531 - Loss: 0.5313536524772644, aux loss1: 1.15591299533844, 
		 aux loss2: 0.6657685041427612, total loss: 1.144434928894043
28th Epoch, 10110th Step, learning rate = 0.008983072826323239 - Loss: 0.42442435026168823, aux loss1: 0.9090874195098877, 
		 aux loss2: 0.509994387626648, total loss: 0.9011483192443848
28th Epoch, 10115th Step, learning rate = 0.008982566831152132 - Loss: 0.5604853630065918, aux loss1: 1.0065298080444336, 
		 aux loss2: 0.6563193202018738, total loss: 1.1249719858169556
28th Epoch, 10120th Step, learning rate = 0.008982060832813991 - Loss: 0.4375341534614563, aux loss1: 0.8918685913085938, 
		 aux loss2: 0.5302752256393433, total loss: 0.9172048568725586
28th Epoch, 10125th Step, learning rate = 0.008981554831308601 - Loss: 0.4088270962238312, aux loss1: 0.9173789024353027, 
		 aux loss2: 0.5136126279830933, total loss: 0.8894858360290527
28th Epoch, 10130th Step, learning rate = 0.008981048826635744 - Loss: 0.4436524510383606, aux loss1: 0.9432188272476196, 
		 aux loss2: 0.5521512031555176, total loss: 0.9474785923957825
28th Epoch, 10135th Step, learning rate = 0.0089805428187952 - Loss: 0.4368685185909271, aux loss1: 0.9439427852630615, 
		 aux loss2: 0.5338681936264038, total loss: 0.9335986971855164
28th Epoch, 10140th Step, learning rate = 0.00898003680778675 - Loss: 0.37063077092170715, aux loss1: 0.89168381690979, 
		 aux loss2: 0.4794132113456726, total loss: 0.8299012184143066
28th Epoch, 10145th Step, learning rate = 0.008979530793610177 - Loss: 0.4628705084323883, aux loss1: 0.9008291363716125, 
		 aux loss2: 0.528944194316864, total loss: 0.9446969032287598
28th Epoch, 10150th Step, learning rate = 0.008979024776265263 - Loss: 0.5398946404457092, aux loss1: 1.1985894441604614, 
		 aux loss2: 0.7077052593231201, total loss: 1.1825536489486694
28th Epoch, 10155th Step, learning rate = 0.00897851875575179 - Loss: 0.3652881979942322, aux loss1: 0.8162952661514282, 
		 aux loss2: 0.4606078267097473, total loss: 0.7944199442863464
28th Epoch, 10160th Step, learning rate = 0.008978012732069537 - Loss: 0.48019808530807495, aux loss1: 0.9570333957672119, 
		 aux loss2: 0.5711453557014465, total loss: 0.995766282081604
28th Epoch, 10165th Step, learning rate = 0.008977506705218293 - Loss: 0.6182361245155334, aux loss1: 1.1285191774368286, 
		 aux loss2: 0.7456157207489014, total loss: 1.2550381422042847
28th Epoch, 10170th Step, learning rate = 0.008977000675197832 - Loss: 0.5012151598930359, aux loss1: 1.0025708675384521, 
		 aux loss2: 0.610548198223114, total loss: 1.046205759048462
28th Epoch, 10175th Step, learning rate = 0.008976494642007938 - Loss: 0.4514286518096924, aux loss1: 0.9559839963912964, 
		 aux loss2: 0.5667319297790527, total loss: 0.9649166464805603
28th Epoch, 10180th Step, learning rate = 0.008975988605648393 - Loss: 0.5167914628982544, aux loss1: 1.0060174465179443, 
		 aux loss2: 0.6240230798721313, total loss: 1.0682059526443481
28th Epoch, 10185th Step, learning rate = 0.00897548256611898 - Loss: 0.3960128426551819, aux loss1: 0.8041610717773438, 
		 aux loss2: 0.4782736301422119, total loss: 0.8285706043243408
28th Epoch, 10190th Step, learning rate = 0.008974976523419479 - Loss: 0.5374392867088318, aux loss1: 1.1324985027313232, 
		 aux loss2: 0.6510530114173889, total loss: 1.1376100778579712
28th Epoch, 10195th Step, learning rate = 0.00897447047754967 - Loss: 0.46761900186538696, aux loss1: 0.9188506603240967, 
		 aux loss2: 0.5525951385498047, total loss: 0.9643122553825378
28th Epoch, 10200th Step, learning rate = 0.008973964428509338 - Loss: 0.38699454069137573, aux loss1: 0.9339891672134399, 
		 aux loss2: 0.476109117269516, total loss: 0.8576349020004272
<10200th step>
*************************** Test ***************************
time:3m 15s, 10200th Step, Loss: 0.7578186988830566, Mean IoU = 31.817%
************************************************************
28th Epoch, 10205th Step, learning rate = 0.008973458376298262 - Loss: 0.5461113452911377, aux loss1: 1.0402809381484985, 
		 aux loss2: 0.6481726765632629, total loss: 1.1174647808074951
28th Epoch, 10210th Step, learning rate = 0.008972952320916223 - Loss: 0.3970428705215454, aux loss1: 0.9079794883728027, 
		 aux loss2: 0.4946725368499756, total loss: 0.8673056960105896
28th Epoch, 10215th Step, learning rate = 0.008972446262363005 - Loss: 0.5148604512214661, aux loss1: 0.9683472514152527, 
		 aux loss2: 0.6120686531066895, total loss: 1.05019211769104
28th Epoch, 10220th Step, learning rate = 0.008971940200638389 - Loss: 0.5043285489082336, aux loss1: 1.0103232860565186, 
		 aux loss2: 0.6141444444656372, total loss: 1.0530833005905151
28th Epoch, 10225th Step, learning rate = 0.008971434135742154 - Loss: 0.4888617992401123, aux loss1: 0.9452854990959167, 
		 aux loss2: 0.5613616704940796, total loss: 0.9969921112060547
28th Epoch, 10230th Step, learning rate = 0.008970928067674083 - Loss: 0.5058623552322388, aux loss1: 0.9672529697418213, 
		 aux loss2: 0.5928090810775757, total loss: 1.0331618785858154
28th Epoch, 10235th Step, learning rate = 0.008970421996433955 - Loss: 0.5415393710136414, aux loss1: 1.1166305541992188, 
		 aux loss2: 0.6682288646697998, total loss: 1.14382004737854
28th Epoch, 10240th Step, learning rate = 0.008969915922021558 - Loss: 0.40933623909950256, aux loss1: 0.8342570662498474, 
		 aux loss2: 0.48788559436798096, total loss: 0.8547676205635071
28th Epoch, 10245th Step, learning rate = 0.008969409844436664 - Loss: 0.3111475110054016, aux loss1: 0.7251103520393372, 
		 aux loss2: 0.3926622271537781, total loss: 0.6857455372810364
28th Epoch, 10250th Step, learning rate = 0.008968903763679061 - Loss: 0.4925902485847473, aux loss1: 0.9081632494926453, 
		 aux loss2: 0.5833176374435425, total loss: 0.9983662366867065
28th Epoch, 10255th Step, learning rate = 0.008968397679748528 - Loss: 0.43227019906044006, aux loss1: 0.9862861633300781, 
		 aux loss2: 0.5381360650062561, total loss: 0.9434105157852173
28th Epoch, 10260th Step, learning rate = 0.008967891592644845 - Loss: 0.4374440908432007, aux loss1: 0.9387879371643066, 
		 aux loss2: 0.5168609023094177, total loss: 0.9258248209953308
28th Epoch, 10265th Step, learning rate = 0.008967385502367795 - Loss: 0.40119847655296326, aux loss1: 0.8739203810691833, 
		 aux loss2: 0.48913127183914185, total loss: 0.8590271472930908
28th Epoch, 10270th Step, learning rate = 0.00896687940891716 - Loss: 0.4872089624404907, aux loss1: 1.0159131288528442, 
		 aux loss2: 0.6028406620025635, total loss: 1.0331192016601562
28th Epoch, 10275th Step, learning rate = 0.008966373312292716 - Loss: 0.3901633620262146, aux loss1: 0.9575804471969604, 
		 aux loss2: 0.49045008420944214, total loss: 0.8736175894737244
28th Epoch, 10280th Step, learning rate = 0.008965867212494249 - Loss: 0.49403315782546997, aux loss1: 0.9631009697914124, 
		 aux loss2: 0.5914977788925171, total loss: 1.0195626020431519
28th Epoch, 10285th Step, learning rate = 0.008965361109521537 - Loss: 0.4544109106063843, aux loss1: 0.8845478296279907, 
		 aux loss2: 0.5435503125190735, total loss: 0.9371954202651978
28th Epoch, 10290th Step, learning rate = 0.008964855003374366 - Loss: 0.4251738488674164, aux loss1: 0.8715943098068237, 
		 aux loss2: 0.502132773399353, total loss: 0.887505292892456
28th Epoch, 10295th Step, learning rate = 0.008964348894052511 - Loss: 0.6466270685195923, aux loss1: 1.1126372814178467, 
		 aux loss2: 0.7701337337493896, total loss: 1.2884716987609863
28th Epoch, 10300th Step, learning rate = 0.008963842781555756 - Loss: 0.5397232174873352, aux loss1: 1.0760892629623413, 
		 aux loss2: 0.6537861227989197, total loss: 1.1240644454956055
<10300th step>
*************************** Test ***************************
time:3m 14s, 10300th Step, Loss: 0.6417180299758911, Mean IoU = 35.899%
************************************************************
28th Epoch, 10305th Step, learning rate = 0.00896333666588388 - Loss: 0.4671141803264618, aux loss1: 0.9591774344444275, 
		 aux loss2: 0.5955985188484192, total loss: 0.9931068420410156
28th Epoch, 10310th Step, learning rate = 0.008962830547036667 - Loss: 0.5468937158584595, aux loss1: 0.9772314429283142, 
		 aux loss2: 0.6167369484901428, total loss: 1.0867578983306885
28th Epoch, 10315th Step, learning rate = 0.008962324425013895 - Loss: 0.4173921048641205, aux loss1: 0.870161771774292, 
		 aux loss2: 0.5207706689834595, total loss: 0.8867489695549011
28th Epoch, 10320th Step, learning rate = 0.008961818299815346 - Loss: 0.5882932543754578, aux loss1: 1.0390788316726685, 
		 aux loss2: 0.6636219620704651, total loss: 1.1654657125473022
28th Epoch, 10325th Step, learning rate = 0.008961312171440802 - Loss: 0.4792918264865875, aux loss1: 0.9792314171791077, 
		 aux loss2: 0.5683884620666504, total loss: 1.00041663646698
28th Epoch, 10330th Step, learning rate = 0.008960806039890041 - Loss: 0.5514490008354187, aux loss1: 1.012737512588501, 
		 aux loss2: 0.6382169723510742, total loss: 1.1105570793151855
28th Epoch, 10335th Step, learning rate = 0.008960299905162844 - Loss: 0.47147178649902344, aux loss1: 0.9623849391937256, 
		 aux loss2: 0.5672656297683716, total loss: 0.9870935082435608
28th Epoch, 10340th Step, learning rate = 0.008959793767258993 - Loss: 0.6197009682655334, aux loss1: 1.0416704416275024, 
		 aux loss2: 0.700913667678833, total loss: 1.2125675678253174
28th Epoch, 10345th Step, learning rate = 0.00895928762617827 - Loss: 0.4130131006240845, aux loss1: 1.008640170097351, 
		 aux loss2: 0.542605996131897, total loss: 0.9326475262641907
28th Epoch, 10350th Step, learning rate = 0.008958781481920454 - Loss: 0.48754820227622986, aux loss1: 0.9299778342247009, 
		 aux loss2: 0.5722565054893494, total loss: 0.9954441785812378
28th Epoch, 10355th Step, learning rate = 0.008958275334485325 - Loss: 0.38880911469459534, aux loss1: 0.8146243691444397, 
		 aux loss2: 0.46328097581863403, total loss: 0.8185088038444519
28th Epoch, 10360th Step, learning rate = 0.008957769183872664 - Loss: 0.409148246049881, aux loss1: 0.832642674446106, 
		 aux loss2: 0.4816087484359741, total loss: 0.8515845537185669
28th Epoch, 10365th Step, learning rate = 0.008957263030082253 - Loss: 0.5132737755775452, aux loss1: 0.9213399291038513, 
		 aux loss2: 0.5925561189651489, total loss: 1.0266982316970825
28th Epoch, 10370th Step, learning rate = 0.00895675687311387 - Loss: 0.4338582158088684, aux loss1: 0.994970977306366, 
		 aux loss2: 0.5154003500938416, total loss: 0.9385096430778503
28th Epoch, 10375th Step, learning rate = 0.008956250712967297 - Loss: 0.41989263892173767, aux loss1: 0.8941154479980469, 
		 aux loss2: 0.5190466046333313, total loss: 0.8957459330558777
28th Epoch, 10380th Step, learning rate = 0.008955744549642316 - Loss: 0.5189688801765442, aux loss1: 0.9631435871124268, 
		 aux loss2: 0.6221445798873901, total loss: 1.056769847869873
28th Epoch, 10385th Step, learning rate = 0.008955238383138704 - Loss: 0.4173451066017151, aux loss1: 0.8732813596725464, 
		 aux loss2: 0.49389925599098206, total loss: 0.8768892288208008
29th Epoch, 10390th Step, learning rate = 0.008954732213456244 - Loss: 0.6213510036468506, aux loss1: 1.140321969985962, 
		 aux loss2: 0.7364630103111267, total loss: 1.2580327987670898
29th Epoch, 10395th Step, learning rate = 0.008954226040594716 - Loss: 0.4582071006298065, aux loss1: 0.8437139987945557, 
		 aux loss2: 0.5259731411933899, total loss: 0.9217106103897095
29th Epoch, 10400th Step, learning rate = 0.008953719864553898 - Loss: 0.36660638451576233, aux loss1: 0.7961047291755676, 
		 aux loss2: 0.43281447887420654, total loss: 0.7785636186599731
<10400th step>
*************************** Test ***************************
time:3m 13s, 10400th Step, Loss: 0.5730188488960266, Mean IoU = 37.436%
************************************************************
29th Epoch, 10405th Step, learning rate = 0.008953213685333574 - Loss: 0.4742833375930786, aux loss1: 1.024291753768921, 
		 aux loss2: 0.6002751588821411, total loss: 1.0216809511184692
29th Epoch, 10410th Step, learning rate = 0.008952707502933522 - Loss: 0.6062156558036804, aux loss1: 1.0560964345932007, 
		 aux loss2: 0.6971750259399414, total loss: 1.2019145488739014
29th Epoch, 10415th Step, learning rate = 0.008952201317353524 - Loss: 0.3553430438041687, aux loss1: 0.7891696691513062, 
		 aux loss2: 0.43032020330429077, total loss: 0.7642220258712769
29th Epoch, 10420th Step, learning rate = 0.008951695128593357 - Loss: 0.5023159384727478, aux loss1: 1.0674171447753906, 
		 aux loss2: 0.6388913989067078, total loss: 1.0780977010726929
29th Epoch, 10425th Step, learning rate = 0.008951188936652806 - Loss: 0.447613000869751, aux loss1: 0.9497918486595154, 
		 aux loss2: 0.5469016432762146, total loss: 0.9513112306594849
29th Epoch, 10430th Step, learning rate = 0.008950682741531647 - Loss: 0.4886324107646942, aux loss1: 0.9827103018760681, 
		 aux loss2: 0.5906064510345459, total loss: 1.0196880102157593
29th Epoch, 10435th Step, learning rate = 0.008950176543229662 - Loss: 0.4847467839717865, aux loss1: 1.1378328800201416, 
		 aux loss2: 0.6023142337799072, total loss: 1.0670223236083984
29th Epoch, 10440th Step, learning rate = 0.008949670341746629 - Loss: 0.5239296555519104, aux loss1: 1.0222328901290894, 
		 aux loss2: 0.6279115676879883, total loss: 1.0817642211914062
29th Epoch, 10445th Step, learning rate = 0.00894916413708233 - Loss: 0.3763563334941864, aux loss1: 0.7964906692504883, 
		 aux loss2: 0.4663732349872589, total loss: 0.801852822303772
29th Epoch, 10450th Step, learning rate = 0.008948657929236548 - Loss: 0.4897391200065613, aux loss1: 1.0352909564971924, 
		 aux loss2: 0.59091717004776, total loss: 1.0366933345794678
29th Epoch, 10455th Step, learning rate = 0.008948151718209056 - Loss: 0.4859846532344818, aux loss1: 0.9250996708869934, 
		 aux loss2: 0.6033018231391907, total loss: 1.0048353672027588
29th Epoch, 10460th Step, learning rate = 0.008947645503999641 - Loss: 0.42272594571113586, aux loss1: 1.0016124248504639, 
		 aux loss2: 0.5242125988006592, total loss: 0.9328947067260742
29th Epoch, 10465th Step, learning rate = 0.008947139286608077 - Loss: 0.3547559678554535, aux loss1: 0.781034529209137, 
		 aux loss2: 0.4306780993938446, total loss: 0.7613375782966614
29th Epoch, 10470th Step, learning rate = 0.00894663306603415 - Loss: 0.38162192702293396, aux loss1: 0.8135711550712585, 
		 aux loss2: 0.4527617394924164, total loss: 0.806797981262207
29th Epoch, 10475th Step, learning rate = 0.008946126842277635 - Loss: 0.5822697281837463, aux loss1: 0.9435003399848938, 
		 aux loss2: 0.6455100178718567, total loss: 1.1235238313674927
29th Epoch, 10480th Step, learning rate = 0.008945620615338313 - Loss: 0.5031552314758301, aux loss1: 1.0995306968688965, 
		 aux loss2: 0.6170035600662231, total loss: 1.0798158645629883
29th Epoch, 10485th Step, learning rate = 0.008945114385215967 - Loss: 0.5575753450393677, aux loss1: 1.0519757270812988, 
		 aux loss2: 0.670769453048706, total loss: 1.1414759159088135
29th Epoch, 10490th Step, learning rate = 0.008944608151910373 - Loss: 0.4189208149909973, aux loss1: 0.7970688939094543, 
		 aux loss2: 0.48694825172424316, total loss: 0.8528207540512085
29th Epoch, 10495th Step, learning rate = 0.008944101915421311 - Loss: 0.43400654196739197, aux loss1: 0.9211002588272095, 
		 aux loss2: 0.5211317539215088, total loss: 0.9187893271446228
29th Epoch, 10500th Step, learning rate = 0.008943595675748563 - Loss: 0.7472690939903259, aux loss1: 1.3639384508132935, 
		 aux loss2: 0.9177761077880859, total loss: 1.5235611200332642
<10500th step>
*************************** Test ***************************
time:3m 18s, 10500th Step, Loss: 0.7766299247741699, Mean IoU = 35.531%
************************************************************
29th Epoch, 10505th Step, learning rate = 0.00894308943289191 - Loss: 0.42260903120040894, aux loss1: 0.8214172124862671, 
		 aux loss2: 0.4965604841709137, total loss: 0.8676583766937256
29th Epoch, 10510th Step, learning rate = 0.008942583186851125 - Loss: 0.3935565650463104, aux loss1: 0.848882794380188, 
		 aux loss2: 0.4885668456554413, total loss: 0.8436481356620789
29th Epoch, 10515th Step, learning rate = 0.008942076937625994 - Loss: 0.5443447232246399, aux loss1: 1.0359678268432617, 
		 aux loss2: 0.6483423709869385, total loss: 1.1144720315933228
29th Epoch, 10520th Step, learning rate = 0.008941570685216295 - Loss: 0.5764298439025879, aux loss1: 1.0720936059951782, 
		 aux loss2: 0.6865132451057434, total loss: 1.1726632118225098
29th Epoch, 10525th Step, learning rate = 0.008941064429621807 - Loss: 0.5556183457374573, aux loss1: 0.9689145684242249, 
		 aux loss2: 0.6473920941352844, total loss: 1.1052496433258057
29th Epoch, 10530th Step, learning rate = 0.00894055817084231 - Loss: 0.41627538204193115, aux loss1: 0.9398373365402222, 
		 aux loss2: 0.5254784226417542, total loss: 0.9084179401397705
29th Epoch, 10535th Step, learning rate = 0.008940051908877584 - Loss: 0.49245214462280273, aux loss1: 0.9976233839988708, 
		 aux loss2: 0.5939149260520935, total loss: 1.029305100440979
29th Epoch, 10540th Step, learning rate = 0.008939545643727407 - Loss: 0.5600752830505371, aux loss1: 1.017062783241272, 
		 aux loss2: 0.6467743515968323, total loss: 1.1239038705825806
29th Epoch, 10545th Step, learning rate = 0.008939039375391561 - Loss: 0.3177109658718109, aux loss1: 0.7376834750175476, 
		 aux loss2: 0.3929796516895294, total loss: 0.6962078809738159
29th Epoch, 10550th Step, learning rate = 0.008938533103869824 - Loss: 0.48209235072135925, aux loss1: 0.9613004922866821, 
		 aux loss2: 0.5825508236885071, total loss: 1.0035028457641602
29th Epoch, 10555th Step, learning rate = 0.008938026829161973 - Loss: 0.4782831072807312, aux loss1: 0.9400537610054016, 
		 aux loss2: 0.5632842183113098, total loss: 0.9856128692626953
29th Epoch, 10560th Step, learning rate = 0.008937520551267794 - Loss: 0.42139557003974915, aux loss1: 0.927713930606842, 
		 aux loss2: 0.5024543404579163, total loss: 0.9006915092468262
29th Epoch, 10565th Step, learning rate = 0.008937014270187059 - Loss: 0.3973495662212372, aux loss1: 0.8061500191688538, 
		 aux loss2: 0.48836416006088257, total loss: 0.8345402479171753
29th Epoch, 10570th Step, learning rate = 0.008936507985919552 - Loss: 0.42656704783439636, aux loss1: 0.885948657989502, 
		 aux loss2: 0.5123657584190369, total loss: 0.8972979784011841
29th Epoch, 10575th Step, learning rate = 0.008936001698465052 - Loss: 0.6624261736869812, aux loss1: 1.1393229961395264, 
		 aux loss2: 0.7803986668586731, total loss: 1.316382646560669
29th Epoch, 10580th Step, learning rate = 0.008935495407823336 - Loss: 0.5125395059585571, aux loss1: 1.0365875959396362, 
		 aux loss2: 0.6083746552467346, total loss: 1.0668656826019287
29th Epoch, 10585th Step, learning rate = 0.008934989113994185 - Loss: 0.48255735635757446, aux loss1: 0.9199153780937195, 
		 aux loss2: 0.5691086053848267, total loss: 0.9861754179000854
29th Epoch, 10590th Step, learning rate = 0.008934482816977377 - Loss: 0.4372098445892334, aux loss1: 0.9126949906349182, 
		 aux loss2: 0.5289639234542847, total loss: 0.9226039052009583
29th Epoch, 10595th Step, learning rate = 0.008933976516772692 - Loss: 0.536498486995697, aux loss1: 1.0321413278579712, 
		 aux loss2: 0.6896263360977173, total loss: 1.1219913959503174
29th Epoch, 10600th Step, learning rate = 0.00893347021337991 - Loss: 0.5430138111114502, aux loss1: 0.9363076686859131, 
		 aux loss2: 0.6115783452987671, total loss: 1.0685374736785889
<10600th step>
*************************** Test ***************************
time:3m 15s, 10600th Step, Loss: 0.7836499810218811, Mean IoU = 34.527%
************************************************************
29th Epoch, 10605th Step, learning rate = 0.00893296390679881 - Loss: 0.4590194821357727, aux loss1: 0.9433963298797607, 
		 aux loss2: 0.563863217830658, total loss: 0.9675836563110352
29th Epoch, 10610th Step, learning rate = 0.00893245759702917 - Loss: 0.4324541389942169, aux loss1: 0.9104778170585632, 
		 aux loss2: 0.5168523192405701, total loss: 0.9123384356498718
29th Epoch, 10615th Step, learning rate = 0.008931951284070769 - Loss: 0.5330137610435486, aux loss1: 0.999134361743927, 
		 aux loss2: 0.6140282154083252, total loss: 1.0783653259277344
29th Epoch, 10620th Step, learning rate = 0.008931444967923387 - Loss: 0.40963810682296753, aux loss1: 0.8850163817405701, 
		 aux loss2: 0.4891822934150696, total loss: 0.8708159327507019
29th Epoch, 10625th Step, learning rate = 0.008930938648586803 - Loss: 0.48698657751083374, aux loss1: 0.8590605854988098, 
		 aux loss2: 0.5666064023971558, total loss: 0.9713472723960876
29th Epoch, 10630th Step, learning rate = 0.008930432326060798 - Loss: 0.6224198341369629, aux loss1: 1.0308524370193481, 
		 aux loss2: 0.6759824156761169, total loss: 1.202068567276001
29th Epoch, 10635th Step, learning rate = 0.008929926000345147 - Loss: 0.6144649386405945, aux loss1: 1.189243197441101, 
		 aux loss2: 0.7452785968780518, total loss: 1.2693493366241455
29th Epoch, 10640th Step, learning rate = 0.00892941967143963 - Loss: 0.3832220733165741, aux loss1: 0.9048725962638855, 
		 aux loss2: 0.4831337034702301, total loss: 0.8479373455047607
29th Epoch, 10645th Step, learning rate = 0.008928913339344027 - Loss: 0.5232493877410889, aux loss1: 0.957815408706665, 
		 aux loss2: 0.6172893047332764, total loss: 1.0575097799301147
29th Epoch, 10650th Step, learning rate = 0.008928407004058118 - Loss: 0.5647061467170715, aux loss1: 1.107074499130249, 
		 aux loss2: 0.6802239418029785, total loss: 1.1689181327819824
29th Epoch, 10655th Step, learning rate = 0.008927900665581679 - Loss: 0.45202627778053284, aux loss1: 0.9123753309249878, 
		 aux loss2: 0.5360580682754517, total loss: 0.9401621222496033
29th Epoch, 10660th Step, learning rate = 0.00892739432391449 - Loss: 0.45228567719459534, aux loss1: 0.9014849066734314, 
		 aux loss2: 0.5353225469589233, total loss: 0.936860203742981
29th Epoch, 10665th Step, learning rate = 0.00892688797905633 - Loss: 0.4152025878429413, aux loss1: 0.844841480255127, 
		 aux loss2: 0.5055556297302246, total loss: 0.8708772659301758
29th Epoch, 10670th Step, learning rate = 0.00892638163100698 - Loss: 0.359485924243927, aux loss1: 0.9712150692939758, 
		 aux loss2: 0.4617575407028198, total loss: 0.8355534076690674
29th Epoch, 10675th Step, learning rate = 0.008925875279766215 - Loss: 0.6444404721260071, aux loss1: 1.2502890825271606, 
		 aux loss2: 0.7707501649856567, total loss: 1.3278272151947021
29th Epoch, 10680th Step, learning rate = 0.008925368925333816 - Loss: 0.7663455605506897, aux loss1: 1.206322193145752, 
		 aux loss2: 0.8608624935150146, total loss: 1.47258722782135
29th Epoch, 10685th Step, learning rate = 0.00892486256770956 - Loss: 0.5325108766555786, aux loss1: 1.0490224361419678, 
		 aux loss2: 0.6480154991149902, total loss: 1.1064238548278809
29th Epoch, 10690th Step, learning rate = 0.008924356206893228 - Loss: 0.5936444401741028, aux loss1: 1.069091558456421, 
		 aux loss2: 0.6757873892784119, total loss: 1.1846868991851807
29th Epoch, 10695th Step, learning rate = 0.008923849842884597 - Loss: 0.5783343315124512, aux loss1: 1.155450701713562, 
		 aux loss2: 0.6938925981521606, total loss: 1.202526569366455
29th Epoch, 10700th Step, learning rate = 0.008923343475683444 - Loss: 0.3741092085838318, aux loss1: 0.8619928359985352, 
		 aux loss2: 0.45610153675079346, total loss: 0.8151476979255676
<10700th step>
*************************** Test ***************************
time:3m 16s, 10700th Step, Loss: 0.6115286946296692, Mean IoU = 36.685%
************************************************************
29th Epoch, 10705th Step, learning rate = 0.008922837105289553 - Loss: 0.53969806432724, aux loss1: 1.1135646104812622, 
		 aux loss2: 0.6639291644096375, total loss: 1.1393392086029053
29th Epoch, 10710th Step, learning rate = 0.008922330731702696 - Loss: 0.49206697940826416, aux loss1: 0.9062072038650513, 
		 aux loss2: 0.5761163234710693, total loss: 0.9943756461143494
29th Epoch, 10715th Step, learning rate = 0.008921824354922656 - Loss: 0.4298474192619324, aux loss1: 0.8460062742233276, 
		 aux loss2: 0.5068601369857788, total loss: 0.8863933682441711
29th Epoch, 10720th Step, learning rate = 0.00892131797494921 - Loss: 0.3874441981315613, aux loss1: 0.7601818442344666, 
		 aux loss2: 0.45519834756851196, total loss: 0.7975780963897705
29th Epoch, 10725th Step, learning rate = 0.008920811591782136 - Loss: 0.4878385066986084, aux loss1: 0.9370822906494141, 
		 aux loss2: 0.553399920463562, total loss: 0.9903231859207153
29th Epoch, 10730th Step, learning rate = 0.008920305205421215 - Loss: 0.4128679037094116, aux loss1: 0.8515742421150208, 
		 aux loss2: 0.4879249930381775, total loss: 0.8635101914405823
29th Epoch, 10735th Step, learning rate = 0.00891979881586622 - Loss: 0.39569413661956787, aux loss1: 0.8276074528694153, 
		 aux loss2: 0.4765486419200897, total loss: 0.8345958590507507
29th Epoch, 10740th Step, learning rate = 0.008919292423116936 - Loss: 0.36771562695503235, aux loss1: 0.7952893972396851, 
		 aux loss2: 0.4583008587360382, total loss: 0.7896227836608887
29th Epoch, 10745th Step, learning rate = 0.008918786027173135 - Loss: 0.3410944640636444, aux loss1: 0.8677868843078613, 
		 aux loss2: 0.4352612793445587, total loss: 0.7755350470542908
29th Epoch, 10750th Step, learning rate = 0.0089182796280346 - Loss: 0.3934641480445862, aux loss1: 0.8554620146751404, 
		 aux loss2: 0.4807887375354767, total loss: 0.8424182534217834
29th Epoch, 10755th Step, learning rate = 0.00891777322570111 - Loss: 0.44001534581184387, aux loss1: 0.9140756130218506, 
		 aux loss2: 0.5302578806877136, total loss: 0.92634117603302
30th Epoch, 10760th Step, learning rate = 0.008917266820172437 - Loss: 0.4931967854499817, aux loss1: 0.9648520946502686, 
		 aux loss2: 0.5727580785751343, total loss: 1.0117557048797607
30th Epoch, 10765th Step, learning rate = 0.008916760411448364 - Loss: 0.5115832686424255, aux loss1: 0.9953507781028748, 
		 aux loss2: 0.5963229537010193, total loss: 1.048717737197876
30th Epoch, 10770th Step, learning rate = 0.008916253999528669 - Loss: 0.4327513575553894, aux loss1: 0.9341309070587158, 
		 aux loss2: 0.5236464142799377, total loss: 0.9224492311477661
30th Epoch, 10775th Step, learning rate = 0.00891574758441313 - Loss: 0.5270616412162781, aux loss1: 1.0840851068496704, 
		 aux loss2: 0.6557201743125916, total loss: 1.1145752668380737
30th Epoch, 10780th Step, learning rate = 0.008915241166101524 - Loss: 0.3780897259712219, aux loss1: 0.8602644801139832, 
		 aux loss2: 0.4543077051639557, total loss: 0.8178921937942505
30th Epoch, 10785th Step, learning rate = 0.00891473474459363 - Loss: 0.5682793855667114, aux loss1: 1.073861002922058, 
		 aux loss2: 0.6739469766616821, total loss: 1.1600165367126465
30th Epoch, 10790th Step, learning rate = 0.008914228319889226 - Loss: 0.37535133957862854, aux loss1: 0.7890297174453735, 
		 aux loss2: 0.44026583433151245, total loss: 0.7881665825843811
30th Epoch, 10795th Step, learning rate = 0.00891372189198809 - Loss: 0.47210535407066345, aux loss1: 0.9317330121994019, 
		 aux loss2: 0.5790364742279053, total loss: 0.9832398891448975
30th Epoch, 10800th Step, learning rate = 0.00891321546089 - Loss: 0.617256760597229, aux loss1: 1.061086893081665, 
		 aux loss2: 0.7121792435646057, total loss: 1.2204545736312866
<10800th step>
*************************** Test ***************************
time:3m 14s, 10800th Step, Loss: 0.6031860709190369, Mean IoU = 37.709%
************************************************************
30th Epoch, 10805th Step, learning rate = 0.008912709026594733 - Loss: 0.4071502387523651, aux loss1: 0.8360122442245483, 
		 aux loss2: 0.49986690282821655, total loss: 0.8579006791114807
30th Epoch, 10810th Step, learning rate = 0.008912202589102068 - Loss: 0.43497127294540405, aux loss1: 0.9514845013618469, 
		 aux loss2: 0.5333112478256226, total loss: 0.9337411522865295
30th Epoch, 10815th Step, learning rate = 0.008911696148411783 - Loss: 0.5300525426864624, aux loss1: 1.0243688821792603, 
		 aux loss2: 0.6252386569976807, total loss: 1.0874587297439575
30th Epoch, 10820th Step, learning rate = 0.008911189704523656 - Loss: 0.6557379961013794, aux loss1: 1.247503638267517, 
		 aux loss2: 0.7752293348312378, total loss: 1.3400808572769165
30th Epoch, 10825th Step, learning rate = 0.008910683257437465 - Loss: 0.6605877876281738, aux loss1: 1.1916368007659912, 
		 aux loss2: 0.7958585619926453, total loss: 1.3364222049713135
30th Epoch, 10830th Step, learning rate = 0.008910176807152987 - Loss: 0.42831742763519287, aux loss1: 0.8997649550437927, 
		 aux loss2: 0.5309966802597046, total loss: 0.910645604133606
30th Epoch, 10835th Step, learning rate = 0.00890967035367 - Loss: 0.39855900406837463, aux loss1: 0.944307267665863, 
		 aux loss2: 0.5132754445075989, total loss: 0.887161374092102
30th Epoch, 10840th Step, learning rate = 0.00890916389698828 - Loss: 0.44182315468788147, aux loss1: 0.9390548467636108, 
		 aux loss2: 0.5704385638237, total loss: 0.9517149925231934
30th Epoch, 10845th Step, learning rate = 0.00890865743710761 - Loss: 0.40728071331977844, aux loss1: 0.8078852295875549, 
		 aux loss2: 0.4874725639820099, total loss: 0.8446353077888489
30th Epoch, 10850th Step, learning rate = 0.008908150974027763 - Loss: 0.45409655570983887, aux loss1: 0.8698673248291016, 
		 aux loss2: 0.5574361085891724, total loss: 0.9380311965942383
30th Epoch, 10855th Step, learning rate = 0.008907644507748518 - Loss: 0.413774311542511, aux loss1: 0.8368202447891235, 
		 aux loss2: 0.5014671683311462, total loss: 0.8654072880744934
30th Epoch, 10860th Step, learning rate = 0.008907138038269652 - Loss: 0.5340449213981628, aux loss1: 1.021268367767334, 
		 aux loss2: 0.6668311953544617, total loss: 1.1071579456329346
30th Epoch, 10865th Step, learning rate = 0.008906631565590946 - Loss: 0.4399578869342804, aux loss1: 0.8908619284629822, 
		 aux loss2: 0.516271710395813, total loss: 0.9137251973152161
30th Epoch, 10870th Step, learning rate = 0.008906125089712173 - Loss: 0.4287310242652893, aux loss1: 0.9218433499336243, 
		 aux loss2: 0.5173113942146301, total loss: 0.9122085571289062
30th Epoch, 10875th Step, learning rate = 0.008905618610633112 - Loss: 0.4181012511253357, aux loss1: 0.9215107560157776, 
		 aux loss2: 0.5254716277122498, total loss: 0.9047430753707886
30th Epoch, 10880th Step, learning rate = 0.008905112128353543 - Loss: 0.6539186835289001, aux loss1: 1.1850981712341309, 
		 aux loss2: 0.7561094760894775, total loss: 1.311892032623291
30th Epoch, 10885th Step, learning rate = 0.008904605642873242 - Loss: 0.4830397665500641, aux loss1: 0.9995602369308472, 
		 aux loss2: 0.5888729095458984, total loss: 1.018457055091858
30th Epoch, 10890th Step, learning rate = 0.008904099154191984 - Loss: 0.4573601186275482, aux loss1: 0.9057806134223938, 
		 aux loss2: 0.5510839223861694, total loss: 0.94952791929245
30th Epoch, 10895th Step, learning rate = 0.00890359266230955 - Loss: 0.4725571870803833, aux loss1: 0.956771731376648, 
		 aux loss2: 0.5464446544647217, total loss: 0.9781665802001953
30th Epoch, 10900th Step, learning rate = 0.008903086167225715 - Loss: 0.4509768784046173, aux loss1: 0.8387022614479065, 
		 aux loss2: 0.5270313024520874, total loss: 0.9134001135826111
<10900th step>
*************************** Test ***************************
time:3m 13s, 10900th Step, Loss: 0.6222882866859436, Mean IoU = 37.008%
************************************************************
30th Epoch, 10905th Step, learning rate = 0.00890257966894026 - Loss: 0.5426484942436218, aux loss1: 1.0152565240859985, 
		 aux loss2: 0.6148265600204468, total loss: 1.093156099319458
30th Epoch, 10910th Step, learning rate = 0.008902073167452958 - Loss: 0.537138044834137, aux loss1: 0.9871306419372559, 
		 aux loss2: 0.6028558611869812, total loss: 1.074419617652893
30th Epoch, 10915th Step, learning rate = 0.008901566662763587 - Loss: 0.43219736218452454, aux loss1: 0.8270118832588196, 
		 aux loss2: 0.5017907023429871, total loss: 0.8810172080993652
30th Epoch, 10920th Step, learning rate = 0.008901060154871928 - Loss: 0.497614324092865, aux loss1: 0.9446732997894287, 
		 aux loss2: 0.5789650678634644, total loss: 1.0126023292541504
30th Epoch, 10925th Step, learning rate = 0.008900553643777755 - Loss: 0.47812971472740173, aux loss1: 0.9646251797676086, 
		 aux loss2: 0.5905949473381042, total loss: 1.0037552118301392
30th Epoch, 10930th Step, learning rate = 0.008900047129480846 - Loss: 0.40364429354667664, aux loss1: 0.7753696441650391, 
		 aux loss2: 0.4659479558467865, total loss: 0.8226343989372253
30th Epoch, 10935th Step, learning rate = 0.008899540611980977 - Loss: 0.42703717947006226, aux loss1: 0.8985401391983032, 
		 aux loss2: 0.5172554850578308, total loss: 0.9035014510154724
30th Epoch, 10940th Step, learning rate = 0.008899034091277926 - Loss: 0.5305298566818237, aux loss1: 1.0856529474258423, 
		 aux loss2: 0.6694839000701904, total loss: 1.1240192651748657
30th Epoch, 10945th Step, learning rate = 0.008898527567371473 - Loss: 0.5550400018692017, aux loss1: 1.0129035711288452, 
		 aux loss2: 0.6298776268959045, total loss: 1.110862135887146
30th Epoch, 10950th Step, learning rate = 0.008898021040261392 - Loss: 0.5097041726112366, aux loss1: 0.9733672738075256, 
		 aux loss2: 0.6020989418029785, total loss: 1.0425539016723633
30th Epoch, 10955th Step, learning rate = 0.00889751450994746 - Loss: 0.5349907279014587, aux loss1: 1.1089894771575928, 
		 aux loss2: 0.6645774841308594, total loss: 1.1335185766220093
30th Epoch, 10960th Step, learning rate = 0.008897007976429455 - Loss: 0.582628071308136, aux loss1: 1.0348529815673828, 
		 aux loss2: 0.6773932576179504, total loss: 1.16404128074646
30th Epoch, 10965th Step, learning rate = 0.008896501439707154 - Loss: 0.394177109003067, aux loss1: 0.8430867791175842, 
		 aux loss2: 0.46836453676223755, total loss: 0.8344489932060242
30th Epoch, 10970th Step, learning rate = 0.008895994899780334 - Loss: 0.5034406781196594, aux loss1: 0.9419808983802795, 
		 aux loss2: 0.6271660923957825, total loss: 1.0369013547897339
30th Epoch, 10975th Step, learning rate = 0.008895488356648773 - Loss: 0.45196273922920227, aux loss1: 0.8849726915359497, 
		 aux loss2: 0.5435488224029541, total loss: 0.9348740577697754
30th Epoch, 10980th Step, learning rate = 0.008894981810312246 - Loss: 0.31738001108169556, aux loss1: 0.7679533362388611, 
		 aux loss2: 0.4025648236274719, total loss: 0.708791971206665
30th Epoch, 10985th Step, learning rate = 0.00889447526077053 - Loss: 0.5358052253723145, aux loss1: 1.0566970109939575, 
		 aux loss2: 0.6616771221160889, total loss: 1.1174851655960083
30th Epoch, 10990th Step, learning rate = 0.008893968708023404 - Loss: 0.6919369697570801, aux loss1: 1.2270101308822632, 
		 aux loss2: 0.7968549132347107, total loss: 1.378782033920288
30th Epoch, 10995th Step, learning rate = 0.008893462152070644 - Loss: 0.2875310778617859, aux loss1: 0.7819671630859375, 
		 aux loss2: 0.37134069204330444, total loss: 0.6706575155258179
30th Epoch, 11000th Step, learning rate = 0.008892955592912026 - Loss: 0.47332486510276794, aux loss1: 0.9886506795883179, 
		 aux loss2: 0.574052095413208, total loss: 0.9995409250259399
<11000th step>
*************************** Test ***************************
time:3m 10s, 11000th Step, Loss: 0.6045109629631042, Mean IoU = 36.631%
************************************************************
30th Epoch, 11005th Step, learning rate = 0.008892449030547325 - Loss: 0.43404287099838257, aux loss1: 0.958480954170227, 
		 aux loss2: 0.5227672457695007, total loss: 0.9306941032409668
30th Epoch, 11010th Step, learning rate = 0.008891942464976323 - Loss: 0.4945911467075348, aux loss1: 1.0857629776000977, 
		 aux loss2: 0.6108458042144775, total loss: 1.064658284187317
30th Epoch, 11015th Step, learning rate = 0.008891435896198794 - Loss: 0.6315012574195862, aux loss1: 1.234394907951355, 
		 aux loss2: 0.7755278944969177, total loss: 1.3120309114456177
30th Epoch, 11020th Step, learning rate = 0.008890929324214512 - Loss: 0.4629548192024231, aux loss1: 0.8480836749076843, 
		 aux loss2: 0.5283241868019104, total loss: 0.9287096261978149
30th Epoch, 11025th Step, learning rate = 0.008890422749023255 - Loss: 0.3610398471355438, aux loss1: 0.7732133269309998, 
		 aux loss2: 0.4580724239349365, total loss: 0.7762328386306763
30th Epoch, 11030th Step, learning rate = 0.008889916170624805 - Loss: 0.5189669132232666, aux loss1: 0.927233099937439, 
		 aux loss2: 0.5835657715797424, total loss: 1.0305631160736084
30th Epoch, 11035th Step, learning rate = 0.008889409589018932 - Loss: 0.48805078864097595, aux loss1: 1.0284827947616577, 
		 aux loss2: 0.5975145101547241, total loss: 1.0356013774871826
30th Epoch, 11040th Step, learning rate = 0.008888903004205416 - Loss: 0.497224897146225, aux loss1: 0.9920059442520142, 
		 aux loss2: 0.6038885712623596, total loss: 1.0363820791244507
30th Epoch, 11045th Step, learning rate = 0.008888396416184033 - Loss: 0.41581398248672485, aux loss1: 0.854660153388977, 
		 aux loss2: 0.48779040575027466, total loss: 0.8673281669616699
30th Epoch, 11050th Step, learning rate = 0.008887889824954557 - Loss: 0.6452161073684692, aux loss1: 1.0270551443099976, 
		 aux loss2: 0.7573947906494141, total loss: 1.2562905550003052
30th Epoch, 11055th Step, learning rate = 0.008887383230516768 - Loss: 0.40121376514434814, aux loss1: 0.8174583911895752, 
		 aux loss2: 0.47885337471961975, total loss: 0.8379926681518555
30th Epoch, 11060th Step, learning rate = 0.00888687663287044 - Loss: 0.5773352384567261, aux loss1: 1.0481584072113037, 
		 aux loss2: 0.6749989986419678, total loss: 1.1617823839187622
30th Epoch, 11065th Step, learning rate = 0.008886370032015353 - Loss: 0.3540065884590149, aux loss1: 0.8712628483772278, 
		 aux loss2: 0.43346935510635376, total loss: 0.7887731790542603
30th Epoch, 11070th Step, learning rate = 0.00888586342795128 - Loss: 0.43526390194892883, aux loss1: 0.8406504988670349, 
		 aux loss2: 0.49938786029815674, total loss: 0.887214183807373
30th Epoch, 11075th Step, learning rate = 0.008885356820677998 - Loss: 0.6165130138397217, aux loss1: 1.299660325050354, 
		 aux loss2: 0.7647877931594849, total loss: 1.312326192855835
30th Epoch, 11080th Step, learning rate = 0.008884850210195283 - Loss: 0.40899917483329773, aux loss1: 0.8180502653121948, 
		 aux loss2: 0.48560085892677307, total loss: 0.8486546277999878
30th Epoch, 11085th Step, learning rate = 0.008884343596502914 - Loss: 0.5547785758972168, aux loss1: 1.0008344650268555, 
		 aux loss2: 0.6471667289733887, total loss: 1.1138956546783447
30th Epoch, 11090th Step, learning rate = 0.008883836979600664 - Loss: 0.3851952850818634, aux loss1: 0.888200581073761, 
		 aux loss2: 0.48331037163734436, total loss: 0.8449795842170715
30th Epoch, 11095th Step, learning rate = 0.00888333035948831 - Loss: 0.42395663261413574, aux loss1: 0.8973408937454224, 
		 aux loss2: 0.5075491666793823, total loss: 0.8961786031723022
30th Epoch, 11100th Step, learning rate = 0.008882823736165632 - Loss: 0.48774540424346924, aux loss1: 1.0057886838912964, 
		 aux loss2: 0.589924156665802, total loss: 1.02545166015625
<11100th step>
*************************** Test ***************************
time:3m 16s, 11100th Step, Loss: 0.6136444211006165, Mean IoU = 37.390%
************************************************************
30th Epoch, 11105th Step, learning rate = 0.0088823171096324 - Loss: 0.4479670524597168, aux loss1: 0.9805147051811218, 
		 aux loss2: 0.5485627055168152, total loss: 0.9615465402603149
30th Epoch, 11110th Step, learning rate = 0.008881810479888393 - Loss: 0.36505061388015747, aux loss1: 0.81242436170578, 
		 aux loss2: 0.43813183903694153, total loss: 0.7840306758880615
30th Epoch, 11115th Step, learning rate = 0.00888130384693339 - Loss: 0.42821818590164185, aux loss1: 1.0163081884384155, 
		 aux loss2: 0.5509724020957947, total loss: 0.9534996151924133
30th Epoch, 11120th Step, learning rate = 0.008880797210767163 - Loss: 0.4276209771633148, aux loss1: 0.8675621151924133, 
		 aux loss2: 0.5135095119476318, total loss: 0.8932934403419495
30th Epoch, 11125th Step, learning rate = 0.00888029057138949 - Loss: 0.44803258776664734, aux loss1: 0.862684965133667, 
		 aux loss2: 0.5259022116661072, total loss: 0.9171990156173706
30th Epoch, 11130th Step, learning rate = 0.008879783928800147 - Loss: 0.5288720726966858, aux loss1: 0.9861669540405273, 
		 aux loss2: 0.6018226146697998, total loss: 1.0654512643814087
31th Epoch, 11135th Step, learning rate = 0.00887927728299891 - Loss: 0.5212308168411255, aux loss1: 1.0320806503295898, 
		 aux loss2: 0.6350091099739075, total loss: 1.0848586559295654
31th Epoch, 11140th Step, learning rate = 0.008878770633985554 - Loss: 0.36974796652793884, aux loss1: 0.7819894552230835, 
		 aux loss2: 0.4457663595676422, total loss: 0.782651424407959
31th Epoch, 11145th Step, learning rate = 0.008878263981759857 - Loss: 0.40265676379203796, aux loss1: 0.815692126750946, 
		 aux loss2: 0.4741332530975342, total loss: 0.8370176553726196
31th Epoch, 11150th Step, learning rate = 0.008877757326321591 - Loss: 0.37174075841903687, aux loss1: 0.8184848427772522, 
		 aux loss2: 0.46407994627952576, total loss: 0.8029181957244873
31th Epoch, 11155th Step, learning rate = 0.008877250667670538 - Loss: 0.3165711760520935, aux loss1: 0.754029393196106, 
		 aux loss2: 0.39158424735069275, total loss: 0.6994136571884155
31th Epoch, 11160th Step, learning rate = 0.008876744005806469 - Loss: 0.35270068049430847, aux loss1: 0.8002372980117798, 
		 aux loss2: 0.4289941191673279, total loss: 0.764369547367096
31th Epoch, 11165th Step, learning rate = 0.00887623734072916 - Loss: 0.3786149322986603, aux loss1: 0.7660115957260132, 
		 aux loss2: 0.4513411521911621, total loss: 0.7889548540115356
31th Epoch, 11170th Step, learning rate = 0.008875730672438392 - Loss: 0.45321616530418396, aux loss1: 0.9304154515266418, 
		 aux loss2: 0.5511098504066467, total loss: 0.9527847766876221
31th Epoch, 11175th Step, learning rate = 0.008875224000933933 - Loss: 0.42577117681503296, aux loss1: 0.8149310946464539, 
		 aux loss2: 0.5165326595306396, total loss: 0.8768635988235474
31th Epoch, 11180th Step, learning rate = 0.008874717326215564 - Loss: 0.5758429169654846, aux loss1: 1.1574950218200684, 
		 aux loss2: 0.7139060497283936, total loss: 1.2086538076400757
31th Epoch, 11185th Step, learning rate = 0.008874210648283058 - Loss: 0.37102895975112915, aux loss1: 0.8134841918945312, 
		 aux loss2: 0.4405622184276581, total loss: 0.7912991046905518
31th Epoch, 11190th Step, learning rate = 0.008873703967136196 - Loss: 0.3993605077266693, aux loss1: 0.7712534070014954, 
		 aux loss2: 0.48429033160209656, total loss: 0.8244526386260986
31th Epoch, 11195th Step, learning rate = 0.008873197282774746 - Loss: 0.33057230710983276, aux loss1: 0.6980268955230713, 
		 aux loss2: 0.4052523970603943, total loss: 0.7020813822746277
31th Epoch, 11200th Step, learning rate = 0.008872690595198489 - Loss: 0.46658533811569214, aux loss1: 0.9495576024055481, 
		 aux loss2: 0.5794185996055603, total loss: 0.983220100402832
<11200th step>
*************************** Test ***************************
time:3m 12s, 11200th Step, Loss: 0.6018614768981934, Mean IoU = 38.428%
************************************************************
31th Epoch, 11205th Step, learning rate = 0.008872183904407199 - Loss: 0.43045082688331604, aux loss1: 0.8386008739471436, 
		 aux loss2: 0.5012506246566772, total loss: 0.8825313448905945
31th Epoch, 11210th Step, learning rate = 0.008871677210400653 - Loss: 0.40000849962234497, aux loss1: 0.7426449656486511, 
		 aux loss2: 0.4621848464012146, total loss: 0.8076759576797485
31th Epoch, 11215th Step, learning rate = 0.008871170513178624 - Loss: 0.3907805383205414, aux loss1: 0.8677382469177246, 
		 aux loss2: 0.4961719214916229, total loss: 0.8495708703994751
31th Epoch, 11220th Step, learning rate = 0.00887066381274089 - Loss: 0.5763987898826599, aux loss1: 1.1217169761657715, 
		 aux loss2: 0.6948213577270508, total loss: 1.1908425092697144
31th Epoch, 11225th Step, learning rate = 0.008870157109087224 - Loss: 0.46210676431655884, aux loss1: 0.9285456538200378, 
		 aux loss2: 0.5338194370269775, total loss: 0.9541982412338257
31th Epoch, 11230th Step, learning rate = 0.008869650402217402 - Loss: 0.4730268716812134, aux loss1: 0.9594465494155884, 
		 aux loss2: 0.5582704544067383, total loss: 0.984169065952301
31th Epoch, 11235th Step, learning rate = 0.0088691436921312 - Loss: 0.37253841757774353, aux loss1: 0.8781474828720093, 
		 aux loss2: 0.47159579396247864, total loss: 0.8246209621429443
31th Epoch, 11240th Step, learning rate = 0.008868636978828396 - Loss: 0.5280640721321106, aux loss1: 1.0515047311782837, 
		 aux loss2: 0.6383641362190247, total loss: 1.0988612174987793
31th Epoch, 11245th Step, learning rate = 0.008868130262308762 - Loss: 0.5398496389389038, aux loss1: 1.0791012048721313, 
		 aux loss2: 0.6461635828018188, total loss: 1.1220453977584839
31th Epoch, 11250th Step, learning rate = 0.008867623542572074 - Loss: 0.35589084029197693, aux loss1: 0.8217940330505371, 
		 aux loss2: 0.448772668838501, total loss: 0.7819380760192871
31th Epoch, 11255th Step, learning rate = 0.008867116819618106 - Loss: 0.4087001085281372, aux loss1: 0.9595358967781067, 
		 aux loss2: 0.5028629899024963, total loss: 0.8977060317993164
31th Epoch, 11260th Step, learning rate = 0.008866610093446636 - Loss: 0.43543192744255066, aux loss1: 0.9766577482223511, 
		 aux loss2: 0.5442501902580261, total loss: 0.946129322052002
31th Epoch, 11265th Step, learning rate = 0.00886610336405744 - Loss: 0.4133327007293701, aux loss1: 0.8242921233177185, 
		 aux loss2: 0.48250889778137207, total loss: 0.8536238670349121
31th Epoch, 11270th Step, learning rate = 0.00886559663145029 - Loss: 0.36475077271461487, aux loss1: 0.8040726780891418, 
		 aux loss2: 0.44021326303482056, total loss: 0.7820578813552856
31th Epoch, 11275th Step, learning rate = 0.008865089895624963 - Loss: 0.4252871572971344, aux loss1: 0.7744483351707458, 
		 aux loss2: 0.48495566844940186, total loss: 0.8516039848327637
31th Epoch, 11280th Step, learning rate = 0.008864583156581233 - Loss: 0.4337701201438904, aux loss1: 0.8671892881393433, 
		 aux loss2: 0.5217461585998535, total loss: 0.9026253819465637
31th Epoch, 11285th Step, learning rate = 0.008864076414318876 - Loss: 0.43636244535446167, aux loss1: 0.9787355065345764, 
		 aux loss2: 0.5528337359428406, total loss: 0.9511165618896484
31th Epoch, 11290th Step, learning rate = 0.008863569668837666 - Loss: 0.40951675176620483, aux loss1: 0.9366418719291687, 
		 aux loss2: 0.5128780007362366, total loss: 0.8956605195999146
31th Epoch, 11295th Step, learning rate = 0.008863062920137381 - Loss: 0.5537497401237488, aux loss1: 1.0318869352340698, 
		 aux loss2: 0.6378816366195679, total loss: 1.1184685230255127
31th Epoch, 11300th Step, learning rate = 0.008862556168217793 - Loss: 0.5007442235946655, aux loss1: 0.9688182473182678, 
		 aux loss2: 0.5950284004211426, total loss: 1.0294010639190674
<11300th step>
*************************** Test ***************************
time:3m 18s, 11300th Step, Loss: 0.6603232622146606, Mean IoU = 35.731%
************************************************************
31th Epoch, 11305th Step, learning rate = 0.00886204941307868 - Loss: 0.43083667755126953, aux loss1: 0.9065219163894653, 
		 aux loss2: 0.4999631345272064, total loss: 0.9027785062789917
31th Epoch, 11310th Step, learning rate = 0.008861542654719811 - Loss: 0.5994447469711304, aux loss1: 1.1328487396240234, 
		 aux loss2: 0.7150067687034607, total loss: 1.2253021001815796
31th Epoch, 11315th Step, learning rate = 0.008861035893140969 - Loss: 0.5102947354316711, aux loss1: 0.9417608380317688, 
		 aux loss2: 0.5867762565612793, total loss: 1.0275334119796753
31th Epoch, 11320th Step, learning rate = 0.008860529128341925 - Loss: 0.4620402157306671, aux loss1: 1.0197510719299316, 
		 aux loss2: 0.5952969193458557, total loss: 1.0060843229293823
31th Epoch, 11325th Step, learning rate = 0.008860022360322451 - Loss: 0.40355363488197327, aux loss1: 0.9597604870796204, 
		 aux loss2: 0.5209344625473022, total loss: 0.8998556137084961
31th Epoch, 11330th Step, learning rate = 0.008859515589082326 - Loss: 0.5432525277137756, aux loss1: 1.0159077644348145, 
		 aux loss2: 0.6498464941978455, total loss: 1.1079634428024292
31th Epoch, 11335th Step, learning rate = 0.008859008814621325 - Loss: 0.5690608024597168, aux loss1: 1.0783485174179077, 
		 aux loss2: 0.695904552936554, total loss: 1.1709271669387817
31th Epoch, 11340th Step, learning rate = 0.00885850203693922 - Loss: 0.4509715735912323, aux loss1: 0.9784367084503174, 
		 aux loss2: 0.5567613840103149, total loss: 0.9672071933746338
31th Epoch, 11345th Step, learning rate = 0.008857995256035787 - Loss: 0.5396329760551453, aux loss1: 1.1376858949661255, 
		 aux loss2: 0.6676896810531616, total loss: 1.1480146646499634
31th Epoch, 11350th Step, learning rate = 0.008857488471910802 - Loss: 0.45049798488616943, aux loss1: 0.9808460474014282, 
		 aux loss2: 0.5260751843452454, total loss: 0.955181896686554
31th Epoch, 11355th Step, learning rate = 0.008856981684564039 - Loss: 0.40447574853897095, aux loss1: 0.9257752299308777, 
		 aux loss2: 0.5015774369239807, total loss: 0.8828392624855042
31th Epoch, 11360th Step, learning rate = 0.00885647489399527 - Loss: 0.3723208010196686, aux loss1: 0.8009703755378723, 
		 aux loss2: 0.451721727848053, total loss: 0.7933005690574646
31th Epoch, 11365th Step, learning rate = 0.008855968100204274 - Loss: 0.3702629506587982, aux loss1: 0.8167785406112671, 
		 aux loss2: 0.44395387172698975, total loss: 0.7928780913352966
31th Epoch, 11370th Step, learning rate = 0.008855461303190823 - Loss: 0.3339577615261078, aux loss1: 0.8194488286972046, 
		 aux loss2: 0.42261630296707153, total loss: 0.7488389611244202
31th Epoch, 11375th Step, learning rate = 0.008854954502954692 - Loss: 0.38688838481903076, aux loss1: 0.7420525550842285, 
		 aux loss2: 0.4300714433193207, total loss: 0.7815327644348145
31th Epoch, 11380th Step, learning rate = 0.008854447699495656 - Loss: 0.41131389141082764, aux loss1: 0.9828377366065979, 
		 aux loss2: 0.5232674479484558, total loss: 0.915472149848938
31th Epoch, 11385th Step, learning rate = 0.008853940892813487 - Loss: 0.41341328620910645, aux loss1: 0.9037190675735474, 
		 aux loss2: 0.5348088145256042, total loss: 0.8984525203704834
31th Epoch, 11390th Step, learning rate = 0.008853434082907966 - Loss: 0.3568592965602875, aux loss1: 0.8533913493156433, 
		 aux loss2: 0.45293715596199036, total loss: 0.7940515875816345
31th Epoch, 11395th Step, learning rate = 0.00885292726977886 - Loss: 0.44818609952926636, aux loss1: 0.9988453984260559, 
		 aux loss2: 0.5681249499320984, total loss: 0.9750896692276001
31th Epoch, 11400th Step, learning rate = 0.00885242045342595 - Loss: 0.4035898745059967, aux loss1: 0.8963015675544739, 
		 aux loss2: 0.5084875822067261, total loss: 0.8758753538131714
<11400th step>
*************************** Test ***************************
time:3m 13s, 11400th Step, Loss: 0.5695555806159973, Mean IoU = 38.878%
************************************************************
31th Epoch, 11405th Step, learning rate = 0.008851913633849004 - Loss: 0.38751962780952454, aux loss1: 0.807456374168396, 
		 aux loss2: 0.45963695645332336, total loss: 0.8136113882064819
31th Epoch, 11410th Step, learning rate = 0.008851406811047801 - Loss: 0.3945758640766144, aux loss1: 0.8390864133834839, 
		 aux loss2: 0.4867953360080719, total loss: 0.8410199284553528
31th Epoch, 11415th Step, learning rate = 0.008850899985022113 - Loss: 0.3633749186992645, aux loss1: 0.829901933670044, 
		 aux loss2: 0.45815151929855347, total loss: 0.7956061363220215
31th Epoch, 11420th Step, learning rate = 0.008850393155771717 - Loss: 0.6615341901779175, aux loss1: 1.1830061674118042, 
		 aux loss2: 0.7617325782775879, total loss: 1.3211290836334229
31th Epoch, 11425th Step, learning rate = 0.008849886323296384 - Loss: 0.5140290856361389, aux loss1: 0.9270841479301453, 
		 aux loss2: 0.5837242007255554, total loss: 1.0256439447402954
31th Epoch, 11430th Step, learning rate = 0.00884937948759589 - Loss: 0.5900955200195312, aux loss1: 0.9599208235740662, 
		 aux loss2: 0.6635199189186096, total loss: 1.143479824066162
31th Epoch, 11435th Step, learning rate = 0.008848872648670009 - Loss: 0.47035688161849976, aux loss1: 0.980564296245575, 
		 aux loss2: 0.5900406837463379, total loss: 1.000542402267456
31th Epoch, 11440th Step, learning rate = 0.008848365806518514 - Loss: 0.4878648817539215, aux loss1: 1.0316784381866455, 
		 aux loss2: 0.6029943823814392, total loss: 1.0385661125183105
31th Epoch, 11445th Step, learning rate = 0.008847858961141182 - Loss: 0.6301315426826477, aux loss1: 1.1192033290863037, 
		 aux loss2: 0.7124559283256531, total loss: 1.2508749961853027
31th Epoch, 11450th Step, learning rate = 0.008847352112537786 - Loss: 0.5364934206008911, aux loss1: 1.045932650566101, 
		 aux loss2: 0.6537280678749084, total loss: 1.1117644309997559
31th Epoch, 11455th Step, learning rate = 0.008846845260708098 - Loss: 0.3712581992149353, aux loss1: 0.7970674633979797, 
		 aux loss2: 0.44980522990226746, total loss: 0.7903005480766296
31th Epoch, 11460th Step, learning rate = 0.008846338405651896 - Loss: 0.4034340977668762, aux loss1: 0.8639127016067505, 
		 aux loss2: 0.49663740396499634, total loss: 0.861262857913971
31th Epoch, 11465th Step, learning rate = 0.00884583154736895 - Loss: 0.4221901595592499, aux loss1: 0.8393188118934631, 
		 aux loss2: 0.4946107864379883, total loss: 0.8718301653862
31th Epoch, 11470th Step, learning rate = 0.008845324685859036 - Loss: 0.5839403867721558, aux loss1: 1.0553942918777466, 
		 aux loss2: 0.6884334087371826, total loss: 1.1759320497512817
31th Epoch, 11475th Step, learning rate = 0.008844817821121927 - Loss: 0.4728493392467499, aux loss1: 1.0477722883224487, 
		 aux loss2: 0.5876744389533997, total loss: 1.022250771522522
31th Epoch, 11480th Step, learning rate = 0.0088443109531574 - Loss: 0.39113667607307434, aux loss1: 0.873323917388916, 
		 aux loss2: 0.486121267080307, total loss: 0.8475823998451233
31th Epoch, 11485th Step, learning rate = 0.008843804081965225 - Loss: 0.4262734651565552, aux loss1: 0.9197622537612915, 
		 aux loss2: 0.5130253434181213, total loss: 0.9074122905731201
31th Epoch, 11490th Step, learning rate = 0.008843297207545177 - Loss: 0.3391968905925751, aux loss1: 0.8022898435592651, 
		 aux loss2: 0.43023017048835754, total loss: 0.751975953578949
31th Epoch, 11495th Step, learning rate = 0.008842790329897031 - Loss: 0.5518189668655396, aux loss1: 1.0503379106521606, 
		 aux loss2: 0.656514048576355, total loss: 1.1295260190963745
31th Epoch, 11500th Step, learning rate = 0.008842283449020561 - Loss: 0.44700145721435547, aux loss1: 0.9252969026565552, 
		 aux loss2: 0.5259167551994324, total loss: 0.9349572658538818
<11500th step>
*************************** Test ***************************
time:3m 13s, 11500th Step, Loss: 0.6376749873161316, Mean IoU = 37.744%
************************************************************
32th Epoch, 11505th Step, learning rate = 0.008841776564915539 - Loss: 0.5940839052200317, aux loss1: 1.0926740169525146, 
		 aux loss2: 0.6863393783569336, total loss: 1.1964218616485596
32th Epoch, 11510th Step, learning rate = 0.00884126967758174 - Loss: 0.5630618929862976, aux loss1: 1.0513331890106201, 
		 aux loss2: 0.6839936971664429, total loss: 1.1520593166351318
32th Epoch, 11515th Step, learning rate = 0.008840762787018938 - Loss: 0.37839940190315247, aux loss1: 0.8252018094062805, 
		 aux loss2: 0.4607989192008972, total loss: 0.8102794885635376
32th Epoch, 11520th Step, learning rate = 0.008840255893226907 - Loss: 0.37640535831451416, aux loss1: 0.8043313026428223, 
		 aux loss2: 0.4448624849319458, total loss: 0.7956497669219971
32th Epoch, 11525th Step, learning rate = 0.00883974899620542 - Loss: 0.5319361090660095, aux loss1: 1.0804617404937744, 
		 aux loss2: 0.6305489540100098, total loss: 1.1082942485809326
32th Epoch, 11530th Step, learning rate = 0.00883924209595425 - Loss: 0.44305112957954407, aux loss1: 0.9846222400665283, 
		 aux loss2: 0.5493514537811279, total loss: 0.9581783413887024
32th Epoch, 11535th Step, learning rate = 0.008838735192473171 - Loss: 0.5098096132278442, aux loss1: 0.9548722505569458, 
		 aux loss2: 0.6005173921585083, total loss: 1.0364782810211182
32th Epoch, 11540th Step, learning rate = 0.00883822828576196 - Loss: 0.49844202399253845, aux loss1: 0.8990268707275391, 
		 aux loss2: 0.5805536508560181, total loss: 1.0003715753555298
32th Epoch, 11545th Step, learning rate = 0.008837721375820385 - Loss: 0.7141135334968567, aux loss1: 1.2677514553070068, 
		 aux loss2: 0.8787103891372681, total loss: 1.4459232091903687
32th Epoch, 11550th Step, learning rate = 0.008837214462648221 - Loss: 0.4626932144165039, aux loss1: 0.9312485456466675, 
		 aux loss2: 0.5571858286857605, total loss: 0.9649421572685242
32th Epoch, 11555th Step, learning rate = 0.008836707546245244 - Loss: 0.37360095977783203, aux loss1: 0.8254364728927612, 
		 aux loss2: 0.4575851857662201, total loss: 0.8042659759521484
32th Epoch, 11560th Step, learning rate = 0.008836200626611225 - Loss: 0.38522815704345703, aux loss1: 0.9598634243011475, 
		 aux loss2: 0.5198163986206055, total loss: 0.8811137676239014
32th Epoch, 11565th Step, learning rate = 0.008835693703745939 - Loss: 0.6609276533126831, aux loss1: 1.2541981935501099, 
		 aux loss2: 0.800776481628418, total loss: 1.3574976921081543
32th Epoch, 11570th Step, learning rate = 0.008835186777649159 - Loss: 0.5081408619880676, aux loss1: 0.9039674997329712, 
		 aux loss2: 0.5878570675849915, total loss: 1.0144739151000977
32th Epoch, 11575th Step, learning rate = 0.008834679848320658 - Loss: 0.33950287103652954, aux loss1: 0.7778809666633606, 
		 aux loss2: 0.42592543363571167, total loss: 0.743237316608429
32th Epoch, 11580th Step, learning rate = 0.00883417291576021 - Loss: 0.3915501832962036, aux loss1: 0.7983785271644592, 
		 aux loss2: 0.47255632281303406, total loss: 0.8200863003730774
32th Epoch, 11585th Step, learning rate = 0.008833665979967589 - Loss: 0.41179078817367554, aux loss1: 0.8267098069190979, 
		 aux loss2: 0.5056495666503906, total loss: 0.8620635867118835
32th Epoch, 11590th Step, learning rate = 0.008833159040942565 - Loss: 0.49350276589393616, aux loss1: 0.9119897484779358, 
		 aux loss2: 0.5707216262817383, total loss: 0.995388388633728
32th Epoch, 11595th Step, learning rate = 0.008832652098684914 - Loss: 0.40369105339050293, aux loss1: 0.9324212670326233, 
		 aux loss2: 0.5199892520904541, total loss: 0.891413152217865
32th Epoch, 11600th Step, learning rate = 0.008832145153194412 - Loss: 0.42434975504875183, aux loss1: 0.8584343791007996, 
		 aux loss2: 0.5002831220626831, total loss: 0.8819933533668518
<11600th step>
*************************** Test ***************************
time:3m 14s, 11600th Step, Loss: 0.6140932440757751, Mean IoU = 37.993%
************************************************************
32th Epoch, 11605th Step, learning rate = 0.008831638204470825 - Loss: 0.42882707715034485, aux loss1: 1.0296950340270996, 
		 aux loss2: 0.5630462169647217, total loss: 0.9629541039466858
32th Epoch, 11610th Step, learning rate = 0.00883113125251393 - Loss: 0.52370285987854, aux loss1: 1.1003471612930298, 
		 aux loss2: 0.6424883008003235, total loss: 1.110802412033081
32th Epoch, 11615th Step, learning rate = 0.008830624297323503 - Loss: 0.5093163847923279, aux loss1: 1.0537017583847046, 
		 aux loss2: 0.6058800220489502, total loss: 1.0677789449691772
32th Epoch, 11620th Step, learning rate = 0.008830117338899313 - Loss: 0.3883058428764343, aux loss1: 0.8798868060112, 
		 aux loss2: 0.4673692584037781, total loss: 0.8392195701599121
32th Epoch, 11625th Step, learning rate = 0.008829610377241136 - Loss: 0.5193808674812317, aux loss1: 0.9987019896507263, 
		 aux loss2: 0.6234864592552185, total loss: 1.0683860778808594
32th Epoch, 11630th Step, learning rate = 0.00882910341234874 - Loss: 0.47771158814430237, aux loss1: 1.0310496091842651, 
		 aux loss2: 0.5888333320617676, total loss: 1.0225598812103271
32th Epoch, 11635th Step, learning rate = 0.008828596444221903 - Loss: 0.5262550115585327, aux loss1: 1.0237544775009155, 
		 aux loss2: 0.6236657500267029, total loss: 1.0828475952148438
32th Epoch, 11640th Step, learning rate = 0.0088280894728604 - Loss: 0.46978169679641724, aux loss1: 1.1055833101272583, 
		 aux loss2: 0.5993124842643738, total loss: 1.0411816835403442
32th Epoch, 11645th Step, learning rate = 0.008827582498263997 - Loss: 0.4178912937641144, aux loss1: 0.9401572942733765, 
		 aux loss2: 0.5272479057312012, total loss: 0.910837709903717
32th Epoch, 11650th Step, learning rate = 0.00882707552043247 - Loss: 0.5019624829292297, aux loss1: 0.9789963364601135, 
		 aux loss2: 0.609760046005249, total loss: 1.0395654439926147
32th Epoch, 11655th Step, learning rate = 0.008826568539365596 - Loss: 0.466232031583786, aux loss1: 1.048202633857727, 
		 aux loss2: 0.6013626456260681, total loss: 1.021237850189209
32th Epoch, 11660th Step, learning rate = 0.00882606155506314 - Loss: 0.5570641160011292, aux loss1: 1.005383014678955, 
		 aux loss2: 0.650518536567688, total loss: 1.1188864707946777
32th Epoch, 11665th Step, learning rate = 0.00882555456752488 - Loss: 0.50905442237854, aux loss1: 0.9394383430480957, 
		 aux loss2: 0.6086205840110779, total loss: 1.0343341827392578
32th Epoch, 11670th Step, learning rate = 0.008825047576750589 - Loss: 0.512639582157135, aux loss1: 0.9006000757217407, 
		 aux loss2: 0.579643726348877, total loss: 1.0146771669387817
32th Epoch, 11675th Step, learning rate = 0.008824540582740039 - Loss: 0.4026137590408325, aux loss1: 0.8512333035469055, 
		 aux loss2: 0.4948117434978485, total loss: 0.8559085130691528
32th Epoch, 11680th Step, learning rate = 0.008824033585493002 - Loss: 0.336923748254776, aux loss1: 0.8524174094200134, 
		 aux loss2: 0.4221051335334778, total loss: 0.761491060256958
32th Epoch, 11685th Step, learning rate = 0.00882352658500925 - Loss: 0.5476028919219971, aux loss1: 0.9674944281578064, 
		 aux loss2: 0.6115703582763672, total loss: 1.0824793577194214
32th Epoch, 11690th Step, learning rate = 0.008823019581288557 - Loss: 0.4340106248855591, aux loss1: 0.981744110584259, 
		 aux loss2: 0.5463976263999939, total loss: 0.9470928907394409
32th Epoch, 11695th Step, learning rate = 0.008822512574330697 - Loss: 0.47557228803634644, aux loss1: 0.9030739068984985, 
		 aux loss2: 0.5622548460960388, total loss: 0.9713964462280273
32th Epoch, 11700th Step, learning rate = 0.008822005564135439 - Loss: 0.4417082965373993, aux loss1: 0.8489581346511841, 
		 aux loss2: 0.5110569596290588, total loss: 0.9008185267448425
<11700th step>
*************************** Test ***************************
time:3m 13s, 11700th Step, Loss: 0.6881831288337708, Mean IoU = 34.817%
************************************************************
32th Epoch, 11705th Step, learning rate = 0.008821498550702559 - Loss: 0.48930788040161133, aux loss1: 0.9565104842185974, 
		 aux loss2: 0.5796658396720886, total loss: 1.0081273317337036
32th Epoch, 11710th Step, learning rate = 0.008820991534031828 - Loss: 0.36609211564064026, aux loss1: 0.795212984085083, 
		 aux loss2: 0.4362249970436096, total loss: 0.7791460752487183
32th Epoch, 11715th Step, learning rate = 0.008820484514123018 - Loss: 0.37528398633003235, aux loss1: 0.79802006483078, 
		 aux loss2: 0.4612595736980438, total loss: 0.7991938591003418
32th Epoch, 11720th Step, learning rate = 0.008819977490975904 - Loss: 0.49991023540496826, aux loss1: 1.0330754518508911, 
		 aux loss2: 0.6153072714805603, total loss: 1.0559557676315308
32th Epoch, 11725th Step, learning rate = 0.008819470464590256 - Loss: 0.4422190189361572, aux loss1: 1.0010576248168945, 
		 aux loss2: 0.5661354660987854, total loss: 0.9689905047416687
32th Epoch, 11730th Step, learning rate = 0.008818963434965847 - Loss: 0.43661487102508545, aux loss1: 0.9342908263206482, 
		 aux loss2: 0.5462721586227417, total loss: 0.9354109764099121
32th Epoch, 11735th Step, learning rate = 0.008818456402102449 - Loss: 0.36491093039512634, aux loss1: 0.7519826889038086, 
		 aux loss2: 0.43138888478279114, total loss: 0.7630612850189209
32th Epoch, 11740th Step, learning rate = 0.008817949365999835 - Loss: 0.3637566864490509, aux loss1: 0.8525398373603821, 
		 aux loss2: 0.4452207386493683, total loss: 0.7976069450378418
32th Epoch, 11745th Step, learning rate = 0.008817442326657777 - Loss: 0.3829725384712219, aux loss1: 0.8017651438713074, 
		 aux loss2: 0.44210442900657654, total loss: 0.8003438711166382
32th Epoch, 11750th Step, learning rate = 0.008816935284076049 - Loss: 0.38779598474502563, aux loss1: 0.9197097420692444, 
		 aux loss2: 0.4926530122756958, total loss: 0.8607701063156128
32th Epoch, 11755th Step, learning rate = 0.00881642823825442 - Loss: 0.49317672848701477, aux loss1: 1.1102176904678345, 
		 aux loss2: 0.6086125373840332, total loss: 1.0696871280670166
32th Epoch, 11760th Step, learning rate = 0.008815921189192666 - Loss: 0.48820358514785767, aux loss1: 0.9374054670333862, 
		 aux loss2: 0.5536388754844666, total loss: 0.9908808469772339
32th Epoch, 11765th Step, learning rate = 0.008815414136890558 - Loss: 0.34387844800949097, aux loss1: 0.8357498645782471, 
		 aux loss2: 0.42735737562179565, total loss: 0.7655463814735413
32th Epoch, 11770th Step, learning rate = 0.008814907081347866 - Loss: 0.5049046874046326, aux loss1: 1.0052610635757446, 
		 aux loss2: 0.5917331576347351, total loss: 1.043176293373108
32th Epoch, 11775th Step, learning rate = 0.008814400022564365 - Loss: 0.5140437483787537, aux loss1: 1.1177704334259033, 
		 aux loss2: 0.6324822306632996, total loss: 1.1023677587509155
32th Epoch, 11780th Step, learning rate = 0.008813892960539825 - Loss: 0.3624790608882904, aux loss1: 0.7710060477256775, 
		 aux loss2: 0.43785056471824646, total loss: 0.7689211368560791
32th Epoch, 11785th Step, learning rate = 0.00881338589527402 - Loss: 0.4371241331100464, aux loss1: 0.912950873374939, 
		 aux loss2: 0.5234691500663757, total loss: 0.9203970432281494
32th Epoch, 11790th Step, learning rate = 0.00881287882676672 - Loss: 0.44586601853370667, aux loss1: 0.9488465785980225, 
		 aux loss2: 0.5394096374511719, total loss: 0.9462838768959045
32th Epoch, 11795th Step, learning rate = 0.008812371755017699 - Loss: 0.40796175599098206, aux loss1: 0.8230101466178894, 
		 aux loss2: 0.4920971095561981, total loss: 0.8517036437988281
32th Epoch, 11800th Step, learning rate = 0.008811864680026728 - Loss: 0.4494113028049469, aux loss1: 1.0202529430389404, 
		 aux loss2: 0.5332736968994141, total loss: 0.9687966704368591
<11800th step>
*************************** Test ***************************
time:3m 15s, 11800th Step, Loss: 0.6329243183135986, Mean IoU = 37.733%
************************************************************
32th Epoch, 11805th Step, learning rate = 0.008811357601793579 - Loss: 0.6159029006958008, aux loss1: 1.1589605808258057, 
		 aux loss2: 0.7502900958061218, total loss: 1.263707160949707
32th Epoch, 11810th Step, learning rate = 0.008810850520318023 - Loss: 0.42169755697250366, aux loss1: 0.8479404449462891, 
		 aux loss2: 0.49465301632881165, total loss: 0.8739408850669861
32th Epoch, 11815th Step, learning rate = 0.008810343435599834 - Loss: 0.49521392583847046, aux loss1: 1.0341122150421143, 
		 aux loss2: 0.5946619510650635, total loss: 1.0433123111724854
32th Epoch, 11820th Step, learning rate = 0.008809836347638784 - Loss: 0.5218888521194458, aux loss1: 0.9409940242767334, 
		 aux loss2: 0.6118847131729126, total loss: 1.048940896987915
32th Epoch, 11825th Step, learning rate = 0.008809329256434644 - Loss: 0.43647217750549316, aux loss1: 0.9982667565345764, 
		 aux loss2: 0.5390583276748657, total loss: 0.9515755772590637
32th Epoch, 11830th Step, learning rate = 0.008808822161987183 - Loss: 0.5819872617721558, aux loss1: 1.1493240594863892, 
		 aux loss2: 0.720206081867218, total loss: 1.2148669958114624
32th Epoch, 11835th Step, learning rate = 0.008808315064296178 - Loss: 0.37242391705513, aux loss1: 0.8209456205368042, 
		 aux loss2: 0.4766296446323395, total loss: 0.8093594312667847
32th Epoch, 11840th Step, learning rate = 0.008807807963361397 - Loss: 0.5770614147186279, aux loss1: 1.1187564134597778, 
		 aux loss2: 0.7043651938438416, total loss: 1.194434404373169
32th Epoch, 11845th Step, learning rate = 0.008807300859182613 - Loss: 0.486776739358902, aux loss1: 0.9773219227790833, 
		 aux loss2: 0.5776193737983704, total loss: 1.0110211372375488
32th Epoch, 11850th Step, learning rate = 0.0088067937517596 - Loss: 0.48246896266937256, aux loss1: 0.9468432068824768, 
		 aux loss2: 0.5377534627914429, total loss: 0.9816232919692993
32th Epoch, 11855th Step, learning rate = 0.008806286641092124 - Loss: 0.33350449800491333, aux loss1: 0.7492014169692993, 
		 aux loss2: 0.42738622426986694, total loss: 0.7292194366455078
32th Epoch, 11860th Step, learning rate = 0.00880577952717996 - Loss: 0.3608424961566925, aux loss1: 0.8449395895004272, 
		 aux loss2: 0.45745334029197693, total loss: 0.797305703163147
32th Epoch, 11865th Step, learning rate = 0.008805272410022881 - Loss: 0.42314618825912476, aux loss1: 0.9026849269866943, 
		 aux loss2: 0.5123624801635742, total loss: 0.8988966941833496
32th Epoch, 11870th Step, learning rate = 0.008804765289620658 - Loss: 0.4462301731109619, aux loss1: 0.9225251078605652, 
		 aux loss2: 0.5525837540626526, total loss: 0.9440212249755859
33th Epoch, 11875th Step, learning rate = 0.008804258165973062 - Loss: 0.4329550564289093, aux loss1: 0.8393551707267761, 
		 aux loss2: 0.535627543926239, total loss: 0.8990126848220825
33th Epoch, 11880th Step, learning rate = 0.008803751039079861 - Loss: 0.46177637577056885, aux loss1: 0.9395645260810852, 
		 aux loss2: 0.5568052530288696, total loss: 0.9663679003715515
33th Epoch, 11885th Step, learning rate = 0.008803243908940833 - Loss: 0.40017586946487427, aux loss1: 0.8682441711425781, 
		 aux loss2: 0.4731930196285248, total loss: 0.8499263525009155
33th Epoch, 11890th Step, learning rate = 0.008802736775555745 - Loss: 0.6912373900413513, aux loss1: 1.248879313468933, 
		 aux loss2: 0.8224281072616577, total loss: 1.3948724269866943
33th Epoch, 11895th Step, learning rate = 0.00880222963892437 - Loss: 0.44891881942749023, aux loss1: 0.9304119348526001, 
		 aux loss2: 0.5498867034912109, total loss: 0.9479970932006836
33th Epoch, 11900th Step, learning rate = 0.008801722499046477 - Loss: 0.41359278559684753, aux loss1: 0.8951742053031921, 
		 aux loss2: 0.505243718624115, total loss: 0.8842425346374512
<11900th step>
*************************** Test ***************************
time:3m 16s, 11900th Step, Loss: 0.6594716310501099, Mean IoU = 36.671%
************************************************************
33th Epoch, 11905th Step, learning rate = 0.008801215355921842 - Loss: 0.4251100420951843, aux loss1: 0.9216912388801575, 
		 aux loss2: 0.5688295364379883, total loss: 0.9291492700576782
33th Epoch, 11910th Step, learning rate = 0.008800708209550234 - Loss: 0.36700111627578735, aux loss1: 0.8730085492134094, 
		 aux loss2: 0.4785807430744171, total loss: 0.8203359842300415
33th Epoch, 11915th Step, learning rate = 0.008800201059931421 - Loss: 0.3343840539455414, aux loss1: 0.7827526330947876, 
		 aux loss2: 0.41667941212654114, total loss: 0.7358816266059875
33th Epoch, 11920th Step, learning rate = 0.008799693907065179 - Loss: 0.4767761826515198, aux loss1: 0.9001028537750244, 
		 aux loss2: 0.5522100329399109, total loss: 0.9676910638809204
33th Epoch, 11925th Step, learning rate = 0.008799186750951279 - Loss: 0.4041021168231964, aux loss1: 0.7866554260253906, 
		 aux loss2: 0.4732869863510132, total loss: 0.8294135332107544
33th Epoch, 11930th Step, learning rate = 0.00879867959158949 - Loss: 0.3911284804344177, aux loss1: 0.8988394737243652, 
		 aux loss2: 0.46732062101364136, total loss: 0.8477085828781128
33th Epoch, 11935th Step, learning rate = 0.008798172428979584 - Loss: 0.33551713824272156, aux loss1: 0.7903925776481628, 
		 aux loss2: 0.4433285593986511, total loss: 0.7499663829803467
33th Epoch, 11940th Step, learning rate = 0.008797665263121332 - Loss: 0.4509344696998596, aux loss1: 0.8832769393920898, 
		 aux loss2: 0.5358502864837646, total loss: 0.9302576780319214
33th Epoch, 11945th Step, learning rate = 0.008797158094014506 - Loss: 0.6226728558540344, aux loss1: 1.231401801109314, 
		 aux loss2: 0.7626014351844788, total loss: 1.2971340417861938
33th Epoch, 11950th Step, learning rate = 0.008796650921658874 - Loss: 0.40307313203811646, aux loss1: 0.8024301528930664, 
		 aux loss2: 0.4751536250114441, total loss: 0.8338636159896851
33th Epoch, 11955th Step, learning rate = 0.00879614374605421 - Loss: 0.5826787352561951, aux loss1: 1.182251214981079, 
		 aux loss2: 0.7223047018051147, total loss: 1.22627592086792
33th Epoch, 11960th Step, learning rate = 0.008795636567200288 - Loss: 0.3565742075443268, aux loss1: 0.7994471788406372, 
		 aux loss2: 0.44739586114883423, total loss: 0.7753667235374451
33th Epoch, 11965th Step, learning rate = 0.008795129385096873 - Loss: 0.3899478614330292, aux loss1: 0.8692538142204285, 
		 aux loss2: 0.4671913981437683, total loss: 0.837600588798523
33th Epoch, 11970th Step, learning rate = 0.008794622199743737 - Loss: 0.42157870531082153, aux loss1: 0.8465954065322876, 
		 aux loss2: 0.5168872475624084, total loss: 0.8823122978210449
33th Epoch, 11975th Step, learning rate = 0.008794115011140654 - Loss: 0.3510625958442688, aux loss1: 0.8393086791038513, 
		 aux loss2: 0.44141921401023865, total loss: 0.7794228792190552
33th Epoch, 11980th Step, learning rate = 0.008793607819287393 - Loss: 0.4696196913719177, aux loss1: 0.9928455352783203, 
		 aux loss2: 0.5536542534828186, total loss: 0.9889350533485413
33th Epoch, 11985th Step, learning rate = 0.008793100624183727 - Loss: 0.4805416464805603, aux loss1: 0.951493501663208, 
		 aux loss2: 0.5663464665412903, total loss: 0.9925283193588257
33th Epoch, 11990th Step, learning rate = 0.008792593425829423 - Loss: 0.35744237899780273, aux loss1: 0.7932711243629456, 
		 aux loss2: 0.4405485987663269, total loss: 0.7716431617736816
33th Epoch, 11995th Step, learning rate = 0.008792086224224253 - Loss: 0.34029197692871094, aux loss1: 0.7964256405830383, 
		 aux loss2: 0.4292934536933899, total loss: 0.7509371042251587
33th Epoch, 12000th Step, learning rate = 0.00879157901936799 - Loss: 0.4130977690219879, aux loss1: 0.941183865070343, 
		 aux loss2: 0.5343902111053467, total loss: 0.9092090129852295
<12000th step>
*************************** Test ***************************
time:3m 11s, 12000th Step, Loss: 0.5671347975730896, Mean IoU = 37.931%
************************************************************
33th Epoch, 12005th Step, learning rate = 0.008791071811260405 - Loss: 0.5652980208396912, aux loss1: 1.083114504814148, 
		 aux loss2: 0.691706120967865, total loss: 1.1669148206710815
33th Epoch, 12010th Step, learning rate = 0.008790564599901265 - Loss: 0.5331836342811584, aux loss1: 1.0399736166000366, 
		 aux loss2: 0.637590765953064, total loss: 1.1002120971679688
33th Epoch, 12015th Step, learning rate = 0.008790057385290343 - Loss: 0.4845060110092163, aux loss1: 0.9090856909751892, 
		 aux loss2: 0.581422746181488, total loss: 0.9898008108139038
33th Epoch, 12020th Step, learning rate = 0.00878955016742741 - Loss: 0.37993311882019043, aux loss1: 0.86052405834198, 
		 aux loss2: 0.4597094655036926, total loss: 0.8219741582870483
33th Epoch, 12025th Step, learning rate = 0.008789042946312236 - Loss: 0.4424305856227875, aux loss1: 0.929241418838501, 
		 aux loss2: 0.5435001254081726, total loss: 0.9386031031608582
33th Epoch, 12030th Step, learning rate = 0.008788535721944593 - Loss: 0.5476917028427124, aux loss1: 1.049709439277649, 
		 aux loss2: 0.6900010704994202, total loss: 1.138604998588562
33th Epoch, 12035th Step, learning rate = 0.008788028494324248 - Loss: 0.45612215995788574, aux loss1: 0.9100397825241089, 
		 aux loss2: 0.5726983547210693, total loss: 0.9582134485244751
33th Epoch, 12040th Step, learning rate = 0.008787521263450974 - Loss: 0.5000523924827576, aux loss1: 1.0471391677856445, 
		 aux loss2: 0.6155245304107666, total loss: 1.0604039430618286
33th Epoch, 12045th Step, learning rate = 0.008787014029324542 - Loss: 0.40907615423202515, aux loss1: 0.8134086728096008, 
		 aux loss2: 0.4955328702926636, total loss: 0.8513119220733643
33th Epoch, 12050th Step, learning rate = 0.008786506791944721 - Loss: 0.3905678987503052, aux loss1: 0.8148123621940613, 
		 aux loss2: 0.4703235626220703, total loss: 0.8231410384178162
33th Epoch, 12055th Step, learning rate = 0.008785999551311284 - Loss: 0.45789799094200134, aux loss1: 0.9866188764572144, 
		 aux loss2: 0.5806906223297119, total loss: 0.9861599206924438
33th Epoch, 12060th Step, learning rate = 0.008785492307423998 - Loss: 0.5472906231880188, aux loss1: 1.147463083267212, 
		 aux loss2: 0.6853207945823669, total loss: 1.165657877922058
33th Epoch, 12065th Step, learning rate = 0.008784985060282637 - Loss: 0.39535486698150635, aux loss1: 0.8896924257278442, 
		 aux loss2: 0.48869097232818604, total loss: 0.8577390313148499
33th Epoch, 12070th Step, learning rate = 0.008784477809886969 - Loss: 0.4612251818180084, aux loss1: 0.9734596610069275, 
		 aux loss2: 0.5457074642181396, total loss: 0.9715461134910583
33th Epoch, 12075th Step, learning rate = 0.008783970556236764 - Loss: 0.3859194815158844, aux loss1: 0.8704785704612732, 
		 aux loss2: 0.46746963262557983, total loss: 0.8340509533882141
33th Epoch, 12080th Step, learning rate = 0.008783463299331792 - Loss: 0.45186862349510193, aux loss1: 0.9015281796455383, 
		 aux loss2: 0.5192615389823914, total loss: 0.9300317168235779
33th Epoch, 12085th Step, learning rate = 0.008782956039171825 - Loss: 0.4371117651462555, aux loss1: 0.9065788388252258, 
		 aux loss2: 0.5247483253479004, total loss: 0.9189847707748413
33th Epoch, 12090th Step, learning rate = 0.008782448775756633 - Loss: 0.48085838556289673, aux loss1: 1.0130817890167236, 
		 aux loss2: 0.6083552837371826, total loss: 1.0281250476837158
33th Epoch, 12095th Step, learning rate = 0.008781941509085985 - Loss: 0.6642462015151978, aux loss1: 1.129754900932312, 
		 aux loss2: 0.7795237898826599, total loss: 1.3149821758270264
33th Epoch, 12100th Step, learning rate = 0.008781434239159653 - Loss: 0.5447500348091125, aux loss1: 1.109789490699768, 
		 aux loss2: 0.6447820067405701, total loss: 1.1355996131896973
<12100th step>
*************************** Test ***************************
time:3m 10s, 12100th Step, Loss: 0.6464542150497437, Mean IoU = 36.988%
************************************************************
33th Epoch, 12105th Step, learning rate = 0.008780926965977405 - Loss: 0.48675277829170227, aux loss1: 1.1250933408737183, 
		 aux loss2: 0.6294731497764587, total loss: 1.0760700702667236
33th Epoch, 12110th Step, learning rate = 0.008780419689539014 - Loss: 0.5640213489532471, aux loss1: 1.0214366912841797, 
		 aux loss2: 0.6515865325927734, total loss: 1.131087064743042
33th Epoch, 12115th Step, learning rate = 0.008779912409844244 - Loss: 0.4108799695968628, aux loss1: 0.8986536264419556, 
		 aux loss2: 0.48761969804763794, total loss: 0.8755239248275757
33th Epoch, 12120th Step, learning rate = 0.008779405126892873 - Loss: 0.4415454864501953, aux loss1: 0.9398872256278992, 
		 aux loss2: 0.5449482798576355, total loss: 0.9414910078048706
33th Epoch, 12125th Step, learning rate = 0.008778897840684667 - Loss: 0.40983760356903076, aux loss1: 0.8237572312355042, 
		 aux loss2: 0.4916559159755707, total loss: 0.8536271452903748
33th Epoch, 12130th Step, learning rate = 0.008778390551219395 - Loss: 0.4513581693172455, aux loss1: 0.9620839357376099, 
		 aux loss2: 0.5616629719734192, total loss: 0.9646484851837158
33th Epoch, 12135th Step, learning rate = 0.008777883258496828 - Loss: 0.41121432185173035, aux loss1: 0.9089988470077515, 
		 aux loss2: 0.503903865814209, total loss: 0.8854755163192749
33th Epoch, 12140th Step, learning rate = 0.008777375962516737 - Loss: 0.4780002534389496, aux loss1: 0.9943082928657532, 
		 aux loss2: 0.5916606187820435, total loss: 1.012956976890564
33th Epoch, 12145th Step, learning rate = 0.00877686866327889 - Loss: 0.5525301098823547, aux loss1: 1.0739878416061401, 
		 aux loss2: 0.6560893654823303, total loss: 1.137162208557129
33th Epoch, 12150th Step, learning rate = 0.00877636136078306 - Loss: 0.39932677149772644, aux loss1: 0.8236883282661438, 
		 aux loss2: 0.47621169686317444, total loss: 0.8369179964065552
33th Epoch, 12155th Step, learning rate = 0.008775854055029012 - Loss: 0.4988013803958893, aux loss1: 1.0140430927276611, 
		 aux loss2: 0.6050571799278259, total loss: 1.0450371503829956
33th Epoch, 12160th Step, learning rate = 0.008775346746016521 - Loss: 0.47586095333099365, aux loss1: 1.0743834972381592, 
		 aux loss2: 0.6185016632080078, total loss: 1.0455766916275024
33th Epoch, 12165th Step, learning rate = 0.008774839433745352 - Loss: 0.42451390624046326, aux loss1: 0.9040117263793945, 
		 aux loss2: 0.532895028591156, total loss: 0.9088754653930664
33th Epoch, 12170th Step, learning rate = 0.008774332118215279 - Loss: 0.5223461389541626, aux loss1: 0.9780545830726624, 
		 aux loss2: 0.6208740472793579, total loss: 1.0641121864318848
33th Epoch, 12175th Step, learning rate = 0.008773824799426067 - Loss: 0.4659023582935333, aux loss1: 0.891018807888031, 
		 aux loss2: 0.5546437501907349, total loss: 0.9550654888153076
33th Epoch, 12180th Step, learning rate = 0.008773317477377491 - Loss: 0.48745280504226685, aux loss1: 0.8814118504524231, 
		 aux loss2: 0.5696626901626587, total loss: 0.9797414541244507
33th Epoch, 12185th Step, learning rate = 0.008772810152069316 - Loss: 0.5095090270042419, aux loss1: 1.1042784452438354, 
		 aux loss2: 0.6394374966621399, total loss: 1.0965675115585327
33th Epoch, 12190th Step, learning rate = 0.008772302823501315 - Loss: 0.5064873695373535, aux loss1: 0.9202566146850586, 
		 aux loss2: 0.5880516767501831, total loss: 1.0177850723266602
33th Epoch, 12195th Step, learning rate = 0.008771795491673255 - Loss: 0.3937654197216034, aux loss1: 0.874396800994873, 
		 aux loss2: 0.47916969656944275, total loss: 0.8477523326873779
33th Epoch, 12200th Step, learning rate = 0.008771288156584909 - Loss: 0.45092713832855225, aux loss1: 1.0312306880950928, 
		 aux loss2: 0.5889155864715576, total loss: 0.995862603187561
<12200th step>
*************************** Test ***************************
time:3m 13s, 12200th Step, Loss: 0.5750154256820679, Mean IoU = 38.683%
************************************************************
33th Epoch, 12205th Step, learning rate = 0.008770780818236042 - Loss: 0.656363308429718, aux loss1: 1.1831421852111816, 
		 aux loss2: 0.7652761340141296, total loss: 1.3174165487289429
33th Epoch, 12210th Step, learning rate = 0.008770273476626426 - Loss: 0.38309380412101746, aux loss1: 0.7964909672737122, 
		 aux loss2: 0.4749380946159363, total loss: 0.8120163679122925
33th Epoch, 12215th Step, learning rate = 0.00876976613175583 - Loss: 0.34131699800491333, aux loss1: 0.791031002998352, 
		 aux loss2: 0.42176082730293274, total loss: 0.7473306059837341
33th Epoch, 12220th Step, learning rate = 0.008769258783624025 - Loss: 0.3452438414096832, aux loss1: 0.7384042143821716, 
		 aux loss2: 0.4235030710697174, total loss: 0.7361663579940796
33th Epoch, 12225th Step, learning rate = 0.008768751432230779 - Loss: 0.6348191499710083, aux loss1: 1.2992819547653198, 
		 aux loss2: 0.7672234177589417, total loss: 1.3314931392669678
33th Epoch, 12230th Step, learning rate = 0.008768244077575859 - Loss: 0.3963472545146942, aux loss1: 0.9061360359191895, 
		 aux loss2: 0.4874816834926605, total loss: 0.8631807565689087
33th Epoch, 12235th Step, learning rate = 0.008767736719659039 - Loss: 0.4694081246852875, aux loss1: 1.0323046445846558, 
		 aux loss2: 0.6002134084701538, total loss: 1.0191848278045654
33th Epoch, 12240th Step, learning rate = 0.008767229358480086 - Loss: 0.4782148003578186, aux loss1: 0.9034816026687622, 
		 aux loss2: 0.5555587410926819, total loss: 0.9714828133583069
34th Epoch, 12245th Step, learning rate = 0.008766721994038766 - Loss: 0.45841264724731445, aux loss1: 0.9800044298171997, 
		 aux loss2: 0.5879898071289062, total loss: 0.9876099228858948
34th Epoch, 12250th Step, learning rate = 0.008766214626334857 - Loss: 0.6461107134819031, aux loss1: 1.0788614749908447, 
		 aux loss2: 0.7405836582183838, total loss: 1.2660026550292969
34th Epoch, 12255th Step, learning rate = 0.008765707255368118 - Loss: 0.3438722491264343, aux loss1: 0.8068417310714722, 
		 aux loss2: 0.4280778467655182, total loss: 0.7571558952331543
34th Epoch, 12260th Step, learning rate = 0.008765199881138323 - Loss: 0.3582141399383545, aux loss1: 0.883230984210968, 
		 aux loss2: 0.45566368103027344, total loss: 0.8054489493370056
34th Epoch, 12265th Step, learning rate = 0.008764692503645245 - Loss: 0.6548569798469543, aux loss1: 1.2514773607254028, 
		 aux loss2: 0.7882776856422424, total loss: 1.3456112146377563
34th Epoch, 12270th Step, learning rate = 0.008764185122888646 - Loss: 0.3679254949092865, aux loss1: 0.8339416980743408, 
		 aux loss2: 0.4602717161178589, total loss: 0.8022167086601257
34th Epoch, 12275th Step, learning rate = 0.008763677738868299 - Loss: 0.39122435450553894, aux loss1: 0.9398617744445801, 
		 aux loss2: 0.4848829507827759, total loss: 0.8671361207962036
34th Epoch, 12280th Step, learning rate = 0.008763170351583971 - Loss: 0.48166030645370483, aux loss1: 1.0244767665863037, 
		 aux loss2: 0.5669713020324707, total loss: 1.015791893005371
34th Epoch, 12285th Step, learning rate = 0.008762662961035434 - Loss: 0.4077521562576294, aux loss1: 0.856471061706543, 
		 aux loss2: 0.5059823393821716, total loss: 0.8670864105224609
34th Epoch, 12290th Step, learning rate = 0.008762155567222454 - Loss: 0.4097306430339813, aux loss1: 0.9752401113510132, 
		 aux loss2: 0.5323482751846313, total loss: 0.9152420163154602
34th Epoch, 12295th Step, learning rate = 0.008761648170144801 - Loss: 0.45053693652153015, aux loss1: 0.8513454794883728, 
		 aux loss2: 0.5260342359542847, total loss: 0.9163542985916138
34th Epoch, 12300th Step, learning rate = 0.008761140769802247 - Loss: 0.42920586466789246, aux loss1: 0.8958827257156372, 
		 aux loss2: 0.5484273433685303, total loss: 0.9173416495323181
<12300th step>
*************************** Test ***************************
time:3m 11s, 12300th Step, Loss: 0.6411892771720886, Mean IoU = 38.048%
************************************************************
34th Epoch, 12305th Step, learning rate = 0.008760633366194554 - Loss: 0.4813115894794464, aux loss1: 0.9067803025245667, 
		 aux loss2: 0.5675060749053955, total loss: 0.9803481698036194
34th Epoch, 12310th Step, learning rate = 0.008760125959321498 - Loss: 0.4098750948905945, aux loss1: 0.9622882008552551, 
		 aux loss2: 0.5361480116844177, total loss: 0.9130207300186157
34th Epoch, 12315th Step, learning rate = 0.008759618549182844 - Loss: 0.4596056342124939, aux loss1: 0.9086433053016663, 
		 aux loss2: 0.5674025416374207, total loss: 0.9591596126556396
34th Epoch, 12320th Step, learning rate = 0.00875911113577836 - Loss: 0.6255782842636108, aux loss1: 1.2720190286636353, 
		 aux loss2: 0.8137338757514954, total loss: 1.3326776027679443
34th Epoch, 12325th Step, learning rate = 0.008758603719107819 - Loss: 0.5574313998222351, aux loss1: 1.143410325050354, 
		 aux loss2: 0.6975289583206177, total loss: 1.1794661283493042
34th Epoch, 12330th Step, learning rate = 0.008758096299170983 - Loss: 0.40577155351638794, aux loss1: 0.8526977896690369, 
		 aux loss2: 0.48826220631599426, total loss: 0.8568857908248901
34th Epoch, 12335th Step, learning rate = 0.008757588875967628 - Loss: 0.4323877990245819, aux loss1: 0.9696135520935059, 
		 aux loss2: 0.5298592448234558, total loss: 0.9352155327796936
34th Epoch, 12340th Step, learning rate = 0.008757081449497519 - Loss: 0.3818601965904236, aux loss1: 0.8549841046333313, 
		 aux loss2: 0.47856462001800537, total loss: 0.8297812938690186
34th Epoch, 12345th Step, learning rate = 0.008756574019760424 - Loss: 0.46044400334358215, aux loss1: 0.9718867540359497, 
		 aux loss2: 0.5721865296363831, total loss: 0.9808846712112427
34th Epoch, 12350th Step, learning rate = 0.008756066586756112 - Loss: 0.45792675018310547, aux loss1: 0.9227710962295532, 
		 aux loss2: 0.5608533024787903, total loss: 0.9590994119644165
34th Epoch, 12355th Step, learning rate = 0.008755559150484354 - Loss: 0.47443145513534546, aux loss1: 1.0010439157485962, 
		 aux loss2: 0.5727034211158752, total loss: 1.0038260221481323
34th Epoch, 12360th Step, learning rate = 0.008755051710944917 - Loss: 0.49938011169433594, aux loss1: 0.938037097454071, 
		 aux loss2: 0.5938214659690857, total loss: 1.018319845199585
34th Epoch, 12365th Step, learning rate = 0.008754544268137567 - Loss: 0.42597129940986633, aux loss1: 1.009769082069397, 
		 aux loss2: 0.5569030046463013, total loss: 0.9516632556915283
34th Epoch, 12370th Step, learning rate = 0.008754036822062076 - Loss: 0.43960657715797424, aux loss1: 0.926463782787323, 
		 aux loss2: 0.5379598736763, total loss: 0.9327297210693359
34th Epoch, 12375th Step, learning rate = 0.008753529372718213 - Loss: 0.558841347694397, aux loss1: 1.0421110391616821, 
		 aux loss2: 0.6689050793647766, total loss: 1.1390366554260254
34th Epoch, 12380th Step, learning rate = 0.008753021920105743 - Loss: 0.41123977303504944, aux loss1: 0.8993731141090393, 
		 aux loss2: 0.5222450494766235, total loss: 0.8899497389793396
34th Epoch, 12385th Step, learning rate = 0.008752514464224436 - Loss: 0.49043646454811096, aux loss1: 0.9207950830459595, 
		 aux loss2: 0.5717840790748596, total loss: 0.9953886270523071
34th Epoch, 12390th Step, learning rate = 0.00875200700507406 - Loss: 0.36656779050827026, aux loss1: 0.871638834476471, 
		 aux loss2: 0.4648933708667755, total loss: 0.8140168190002441
34th Epoch, 12395th Step, learning rate = 0.008751499542654386 - Loss: 0.6052017211914062, aux loss1: 1.3416993618011475, 
		 aux loss2: 0.8209635615348816, total loss: 1.336097002029419
34th Epoch, 12400th Step, learning rate = 0.008750992076965178 - Loss: 0.3437577784061432, aux loss1: 0.7666637897491455, 
		 aux loss2: 0.43143796920776367, total loss: 0.7463321089744568
<12400th step>
*************************** Test ***************************
time:3m 17s, 12400th Step, Loss: 0.6049585342407227, Mean IoU = 37.089%
************************************************************
34th Epoch, 12405th Step, learning rate = 0.008750484608006205 - Loss: 0.4688161611557007, aux loss1: 0.9506004452705383, 
		 aux loss2: 0.5748558640480042, total loss: 0.9839386940002441
34th Epoch, 12410th Step, learning rate = 0.00874997713577724 - Loss: 0.40515992045402527, aux loss1: 0.8993483781814575, 
		 aux loss2: 0.49971869587898254, total loss: 0.8748519420623779
34th Epoch, 12415th Step, learning rate = 0.008749469660278045 - Loss: 0.35888004302978516, aux loss1: 0.8492451310157776, 
		 aux loss2: 0.44558727741241455, total loss: 0.7918885350227356
34th Epoch, 12420th Step, learning rate = 0.008748962181508392 - Loss: 0.4049021005630493, aux loss1: 0.8714902400970459, 
		 aux loss2: 0.5224828720092773, total loss: 0.8753423094749451
34th Epoch, 12425th Step, learning rate = 0.008748454699468049 - Loss: 0.4884214699268341, aux loss1: 0.9967876076698303, 
		 aux loss2: 0.5871394872665405, total loss: 1.0223135948181152
34th Epoch, 12430th Step, learning rate = 0.008747947214156782 - Loss: 0.3436293601989746, aux loss1: 0.7954939603805542, 
		 aux loss2: 0.44399160146713257, total loss: 0.759874165058136
34th Epoch, 12435th Step, learning rate = 0.00874743972557436 - Loss: 0.5036723613739014, aux loss1: 0.9535253047943115, 
		 aux loss2: 0.5978497266769409, total loss: 1.028869867324829
34th Epoch, 12440th Step, learning rate = 0.008746932233720552 - Loss: 0.4097227454185486, aux loss1: 0.8805229067802429, 
		 aux loss2: 0.4990854263305664, total loss: 0.8735138177871704
34th Epoch, 12445th Step, learning rate = 0.008746424738595125 - Loss: 0.705231249332428, aux loss1: 1.1794657707214355, 
		 aux loss2: 0.7853605151176453, total loss: 1.3732153177261353
34th Epoch, 12450th Step, learning rate = 0.008745917240197847 - Loss: 0.448060542345047, aux loss1: 0.9510752558708191, 
		 aux loss2: 0.5708284974098206, total loss: 0.961714506149292
34th Epoch, 12455th Step, learning rate = 0.008745409738528487 - Loss: 0.3689417839050293, aux loss1: 0.8434033989906311, 
		 aux loss2: 0.4590918719768524, total loss: 0.805599570274353
34th Epoch, 12460th Step, learning rate = 0.008744902233586812 - Loss: 0.3425550162792206, aux loss1: 0.8253956437110901, 
		 aux loss2: 0.4202101528644562, total loss: 0.7582578063011169
34th Epoch, 12465th Step, learning rate = 0.00874439472537259 - Loss: 0.6489638686180115, aux loss1: 1.1992241144180298, 
		 aux loss2: 0.7554591298103333, total loss: 1.3109147548675537
34th Epoch, 12470th Step, learning rate = 0.008743887213885589 - Loss: 0.5755003094673157, aux loss1: 1.105934977531433, 
		 aux loss2: 0.7000527381896973, total loss: 1.1873018741607666
34th Epoch, 12475th Step, learning rate = 0.008743379699125576 - Loss: 0.6744202375411987, aux loss1: 1.3190902471542358, 
		 aux loss2: 0.8379600048065186, total loss: 1.4053312540054321
34th Epoch, 12480th Step, learning rate = 0.008742872181092319 - Loss: 0.489452600479126, aux loss1: 0.9309548735618591, 
		 aux loss2: 0.5783504843711853, total loss: 1.0000792741775513
34th Epoch, 12485th Step, learning rate = 0.008742364659785588 - Loss: 0.4092257022857666, aux loss1: 0.8791849613189697, 
		 aux loss2: 0.4958480894565582, total loss: 0.8713204264640808
34th Epoch, 12490th Step, learning rate = 0.00874185713520515 - Loss: 0.4622708261013031, aux loss1: 0.8372645378112793, 
		 aux loss2: 0.532438337802887, total loss: 0.9264255166053772
34th Epoch, 12495th Step, learning rate = 0.008741349607350768 - Loss: 0.3517531752586365, aux loss1: 0.7965362668037415, 
		 aux loss2: 0.4279530346393585, total loss: 0.7618952989578247
34th Epoch, 12500th Step, learning rate = 0.008740842076222218 - Loss: 0.35938018560409546, aux loss1: 0.8038291931152344, 
		 aux loss2: 0.44353941082954407, total loss: 0.7779447436332703
<12500th step>
*************************** Test ***************************
time:3m 13s, 12500th Step, Loss: 0.6971527338027954, Mean IoU = 36.836%
************************************************************
34th Epoch, 12505th Step, learning rate = 0.008740334541819259 - Loss: 0.4530957043170929, aux loss1: 0.9769947528839111, 
		 aux loss2: 0.5562968254089355, total loss: 0.9687128663063049
34th Epoch, 12510th Step, learning rate = 0.008739827004141663 - Loss: 0.49738889932632446, aux loss1: 0.9748631715774536, 
		 aux loss2: 0.59466952085495, total loss: 1.0277156829833984
34th Epoch, 12515th Step, learning rate = 0.008739319463189201 - Loss: 0.379923552274704, aux loss1: 0.8701573610305786, 
		 aux loss2: 0.46068328619003296, total loss: 0.8252440690994263
34th Epoch, 12520th Step, learning rate = 0.008738811918961633 - Loss: 0.4267953038215637, aux loss1: 0.8453130125999451, 
		 aux loss2: 0.517683744430542, total loss: 0.8874627351760864
34th Epoch, 12525th Step, learning rate = 0.008738304371458732 - Loss: 0.39817678928375244, aux loss1: 0.9198401570320129, 
		 aux loss2: 0.49706563353538513, total loss: 0.8729551434516907
34th Epoch, 12530th Step, learning rate = 0.008737796820680262 - Loss: 0.3871268033981323, aux loss1: 0.8186560869216919, 
		 aux loss2: 0.4733622968196869, total loss: 0.8220685720443726
34th Epoch, 12535th Step, learning rate = 0.008737289266625994 - Loss: 0.44147366285324097, aux loss1: 0.8215900659561157, 
		 aux loss2: 0.5039511322975159, total loss: 0.889531135559082
34th Epoch, 12540th Step, learning rate = 0.008736781709295694 - Loss: 0.5448415875434875, aux loss1: 1.078329086303711, 
		 aux loss2: 0.6306982040405273, total loss: 1.120619535446167
34th Epoch, 12545th Step, learning rate = 0.00873627414868913 - Loss: 0.39015501737594604, aux loss1: 0.8925098776817322, 
		 aux loss2: 0.49615392088890076, total loss: 0.8563695549964905
34th Epoch, 12550th Step, learning rate = 0.008735766584806065 - Loss: 0.49514925479888916, aux loss1: 0.8595321774482727, 
		 aux loss2: 0.5699719786643982, total loss: 0.9809977412223816
34th Epoch, 12555th Step, learning rate = 0.008735259017646272 - Loss: 0.3392011225223541, aux loss1: 0.8005487322807312, 
		 aux loss2: 0.4422883689403534, total loss: 0.7562810778617859
34th Epoch, 12560th Step, learning rate = 0.008734751447209517 - Loss: 0.38748905062675476, aux loss1: 0.868893563747406, 
		 aux loss2: 0.4845830798149109, total loss: 0.8419903516769409
34th Epoch, 12565th Step, learning rate = 0.008734243873495563 - Loss: 0.41924288868904114, aux loss1: 0.9006185531616211, 
		 aux loss2: 0.5244943499565125, total loss: 0.899226188659668
34th Epoch, 12570th Step, learning rate = 0.008733736296504183 - Loss: 0.3062089681625366, aux loss1: 0.7266948819160461, 
		 aux loss2: 0.38332629203796387, total loss: 0.6775479316711426
34th Epoch, 12575th Step, learning rate = 0.008733228716235142 - Loss: 0.48006775975227356, aux loss1: 0.9325981736183167, 
		 aux loss2: 0.5835429430007935, total loss: 0.9932644367218018
34th Epoch, 12580th Step, learning rate = 0.008732721132688205 - Loss: 0.3380545973777771, aux loss1: 0.7666231989860535, 
		 aux loss2: 0.4033190906047821, total loss: 0.7293692231178284
34th Epoch, 12585th Step, learning rate = 0.00873221354586314 - Loss: 0.36768391728401184, aux loss1: 0.8923150897026062, 
		 aux loss2: 0.47379395365715027, total loss: 0.8248960971832275
34th Epoch, 12590th Step, learning rate = 0.008731705955759717 - Loss: 0.34888365864753723, aux loss1: 0.8483816981315613, 
		 aux loss2: 0.43972504138946533, total loss: 0.7792882323265076
34th Epoch, 12595th Step, learning rate = 0.008731198362377702 - Loss: 0.4229027330875397, aux loss1: 0.9666262269020081, 
		 aux loss2: 0.5348410606384277, total loss: 0.926827073097229
34th Epoch, 12600th Step, learning rate = 0.00873069076571686 - Loss: 0.47911006212234497, aux loss1: 1.0001230239868164, 
		 aux loss2: 0.5905377268791199, total loss: 1.015362024307251
<12600th step>
*************************** Test ***************************
time:3m 11s, 12600th Step, Loss: 0.5917152166366577, Mean IoU = 38.800%
************************************************************
34th Epoch, 12605th Step, learning rate = 0.008730183165776959 - Loss: 0.29664450883865356, aux loss1: 0.7580540776252747, 
		 aux loss2: 0.37879177927970886, total loss: 0.6755774617195129
34th Epoch, 12610th Step, learning rate = 0.008729675562557767 - Loss: 0.4914281666278839, aux loss1: 0.9265487194061279, 
		 aux loss2: 0.559480607509613, total loss: 0.9931850433349609
35th Epoch, 12615th Step, learning rate = 0.008729167956059049 - Loss: 0.5117801427841187, aux loss1: 0.971046507358551, 
		 aux loss2: 0.60960453748703, total loss: 1.0469359159469604
35th Epoch, 12620th Step, learning rate = 0.008728660346280573 - Loss: 0.5340636968612671, aux loss1: 1.0083327293395996, 
		 aux loss2: 0.621431827545166, total loss: 1.0851362943649292
35th Epoch, 12625th Step, learning rate = 0.008728152733222107 - Loss: 0.3292768895626068, aux loss1: 0.8286381959915161, 
		 aux loss2: 0.4112474322319031, total loss: 0.7423673272132874
35th Epoch, 12630th Step, learning rate = 0.008727645116883417 - Loss: 0.39993157982826233, aux loss1: 0.8128997683525085, 
		 aux loss2: 0.48977482318878174, total loss: 0.8397114276885986
35th Epoch, 12635th Step, learning rate = 0.008727137497264269 - Loss: 0.3757553696632385, aux loss1: 0.8465806841850281, 
		 aux loss2: 0.46743476390838623, total loss: 0.8167035579681396
35th Epoch, 12640th Step, learning rate = 0.00872662987436443 - Loss: 0.4537772536277771, aux loss1: 0.9408305883407593, 
		 aux loss2: 0.5487884283065796, total loss: 0.9555417895317078
35th Epoch, 12645th Step, learning rate = 0.008726122248183667 - Loss: 0.38254690170288086, aux loss1: 0.7393655180931091, 
		 aux loss2: 0.4667162597179413, total loss: 0.7910431027412415
35th Epoch, 12650th Step, learning rate = 0.008725614618721749 - Loss: 0.5360178351402283, aux loss1: 0.9622664451599121, 
		 aux loss2: 0.6527612209320068, total loss: 1.0858023166656494
35th Epoch, 12655th Step, learning rate = 0.008725106985978438 - Loss: 0.42066916823387146, aux loss1: 0.794162392616272, 
		 aux loss2: 0.5166752338409424, total loss: 0.8655880093574524
35th Epoch, 12660th Step, learning rate = 0.008724599349953505 - Loss: 0.35956528782844543, aux loss1: 0.8121114373207092, 
		 aux loss2: 0.47712013125419617, total loss: 0.7940467596054077
35th Epoch, 12665th Step, learning rate = 0.008724091710646715 - Loss: 0.39095476269721985, aux loss1: 0.7968248724937439, 
		 aux loss2: 0.48226800560951233, total loss: 0.8229094743728638
35th Epoch, 12670th Step, learning rate = 0.008723584068057833 - Loss: 0.6414101719856262, aux loss1: 1.1866343021392822, 
		 aux loss2: 0.7712211012840271, total loss: 1.3058888912200928
35th Epoch, 12675th Step, learning rate = 0.008723076422186627 - Loss: 0.45749029517173767, aux loss1: 0.9331777095794678, 
		 aux loss2: 0.5581855177879333, total loss: 0.9607178568840027
35th Epoch, 12680th Step, learning rate = 0.008722568773032863 - Loss: 0.3065079152584076, aux loss1: 0.7026837468147278, 
		 aux loss2: 0.3899005949497223, total loss: 0.6732733249664307
35th Epoch, 12685th Step, learning rate = 0.00872206112059631 - Loss: 0.4917321503162384, aux loss1: 0.8610555529594421, 
		 aux loss2: 0.5808801054954529, total loss: 0.9824008941650391
35th Epoch, 12690th Step, learning rate = 0.00872155346487673 - Loss: 0.4462118148803711, aux loss1: 0.9620234370231628, 
		 aux loss2: 0.5511680841445923, total loss: 0.9552860260009766
35th Epoch, 12695th Step, learning rate = 0.008721045805873896 - Loss: 0.35466498136520386, aux loss1: 0.8712297677993774, 
		 aux loss2: 0.46402862668037415, total loss: 0.8016453981399536
35th Epoch, 12700th Step, learning rate = 0.008720538143587567 - Loss: 0.47843772172927856, aux loss1: 0.9882311224937439, 
		 aux loss2: 0.5856727957725525, total loss: 1.009176254272461
<12700th step>
*************************** Test ***************************
time:3m 16s, 12700th Step, Loss: 0.5741013288497925, Mean IoU = 39.084%
************************************************************
35th Epoch, 12705th Step, learning rate = 0.008720030478017513 - Loss: 0.5762228965759277, aux loss1: 1.1218477487564087, 
		 aux loss2: 0.7132059335708618, total loss: 1.1980595588684082
35th Epoch, 12710th Step, learning rate = 0.0087195228091635 - Loss: 0.34413254261016846, aux loss1: 0.7824226021766663, 
		 aux loss2: 0.4110623002052307, total loss: 0.7432842254638672
35th Epoch, 12715th Step, learning rate = 0.008719015137025294 - Loss: 0.35301655530929565, aux loss1: 0.8137478828430176, 
		 aux loss2: 0.46240559220314026, total loss: 0.7821031808853149
35th Epoch, 12720th Step, learning rate = 0.008718507461602664 - Loss: 0.4431246221065521, aux loss1: 0.8338515758514404, 
		 aux loss2: 0.5122198462486267, total loss: 0.8981680274009705
35th Epoch, 12725th Step, learning rate = 0.008717999782895372 - Loss: 0.42962804436683655, aux loss1: 0.9791122078895569, 
		 aux loss2: 0.5376458168029785, total loss: 0.9384200572967529
35th Epoch, 12730th Step, learning rate = 0.008717492100903185 - Loss: 0.4147929549217224, aux loss1: 0.9498464465141296, 
		 aux loss2: 0.5199816823005676, total loss: 0.9077395796775818
35th Epoch, 12735th Step, learning rate = 0.008716984415625875 - Loss: 0.4591955542564392, aux loss1: 0.9810705184936523, 
		 aux loss2: 0.5595226287841797, total loss: 0.9773257970809937
35th Epoch, 12740th Step, learning rate = 0.0087164767270632 - Loss: 0.4094425439834595, aux loss1: 0.8585631251335144, 
		 aux loss2: 0.48893019556999207, total loss: 0.862583577632904
35th Epoch, 12745th Step, learning rate = 0.008715969035214929 - Loss: 0.6002454161643982, aux loss1: 1.1331695318222046, 
		 aux loss2: 0.7144692540168762, total loss: 1.22598397731781
35th Epoch, 12750th Step, learning rate = 0.00871546134008083 - Loss: 0.3577647805213928, aux loss1: 0.8060207366943359, 
		 aux loss2: 0.46531763672828674, total loss: 0.7856980562210083
35th Epoch, 12755th Step, learning rate = 0.008714953641660667 - Loss: 0.5347959399223328, aux loss1: 0.9817842245101929, 
		 aux loss2: 0.628013014793396, total loss: 1.0805363655090332
35th Epoch, 12760th Step, learning rate = 0.008714445939954206 - Loss: 0.380822092294693, aux loss1: 0.8665409088134766, 
		 aux loss2: 0.4814814329147339, total loss: 0.833376944065094
35th Epoch, 12765th Step, learning rate = 0.008713938234961215 - Loss: 0.38928014039993286, aux loss1: 0.8124657273292542, 
		 aux loss2: 0.4790734052658081, total loss: 0.8246492147445679
35th Epoch, 12770th Step, learning rate = 0.008713430526681458 - Loss: 0.4036329984664917, aux loss1: 0.8648346662521362, 
		 aux loss2: 0.5122795701026917, total loss: 0.8679952621459961
35th Epoch, 12775th Step, learning rate = 0.008712922815114703 - Loss: 0.5273427367210388, aux loss1: 1.1330046653747559, 
		 aux loss2: 0.6431853771209717, total loss: 1.1245182752609253
35th Epoch, 12780th Step, learning rate = 0.008712415100260714 - Loss: 0.47849342226982117, aux loss1: 0.9597600698471069, 
		 aux loss2: 0.5694551467895508, total loss: 0.994203507900238
35th Epoch, 12785th Step, learning rate = 0.008711907382119256 - Loss: 0.39643606543540955, aux loss1: 0.9095445871353149, 
		 aux loss2: 0.4990580677986145, total loss: 0.8689227104187012
35th Epoch, 12790th Step, learning rate = 0.008711399660690098 - Loss: 0.4462582767009735, aux loss1: 0.9733408093452454, 
		 aux loss2: 0.5674433708190918, total loss: 0.9652378559112549
35th Epoch, 12795th Step, learning rate = 0.008710891935973004 - Loss: 0.3906765580177307, aux loss1: 0.8474778532981873, 
		 aux loss2: 0.47940292954444885, total loss: 0.8366811275482178
35th Epoch, 12800th Step, learning rate = 0.008710384207967738 - Loss: 0.346051424741745, aux loss1: 0.7464097142219543, 
		 aux loss2: 0.4220544695854187, total loss: 0.7387961745262146
<12800th step>
*************************** Test ***************************
time:3m 16s, 12800th Step, Loss: 0.602168083190918, Mean IoU = 38.919%
************************************************************
35th Epoch, 12805th Step, learning rate = 0.008709876476674068 - Loss: 0.3815411627292633, aux loss1: 0.7928857803344727, 
		 aux loss2: 0.4766906201839447, total loss: 0.8100832104682922
35th Epoch, 12810th Step, learning rate = 0.008709368742091762 - Loss: 0.47072941064834595, aux loss1: 1.1936959028244019, 
		 aux loss2: 0.5880244970321655, total loss: 1.0640480518341064
35th Epoch, 12815th Step, learning rate = 0.008708861004220579 - Loss: 0.46252480149269104, aux loss1: 0.9077128171920776, 
		 aux loss2: 0.5375301837921143, total loss: 0.9498507380485535
35th Epoch, 12820th Step, learning rate = 0.00870835326306029 - Loss: 0.4748498499393463, aux loss1: 0.8768952488899231, 
		 aux loss2: 0.5689931511878967, total loss: 0.9655157327651978
35th Epoch, 12825th Step, learning rate = 0.00870784551861066 - Loss: 0.3160567879676819, aux loss1: 0.7330512404441833, 
		 aux loss2: 0.3915292024612427, total loss: 0.6925838589668274
35th Epoch, 12830th Step, learning rate = 0.008707337770871452 - Loss: 0.479709267616272, aux loss1: 0.9966021180152893, 
		 aux loss2: 0.5839327573776245, total loss: 1.0122630596160889
35th Epoch, 12835th Step, learning rate = 0.008706830019842435 - Loss: 0.40286561846733093, aux loss1: 0.7743790149688721, 
		 aux loss2: 0.46322011947631836, total loss: 0.8204674124717712
35th Epoch, 12840th Step, learning rate = 0.008706322265523371 - Loss: 0.5232235193252563, aux loss1: 0.9818480610847473, 
		 aux loss2: 0.6327477097511292, total loss: 1.0708770751953125
35th Epoch, 12845th Step, learning rate = 0.008705814507914031 - Loss: 0.49237844347953796, aux loss1: 0.9747908115386963, 
		 aux loss2: 0.5760377645492554, total loss: 1.0152307748794556
35th Epoch, 12850th Step, learning rate = 0.008705306747014174 - Loss: 0.412639856338501, aux loss1: 0.8802923560142517, 
		 aux loss2: 0.5026932954788208, total loss: 0.8778048753738403
35th Epoch, 12855th Step, learning rate = 0.008704798982823567 - Loss: 0.6073081493377686, aux loss1: 1.0495833158493042, 
		 aux loss2: 0.7177621722221375, total loss: 1.2092880010604858
35th Epoch, 12860th Step, learning rate = 0.00870429121534198 - Loss: 0.47619393467903137, aux loss1: 0.9569013714790344, 
		 aux loss2: 0.5638788938522339, total loss: 0.9888159036636353
35th Epoch, 12865th Step, learning rate = 0.008703783444569173 - Loss: 0.436920702457428, aux loss1: 0.9074529409408569, 
		 aux loss2: 0.5126969814300537, total loss: 0.9142354130744934
35th Epoch, 12870th Step, learning rate = 0.008703275670504912 - Loss: 0.43213504552841187, aux loss1: 0.9030297994613647, 
		 aux loss2: 0.5306278467178345, total loss: 0.9152951240539551
35th Epoch, 12875th Step, learning rate = 0.008702767893148965 - Loss: 0.47182226181030273, aux loss1: 0.9034860134124756, 
		 aux loss2: 0.5654025673866272, total loss: 0.9690290689468384
35th Epoch, 12880th Step, learning rate = 0.008702260112501095 - Loss: 0.34839871525764465, aux loss1: 0.846799373626709, 
		 aux loss2: 0.44973692297935486, total loss: 0.7823333740234375
35th Epoch, 12885th Step, learning rate = 0.008701752328561069 - Loss: 0.461225688457489, aux loss1: 0.8958025574684143, 
		 aux loss2: 0.5521654486656189, total loss: 0.9508326649665833
35th Epoch, 12890th Step, learning rate = 0.00870124454132865 - Loss: 0.4296514689922333, aux loss1: 0.9449913501739502, 
		 aux loss2: 0.5209700465202332, total loss: 0.921536922454834
35th Epoch, 12895th Step, learning rate = 0.008700736750803606 - Loss: 0.3252164125442505, aux loss1: 0.7507957220077515, 
		 aux loss2: 0.40017691254615784, total loss: 0.7105259299278259
35th Epoch, 12900th Step, learning rate = 0.0087002289569857 - Loss: 0.5217037200927734, aux loss1: 1.0910683870315552, 
		 aux loss2: 0.6570496559143066, total loss: 1.1118440628051758
<12900th step>
*************************** Test ***************************
time:3m 13s, 12900th Step, Loss: 0.5580440163612366, Mean IoU = 39.232%
************************************************************
35th Epoch, 12905th Step, learning rate = 0.008699721159874696 - Loss: 0.46076223254203796, aux loss1: 0.9515882134437561, 
		 aux loss2: 0.5530292391777039, total loss: 0.9674503803253174
35th Epoch, 12910th Step, learning rate = 0.008699213359470362 - Loss: 0.35987454652786255, aux loss1: 0.9503743648529053, 
		 aux loss2: 0.45873376727104187, total loss: 0.8284803628921509
35th Epoch, 12915th Step, learning rate = 0.008698705555772462 - Loss: 0.3743970990180969, aux loss1: 0.8249764442443848, 
		 aux loss2: 0.47518858313560486, total loss: 0.8119655251502991
35th Epoch, 12920th Step, learning rate = 0.00869819774878076 - Loss: 0.6125211119651794, aux loss1: 1.202542781829834, 
		 aux loss2: 0.7202836275100708, total loss: 1.261397361755371
35th Epoch, 12925th Step, learning rate = 0.008697689938495021 - Loss: 0.38064199686050415, aux loss1: 0.7292706966400146, 
		 aux loss2: 0.44158467650413513, total loss: 0.7760571241378784
35th Epoch, 12930th Step, learning rate = 0.008697182124915014 - Loss: 0.41852250695228577, aux loss1: 0.9044797420501709, 
		 aux loss2: 0.5149565935134888, total loss: 0.8958490490913391
35th Epoch, 12935th Step, learning rate = 0.008696674308040496 - Loss: 0.563602089881897, aux loss1: 1.0847055912017822, 
		 aux loss2: 0.6954114437103271, total loss: 1.1671783924102783
35th Epoch, 12940th Step, learning rate = 0.008696166487871238 - Loss: 0.4228953421115875, aux loss1: 0.9175609350204468, 
		 aux loss2: 0.5306369662284851, total loss: 0.9104183912277222
35th Epoch, 12945th Step, learning rate = 0.008695658664407004 - Loss: 0.36427950859069824, aux loss1: 0.8457210063934326, 
		 aux loss2: 0.46232134103775024, total loss: 0.802924394607544
35th Epoch, 12950th Step, learning rate = 0.008695150837647558 - Loss: 0.3652040362358093, aux loss1: 0.7608419060707092, 
		 aux loss2: 0.439924418926239, total loss: 0.7694264054298401
35th Epoch, 12955th Step, learning rate = 0.008694643007592665 - Loss: 0.40204450488090515, aux loss1: 0.9398289918899536, 
		 aux loss2: 0.5028389096260071, total loss: 0.8851287961006165
35th Epoch, 12960th Step, learning rate = 0.008694135174242088 - Loss: 0.42742690443992615, aux loss1: 0.913386344909668, 
		 aux loss2: 0.5278979539871216, total loss: 0.9126020073890686
35th Epoch, 12965th Step, learning rate = 0.008693627337595596 - Loss: 0.4116367995738983, aux loss1: 0.8494970798492432, 
		 aux loss2: 0.5057156682014465, total loss: 0.8687721490859985
35th Epoch, 12970th Step, learning rate = 0.00869311949765295 - Loss: 0.41896265745162964, aux loss1: 0.9551525712013245, 
		 aux loss2: 0.5400146842002869, total loss: 0.9215143322944641
35th Epoch, 12975th Step, learning rate = 0.008692611654413915 - Loss: 0.2874491810798645, aux loss1: 0.6524098515510559, 
		 aux loss2: 0.339800089597702, total loss: 0.6190921664237976
35th Epoch, 12980th Step, learning rate = 0.008692103807878255 - Loss: 0.4223622977733612, aux loss1: 0.8847047090530396, 
		 aux loss2: 0.532893717288971, total loss: 0.900931179523468
35th Epoch, 12985th Step, learning rate = 0.008691595958045738 - Loss: 0.6149454712867737, aux loss1: 1.0057677030563354, 
		 aux loss2: 0.6903660297393799, total loss: 1.1928222179412842
36th Epoch, 12990th Step, learning rate = 0.008691088104916126 - Loss: 0.32372796535491943, aux loss1: 0.7856098413467407, 
		 aux loss2: 0.4089645743370056, total loss: 0.7229967713356018
36th Epoch, 12995th Step, learning rate = 0.008690580248489182 - Loss: 0.32947665452957153, aux loss1: 0.766328752040863, 
		 aux loss2: 0.41029685735702515, total loss: 0.7234940528869629
36th Epoch, 13000th Step, learning rate = 0.008690072388764675 - Loss: 0.3559877872467041, aux loss1: 0.7968520522117615, 
		 aux loss2: 0.4466031789779663, total loss: 0.7736846804618835
<13000th step>
*************************** Test ***************************
time:3m 18s, 13000th Step, Loss: 0.6445757746696472, Mean IoU = 38.253%
************************************************************
36th Epoch, 13005th Step, learning rate = 0.008689564525742367 - Loss: 0.5359961986541748, aux loss1: 0.9590620398521423, 
		 aux loss2: 0.6297038197517395, total loss: 1.0755963325500488
36th Epoch, 13010th Step, learning rate = 0.00868905665942202 - Loss: 0.46062493324279785, aux loss1: 1.0347973108291626, 
		 aux loss2: 0.6331580281257629, total loss: 1.0243273973464966
36th Epoch, 13015th Step, learning rate = 0.0086885487898034 - Loss: 0.5612715482711792, aux loss1: 1.0380468368530273, 
		 aux loss2: 0.6608377695083618, total loss: 1.1370207071304321
36th Epoch, 13020th Step, learning rate = 0.008688040916886275 - Loss: 0.38883766531944275, aux loss1: 0.9063040614128113, 
		 aux loss2: 0.4741380512714386, total loss: 0.8503841757774353
36th Epoch, 13025th Step, learning rate = 0.008687533040670405 - Loss: 0.603487491607666, aux loss1: 1.1437981128692627, 
		 aux loss2: 0.7386571168899536, total loss: 1.2420897483825684
36th Epoch, 13030th Step, learning rate = 0.008687025161155557 - Loss: 0.40387532114982605, aux loss1: 0.89790940284729, 
		 aux loss2: 0.5065113306045532, total loss: 0.8758527040481567
36th Epoch, 13035th Step, learning rate = 0.008686517278341492 - Loss: 0.4325035512447357, aux loss1: 0.9926666617393494, 
		 aux loss2: 0.5576693415641785, total loss: 0.9533712863922119
36th Epoch, 13040th Step, learning rate = 0.008686009392227979 - Loss: 0.36039838194847107, aux loss1: 0.7932484149932861, 
		 aux loss2: 0.4455206096172333, total loss: 0.7765811681747437
36th Epoch, 13045th Step, learning rate = 0.008685501502814776 - Loss: 0.4116708040237427, aux loss1: 0.900194525718689, 
		 aux loss2: 0.513555645942688, total loss: 0.8871514797210693
36th Epoch, 13050th Step, learning rate = 0.008684993610101652 - Loss: 0.38326331973075867, aux loss1: 0.8638660311698914, 
		 aux loss2: 0.4723098576068878, total loss: 0.8313471078872681
36th Epoch, 13055th Step, learning rate = 0.00868448571408837 - Loss: 0.41901805996894836, aux loss1: 1.0045520067214966, 
		 aux loss2: 0.5544760227203369, total loss: 0.9421740770339966
36th Epoch, 13060th Step, learning rate = 0.008683977814774693 - Loss: 0.5094217658042908, aux loss1: 1.0035300254821777, 
		 aux loss2: 0.6185776591300964, total loss: 1.0579118728637695
36th Epoch, 13065th Step, learning rate = 0.008683469912160386 - Loss: 0.3449857532978058, aux loss1: 0.7869901061058044, 
		 aux loss2: 0.43525180220603943, total loss: 0.7551835775375366
36th Epoch, 13070th Step, learning rate = 0.008682962006245213 - Loss: 0.46446847915649414, aux loss1: 0.9604344964027405, 
		 aux loss2: 0.5642080307006836, total loss: 0.97828209400177
36th Epoch, 13075th Step, learning rate = 0.008682454097028938 - Loss: 0.8611136674880981, aux loss1: 1.411161184310913, 
		 aux loss2: 1.019814133644104, total loss: 1.692387580871582
36th Epoch, 13080th Step, learning rate = 0.008681946184511326 - Loss: 0.4270451068878174, aux loss1: 0.8427314162254333, 
		 aux loss2: 0.5126132965087891, total loss: 0.8849098682403564
36th Epoch, 13085th Step, learning rate = 0.00868143826869214 - Loss: 0.2893112301826477, aux loss1: 0.6434473991394043, 
		 aux loss2: 0.35495319962501526, total loss: 0.624326765537262
36th Epoch, 13090th Step, learning rate = 0.008680930349571141 - Loss: 0.5008997917175293, aux loss1: 0.9926077723503113, 
		 aux loss2: 0.6288653612136841, total loss: 1.050228238105774
36th Epoch, 13095th Step, learning rate = 0.008680422427148098 - Loss: 0.37238743901252747, aux loss1: 0.8624900579452515, 
		 aux loss2: 0.46959710121154785, total loss: 0.8189733624458313
36th Epoch, 13100th Step, learning rate = 0.008679914501422772 - Loss: 0.43874719738960266, aux loss1: 0.97572922706604, 
		 aux loss2: 0.5527318120002747, total loss: 0.9525586366653442
<13100th step>
*************************** Test ***************************
time:3m 12s, 13100th Step, Loss: 0.613960325717926, Mean IoU = 38.565%
************************************************************
36th Epoch, 13105th Step, learning rate = 0.008679406572394927 - Loss: 0.4487260580062866, aux loss1: 0.9733244776725769, 
		 aux loss2: 0.5525745749473572, total loss: 0.9617531895637512
36th Epoch, 13110th Step, learning rate = 0.008678898640064327 - Loss: 0.35689178109169006, aux loss1: 0.8031915426254272, 
		 aux loss2: 0.4376625716686249, total loss: 0.7729142904281616
36th Epoch, 13115th Step, learning rate = 0.008678390704430737 - Loss: 0.5069650411605835, aux loss1: 1.0278747081756592, 
		 aux loss2: 0.6165364384651184, total loss: 1.0619421005249023
36th Epoch, 13120th Step, learning rate = 0.008677882765493918 - Loss: 0.5807522535324097, aux loss1: 1.209728479385376, 
		 aux loss2: 0.722834050655365, total loss: 1.2328044176101685
36th Epoch, 13125th Step, learning rate = 0.008677374823253634 - Loss: 0.3646247982978821, aux loss1: 0.8513280749320984, 
		 aux loss2: 0.45117828249931335, total loss: 0.8004945516586304
36th Epoch, 13130th Step, learning rate = 0.008676866877709652 - Loss: 0.36106765270233154, aux loss1: 0.7861076593399048, 
		 aux loss2: 0.4097032845020294, total loss: 0.7607812881469727
36th Epoch, 13135th Step, learning rate = 0.008676358928861734 - Loss: 0.5022635459899902, aux loss1: 0.9897992014884949, 
		 aux loss2: 0.6214967370033264, total loss: 1.0478019714355469
36th Epoch, 13140th Step, learning rate = 0.00867585097670964 - Loss: 0.44164448976516724, aux loss1: 0.9300734400749207, 
		 aux loss2: 0.5486684441566467, total loss: 0.9401339292526245
36th Epoch, 13145th Step, learning rate = 0.00867534302125314 - Loss: 0.4262833893299103, aux loss1: 0.8864946961402893, 
		 aux loss2: 0.5300732254981995, total loss: 0.90426105260849
36th Epoch, 13150th Step, learning rate = 0.008674835062491995 - Loss: 0.4538556933403015, aux loss1: 1.0587494373321533, 
		 aux loss2: 0.5762906074523926, total loss: 1.0019967555999756
36th Epoch, 13155th Step, learning rate = 0.008674327100425965 - Loss: 0.6442281603813171, aux loss1: 1.095244288444519, 
		 aux loss2: 0.7588213682174683, total loss: 1.2763299942016602
36th Epoch, 13160th Step, learning rate = 0.008673819135054817 - Loss: 0.5106213092803955, aux loss1: 1.0737484693527222, 
		 aux loss2: 0.6256327629089355, total loss: 1.0829989910125732
36th Epoch, 13165th Step, learning rate = 0.008673311166378313 - Loss: 0.6267451047897339, aux loss1: 1.1326466798782349, 
		 aux loss2: 0.7595362067222595, total loss: 1.2703536748886108
36th Epoch, 13170th Step, learning rate = 0.008672803194396218 - Loss: 0.5222644805908203, aux loss1: 1.1378728151321411, 
		 aux loss2: 0.6549137234687805, total loss: 1.1255918741226196
36th Epoch, 13175th Step, learning rate = 0.008672295219108294 - Loss: 0.467607706785202, aux loss1: 1.000842571258545, 
		 aux loss2: 0.5703949928283691, total loss: 0.9960185289382935
36th Epoch, 13180th Step, learning rate = 0.008671787240514303 - Loss: 0.326667457818985, aux loss1: 0.7512557506561279, 
		 aux loss2: 0.4146522283554077, total loss: 0.7179051041603088
36th Epoch, 13185th Step, learning rate = 0.008671279258614013 - Loss: 0.5234065055847168, aux loss1: 0.9493364691734314, 
		 aux loss2: 0.6185184121131897, total loss: 1.0556148290634155
36th Epoch, 13190th Step, learning rate = 0.008670771273407181 - Loss: 0.4871895909309387, aux loss1: 1.102579951286316, 
		 aux loss2: 0.6269921660423279, total loss: 1.0687605142593384
36th Epoch, 13195th Step, learning rate = 0.008670263284893577 - Loss: 0.3926657438278198, aux loss1: 0.8051775693893433, 
		 aux loss2: 0.4681077301502228, total loss: 0.8214621543884277
36th Epoch, 13200th Step, learning rate = 0.008669755293072956 - Loss: 0.41391685605049133, aux loss1: 0.854095995426178, 
		 aux loss2: 0.5032913684844971, total loss: 0.8714621663093567
<13200th step>
*************************** Test ***************************
time:3m 16s, 13200th Step, Loss: 0.5596514940261841, Mean IoU = 39.633%
************************************************************
36th Epoch, 13205th Step, learning rate = 0.00866924729794509 - Loss: 0.434858113527298, aux loss1: 0.9185017943382263, 
		 aux loss2: 0.5510265827178955, total loss: 0.9308193325996399
36th Epoch, 13210th Step, learning rate = 0.008668739299509736 - Loss: 0.3771606981754303, aux loss1: 0.8294529914855957, 
		 aux loss2: 0.46315255761146545, total loss: 0.8112576007843018
36th Epoch, 13215th Step, learning rate = 0.008668231297766659 - Loss: 0.5996500849723816, aux loss1: 1.1666259765625, 
		 aux loss2: 0.7229476571083069, total loss: 1.2388169765472412
36th Epoch, 13220th Step, learning rate = 0.008667723292715623 - Loss: 0.48235106468200684, aux loss1: 1.0287911891937256, 
		 aux loss2: 0.6019970178604126, total loss: 1.0317872762680054
36th Epoch, 13225th Step, learning rate = 0.00866721528435639 - Loss: 0.4263216257095337, aux loss1: 0.9347787499427795, 
		 aux loss2: 0.5568781495094299, total loss: 0.9295065402984619
36th Epoch, 13230th Step, learning rate = 0.008666707272688723 - Loss: 0.46512284874916077, aux loss1: 1.003259539604187, 
		 aux loss2: 0.6012197732925415, total loss: 1.0065886974334717
36th Epoch, 13235th Step, learning rate = 0.008666199257712386 - Loss: 0.4433561861515045, aux loss1: 0.9417635202407837, 
		 aux loss2: 0.548322856426239, total loss: 0.9452143907546997
36th Epoch, 13240th Step, learning rate = 0.00866569123942714 - Loss: 0.4564998149871826, aux loss1: 0.9920486807823181, 
		 aux loss2: 0.5692465901374817, total loss: 0.9818130135536194
36th Epoch, 13245th Step, learning rate = 0.008665183217832748 - Loss: 0.40406230092048645, aux loss1: 1.0181947946548462, 
		 aux loss2: 0.5240522027015686, total loss: 0.9191416501998901
36th Epoch, 13250th Step, learning rate = 0.008664675192928975 - Loss: 0.5078626275062561, aux loss1: 0.9220492839813232, 
		 aux loss2: 0.6124535202980042, total loss: 1.02945876121521
36th Epoch, 13255th Step, learning rate = 0.008664167164715584 - Loss: 0.3555147051811218, aux loss1: 0.835610032081604, 
		 aux loss2: 0.4461476802825928, total loss: 0.7846567630767822
36th Epoch, 13260th Step, learning rate = 0.008663659133192335 - Loss: 0.45164093375205994, aux loss1: 0.8789052367210388, 
		 aux loss2: 0.5472421646118164, total loss: 0.9342093467712402
36th Epoch, 13265th Step, learning rate = 0.008663151098358992 - Loss: 0.3673354387283325, aux loss1: 0.8305512070655823, 
		 aux loss2: 0.4523251950740814, total loss: 0.7974308729171753
36th Epoch, 13270th Step, learning rate = 0.008662643060215318 - Loss: 0.46597880125045776, aux loss1: 0.8602458834648132, 
		 aux loss2: 0.5405026078224182, total loss: 0.9402536153793335
36th Epoch, 13275th Step, learning rate = 0.008662135018761077 - Loss: 0.45709162950515747, aux loss1: 0.8816396594047546, 
		 aux loss2: 0.5524888634681702, total loss: 0.9425790905952454
36th Epoch, 13280th Step, learning rate = 0.00866162697399603 - Loss: 0.3819715678691864, aux loss1: 0.8942785859107971, 
		 aux loss2: 0.469522625207901, total loss: 0.8380641937255859
36th Epoch, 13285th Step, learning rate = 0.00866111892591994 - Loss: 0.427147775888443, aux loss1: 0.927090585231781, 
		 aux loss2: 0.5007476210594177, total loss: 0.9055739641189575
36th Epoch, 13290th Step, learning rate = 0.00866061087453257 - Loss: 0.305308997631073, aux loss1: 0.8402748703956604, 
		 aux loss2: 0.38235434889793396, total loss: 0.7103332281112671
36th Epoch, 13295th Step, learning rate = 0.008660102819833681 - Loss: 0.33798283338546753, aux loss1: 0.8712717294692993, 
		 aux loss2: 0.4451736509799957, total loss: 0.7774338722229004
36th Epoch, 13300th Step, learning rate = 0.008659594761823038 - Loss: 0.4622538983821869, aux loss1: 1.0244927406311035, 
		 aux loss2: 0.5907235145568848, total loss: 1.0058910846710205
<13300th step>
*************************** Test ***************************
time:3m 15s, 13300th Step, Loss: 0.6247580647468567, Mean IoU = 37.788%
************************************************************
36th Epoch, 13305th Step, learning rate = 0.008659086700500402 - Loss: 0.42464637756347656, aux loss1: 0.9419615864753723, 
		 aux loss2: 0.5170684456825256, total loss: 0.9140622615814209
36th Epoch, 13310th Step, learning rate = 0.008658578635865537 - Loss: 0.5583330392837524, aux loss1: 1.026016116142273, 
		 aux loss2: 0.6782867312431335, total loss: 1.1374526023864746
36th Epoch, 13315th Step, learning rate = 0.008658070567918204 - Loss: 0.31510403752326965, aux loss1: 0.7333343029022217, 
		 aux loss2: 0.40573248267173767, total loss: 0.6973973512649536
36th Epoch, 13320th Step, learning rate = 0.008657562496658165 - Loss: 0.45694229006767273, aux loss1: 0.9499179124832153, 
		 aux loss2: 0.5752662420272827, total loss: 0.9720242023468018
36th Epoch, 13325th Step, learning rate = 0.008657054422085184 - Loss: 0.5129168033599854, aux loss1: 0.9806197285652161, 
		 aux loss2: 0.6028273105621338, total loss: 1.0482336282730103
36th Epoch, 13330th Step, learning rate = 0.008656546344199021 - Loss: 0.3938913345336914, aux loss1: 0.8590030670166016, 
		 aux loss2: 0.4820476472377777, total loss: 0.844411313533783
36th Epoch, 13335th Step, learning rate = 0.008656038262999441 - Loss: 0.42110076546669006, aux loss1: 0.941564679145813, 
		 aux loss2: 0.5359558463096619, total loss: 0.9179525375366211
36th Epoch, 13340th Step, learning rate = 0.008655530178486205 - Loss: 0.5978716015815735, aux loss1: 1.0812023878097534, 
		 aux loss2: 0.7122142314910889, total loss: 1.207118034362793
36th Epoch, 13345th Step, learning rate = 0.008655022090659076 - Loss: 0.4183693528175354, aux loss1: 0.8938726186752319, 
		 aux loss2: 0.5273599624633789, total loss: 0.8974751830101013
36th Epoch, 13350th Step, learning rate = 0.008654513999517815 - Loss: 0.4559321403503418, aux loss1: 0.9499356746673584, 
		 aux loss2: 0.5791523456573486, total loss: 0.9725738167762756
36th Epoch, 13355th Step, learning rate = 0.008654005905062183 - Loss: 0.501721978187561, aux loss1: 1.038256287574768, 
		 aux loss2: 0.6041694283485413, total loss: 1.0548666715621948
37th Epoch, 13360th Step, learning rate = 0.008653497807291946 - Loss: 0.35886749625205994, aux loss1: 0.7883585095405579, 
		 aux loss2: 0.4651298522949219, total loss: 0.7814270257949829
37th Epoch, 13365th Step, learning rate = 0.008652989706206864 - Loss: 0.49533405900001526, aux loss1: 1.060773491859436, 
		 aux loss2: 0.6371331214904785, total loss: 1.068419337272644
37th Epoch, 13370th Step, learning rate = 0.008652481601806698 - Loss: 0.39952170848846436, aux loss1: 0.8679872751235962, 
		 aux loss2: 0.48829588294029236, total loss: 0.8552362322807312
37th Epoch, 13375th Step, learning rate = 0.008651973494091213 - Loss: 0.34964489936828613, aux loss1: 0.8490772247314453, 
		 aux loss2: 0.45447248220443726, total loss: 0.7861570715904236
37th Epoch, 13380th Step, learning rate = 0.008651465383060167 - Loss: 0.41160255670547485, aux loss1: 0.9231345653533936, 
		 aux loss2: 0.5056178569793701, total loss: 0.8907901048660278
37th Epoch, 13385th Step, learning rate = 0.008650957268713328 - Loss: 0.5349432229995728, aux loss1: 1.043839931488037, 
		 aux loss2: 0.6500082015991211, total loss: 1.1080985069274902
37th Epoch, 13390th Step, learning rate = 0.008650449151050451 - Loss: 0.3674252927303314, aux loss1: 0.8153021931648254, 
		 aux loss2: 0.4572616517543793, total loss: 0.7949206233024597
37th Epoch, 13395th Step, learning rate = 0.008649941030071301 - Loss: 0.705193817615509, aux loss1: 1.3110988140106201, 
		 aux loss2: 0.8947592973709106, total loss: 1.4564272165298462
37th Epoch, 13400th Step, learning rate = 0.008649432905775642 - Loss: 0.4263394773006439, aux loss1: 0.9580129981040955, 
		 aux loss2: 0.5157400369644165, total loss: 0.9200394153594971
<13400th step>
*************************** Test ***************************
time:3m 14s, 13400th Step, Loss: 0.6853731870651245, Mean IoU = 36.487%
************************************************************
37th Epoch, 13405th Step, learning rate = 0.008648924778163232 - Loss: 0.39047273993492126, aux loss1: 0.9365875124931335, 
		 aux loss2: 0.5064324140548706, total loss: 0.8740220069885254
37th Epoch, 13410th Step, learning rate = 0.008648416647233837 - Loss: 0.359531044960022, aux loss1: 0.7396271228790283, 
		 aux loss2: 0.42109185457229614, total loss: 0.7498559355735779
37th Epoch, 13415th Step, learning rate = 0.008647908512987216 - Loss: 0.531000554561615, aux loss1: 1.087066888809204, 
		 aux loss2: 0.6257942318916321, total loss: 1.107438325881958
37th Epoch, 13420th Step, learning rate = 0.008647400375423131 - Loss: 0.3305070400238037, aux loss1: 0.8516523838043213, 
		 aux loss2: 0.4306633174419403, total loss: 0.7582681179046631
37th Epoch, 13425th Step, learning rate = 0.008646892234541344 - Loss: 0.43697845935821533, aux loss1: 0.9373427629470825, 
		 aux loss2: 0.5150378942489624, total loss: 0.9241964817047119
37th Epoch, 13430th Step, learning rate = 0.008646384090341616 - Loss: 0.5290151238441467, aux loss1: 1.1045434474945068, 
		 aux loss2: 0.6759805679321289, total loss: 1.1307704448699951
37th Epoch, 13435th Step, learning rate = 0.00864587594282371 - Loss: 0.2716165781021118, aux loss1: 0.7731248736381531, 
		 aux loss2: 0.3910784423351288, total loss: 0.6599854230880737
37th Epoch, 13440th Step, learning rate = 0.008645367791987388 - Loss: 0.3929809033870697, aux loss1: 0.9126870036125183, 
		 aux loss2: 0.49748384952545166, total loss: 0.8657805919647217
37th Epoch, 13445th Step, learning rate = 0.00864485963783241 - Loss: 0.4405480921268463, aux loss1: 0.8496444225311279, 
		 aux loss2: 0.518253743648529, total loss: 0.9027429223060608
37th Epoch, 13450th Step, learning rate = 0.008644351480358537 - Loss: 0.5070683360099792, aux loss1: 1.0556806325912476, 
		 aux loss2: 0.6112785935401917, total loss: 1.068284034729004
37th Epoch, 13455th Step, learning rate = 0.008643843319565536 - Loss: 0.4488757252693176, aux loss1: 0.8644479513168335, 
		 aux loss2: 0.5487978458404541, total loss: 0.9277292490005493
37th Epoch, 13460th Step, learning rate = 0.008643335155453161 - Loss: 0.47481662034988403, aux loss1: 1.0495854616165161, 
		 aux loss2: 0.6148688197135925, total loss: 1.035639762878418
37th Epoch, 13465th Step, learning rate = 0.008642826988021176 - Loss: 0.38031792640686035, aux loss1: 0.8085982799530029, 
		 aux loss2: 0.45818644762039185, total loss: 0.8061719536781311
37th Epoch, 13470th Step, learning rate = 0.008642318817269345 - Loss: 0.36742648482322693, aux loss1: 0.8409459590911865, 
		 aux loss2: 0.4635046124458313, total loss: 0.8051121830940247
37th Epoch, 13475th Step, learning rate = 0.008641810643197427 - Loss: 0.3115817606449127, aux loss1: 0.8022217750549316, 
		 aux loss2: 0.4046779274940491, total loss: 0.7141194939613342
37th Epoch, 13480th Step, learning rate = 0.008641302465805186 - Loss: 0.45887619256973267, aux loss1: 0.8929335474967957, 
		 aux loss2: 0.5629808306694031, total loss: 0.9519486427307129
37th Epoch, 13485th Step, learning rate = 0.008640794285092379 - Loss: 0.35767900943756104, aux loss1: 0.8641393184661865, 
		 aux loss2: 0.4440651834011078, total loss: 0.794546902179718
37th Epoch, 13490th Step, learning rate = 0.008640286101058771 - Loss: 0.3036178946495056, aux loss1: 0.7310174107551575, 
		 aux loss2: 0.38296979665756226, total loss: 0.6761110424995422
37th Epoch, 13495th Step, learning rate = 0.00863977791370412 - Loss: 0.37165531516075134, aux loss1: 0.8140644431114197, 
		 aux loss2: 0.44767361879348755, total loss: 0.7949441075325012
37th Epoch, 13500th Step, learning rate = 0.008639269723028191 - Loss: 0.5312706232070923, aux loss1: 0.9986522793769836, 
		 aux loss2: 0.642711877822876, total loss: 1.0879510641098022
<13500th step>
*************************** Test ***************************
time:3m 17s, 13500th Step, Loss: 0.5931347608566284, Mean IoU = 39.424%
************************************************************
37th Epoch, 13505th Step, learning rate = 0.008638761529030743 - Loss: 0.46658483147621155, aux loss1: 0.8886852264404297, 
		 aux loss2: 0.5434027314186096, total loss: 0.9505515098571777
37th Epoch, 13510th Step, learning rate = 0.008638253331711539 - Loss: 0.3146092891693115, aux loss1: 0.7971630096435547, 
		 aux loss2: 0.408364862203598, total loss: 0.7171041369438171
37th Epoch, 13515th Step, learning rate = 0.008637745131070337 - Loss: 0.39464709162712097, aux loss1: 0.8906902074813843, 
		 aux loss2: 0.49916258454322815, total loss: 0.8615192174911499
37th Epoch, 13520th Step, learning rate = 0.008637236927106901 - Loss: 0.38030514121055603, aux loss1: 0.8072410821914673, 
		 aux loss2: 0.4654337167739868, total loss: 0.8086509704589844
37th Epoch, 13525th Step, learning rate = 0.00863672871982099 - Loss: 0.4125952422618866, aux loss1: 0.8408005833625793, 
		 aux loss2: 0.49894586205482483, total loss: 0.8644137978553772
37th Epoch, 13530th Step, learning rate = 0.008636220509212367 - Loss: 0.25693634152412415, aux loss1: 0.6729760766029358, 
		 aux loss2: 0.3213287591934204, total loss: 0.587360680103302
37th Epoch, 13535th Step, learning rate = 0.008635712295280791 - Loss: 0.3760194480419159, aux loss1: 0.9163689613342285, 
		 aux loss2: 0.4935210645198822, total loss: 0.8483386039733887
37th Epoch, 13540th Step, learning rate = 0.008635204078026025 - Loss: 0.47047239542007446, aux loss1: 1.0313562154769897, 
		 aux loss2: 0.6111464500427246, total loss: 1.024337887763977
37th Epoch, 13545th Step, learning rate = 0.00863469585744783 - Loss: 0.4374312460422516, aux loss1: 0.9389408826828003, 
		 aux loss2: 0.552158772945404, total loss: 0.9399770498275757
37th Epoch, 13550th Step, learning rate = 0.008634187633545964 - Loss: 0.3664076328277588, aux loss1: 0.8596468567848206, 
		 aux loss2: 0.47206583619117737, total loss: 0.8131279945373535
37th Epoch, 13555th Step, learning rate = 0.00863367940632019 - Loss: 0.4196518361568451, aux loss1: 0.881688117980957, 
		 aux loss2: 0.5127868056297302, total loss: 0.8892730474472046
37th Epoch, 13560th Step, learning rate = 0.008633171175770268 - Loss: 0.4687342941761017, aux loss1: 0.8950585126876831, 
		 aux loss2: 0.5552241802215576, total loss: 0.9593415260314941
37th Epoch, 13565th Step, learning rate = 0.008632662941895962 - Loss: 0.34220781922340393, aux loss1: 0.7916759848594666, 
		 aux loss2: 0.4050361216068268, total loss: 0.7417250871658325
37th Epoch, 13570th Step, learning rate = 0.008632154704697028 - Loss: 0.3560822606086731, aux loss1: 0.8597373962402344, 
		 aux loss2: 0.4582616686820984, total loss: 0.7973081469535828
37th Epoch, 13575th Step, learning rate = 0.008631646464173229 - Loss: 0.3708355724811554, aux loss1: 0.8039445281028748, 
		 aux loss2: 0.46589383482933044, total loss: 0.7983765006065369
37th Epoch, 13580th Step, learning rate = 0.008631138220324326 - Loss: 0.3986290395259857, aux loss1: 0.8958368897438049, 
		 aux loss2: 0.4987736642360687, total loss: 0.8668895959854126
37th Epoch, 13585th Step, learning rate = 0.008630629973150082 - Loss: 0.4961695671081543, aux loss1: 1.0232868194580078, 
		 aux loss2: 0.5874494910240173, total loss: 1.0381354093551636
37th Epoch, 13590th Step, learning rate = 0.008630121722650251 - Loss: 0.3762912154197693, aux loss1: 0.7192898988723755, 
		 aux loss2: 0.43637514114379883, total loss: 0.7666282653808594
37th Epoch, 13595th Step, learning rate = 0.0086296134688246 - Loss: 0.4706052839756012, aux loss1: 0.889333963394165, 
		 aux loss2: 0.5546591877937317, total loss: 0.9592691659927368
37th Epoch, 13600th Step, learning rate = 0.008629105211672889 - Loss: 0.4368726909160614, aux loss1: 0.9094346761703491, 
		 aux loss2: 0.5253866314888, total loss: 0.9198577404022217
<13600th step>
*************************** Test ***************************
time:3m 16s, 13600th Step, Loss: 0.6299530863761902, Mean IoU = 36.345%
************************************************************
37th Epoch, 13605th Step, learning rate = 0.008628596951194873 - Loss: 0.3743791878223419, aux loss1: 0.7918983101844788, 
		 aux loss2: 0.4514122009277344, total loss: 0.7925135493278503
37th Epoch, 13610th Step, learning rate = 0.008628088687390319 - Loss: 0.3884274661540985, aux loss1: 0.8781119585037231, 
		 aux loss2: 0.5009104013442993, total loss: 0.8522252440452576
37th Epoch, 13615th Step, learning rate = 0.008627580420258983 - Loss: 0.46089866757392883, aux loss1: 0.963478684425354, 
		 aux loss2: 0.5761867165565491, total loss: 0.980417013168335
37th Epoch, 13620th Step, learning rate = 0.00862707214980063 - Loss: 0.475652277469635, aux loss1: 1.0460724830627441, 
		 aux loss2: 0.6023968458175659, total loss: 1.0304327011108398
37th Epoch, 13625th Step, learning rate = 0.008626563876015016 - Loss: 0.47335535287857056, aux loss1: 0.918128490447998, 
		 aux loss2: 0.5687255859375, total loss: 0.9762841463088989
37th Epoch, 13630th Step, learning rate = 0.008626055598901903 - Loss: 0.5220485329627991, aux loss1: 0.9687328934669495, 
		 aux loss2: 0.5940842032432556, total loss: 1.0503021478652954
37th Epoch, 13635th Step, learning rate = 0.008625547318461052 - Loss: 0.400419682264328, aux loss1: 0.8808991312980652, 
		 aux loss2: 0.5059544444084167, total loss: 0.8670712113380432
37th Epoch, 13640th Step, learning rate = 0.008625039034692222 - Loss: 0.3925079107284546, aux loss1: 0.9484257102012634, 
		 aux loss2: 0.5023946762084961, total loss: 0.8779935240745544
37th Epoch, 13645th Step, learning rate = 0.008624530747595175 - Loss: 0.4030548334121704, aux loss1: 0.8516782522201538, 
		 aux loss2: 0.5005502104759216, total loss: 0.8587784171104431
37th Epoch, 13650th Step, learning rate = 0.00862402245716967 - Loss: 0.3675282895565033, aux loss1: 0.8221475481987, 
		 aux loss2: 0.4600590765476227, total loss: 0.7981961965560913
37th Epoch, 13655th Step, learning rate = 0.008623514163415467 - Loss: 0.3771127462387085, aux loss1: 0.8961668610572815, 
		 aux loss2: 0.45678722858428955, total loss: 0.8286777138710022
37th Epoch, 13660th Step, learning rate = 0.008623005866332328 - Loss: 0.37420615553855896, aux loss1: 0.8058593273162842, 
		 aux loss2: 0.4554499387741089, total loss: 0.7981439232826233
37th Epoch, 13665th Step, learning rate = 0.008622497565920014 - Loss: 0.34085991978645325, aux loss1: 0.8718041181564331, 
		 aux loss2: 0.4276224672794342, total loss: 0.7734501361846924
37th Epoch, 13670th Step, learning rate = 0.008621989262178279 - Loss: 0.39220812916755676, aux loss1: 0.8950687646865845, 
		 aux loss2: 0.4774770140647888, total loss: 0.8517196178436279
37th Epoch, 13675th Step, learning rate = 0.00862148095510689 - Loss: 0.3494754135608673, aux loss1: 0.7884299755096436, 
		 aux loss2: 0.42819491028785706, total loss: 0.7572823762893677
37th Epoch, 13680th Step, learning rate = 0.008620972644705602 - Loss: 0.3358341157436371, aux loss1: 0.8067775964736938, 
		 aux loss2: 0.41533511877059937, total loss: 0.7440014481544495
37th Epoch, 13685th Step, learning rate = 0.008620464330974178 - Loss: 0.35186588764190674, aux loss1: 0.7629339694976807, 
		 aux loss2: 0.42879658937454224, total loss: 0.752264678478241
37th Epoch, 13690th Step, learning rate = 0.00861995601391238 - Loss: 0.45918118953704834, aux loss1: 0.8767483234405518, 
		 aux loss2: 0.5392211079597473, total loss: 0.9378941655158997
37th Epoch, 13695th Step, learning rate = 0.008619447693519963 - Loss: 0.36682185530662537, aux loss1: 0.8263105750083923, 
		 aux loss2: 0.45422497391700745, total loss: 0.796405017375946
37th Epoch, 13700th Step, learning rate = 0.008618939369796687 - Loss: 0.36149221658706665, aux loss1: 0.8149881958961487, 
		 aux loss2: 0.44551199674606323, total loss: 0.7841935157775879
<13700th step>
*************************** Test ***************************
time:3m 13s, 13700th Step, Loss: 0.5538221597671509, Mean IoU = 39.371%
************************************************************
37th Epoch, 13705th Step, learning rate = 0.008618431042742318 - Loss: 0.48755401372909546, aux loss1: 1.0184236764907837, 
		 aux loss2: 0.5982410907745361, total loss: 1.0323776006698608
37th Epoch, 13710th Step, learning rate = 0.00861792271235661 - Loss: 0.36889374256134033, aux loss1: 0.8245151042938232, 
		 aux loss2: 0.46492162346839905, total loss: 0.8022168874740601
37th Epoch, 13715th Step, learning rate = 0.008617414378639325 - Loss: 0.4976884126663208, aux loss1: 0.9188936948776245, 
		 aux loss2: 0.5742446780204773, total loss: 1.0030543804168701
37th Epoch, 13720th Step, learning rate = 0.008616906041590223 - Loss: 0.55901038646698, aux loss1: 0.9570891261100769, 
		 aux loss2: 0.6548289656639099, total loss: 1.1080687046051025
37th Epoch, 13725th Step, learning rate = 0.008616397701209063 - Loss: 0.5414107441902161, aux loss1: 0.9506630897521973, 
		 aux loss2: 0.6227361559867859, total loss: 1.0757040977478027
38th Epoch, 13730th Step, learning rate = 0.008615889357495602 - Loss: 0.46544140577316284, aux loss1: 0.924358606338501, 
		 aux loss2: 0.5789024829864502, total loss: 0.9743099808692932
38th Epoch, 13735th Step, learning rate = 0.008615381010449608 - Loss: 0.4041159749031067, aux loss1: 0.9313398599624634, 
		 aux loss2: 0.5298231244087219, total loss: 0.8954471945762634
38th Epoch, 13740th Step, learning rate = 0.008614872660070832 - Loss: 0.307594358921051, aux loss1: 0.6915569305419922, 
		 aux loss2: 0.37930312752723694, total loss: 0.6667826771736145
38th Epoch, 13745th Step, learning rate = 0.00861436430635904 - Loss: 0.3344366252422333, aux loss1: 0.7195056080818176, 
		 aux loss2: 0.4166809916496277, total loss: 0.7169607281684875
38th Epoch, 13750th Step, learning rate = 0.008613855949313985 - Loss: 0.4278823137283325, aux loss1: 0.8561177849769592, 
		 aux loss2: 0.5304033160209656, total loss: 0.8968789577484131
38th Epoch, 13755th Step, learning rate = 0.008613347588935434 - Loss: 0.41399338841438293, aux loss1: 0.877013623714447, 
		 aux loss2: 0.48933812975883484, total loss: 0.8728327751159668
38th Epoch, 13760th Step, learning rate = 0.008612839225223141 - Loss: 0.6814159750938416, aux loss1: 1.3010163307189941, 
		 aux loss2: 0.8594287037849426, total loss: 1.415492296218872
38th Epoch, 13765th Step, learning rate = 0.008612330858176866 - Loss: 0.49651798605918884, aux loss1: 0.9824084639549255, 
		 aux loss2: 0.6197755336761475, total loss: 1.0391508340835571
38th Epoch, 13770th Step, learning rate = 0.008611822487796371 - Loss: 0.43521642684936523, aux loss1: 1.0627374649047852, 
		 aux loss2: 0.6072027087211609, total loss: 0.996918797492981
38th Epoch, 13775th Step, learning rate = 0.008611314114081416 - Loss: 0.3370240032672882, aux loss1: 0.8080092668533325, 
		 aux loss2: 0.42142951488494873, total loss: 0.7479985952377319
38th Epoch, 13780th Step, learning rate = 0.008610805737031756 - Loss: 0.3363044261932373, aux loss1: 0.8245947957038879, 
		 aux loss2: 0.4381793141365051, total loss: 0.758954644203186
38th Epoch, 13785th Step, learning rate = 0.008610297356647154 - Loss: 0.6856415867805481, aux loss1: 1.177037000656128, 
		 aux loss2: 0.7667551636695862, total loss: 1.3454546928405762
38th Epoch, 13790th Step, learning rate = 0.008609788972927367 - Loss: 0.4588357210159302, aux loss1: 0.9856316447257996, 
		 aux loss2: 0.597788393497467, total loss: 0.9936405420303345
38th Epoch, 13795th Step, learning rate = 0.008609280585872157 - Loss: 0.3364304006099701, aux loss1: 0.7352260947227478, 
		 aux loss2: 0.4024452865123749, total loss: 0.7179763913154602
38th Epoch, 13800th Step, learning rate = 0.008608772195481283 - Loss: 0.5564855933189392, aux loss1: 1.091694712638855, 
		 aux loss2: 0.6929416060447693, total loss: 1.1611706018447876
<13800th step>
*************************** Test ***************************
time:3m 15s, 13800th Step, Loss: 0.5689769983291626, Mean IoU = 39.244%
************************************************************
38th Epoch, 13805th Step, learning rate = 0.0086082638017545 - Loss: 0.4668123126029968, aux loss1: 0.9328092336654663, 
		 aux loss2: 0.5815991163253784, total loss: 0.9792947769165039
38th Epoch, 13810th Step, learning rate = 0.008607755404691572 - Loss: 0.4490124583244324, aux loss1: 0.9222553372383118, 
		 aux loss2: 0.5459990501403809, total loss: 0.9440886974334717
38th Epoch, 13815th Step, learning rate = 0.008607247004292258 - Loss: 0.5722224116325378, aux loss1: 1.207854986190796, 
		 aux loss2: 0.6952691674232483, total loss: 1.212686538696289
38th Epoch, 13820th Step, learning rate = 0.008606738600556314 - Loss: 0.46002131700515747, aux loss1: 0.9997659921646118, 
		 aux loss2: 0.5942009687423706, total loss: 0.9976314902305603
38th Epoch, 13825th Step, learning rate = 0.0086062301934835 - Loss: 0.5414499640464783, aux loss1: 1.0228594541549683, 
		 aux loss2: 0.6697100400924683, total loss: 1.1161918640136719
38th Epoch, 13830th Step, learning rate = 0.008605721783073577 - Loss: 0.3879353702068329, aux loss1: 0.9326557517051697, 
		 aux loss2: 0.5057941675186157, total loss: 0.870049774646759
38th Epoch, 13835th Step, learning rate = 0.008605213369326303 - Loss: 0.5384023785591125, aux loss1: 1.019243597984314, 
		 aux loss2: 0.6305547952651978, total loss: 1.0963973999023438
38th Epoch, 13840th Step, learning rate = 0.008604704952241434 - Loss: 0.38134798407554626, aux loss1: 0.8340955972671509, 
		 aux loss2: 0.46264132857322693, total loss: 0.8166332244873047
38th Epoch, 13845th Step, learning rate = 0.008604196531818735 - Loss: 0.45758724212646484, aux loss1: 0.914017915725708, 
		 aux loss2: 0.5495319962501526, total loss: 0.9516054391860962
38th Epoch, 13850th Step, learning rate = 0.008603688108057962 - Loss: 0.34413591027259827, aux loss1: 0.8774886727333069, 
		 aux loss2: 0.45236772298812866, total loss: 0.7883296012878418
38th Epoch, 13855th Step, learning rate = 0.008603179680958872 - Loss: 0.5951858758926392, aux loss1: 1.0918203592300415, 
		 aux loss2: 0.6998635530471802, total loss: 1.2026774883270264
38th Epoch, 13860th Step, learning rate = 0.008602671250521225 - Loss: 0.4327492415904999, aux loss1: 0.9855523109436035, 
		 aux loss2: 0.5432029962539673, total loss: 0.9456961750984192
38th Epoch, 13865th Step, learning rate = 0.008602162816744781 - Loss: 0.4278141260147095, aux loss1: 0.8941992521286011, 
		 aux loss2: 0.5170731544494629, total loss: 0.902903139591217
38th Epoch, 13870th Step, learning rate = 0.008601654379629299 - Loss: 0.6688975095748901, aux loss1: 1.149440050125122, 
		 aux loss2: 0.7735790014266968, total loss: 1.3231611251831055
38th Epoch, 13875th Step, learning rate = 0.008601145939174534 - Loss: 0.42090874910354614, aux loss1: 0.9399910569190979, 
		 aux loss2: 0.5109995603561401, total loss: 0.907305896282196
38th Epoch, 13880th Step, learning rate = 0.008600637495380252 - Loss: 0.5186492800712585, aux loss1: 1.0607964992523193, 
		 aux loss2: 0.6447540521621704, total loss: 1.0947898626327515
38th Epoch, 13885th Step, learning rate = 0.008600129048246205 - Loss: 0.38012152910232544, aux loss1: 0.8912875652313232, 
		 aux loss2: 0.48586946725845337, total loss: 0.8418555855751038
38th Epoch, 13890th Step, learning rate = 0.008599620597772153 - Loss: 0.4351576864719391, aux loss1: 0.9403263926506042, 
		 aux loss2: 0.5147169828414917, total loss: 0.9231423735618591
38th Epoch, 13895th Step, learning rate = 0.008599112143957859 - Loss: 0.34738489985466003, aux loss1: 0.8359894752502441, 
		 aux loss2: 0.4472958743572235, total loss: 0.7771000862121582
38th Epoch, 13900th Step, learning rate = 0.008598603686803076 - Loss: 0.34075242280960083, aux loss1: 0.8279680013656616, 
		 aux loss2: 0.42490795254707336, total loss: 0.7591059803962708
<13900th step>
*************************** Test ***************************
time:3m 12s, 13900th Step, Loss: 0.5770725011825562, Mean IoU = 38.654%
************************************************************
38th Epoch, 13905th Step, learning rate = 0.008598095226307565 - Loss: 0.4202847182750702, aux loss1: 0.8219630122184753, 
		 aux loss2: 0.4982709288597107, total loss: 0.8661820292472839
38th Epoch, 13910th Step, learning rate = 0.008597586762471084 - Loss: 0.2997211217880249, aux loss1: 0.6813164353370667, 
		 aux loss2: 0.3754502236843109, total loss: 0.6542961597442627
38th Epoch, 13915th Step, learning rate = 0.008597078295293391 - Loss: 0.48263996839523315, aux loss1: 1.0427058935165405, 
		 aux loss2: 0.6094531416893005, total loss: 1.0392329692840576
38th Epoch, 13920th Step, learning rate = 0.008596569824774247 - Loss: 0.4469555616378784, aux loss1: 0.9089551568031311, 
		 aux loss2: 0.5523045659065247, total loss: 0.940563976764679
38th Epoch, 13925th Step, learning rate = 0.00859606135091341 - Loss: 0.312782883644104, aux loss1: 0.757803201675415, 
		 aux loss2: 0.39475217461586, total loss: 0.6980246901512146
38th Epoch, 13930th Step, learning rate = 0.008595552873710634 - Loss: 0.3756476044654846, aux loss1: 0.7748358249664307, 
		 aux loss2: 0.4607369899749756, total loss: 0.7923932075500488
38th Epoch, 13935th Step, learning rate = 0.008595044393165684 - Loss: 0.38086238503456116, aux loss1: 0.847536563873291, 
		 aux loss2: 0.47339704632759094, total loss: 0.8244822025299072
38th Epoch, 13940th Step, learning rate = 0.008594535909278313 - Loss: 0.4729616045951843, aux loss1: 0.9166277647018433, 
		 aux loss2: 0.5766264200210571, total loss: 0.9786005020141602
38th Epoch, 13945th Step, learning rate = 0.00859402742204828 - Loss: 0.3464699685573578, aux loss1: 0.7925755381584167, 
		 aux loss2: 0.42706817388534546, total loss: 0.75506991147995
38th Epoch, 13950th Step, learning rate = 0.008593518931475346 - Loss: 0.4066857397556305, aux loss1: 0.9223801493644714, 
		 aux loss2: 0.4989994466304779, total loss: 0.88299959897995
38th Epoch, 13955th Step, learning rate = 0.008593010437559268 - Loss: 0.40252697467803955, aux loss1: 1.0607376098632812, 
		 aux loss2: 0.5340421199798584, total loss: 0.9343651533126831
38th Epoch, 13960th Step, learning rate = 0.008592501940299804 - Loss: 0.4480176568031311, aux loss1: 0.9662289619445801, 
		 aux loss2: 0.5566534996032715, total loss: 0.9605478048324585
38th Epoch, 13965th Step, learning rate = 0.008591993439696712 - Loss: 0.4017842411994934, aux loss1: 0.939936101436615, 
		 aux loss2: 0.5106077790260315, total loss: 0.888008177280426
38th Epoch, 13970th Step, learning rate = 0.008591484935749748 - Loss: 0.40949174761772156, aux loss1: 0.8876172304153442, 
		 aux loss2: 0.5097392201423645, total loss: 0.879672646522522
38th Epoch, 13975th Step, learning rate = 0.008590976428458675 - Loss: 0.3283441364765167, aux loss1: 0.7569230198860168, 
		 aux loss2: 0.40203914046287537, total loss: 0.7162367105484009
38th Epoch, 13980th Step, learning rate = 0.008590467917823249 - Loss: 0.30556514859199524, aux loss1: 0.7545349597930908, 
		 aux loss2: 0.39295247197151184, total loss: 0.6891067028045654
38th Epoch, 13985th Step, learning rate = 0.008589959403843224 - Loss: 0.3533458411693573, aux loss1: 0.8103885054588318, 
		 aux loss2: 0.4457973539829254, total loss: 0.774781346321106
38th Epoch, 13990th Step, learning rate = 0.008589450886518364 - Loss: 0.5042663216590881, aux loss1: 1.0355699062347412, 
		 aux loss2: 0.6235769987106323, total loss: 1.0643681287765503
38th Epoch, 13995th Step, learning rate = 0.008588942365848425 - Loss: 0.44687947630882263, aux loss1: 0.9632999897003174, 
		 aux loss2: 0.5564391613006592, total loss: 0.9584451913833618
38th Epoch, 14000th Step, learning rate = 0.008588433841833162 - Loss: 0.4741310179233551, aux loss1: 0.953389048576355, 
		 aux loss2: 0.5612305998802185, total loss: 0.9846400022506714
<14000th step>
*************************** Test ***************************
time:3m 15s, 14000th Step, Loss: 0.6362192630767822, Mean IoU = 38.630%
************************************************************
38th Epoch, 14005th Step, learning rate = 0.008587925314472337 - Loss: 0.3929649293422699, aux loss1: 0.8568766713142395, 
		 aux loss2: 0.5057112574577332, total loss: 0.852312445640564
38th Epoch, 14010th Step, learning rate = 0.008587416783765706 - Loss: 0.33849674463272095, aux loss1: 0.7341541647911072, 
		 aux loss2: 0.4190734028816223, total loss: 0.7263723611831665
38th Epoch, 14015th Step, learning rate = 0.008586908249713025 - Loss: 0.3298380970954895, aux loss1: 0.6724153757095337, 
		 aux loss2: 0.3935614228248596, total loss: 0.6889872550964355
38th Epoch, 14020th Step, learning rate = 0.008586399712314056 - Loss: 0.3604230582714081, aux loss1: 0.7579185962677002, 
		 aux loss2: 0.4505111873149872, total loss: 0.7680031061172485
38th Epoch, 14025th Step, learning rate = 0.008585891171568555 - Loss: 0.37139105796813965, aux loss1: 0.8012261390686035, 
		 aux loss2: 0.4488638639450073, total loss: 0.7913044691085815
38th Epoch, 14030th Step, learning rate = 0.008585382627476278 - Loss: 0.6291483640670776, aux loss1: 1.0698517560958862, 
		 aux loss2: 0.7127938866615295, total loss: 1.2352213859558105
38th Epoch, 14035th Step, learning rate = 0.008584874080036983 - Loss: 0.34800904989242554, aux loss1: 0.848831057548523, 
		 aux loss2: 0.4325377941131592, total loss: 0.775673508644104
38th Epoch, 14040th Step, learning rate = 0.00858436552925043 - Loss: 0.3195190131664276, aux loss1: 0.7662850022315979, 
		 aux loss2: 0.3992944359779358, total loss: 0.7091223001480103
38th Epoch, 14045th Step, learning rate = 0.008583856975116376 - Loss: 0.4282911717891693, aux loss1: 0.8615788817405701, 
		 aux loss2: 0.5119563341140747, total loss: 0.8915473818778992
38th Epoch, 14050th Step, learning rate = 0.008583348417634577 - Loss: 0.39490941166877747, aux loss1: 0.8752228617668152, 
		 aux loss2: 0.5069317817687988, total loss: 0.8602490425109863
38th Epoch, 14055th Step, learning rate = 0.00858283985680479 - Loss: 0.5231549739837646, aux loss1: 1.006893515586853, 
		 aux loss2: 0.618808388710022, total loss: 1.0727463960647583
38th Epoch, 14060th Step, learning rate = 0.008582331292626776 - Loss: 0.5440471768379211, aux loss1: 1.0526173114776611, 
		 aux loss2: 0.6568988561630249, total loss: 1.1225919723510742
38th Epoch, 14065th Step, learning rate = 0.00858182272510029 - Loss: 0.2914915382862091, aux loss1: 0.7150454521179199, 
		 aux loss2: 0.36326712369918823, total loss: 0.651311993598938
38th Epoch, 14070th Step, learning rate = 0.00858131415422509 - Loss: 0.3959903419017792, aux loss1: 0.8965235948562622, 
		 aux loss2: 0.5005027651786804, total loss: 0.8651484847068787
38th Epoch, 14075th Step, learning rate = 0.008580805580000933 - Loss: 0.42609891295433044, aux loss1: 0.9868310689926147, 
		 aux loss2: 0.5289508700370789, total loss: 0.9337285757064819
38th Epoch, 14080th Step, learning rate = 0.008580297002427578 - Loss: 0.43630242347717285, aux loss1: 0.9109943509101868, 
		 aux loss2: 0.5300755500793457, total loss: 0.9216309785842896
38th Epoch, 14085th Step, learning rate = 0.008579788421504779 - Loss: 0.4714972972869873, aux loss1: 1.030429720878601, 
		 aux loss2: 0.6049569845199585, total loss: 1.022608995437622
38th Epoch, 14090th Step, learning rate = 0.008579279837232298 - Loss: 0.46483752131462097, aux loss1: 1.0726128816604614, 
		 aux loss2: 0.597407877445221, total loss: 1.0255845785140991
38th Epoch, 14095th Step, learning rate = 0.008578771249609887 - Loss: 0.3689703345298767, aux loss1: 0.8964454531669617, 
		 aux loss2: 0.4875999987125397, total loss: 0.8329439759254456
39th Epoch, 14100th Step, learning rate = 0.008578262658637308 - Loss: 0.38642653822898865, aux loss1: 0.8661482930183411, 
		 aux loss2: 0.4729616940021515, total loss: 0.8354557156562805
<14100th step>
*************************** Test ***************************
time:3m 14s, 14100th Step, Loss: 0.5748228430747986, Mean IoU = 40.368%
************************************************************
39th Epoch, 14105th Step, learning rate = 0.008577754064314316 - Loss: 0.2918286621570587, aux loss1: 0.7718895673751831, 
		 aux loss2: 0.3806658983230591, total loss: 0.6756619215011597
39th Epoch, 14110th Step, learning rate = 0.008577245466640668 - Loss: 0.44368213415145874, aux loss1: 1.0024422407150269, 
		 aux loss2: 0.5674905776977539, total loss: 0.9714110493659973
39th Epoch, 14115th Step, learning rate = 0.008576736865616122 - Loss: 0.296515554189682, aux loss1: 0.7186024188995361, 
		 aux loss2: 0.3787141740322113, total loss: 0.6635819673538208
39th Epoch, 14120th Step, learning rate = 0.008576228261240436 - Loss: 0.42600464820861816, aux loss1: 0.9760612845420837, 
		 aux loss2: 0.5341106057167053, total loss: 0.9324673414230347
39th Epoch, 14125th Step, learning rate = 0.008575719653513364 - Loss: 0.34580376744270325, aux loss1: 0.7794311046600342, 
		 aux loss2: 0.4324295222759247, total loss: 0.7526049613952637
39th Epoch, 14130th Step, learning rate = 0.008575211042434666 - Loss: 0.43662574887275696, aux loss1: 0.9057896137237549, 
		 aux loss2: 0.5315565466880798, total loss: 0.9209852814674377
39th Epoch, 14135th Step, learning rate = 0.0085747024280041 - Loss: 0.6985487937927246, aux loss1: 1.1658788919448853, 
		 aux loss2: 0.7804758548736572, total loss: 1.3605027198791504
39th Epoch, 14140th Step, learning rate = 0.008574193810221417 - Loss: 0.3407050371170044, aux loss1: 0.7919346690177917, 
		 aux loss2: 0.42999014258384705, total loss: 0.7502815127372742
39th Epoch, 14145th Step, learning rate = 0.00857368518908638 - Loss: 0.5767078995704651, aux loss1: 1.0688532590866089, 
		 aux loss2: 0.7215339541435242, total loss: 1.1859774589538574
39th Epoch, 14150th Step, learning rate = 0.008573176564598743 - Loss: 0.6695282459259033, aux loss1: 1.2542345523834229, 
		 aux loss2: 0.7938803434371948, total loss: 1.3633508682250977
39th Epoch, 14155th Step, learning rate = 0.008572667936758264 - Loss: 0.4381149411201477, aux loss1: 0.9615601897239685, 
		 aux loss2: 0.5340541005134583, total loss: 0.9402046203613281
39th Epoch, 14160th Step, learning rate = 0.0085721593055647 - Loss: 0.379939466714859, aux loss1: 0.8779423832893372, 
		 aux loss2: 0.48164132237434387, total loss: 0.8359787464141846
39th Epoch, 14165th Step, learning rate = 0.008571650671017807 - Loss: 0.38982343673706055, aux loss1: 0.9096099138259888, 
		 aux loss2: 0.5172763466835022, total loss: 0.8696169853210449
39th Epoch, 14170th Step, learning rate = 0.008571142033117343 - Loss: 0.5405828952789307, aux loss1: 1.0459502935409546, 
		 aux loss2: 0.6363842487335205, total loss: 1.1089216470718384
39th Epoch, 14175th Step, learning rate = 0.008570633391863064 - Loss: 0.6649188995361328, aux loss1: 1.1816719770431519, 
		 aux loss2: 0.7656858563423157, total loss: 1.3256947994232178
39th Epoch, 14180th Step, learning rate = 0.008570124747254727 - Loss: 0.32327771186828613, aux loss1: 0.8219446539878845, 
		 aux loss2: 0.4330754578113556, total loss: 0.7430912852287292
39th Epoch, 14185th Step, learning rate = 0.008569616099292087 - Loss: 0.4539352357387543, aux loss1: 1.0285803079605103, 
		 aux loss2: 0.6020107865333557, total loss: 1.003313660621643
39th Epoch, 14190th Step, learning rate = 0.008569107447974903 - Loss: 0.3125467002391815, aux loss1: 0.6565666198730469, 
		 aux loss2: 0.37225502729415894, total loss: 0.6584187150001526
39th Epoch, 14195th Step, learning rate = 0.00856859879330293 - Loss: 0.3636842966079712, aux loss1: 0.8066649436950684, 
		 aux loss2: 0.45337602496147156, total loss: 0.7870342135429382
39th Epoch, 14200th Step, learning rate = 0.008568090135275926 - Loss: 0.43383005261421204, aux loss1: 1.0108064413070679, 
		 aux loss2: 0.549168586730957, total loss: 0.9567394256591797
<14200th step>
*************************** Test ***************************
time:3m 15s, 14200th Step, Loss: 0.6260630488395691, Mean IoU = 38.502%
************************************************************
39th Epoch, 14205th Step, learning rate = 0.00856758147389365 - Loss: 0.34148845076560974, aux loss1: 0.8407831192016602, 
		 aux loss2: 0.42711982131004333, total loss: 0.7645713686943054
39th Epoch, 14210th Step, learning rate = 0.008567072809155852 - Loss: 0.3622082769870758, aux loss1: 0.884083092212677, 
		 aux loss2: 0.48436692357063293, total loss: 0.821179986000061
39th Epoch, 14215th Step, learning rate = 0.00856656414106229 - Loss: 0.40907180309295654, aux loss1: 0.8584753274917603, 
		 aux loss2: 0.5116642713546753, total loss: 0.8712801337242126
39th Epoch, 14220th Step, learning rate = 0.008566055469612725 - Loss: 0.46758946776390076, aux loss1: 0.9937824010848999, 
		 aux loss2: 0.5948411226272583, total loss: 1.0036606788635254
39th Epoch, 14225th Step, learning rate = 0.008565546794806912 - Loss: 0.3703766167163849, aux loss1: 0.859716534614563, 
		 aux loss2: 0.46022239327430725, total loss: 0.8123805522918701
39th Epoch, 14230th Step, learning rate = 0.008565038116644604 - Loss: 0.45705941319465637, aux loss1: 0.989822268486023, 
		 aux loss2: 0.5771575570106506, total loss: 0.9848691821098328
39th Epoch, 14235th Step, learning rate = 0.00856452943512556 - Loss: 0.498948872089386, aux loss1: 1.0741193294525146, 
		 aux loss2: 0.6459393501281738, total loss: 1.079560399055481
39th Epoch, 14240th Step, learning rate = 0.008564020750249536 - Loss: 0.38427937030792236, aux loss1: 0.9801627993583679, 
		 aux loss2: 0.5145478844642639, total loss: 0.8841474056243896
39th Epoch, 14245th Step, learning rate = 0.00856351206201629 - Loss: 0.3401176333427429, aux loss1: 0.7846708297729492, 
		 aux loss2: 0.42603081464767456, total loss: 0.7459312677383423
39th Epoch, 14250th Step, learning rate = 0.008563003370425573 - Loss: 0.49458929896354675, aux loss1: 1.0455862283706665, 
		 aux loss2: 0.62999027967453, total loss: 1.0602613687515259
39th Epoch, 14255th Step, learning rate = 0.008562494675477147 - Loss: 0.394632488489151, aux loss1: 0.8403391242027283, 
		 aux loss2: 0.47711998224258423, total loss: 0.8375822305679321
39th Epoch, 14260th Step, learning rate = 0.008561985977170767 - Loss: 0.4410684108734131, aux loss1: 0.9414505958557129, 
		 aux loss2: 0.5673053860664368, total loss: 0.9504257440567017
39th Epoch, 14265th Step, learning rate = 0.008561477275506185 - Loss: 0.4641612470149994, aux loss1: 0.9373153448104858, 
		 aux loss2: 0.5612642168998718, total loss: 0.9698615074157715
39th Epoch, 14270th Step, learning rate = 0.008560968570483161 - Loss: 0.42735832929611206, aux loss1: 0.8462435603141785, 
		 aux loss2: 0.4940353333950043, total loss: 0.8788455128669739
39th Epoch, 14275th Step, learning rate = 0.00856045986210145 - Loss: 0.4119783639907837, aux loss1: 0.9190534949302673, 
		 aux loss2: 0.5288481712341309, total loss: 0.8992336988449097
39th Epoch, 14280th Step, learning rate = 0.00855995115036081 - Loss: 0.5086145401000977, aux loss1: 0.9080643653869629, 
		 aux loss2: 0.5870051383972168, total loss: 1.0158358812332153
39th Epoch, 14285th Step, learning rate = 0.008559442435260994 - Loss: 0.42029765248298645, aux loss1: 0.9010650515556335, 
		 aux loss2: 0.5450409054756165, total loss: 0.9086335897445679
39th Epoch, 14290th Step, learning rate = 0.00855893371680176 - Loss: 0.45792946219444275, aux loss1: 0.9213866591453552, 
		 aux loss2: 0.5725972056388855, total loss: 0.9633843302726746
39th Epoch, 14295th Step, learning rate = 0.008558424994982862 - Loss: 0.49075135588645935, aux loss1: 0.9818302392959595, 
		 aux loss2: 0.6029935479164124, total loss: 1.0264978408813477
39th Epoch, 14300th Step, learning rate = 0.008557916269804058 - Loss: 0.5029802918434143, aux loss1: 0.9385544061660767, 
		 aux loss2: 0.6055763959884644, total loss: 1.0267771482467651
<14300th step>
*************************** Test ***************************
time:3m 14s, 14300th Step, Loss: 0.561933696269989, Mean IoU = 38.790%
************************************************************
39th Epoch, 14305th Step, learning rate = 0.008557407541265102 - Loss: 0.43252936005592346, aux loss1: 0.9952861070632935, 
		 aux loss2: 0.5521537661552429, total loss: 0.9519767165184021
39th Epoch, 14310th Step, learning rate = 0.008556898809365752 - Loss: 0.44112449884414673, aux loss1: 0.9571601152420044, 
		 aux loss2: 0.5346599817276001, total loss: 0.9421365261077881
39th Epoch, 14315th Step, learning rate = 0.008556390074105764 - Loss: 0.3509008288383484, aux loss1: 0.823782742023468, 
		 aux loss2: 0.4460473656654358, total loss: 0.7764546275138855
39th Epoch, 14320th Step, learning rate = 0.00855588133548489 - Loss: 0.4136524200439453, aux loss1: 0.9867729544639587, 
		 aux loss2: 0.516202449798584, total loss: 0.916165292263031
39th Epoch, 14325th Step, learning rate = 0.008555372593502888 - Loss: 0.37466296553611755, aux loss1: 0.8503779768943787, 
		 aux loss2: 0.4805818200111389, total loss: 0.8220090866088867
39th Epoch, 14330th Step, learning rate = 0.008554863848159516 - Loss: 0.32491204142570496, aux loss1: 0.803819477558136, 
		 aux loss2: 0.4072975218296051, total loss: 0.7289769649505615
39th Epoch, 14335th Step, learning rate = 0.008554355099454526 - Loss: 0.5195898413658142, aux loss1: 0.9881783127784729, 
		 aux loss2: 0.617077648639679, total loss: 1.062874436378479
39th Epoch, 14340th Step, learning rate = 0.008553846347387675 - Loss: 0.5733377933502197, aux loss1: 1.0143355131149292, 
		 aux loss2: 0.6851979494094849, total loss: 1.1517176628112793
39th Epoch, 14345th Step, learning rate = 0.00855333759195872 - Loss: 0.38518181443214417, aux loss1: 0.8117254376411438, 
		 aux loss2: 0.48452869057655334, total loss: 0.8225108981132507
39th Epoch, 14350th Step, learning rate = 0.008552828833167414 - Loss: 0.391324520111084, aux loss1: 0.8617006540298462, 
		 aux loss2: 0.481933057308197, total loss: 0.8426079750061035
39th Epoch, 14355th Step, learning rate = 0.008552320071013517 - Loss: 0.4446752369403839, aux loss1: 1.0140382051467896, 
		 aux loss2: 0.5996171236038208, total loss: 0.9887335300445557
39th Epoch, 14360th Step, learning rate = 0.008551811305496778 - Loss: 0.48440882563591003, aux loss1: 0.995652973651886, 
		 aux loss2: 0.5792873501777649, total loss: 1.014819622039795
39th Epoch, 14365th Step, learning rate = 0.008551302536616958 - Loss: 0.37423521280288696, aux loss1: 0.7918287515640259, 
		 aux loss2: 0.46338266134262085, total loss: 0.7971369028091431
39th Epoch, 14370th Step, learning rate = 0.008550793764373812 - Loss: 0.4213781952857971, aux loss1: 0.9680863618850708, 
		 aux loss2: 0.54695725440979, total loss: 0.9305870532989502
39th Epoch, 14375th Step, learning rate = 0.008550284988767089 - Loss: 0.4633095860481262, aux loss1: 0.9742158055305481, 
		 aux loss2: 0.5797017812728882, total loss: 0.9874550700187683
39th Epoch, 14380th Step, learning rate = 0.008549776209796552 - Loss: 0.4136447608470917, aux loss1: 0.8316468596458435, 
		 aux loss2: 0.48688167333602905, total loss: 0.8578914999961853
39th Epoch, 14385th Step, learning rate = 0.008549267427461956 - Loss: 0.37224307656288147, aux loss1: 0.7777299880981445, 
		 aux loss2: 0.4334518611431122, total loss: 0.7789428234100342
39th Epoch, 14390th Step, learning rate = 0.00854875864176305 - Loss: 0.38973352313041687, aux loss1: 0.8699877262115479, 
		 aux loss2: 0.4887852072715759, total loss: 0.8462439775466919
39th Epoch, 14395th Step, learning rate = 0.008548249852699594 - Loss: 0.5079367160797119, aux loss1: 0.9747530817985535, 
		 aux loss2: 0.6424466967582703, total loss: 1.0573413372039795
39th Epoch, 14400th Step, learning rate = 0.008547741060271343 - Loss: 0.4255451560020447, aux loss1: 0.8375535607337952, 
		 aux loss2: 0.5103321671485901, total loss: 0.8809440732002258
<14400th step>
*************************** Test ***************************
time:3m 15s, 14400th Step, Loss: 0.6174537539482117, Mean IoU = 39.507%
************************************************************
39th Epoch, 14405th Step, learning rate = 0.008547232264478052 - Loss: 0.4914090633392334, aux loss1: 1.1048136949539185, 
		 aux loss2: 0.6235052943229675, total loss: 1.0722553730010986
39th Epoch, 14410th Step, learning rate = 0.008546723465319477 - Loss: 0.4644314646720886, aux loss1: 0.9728730916976929, 
		 aux loss2: 0.564180314540863, total loss: 0.9819655418395996
39th Epoch, 14415th Step, learning rate = 0.008546214662795369 - Loss: 0.3967007100582123, aux loss1: 0.8750706315040588, 
		 aux loss2: 0.4901577830314636, total loss: 0.8552849888801575
39th Epoch, 14420th Step, learning rate = 0.008545705856905486 - Loss: 0.4032979905605316, aux loss1: 0.9834012389183044, 
		 aux loss2: 0.5141618847846985, total loss: 0.9039831161499023
39th Epoch, 14425th Step, learning rate = 0.008545197047649585 - Loss: 0.5140524506568909, aux loss1: 1.0061984062194824, 
		 aux loss2: 0.6412287950515747, total loss: 1.0724035501480103
39th Epoch, 14430th Step, learning rate = 0.00854468823502742 - Loss: 0.34981685876846313, aux loss1: 0.8096928000450134, 
		 aux loss2: 0.43253108859062195, total loss: 0.7657371163368225
39th Epoch, 14435th Step, learning rate = 0.008544179419038742 - Loss: 0.46025291085243225, aux loss1: 0.9060459733009338, 
		 aux loss2: 0.5628234148025513, total loss: 0.9571961164474487
39th Epoch, 14440th Step, learning rate = 0.008543670599683311 - Loss: 0.39356642961502075, aux loss1: 0.823295533657074, 
		 aux loss2: 0.47623878717422485, total loss: 0.8310506343841553
39th Epoch, 14445th Step, learning rate = 0.00854316177696088 - Loss: 0.42316383123397827, aux loss1: 0.8922589421272278, 
		 aux loss2: 0.5212852358818054, total loss: 0.8993556499481201
39th Epoch, 14450th Step, learning rate = 0.008542652950871202 - Loss: 0.5526774525642395, aux loss1: 1.2275859117507935, 
		 aux loss2: 0.7338696718215942, total loss: 1.214501142501831
39th Epoch, 14455th Step, learning rate = 0.008542144121414035 - Loss: 0.4116179049015045, aux loss1: 0.866636335849762, 
		 aux loss2: 0.500578761100769, total loss: 0.8718402981758118
39th Epoch, 14460th Step, learning rate = 0.008541635288589132 - Loss: 0.34666669368743896, aux loss1: 0.8576224446296692, 
		 aux loss2: 0.4466649889945984, total loss: 0.7826194763183594
39th Epoch, 14465th Step, learning rate = 0.00854112645239625 - Loss: 0.5788896679878235, aux loss1: 1.2663137912750244, 
		 aux loss2: 0.741894543170929, total loss: 1.2555416822433472
40th Epoch, 14470th Step, learning rate = 0.008540617612835142 - Loss: 0.40790632367134094, aux loss1: 0.9286704659461975, 
		 aux loss2: 0.5184526443481445, total loss: 0.893888533115387
40th Epoch, 14475th Step, learning rate = 0.008540108769905562 - Loss: 0.41256842017173767, aux loss1: 0.8752831220626831, 
		 aux loss2: 0.4988318979740143, total loss: 0.8746861219406128
40th Epoch, 14480th Step, learning rate = 0.008539599923607267 - Loss: 0.4342358112335205, aux loss1: 0.8998667597770691, 
		 aux loss2: 0.5479036569595337, total loss: 0.9233573079109192
40th Epoch, 14485th Step, learning rate = 0.008539091073940009 - Loss: 0.43143191933631897, aux loss1: 1.0835974216461182, 
		 aux loss2: 0.5383599996566772, total loss: 0.9718551635742188
40th Epoch, 14490th Step, learning rate = 0.008538582220903543 - Loss: 0.34882453083992004, aux loss1: 0.857398271560669, 
		 aux loss2: 0.4564298391342163, total loss: 0.7886160016059875
40th Epoch, 14495th Step, learning rate = 0.008538073364497627 - Loss: 0.3774324357509613, aux loss1: 0.905092716217041, 
		 aux loss2: 0.48123469948768616, total loss: 0.8414541482925415
40th Epoch, 14500th Step, learning rate = 0.00853756450472201 - Loss: 0.4159660041332245, aux loss1: 0.920561671257019, 
		 aux loss2: 0.531108558177948, total loss: 0.904577910900116
<14500th step>
*************************** Test ***************************
time:3m 16s, 14500th Step, Loss: 0.5458803176879883, Mean IoU = 40.641%
************************************************************
40th Epoch, 14505th Step, learning rate = 0.008537055641576452 - Loss: 0.5142123699188232, aux loss1: 1.0959612131118774, 
		 aux loss2: 0.6634846925735474, total loss: 1.1083946228027344
40th Epoch, 14510th Step, learning rate = 0.008536546775060704 - Loss: 0.3447573781013489, aux loss1: 0.896366536617279, 
		 aux loss2: 0.44152021408081055, total loss: 0.7902754545211792
40th Epoch, 14515th Step, learning rate = 0.00853603790517452 - Loss: 0.37018540501594543, aux loss1: 0.8623400926589966, 
		 aux loss2: 0.45328429341316223, total loss: 0.8102011680603027
40th Epoch, 14520th Step, learning rate = 0.008535529031917658 - Loss: 0.2941628694534302, aux loss1: 0.6863241791725159, 
		 aux loss2: 0.35777685046195984, total loss: 0.6431708931922913
40th Epoch, 14525th Step, learning rate = 0.00853502015528987 - Loss: 0.6052078008651733, aux loss1: 1.1053510904312134, 
		 aux loss2: 0.7413302063941956, total loss: 1.2333452701568604
40th Epoch, 14530th Step, learning rate = 0.00853451127529091 - Loss: 0.43315744400024414, aux loss1: 0.9026028513908386, 
		 aux loss2: 0.5327550768852234, total loss: 0.9170403480529785
40th Epoch, 14535th Step, learning rate = 0.008534002391920535 - Loss: 0.5111662149429321, aux loss1: 1.1291391849517822, 
		 aux loss2: 0.6661324501037598, total loss: 1.1163610219955444
40th Epoch, 14540th Step, learning rate = 0.008533493505178494 - Loss: 0.3172008991241455, aux loss1: 0.7689646482467651, 
		 aux loss2: 0.40908083319664, total loss: 0.71152263879776
40th Epoch, 14545th Step, learning rate = 0.008532984615064547 - Loss: 0.45614269375801086, aux loss1: 0.9137594699859619, 
		 aux loss2: 0.5480604767799377, total loss: 0.9494947195053101
40th Epoch, 14550th Step, learning rate = 0.008532475721578446 - Loss: 0.4147526025772095, aux loss1: 1.0103503465652466, 
		 aux loss2: 0.5292957425117493, total loss: 0.92957603931427
40th Epoch, 14555th Step, learning rate = 0.008531966824719942 - Loss: 0.3888413906097412, aux loss1: 0.8309751749038696, 
		 aux loss2: 0.49492892622947693, total loss: 0.8361055254936218
40th Epoch, 14560th Step, learning rate = 0.008531457924488796 - Loss: 0.5175113677978516, aux loss1: 0.9763078689575195, 
		 aux loss2: 0.6209906935691833, total loss: 1.0587999820709229
40th Epoch, 14565th Step, learning rate = 0.008530949020884755 - Loss: 0.5567502379417419, aux loss1: 1.1033663749694824, 
		 aux loss2: 0.6776065826416016, total loss: 1.1588027477264404
40th Epoch, 14570th Step, learning rate = 0.008530440113907576 - Loss: 0.39592814445495605, aux loss1: 0.8677466511726379, 
		 aux loss2: 0.513400137424469, total loss: 0.8616122007369995
40th Epoch, 14575th Step, learning rate = 0.008529931203557016 - Loss: 0.36161670088768005, aux loss1: 0.8779990077018738, 
		 aux loss2: 0.4537312090396881, total loss: 0.8065089583396912
40th Epoch, 14580th Step, learning rate = 0.008529422289832824 - Loss: 0.36647114157676697, aux loss1: 0.8277303576469421, 
		 aux loss2: 0.45220986008644104, total loss: 0.795674204826355
40th Epoch, 14585th Step, learning rate = 0.008528913372734757 - Loss: 0.4820623993873596, aux loss1: 0.9210318922996521, 
		 aux loss2: 0.5615440607070923, total loss: 0.9829895496368408
40th Epoch, 14590th Step, learning rate = 0.00852840445226257 - Loss: 0.4885175824165344, aux loss1: 1.037235975265503, 
		 aux loss2: 0.626382052898407, total loss: 1.050241231918335
40th Epoch, 14595th Step, learning rate = 0.008527895528416013 - Loss: 0.3766211271286011, aux loss1: 0.7794550061225891, 
		 aux loss2: 0.44779250025749207, total loss: 0.7895746827125549
40th Epoch, 14600th Step, learning rate = 0.008527386601194842 - Loss: 0.5041614174842834, aux loss1: 1.0699334144592285, 
		 aux loss2: 0.6495705246925354, total loss: 1.0849696397781372
<14600th step>
*************************** Test ***************************
time:3m 12s, 14600th Step, Loss: 0.5611924529075623, Mean IoU = 40.916%
************************************************************
40th Epoch, 14605th Step, learning rate = 0.008526877670598813 - Loss: 0.5003393292427063, aux loss1: 0.9775674939155579, 
		 aux loss2: 0.6145617961883545, total loss: 1.0394343137741089
40th Epoch, 14610th Step, learning rate = 0.008526368736627675 - Loss: 0.3517514169216156, aux loss1: 0.9155673980712891, 
		 aux loss2: 0.46613532304763794, total loss: 0.8128758072853088
40th Epoch, 14615th Step, learning rate = 0.008525859799281187 - Loss: 0.3592740595340729, aux loss1: 0.9136629104614258, 
		 aux loss2: 0.4713495075702667, total loss: 0.8219127058982849
40th Epoch, 14620th Step, learning rate = 0.008525350858559098 - Loss: 0.41828715801239014, aux loss1: 0.9138455390930176, 
		 aux loss2: 0.5306643843650818, total loss: 0.904706597328186
40th Epoch, 14625th Step, learning rate = 0.008524841914461165 - Loss: 0.36105701327323914, aux loss1: 0.8101059198379517, 
		 aux loss2: 0.4488508999347687, total loss: 0.7836291790008545
40th Epoch, 14630th Step, learning rate = 0.008524332966987139 - Loss: 0.8901335597038269, aux loss1: 1.4461555480957031, 
		 aux loss2: 0.9855033159255981, total loss: 1.7181816101074219
40th Epoch, 14635th Step, learning rate = 0.008523824016136777 - Loss: 0.39836031198501587, aux loss1: 0.8434301018714905, 
		 aux loss2: 0.4819159507751465, total loss: 0.8441557288169861
40th Epoch, 14640th Step, learning rate = 0.008523315061909831 - Loss: 0.47333428263664246, aux loss1: 1.0537012815475464, 
		 aux loss2: 0.6125404238700867, total loss: 1.0344609022140503
40th Epoch, 14645th Step, learning rate = 0.008522806104306054 - Loss: 0.3885710835456848, aux loss1: 0.8962133526802063, 
		 aux loss2: 0.4939405620098114, total loss: 0.8550112843513489
40th Epoch, 14650th Step, learning rate = 0.008522297143325199 - Loss: 0.5202664732933044, aux loss1: 1.1540354490280151, 
		 aux loss2: 0.6532041430473328, total loss: 1.1277587413787842
40th Epoch, 14655th Step, learning rate = 0.008521788178967019 - Loss: 0.4027310311794281, aux loss1: 0.888861358165741, 
		 aux loss2: 0.5049211382865906, total loss: 0.8713579177856445
40th Epoch, 14660th Step, learning rate = 0.008521279211231272 - Loss: 0.3726479113101959, aux loss1: 0.8569504618644714, 
		 aux loss2: 0.4641014039516449, total loss: 0.8153736591339111
40th Epoch, 14665th Step, learning rate = 0.008520770240117707 - Loss: 0.5549071431159973, aux loss1: 1.0786185264587402, 
		 aux loss2: 0.6739586591720581, total loss: 1.1480761766433716
40th Epoch, 14670th Step, learning rate = 0.008520261265626078 - Loss: 0.3544180691242218, aux loss1: 0.7892634868621826, 
		 aux loss2: 0.45371708273887634, total loss: 0.7726839780807495
40th Epoch, 14675th Step, learning rate = 0.00851975228775614 - Loss: 0.5291872620582581, aux loss1: 1.01474928855896, 
		 aux loss2: 0.6338559985160828, total loss: 1.087154507637024
40th Epoch, 14680th Step, learning rate = 0.008519243306507645 - Loss: 0.52757728099823, aux loss1: 1.167230486869812, 
		 aux loss2: 0.6836869716644287, total loss: 1.1512212753295898
40th Epoch, 14685th Step, learning rate = 0.008518734321880345 - Loss: 0.4534705877304077, aux loss1: 0.9897640347480774, 
		 aux loss2: 0.5627322793006897, total loss: 0.9754927158355713
40th Epoch, 14690th Step, learning rate = 0.008518225333873999 - Loss: 0.516367495059967, aux loss1: 1.060423493385315, 
		 aux loss2: 0.6371415853500366, total loss: 1.0893511772155762
40th Epoch, 14695th Step, learning rate = 0.008517716342488353 - Loss: 0.35072362422943115, aux loss1: 0.7712066769599915, 
		 aux loss2: 0.44536495208740234, total loss: 0.760231614112854
40th Epoch, 14700th Step, learning rate = 0.008517207347723163 - Loss: 0.6587199568748474, aux loss1: 1.2627779245376587, 
		 aux loss2: 0.8630405068397522, total loss: 1.3827695846557617
<14700th step>
*************************** Test ***************************
time:3m 12s, 14700th Step, Loss: 0.5853763818740845, Mean IoU = 39.784%
************************************************************
40th Epoch, 14705th Step, learning rate = 0.008516698349578184 - Loss: 0.3259728252887726, aux loss1: 0.8071924448013306, 
		 aux loss2: 0.4063953459262848, total loss: 0.7306886911392212
40th Epoch, 14710th Step, learning rate = 0.008516189348053167 - Loss: 0.46109580993652344, aux loss1: 0.8686878681182861, 
		 aux loss2: 0.551773726940155, total loss: 0.9424117207527161
40th Epoch, 14715th Step, learning rate = 0.008515680343147865 - Loss: 0.35029715299606323, aux loss1: 0.7279261350631714, 
		 aux loss2: 0.412891685962677, total loss: 0.7338316440582275
40th Epoch, 14720th Step, learning rate = 0.008515171334862032 - Loss: 0.3843112587928772, aux loss1: 0.9156332015991211, 
		 aux loss2: 0.49557965993881226, total loss: 0.8572331070899963
40th Epoch, 14725th Step, learning rate = 0.008514662323195421 - Loss: 0.3630977272987366, aux loss1: 0.7782793641090393, 
		 aux loss2: 0.4571094810962677, total loss: 0.7794253826141357
40th Epoch, 14730th Step, learning rate = 0.008514153308147787 - Loss: 0.41785672307014465, aux loss1: 1.0027215480804443, 
		 aux loss2: 0.5424070358276367, total loss: 0.935636043548584
40th Epoch, 14735th Step, learning rate = 0.008513644289718876 - Loss: 0.30384668707847595, aux loss1: 0.7476361393928528, 
		 aux loss2: 0.3799678087234497, total loss: 0.6801247000694275
40th Epoch, 14740th Step, learning rate = 0.008513135267908449 - Loss: 0.3814132511615753, aux loss1: 0.8856148719787598, 
		 aux loss2: 0.48166441917419434, total loss: 0.8397634625434875
40th Epoch, 14745th Step, learning rate = 0.008512626242716256 - Loss: 0.4784187376499176, aux loss1: 0.972601056098938, 
		 aux loss2: 0.6038500666618347, total loss: 1.0117391347885132
40th Epoch, 14750th Step, learning rate = 0.008512117214142047 - Loss: 0.3787597715854645, aux loss1: 0.7766731381416321, 
		 aux loss2: 0.44418686628341675, total loss: 0.7894364595413208
40th Epoch, 14755th Step, learning rate = 0.008511608182185578 - Loss: 0.2923664450645447, aux loss1: 0.8002967834472656, 
		 aux loss2: 0.383735716342926, total loss: 0.6859498023986816
40th Epoch, 14760th Step, learning rate = 0.008511099146846599 - Loss: 0.4038323163986206, aux loss1: 0.9181108474731445, 
		 aux loss2: 0.5413134694099426, total loss: 0.8957909941673279
40th Epoch, 14765th Step, learning rate = 0.008510590108124867 - Loss: 0.3699072599411011, aux loss1: 0.8366293907165527, 
		 aux loss2: 0.45829272270202637, total loss: 0.8042131662368774
40th Epoch, 14770th Step, learning rate = 0.008510081066020131 - Loss: 0.47339579463005066, aux loss1: 1.0180422067642212, 
		 aux loss2: 0.5915060043334961, total loss: 1.0154109001159668
40th Epoch, 14775th Step, learning rate = 0.008509572020532145 - Loss: 0.3617521822452545, aux loss1: 0.8368801474571228, 
		 aux loss2: 0.4616429805755615, total loss: 0.7974734306335449
40th Epoch, 14780th Step, learning rate = 0.008509062971660663 - Loss: 0.3461606204509735, aux loss1: 0.8482592701911926, 
		 aux loss2: 0.45101064443588257, total loss: 0.7810426354408264
40th Epoch, 14785th Step, learning rate = 0.008508553919405436 - Loss: 0.3876420259475708, aux loss1: 0.860508918762207, 
		 aux loss2: 0.46236538887023926, total loss: 0.8307409286499023
40th Epoch, 14790th Step, learning rate = 0.008508044863766216 - Loss: 0.31937646865844727, aux loss1: 0.7156783938407898, 
		 aux loss2: 0.38619551062583923, total loss: 0.6885582208633423
40th Epoch, 14795th Step, learning rate = 0.008507535804742757 - Loss: 0.35616084933280945, aux loss1: 0.8927070498466492, 
		 aux loss2: 0.464600533246994, total loss: 0.8098132610321045
40th Epoch, 14800th Step, learning rate = 0.00850702674233481 - Loss: 0.503742516040802, aux loss1: 1.0961720943450928, 
		 aux loss2: 0.6347941160202026, total loss: 1.0865118503570557
<14800th step>
*************************** Test ***************************
time:3m 11s, 14800th Step, Loss: 0.630873441696167, Mean IoU = 38.263%
************************************************************
40th Epoch, 14805th Step, learning rate = 0.00850651767654213 - Loss: 0.3602440357208252, aux loss1: 0.7877489328384399, 
		 aux loss2: 0.444397509098053, total loss: 0.7743276953697205
40th Epoch, 14810th Step, learning rate = 0.008506008607364465 - Loss: 0.4398336112499237, aux loss1: 0.9446846842765808, 
		 aux loss2: 0.5666577219963074, total loss: 0.9499021768569946
40th Epoch, 14815th Step, learning rate = 0.00850549953480157 - Loss: 0.42793169617652893, aux loss1: 1.034253478050232, 
		 aux loss2: 0.551706075668335, total loss: 0.9588901996612549
40th Epoch, 14820th Step, learning rate = 0.0085049904588532 - Loss: 0.49425122141838074, aux loss1: 0.9671140313148499, 
		 aux loss2: 0.5864444971084595, total loss: 1.0189632177352905
40th Epoch, 14825th Step, learning rate = 0.008504481379519105 - Loss: 0.47280144691467285, aux loss1: 1.0053279399871826, 
		 aux loss2: 0.590920090675354, total loss: 1.010767936706543
40th Epoch, 14830th Step, learning rate = 0.008503972296799035 - Loss: 0.4146118760108948, aux loss1: 0.8668389916419983, 
		 aux loss2: 0.516935408115387, total loss: 0.8814377188682556
40th Epoch, 14835th Step, learning rate = 0.008503463210692744 - Loss: 0.42887505888938904, aux loss1: 0.9124446511268616, 
		 aux loss2: 0.5257004499435425, total loss: 0.9128886461257935
40th Epoch, 14840th Step, learning rate = 0.008502954121199988 - Loss: 0.38328689336776733, aux loss1: 0.8572903871536255, 
		 aux loss2: 0.4702996015548706, total loss: 0.8285938501358032
41th Epoch, 14845th Step, learning rate = 0.008502445028320512 - Loss: 0.4459201395511627, aux loss1: 0.9995035529136658, 
		 aux loss2: 0.6098822951316833, total loss: 0.9897241592407227
41th Epoch, 14850th Step, learning rate = 0.008501935932054073 - Loss: 0.3757883906364441, aux loss1: 0.8639991283416748, 
		 aux loss2: 0.4850468635559082, total loss: 0.8290069103240967
41th Epoch, 14855th Step, learning rate = 0.008501426832400424 - Loss: 0.4665565490722656, aux loss1: 0.9508211016654968, 
		 aux loss2: 0.5714043974876404, total loss: 0.9803646802902222
41th Epoch, 14860th Step, learning rate = 0.008500917729359313 - Loss: 0.35155534744262695, aux loss1: 0.7952814698219299, 
		 aux loss2: 0.42855727672576904, total loss: 0.761562705039978
41th Epoch, 14865th Step, learning rate = 0.008500408622930495 - Loss: 0.2683648467063904, aux loss1: 0.7340461611747742, 
		 aux loss2: 0.34047600626945496, total loss: 0.6247690916061401
41th Epoch, 14870th Step, learning rate = 0.008499899513113722 - Loss: 0.41418343782424927, aux loss1: 0.9228322505950928, 
		 aux loss2: 0.5332686305046082, total loss: 0.9043405652046204
41th Epoch, 14875th Step, learning rate = 0.008499390399908742 - Loss: 0.38961485028266907, aux loss1: 0.9493113160133362, 
		 aux loss2: 0.5125691294670105, total loss: 0.8794358968734741
41th Epoch, 14880th Step, learning rate = 0.008498881283315314 - Loss: 0.38227975368499756, aux loss1: 0.8571276664733887, 
		 aux loss2: 0.4968133270740509, total loss: 0.8381434082984924
41th Epoch, 14885th Step, learning rate = 0.008498372163333183 - Loss: 0.3327541649341583, aux loss1: 0.9712746739387512, 
		 aux loss2: 0.44449397921562195, total loss: 0.8019341826438904
41th Epoch, 14890th Step, learning rate = 0.008497863039962104 - Loss: 0.4757891893386841, aux loss1: 0.9673384428024292, 
		 aux loss2: 0.5779050588607788, total loss: 0.9971527457237244
41th Epoch, 14895th Step, learning rate = 0.008497353913201831 - Loss: 0.4019395411014557, aux loss1: 0.8759538531303406, 
		 aux loss2: 0.5318723917007446, total loss: 0.8774746656417847
41th Epoch, 14900th Step, learning rate = 0.008496844783052113 - Loss: 0.44062837958335876, aux loss1: 1.029823899269104, 
		 aux loss2: 0.5718493461608887, total loss: 0.9783152937889099
<14900th step>
*************************** Test ***************************
time:3m 15s, 14900th Step, Loss: 0.568360447883606, Mean IoU = 40.479%
************************************************************
41th Epoch, 14905th Step, learning rate = 0.0084963356495127 - Loss: 0.4044310450553894, aux loss1: 0.8935267329216003, 
		 aux loss2: 0.5046980381011963, total loss: 0.8743682503700256
41th Epoch, 14910th Step, learning rate = 0.008495826512583347 - Loss: 0.4577964246273041, aux loss1: 0.8881602883338928, 
		 aux loss2: 0.5470789074897766, total loss: 0.9430761337280273
41th Epoch, 14915th Step, learning rate = 0.008495317372263807 - Loss: 0.41464823484420776, aux loss1: 0.8012158870697021, 
		 aux loss2: 0.4880043864250183, total loss: 0.8502147793769836
41th Epoch, 14920th Step, learning rate = 0.008494808228553826 - Loss: 0.5186684131622314, aux loss1: 1.0833455324172974, 
		 aux loss2: 0.658404529094696, total loss: 1.1070339679718018
41th Epoch, 14925th Step, learning rate = 0.008494299081453162 - Loss: 0.39117804169654846, aux loss1: 0.8104615807533264, 
		 aux loss2: 0.476855605840683, total loss: 0.8250587582588196
41th Epoch, 14930th Step, learning rate = 0.008493789930961561 - Loss: 0.36164647340774536, aux loss1: 0.8666389584541321, 
		 aux loss2: 0.4550674855709076, total loss: 0.8036651611328125
41th Epoch, 14935th Step, learning rate = 0.008493280777078779 - Loss: 0.44318312406539917, aux loss1: 0.9598355293273926, 
		 aux loss2: 0.5599114894866943, total loss: 0.9550983905792236
41th Epoch, 14940th Step, learning rate = 0.008492771619804565 - Loss: 0.5232934951782227, aux loss1: 0.9978207945823669, 
		 aux loss2: 0.6297593116760254, total loss: 1.0745434761047363
41th Epoch, 14945th Step, learning rate = 0.00849226245913867 - Loss: 0.3180881142616272, aux loss1: 0.7234658002853394, 
		 aux loss2: 0.3996206521987915, total loss: 0.6949761509895325
41th Epoch, 14950th Step, learning rate = 0.008491753295080852 - Loss: 0.4699016511440277, aux loss1: 0.9680923223495483, 
		 aux loss2: 0.5750744938850403, total loss: 0.9903591871261597
41th Epoch, 14955th Step, learning rate = 0.008491244127630852 - Loss: 0.3047298192977905, aux loss1: 0.7582862377166748, 
		 aux loss2: 0.4064841568470001, total loss: 0.6948093771934509
41th Epoch, 14960th Step, learning rate = 0.008490734956788426 - Loss: 0.3793941140174866, aux loss1: 0.9426523447036743, 
		 aux loss2: 0.499393105506897, total loss: 0.8619470596313477
41th Epoch, 14965th Step, learning rate = 0.00849022578255333 - Loss: 0.41616591811180115, aux loss1: 0.8752975463867188, 
		 aux loss2: 0.5009594559669495, total loss: 0.8791389465332031
41th Epoch, 14970th Step, learning rate = 0.008489716604925307 - Loss: 0.57652747631073, aux loss1: 1.0078455209732056, 
		 aux loss2: 0.6752036213874817, total loss: 1.1489626169204712
41th Epoch, 14975th Step, learning rate = 0.008489207423904114 - Loss: 0.593218207359314, aux loss1: 1.288042664527893, 
		 aux loss2: 0.7901619672775269, total loss: 1.2956959009170532
41th Epoch, 14980th Step, learning rate = 0.008488698239489502 - Loss: 0.48663684725761414, aux loss1: 1.1053416728973389, 
		 aux loss2: 0.6353457570075989, total loss: 1.0723776817321777
41th Epoch, 14985th Step, learning rate = 0.008488189051681218 - Loss: 0.5710874199867249, aux loss1: 1.2678438425064087, 
		 aux loss2: 0.7921745181083679, total loss: 1.2683104276657104
41th Epoch, 14990th Step, learning rate = 0.008487679860479018 - Loss: 0.3699032962322235, aux loss1: 0.8486244678497314, 
		 aux loss2: 0.4740884304046631, total loss: 0.8141260147094727
41th Epoch, 14995th Step, learning rate = 0.008487170665882652 - Loss: 0.3820784389972687, aux loss1: 0.817371666431427, 
		 aux loss2: 0.4793393611907959, total loss: 0.8190256953239441
41th Epoch, 15000th Step, learning rate = 0.008486661467891869 - Loss: 0.37320733070373535, aux loss1: 0.8001329302787781, 
		 aux loss2: 0.44001758098602295, total loss: 0.7892542481422424
<15000th step>
*************************** Test ***************************
time:3m 13s, 15000th Step, Loss: 0.5757189989089966, Mean IoU = 39.769%
************************************************************
41th Epoch, 15005th Step, learning rate = 0.008486152266506421 - Loss: 0.4475729465484619, aux loss1: 0.9218937158584595, 
		 aux loss2: 0.5643733739852905, total loss: 0.9498904347419739
41th Epoch, 15010th Step, learning rate = 0.008485643061726061 - Loss: 0.3719561696052551, aux loss1: 0.7946337461471558, 
		 aux loss2: 0.45986098051071167, total loss: 0.7942907214164734
41th Epoch, 15015th Step, learning rate = 0.008485133853550536 - Loss: 0.5323867797851562, aux loss1: 1.131576418876648, 
		 aux loss2: 0.7153040170669556, total loss: 1.1579813957214355
41th Epoch, 15020th Step, learning rate = 0.008484624641979603 - Loss: 0.49315837025642395, aux loss1: 0.9256534576416016, 
		 aux loss2: 0.5761597156524658, total loss: 1.001318335533142
41th Epoch, 15025th Step, learning rate = 0.008484115427013007 - Loss: 0.4466721713542938, aux loss1: 1.0210425853729248, 
		 aux loss2: 0.5659695267677307, total loss: 0.9793727993965149
41th Epoch, 15030th Step, learning rate = 0.0084836062086505 - Loss: 0.39379754662513733, aux loss1: 0.8590385913848877, 
		 aux loss2: 0.4992118775844574, total loss: 0.851193904876709
41th Epoch, 15035th Step, learning rate = 0.008483096986891838 - Loss: 0.4118388295173645, aux loss1: 0.8804355263710022, 
		 aux loss2: 0.5073068141937256, total loss: 0.878892183303833
41th Epoch, 15040th Step, learning rate = 0.008482587761736765 - Loss: 0.41889867186546326, aux loss1: 0.9605993628501892, 
		 aux loss2: 0.5279165506362915, total loss: 0.9182450771331787
41th Epoch, 15045th Step, learning rate = 0.008482078533185035 - Loss: 0.6726407408714294, aux loss1: 1.0986690521240234, 
		 aux loss2: 0.7616496682167053, total loss: 1.3069013357162476
41th Epoch, 15050th Step, learning rate = 0.0084815693012364 - Loss: 0.40401655435562134, aux loss1: 0.8307352066040039, 
		 aux loss2: 0.48325115442276, total loss: 0.8465375900268555
41th Epoch, 15055th Step, learning rate = 0.008481060065890608 - Loss: 0.3872356712818146, aux loss1: 0.902012825012207, 
		 aux loss2: 0.4941691756248474, total loss: 0.8555071949958801
41th Epoch, 15060th Step, learning rate = 0.008480550827147411 - Loss: 0.3657987117767334, aux loss1: 0.7846354246139526, 
		 aux loss2: 0.44805270433425903, total loss: 0.7804104685783386
41th Epoch, 15065th Step, learning rate = 0.00848004158500656 - Loss: 0.46226152777671814, aux loss1: 0.9445823431015015, 
		 aux loss2: 0.5796980261802673, total loss: 0.977515459060669
41th Epoch, 15070th Step, learning rate = 0.008479532339467804 - Loss: 0.46597498655319214, aux loss1: 1.0669119358062744, 
		 aux loss2: 0.651716947555542, total loss: 1.046735405921936
41th Epoch, 15075th Step, learning rate = 0.008479023090530896 - Loss: 0.4087507724761963, aux loss1: 0.9085474610328674, 
		 aux loss2: 0.5169469714164734, total loss: 0.8880938291549683
41th Epoch, 15080th Step, learning rate = 0.008478513838195586 - Loss: 0.4712497293949127, aux loss1: 1.0019819736480713, 
		 aux loss2: 0.5726760625839233, total loss: 1.0009148120880127
41th Epoch, 15085th Step, learning rate = 0.008478004582461623 - Loss: 0.48662567138671875, aux loss1: 1.0324136018753052, 
		 aux loss2: 0.6242998242378235, total loss: 1.0460697412490845
41th Epoch, 15090th Step, learning rate = 0.00847749532332876 - Loss: 0.6326937079429626, aux loss1: 1.165757179260254, 
		 aux loss2: 0.7971773147583008, total loss: 1.301291823387146
41th Epoch, 15095th Step, learning rate = 0.008476986060796741 - Loss: 0.42747965455055237, aux loss1: 0.8965162038803101, 
		 aux loss2: 0.5206517577171326, total loss: 0.9046952128410339
41th Epoch, 15100th Step, learning rate = 0.008476476794865325 - Loss: 0.4653841555118561, aux loss1: 0.9464259743690491, 
		 aux loss2: 0.5895047783851624, total loss: 0.9851138591766357
<15100th step>
*************************** Test ***************************
time:3m 14s, 15100th Step, Loss: 0.5711786150932312, Mean IoU = 39.389%
************************************************************
41th Epoch, 15105th Step, learning rate = 0.00847596752553426 - Loss: 0.465699702501297, aux loss1: 0.9677585363388062, 
		 aux loss2: 0.5540509223937988, total loss: 0.9776476621627808
41th Epoch, 15110th Step, learning rate = 0.008475458252803292 - Loss: 0.37449997663497925, aux loss1: 0.994644284248352, 
		 aux loss2: 0.4861375391483307, total loss: 0.867348313331604
41th Epoch, 15115th Step, learning rate = 0.008474948976672175 - Loss: 0.36460915207862854, aux loss1: 0.8328537940979004, 
		 aux loss2: 0.455047070980072, total loss: 0.796484112739563
41th Epoch, 15120th Step, learning rate = 0.008474439697140658 - Loss: 0.46645817160606384, aux loss1: 0.9851652383804321, 
		 aux loss2: 0.5916728973388672, total loss: 0.9986768960952759
41th Epoch, 15125th Step, learning rate = 0.008473930414208491 - Loss: 0.387630820274353, aux loss1: 0.894829511642456, 
		 aux loss2: 0.45545458793640137, total loss: 0.8382614850997925
41th Epoch, 15130th Step, learning rate = 0.008473421127875427 - Loss: 0.3732917010784149, aux loss1: 0.8858950138092041, 
		 aux loss2: 0.4790797531604767, total loss: 0.8306921720504761
41th Epoch, 15135th Step, learning rate = 0.008472911838141214 - Loss: 0.5345049500465393, aux loss1: 1.0507758855819702, 
		 aux loss2: 0.6686884164810181, total loss: 1.1172131299972534
41th Epoch, 15140th Step, learning rate = 0.008472402545005602 - Loss: 0.39325252175331116, aux loss1: 0.865053653717041, 
		 aux loss2: 0.47964659333229065, total loss: 0.8446272611618042
41th Epoch, 15145th Step, learning rate = 0.008471893248468343 - Loss: 0.27555209398269653, aux loss1: 0.6988180875778198, 
		 aux loss2: 0.35812777280807495, total loss: 0.6284486651420593
41th Epoch, 15150th Step, learning rate = 0.008471383948529183 - Loss: 0.3983592689037323, aux loss1: 0.8453495502471924, 
		 aux loss2: 0.478779137134552, total loss: 0.8434758186340332
41th Epoch, 15155th Step, learning rate = 0.008470874645187873 - Loss: 0.3393852412700653, aux loss1: 0.6816642880439758, 
		 aux loss2: 0.40651774406433105, total loss: 0.7064915895462036
41th Epoch, 15160th Step, learning rate = 0.008470365338444167 - Loss: 0.5249060392379761, aux loss1: 1.068367838859558, 
		 aux loss2: 0.6666625738143921, total loss: 1.112081527709961
41th Epoch, 15165th Step, learning rate = 0.008469856028297812 - Loss: 0.3879627287387848, aux loss1: 0.8459509611129761, 
		 aux loss2: 0.46586066484451294, total loss: 0.8280923366546631
41th Epoch, 15170th Step, learning rate = 0.008469346714748558 - Loss: 0.503273069858551, aux loss1: 1.0655415058135986, 
		 aux loss2: 0.6468281745910645, total loss: 1.0816668272018433
41th Epoch, 15175th Step, learning rate = 0.008468837397796155 - Loss: 0.2731072008609772, aux loss1: 0.6906856894493103, 
		 aux loss2: 0.3423578143119812, total loss: 0.6172560453414917
41th Epoch, 15180th Step, learning rate = 0.008468328077440353 - Loss: 0.40205490589141846, aux loss1: 0.807185709476471, 
		 aux loss2: 0.4707138240337372, total loss: 0.832496166229248
41th Epoch, 15185th Step, learning rate = 0.008467818753680903 - Loss: 0.3876783847808838, aux loss1: 0.7765390872955322, 
		 aux loss2: 0.4660690128803253, total loss: 0.8070676922798157
41th Epoch, 15190th Step, learning rate = 0.008467309426517551 - Loss: 0.5841002464294434, aux loss1: 1.2005318403244019, 
		 aux loss2: 0.7172805666923523, total loss: 1.2311720848083496
41th Epoch, 15195th Step, learning rate = 0.008466800095950052 - Loss: 0.3539527654647827, aux loss1: 0.8367344737052917, 
		 aux loss2: 0.44126880168914795, total loss: 0.781480610370636
41th Epoch, 15200th Step, learning rate = 0.008466290761978152 - Loss: 0.41924452781677246, aux loss1: 0.8427468538284302, 
		 aux loss2: 0.5146043300628662, total loss: 0.877910315990448
<15200th step>
*************************** Test ***************************
time:3m 19s, 15200th Step, Loss: 0.5530472993850708, Mean IoU = 40.131%
************************************************************
41th Epoch, 15205th Step, learning rate = 0.008465781424601602 - Loss: 0.36196979880332947, aux loss1: 0.9093955755233765, 
		 aux loss2: 0.442592591047287, total loss: 0.8118255734443665
41th Epoch, 15210th Step, learning rate = 0.008465272083820152 - Loss: 0.5093568563461304, aux loss1: 1.1031326055526733, 
		 aux loss2: 0.6420688629150391, total loss: 1.0971242189407349
42th Epoch, 15215th Step, learning rate = 0.00846476273963355 - Loss: 0.3968873620033264, aux loss1: 0.7732821702957153, 
		 aux loss2: 0.4768058657646179, total loss: 0.8195943832397461
42th Epoch, 15220th Step, learning rate = 0.008464253392041548 - Loss: 0.42353489995002747, aux loss1: 1.11568021774292, 
		 aux loss2: 0.6048765778541565, total loss: 1.0001895427703857
42th Epoch, 15225th Step, learning rate = 0.008463744041043893 - Loss: 0.4791739583015442, aux loss1: 1.0057700872421265, 
		 aux loss2: 0.5841736197471619, total loss: 1.014574408531189
42th Epoch, 15230th Step, learning rate = 0.008463234686640335 - Loss: 0.6609687805175781, aux loss1: 1.3354052305221558, 
		 aux loss2: 0.8398802280426025, total loss: 1.3975424766540527
42th Epoch, 15235th Step, learning rate = 0.008462725328830625 - Loss: 0.5329189896583557, aux loss1: 1.0351618528366089, 
		 aux loss2: 0.6542242765426636, total loss: 1.1051573753356934
42th Epoch, 15240th Step, learning rate = 0.008462215967614511 - Loss: 0.3865087926387787, aux loss1: 0.9005550742149353, 
		 aux loss2: 0.4999048113822937, total loss: 0.8566372394561768
42th Epoch, 15245th Step, learning rate = 0.008461706602991743 - Loss: 0.48668941855430603, aux loss1: 1.0188380479812622, 
		 aux loss2: 0.6064397096633911, total loss: 1.0349167585372925
42th Epoch, 15250th Step, learning rate = 0.00846119723496207 - Loss: 0.38806891441345215, aux loss1: 0.9773094058036804, 
		 aux loss2: 0.5225143432617188, total loss: 0.8902674913406372
42th Epoch, 15255th Step, learning rate = 0.008460687863525244 - Loss: 0.36622923612594604, aux loss1: 0.8633507490158081, 
		 aux loss2: 0.4670272171497345, total loss: 0.8120453953742981
42th Epoch, 15260th Step, learning rate = 0.00846017848868101 - Loss: 0.5366040468215942, aux loss1: 1.0531657934188843, 
		 aux loss2: 0.6660993099212646, total loss: 1.1189935207366943
42th Epoch, 15265th Step, learning rate = 0.008459669110429118 - Loss: 0.337636262178421, aux loss1: 0.805250883102417, 
		 aux loss2: 0.42098960280418396, total loss: 0.7476073503494263
42th Epoch, 15270th Step, learning rate = 0.00845915972876932 - Loss: 0.4722587764263153, aux loss1: 1.0522894859313965, 
		 aux loss2: 0.6136934161186218, total loss: 1.0334229469299316
42th Epoch, 15275th Step, learning rate = 0.008458650343701362 - Loss: 0.38930538296699524, aux loss1: 0.8404577970504761, 
		 aux loss2: 0.4932710826396942, total loss: 0.8387511968612671
42th Epoch, 15280th Step, learning rate = 0.008458140955224997 - Loss: 0.47565439343452454, aux loss1: 1.0025396347045898, 
		 aux loss2: 0.5951199531555176, total loss: 1.014464259147644
42th Epoch, 15285th Step, learning rate = 0.00845763156333997 - Loss: 0.3946487009525299, aux loss1: 0.875947117805481, 
		 aux loss2: 0.5150101184844971, total loss: 0.8634369373321533
42th Epoch, 15290th Step, learning rate = 0.008457122168046031 - Loss: 0.3825027644634247, aux loss1: 0.8892612457275391, 
		 aux loss2: 0.5120785236358643, total loss: 0.8541125655174255
42th Epoch, 15295th Step, learning rate = 0.008456612769342934 - Loss: 0.526185154914856, aux loss1: 1.0550391674041748, 
		 aux loss2: 0.6863108277320862, total loss: 1.1172212362289429
42th Epoch, 15300th Step, learning rate = 0.00845610336723042 - Loss: 0.43942001461982727, aux loss1: 0.9356350302696228, 
		 aux loss2: 0.5360962748527527, total loss: 0.9345490336418152
<15300th step>
*************************** Test ***************************
time:3m 12s, 15300th Step, Loss: 0.6284175515174866, Mean IoU = 40.486%
************************************************************
42th Epoch, 15305th Step, learning rate = 0.008455593961708243 - Loss: 0.44680705666542053, aux loss1: 0.9269235730171204, 
		 aux loss2: 0.5589947700500488, total loss: 0.9484820365905762
42th Epoch, 15310th Step, learning rate = 0.008455084552776151 - Loss: 0.4512329697608948, aux loss1: 0.9466886520385742, 
		 aux loss2: 0.5486264824867249, total loss: 0.954690158367157
42th Epoch, 15315th Step, learning rate = 0.008454575140433893 - Loss: 0.3602798581123352, aux loss1: 0.9139121174812317, 
		 aux loss2: 0.48068612813949585, total loss: 0.8267279863357544
42th Epoch, 15320th Step, learning rate = 0.008454065724681216 - Loss: 0.3697497546672821, aux loss1: 0.9035999774932861, 
		 aux loss2: 0.5057599544525146, total loss: 0.843133807182312
42th Epoch, 15325th Step, learning rate = 0.008453556305517872 - Loss: 0.34551694989204407, aux loss1: 0.818343460559845, 
		 aux loss2: 0.4477323293685913, total loss: 0.770112931728363
42th Epoch, 15330th Step, learning rate = 0.008453046882943608 - Loss: 0.37732136249542236, aux loss1: 0.7608310580253601, 
		 aux loss2: 0.472057044506073, total loss: 0.7943934798240662
42th Epoch, 15335th Step, learning rate = 0.008452537456958172 - Loss: 0.41826820373535156, aux loss1: 0.9649769067764282, 
		 aux loss2: 0.5376577973365784, total loss: 0.9228243827819824
42th Epoch, 15340th Step, learning rate = 0.008452028027561316 - Loss: 0.5203893780708313, aux loss1: 1.0680241584777832, 
		 aux loss2: 0.6431257128715515, total loss: 1.098046898841858
42th Epoch, 15345th Step, learning rate = 0.008451518594752783 - Loss: 0.44398170709609985, aux loss1: 0.9599533081054688, 
		 aux loss2: 0.578210175037384, total loss: 0.9632517695426941
42th Epoch, 15350th Step, learning rate = 0.008451009158532329 - Loss: 0.4510054886341095, aux loss1: 0.882524311542511, 
		 aux loss2: 0.5366105437278748, total loss: 0.9304070472717285
42th Epoch, 15355th Step, learning rate = 0.008450499718899697 - Loss: 0.4460434019565582, aux loss1: 0.9556513428688049, 
		 aux loss2: 0.5702294707298279, total loss: 0.9608306288719177
42th Epoch, 15360th Step, learning rate = 0.008449990275854637 - Loss: 0.39475199580192566, aux loss1: 0.8965625166893005, 
		 aux loss2: 0.5026670694351196, total loss: 0.8647875785827637
42th Epoch, 15365th Step, learning rate = 0.008449480829396895 - Loss: 0.43289804458618164, aux loss1: 1.0528441667556763, 
		 aux loss2: 0.5849128365516663, total loss: 0.98271644115448
42th Epoch, 15370th Step, learning rate = 0.008448971379526226 - Loss: 0.35120007395744324, aux loss1: 0.7804072499275208, 
		 aux loss2: 0.44244149327278137, total loss: 0.7622988820075989
42th Epoch, 15375th Step, learning rate = 0.008448461926242374 - Loss: 0.4678434431552887, aux loss1: 0.9156842231750488, 
		 aux loss2: 0.5559090375900269, total loss: 0.9649122953414917
42th Epoch, 15380th Step, learning rate = 0.008447952469545088 - Loss: 0.44016116857528687, aux loss1: 0.96150141954422, 
		 aux loss2: 0.5663896799087524, total loss: 0.9551674723625183
42th Epoch, 15385th Step, learning rate = 0.008447443009434117 - Loss: 0.49562352895736694, aux loss1: 1.0503082275390625, 
		 aux loss2: 0.6171873211860657, total loss: 1.0575909614562988
42th Epoch, 15390th Step, learning rate = 0.008446933545909209 - Loss: 0.3715844750404358, aux loss1: 0.7833714485168457, 
		 aux loss2: 0.4550144672393799, total loss: 0.7886017560958862
42th Epoch, 15395th Step, learning rate = 0.008446424078970113 - Loss: 0.5014595985412598, aux loss1: 0.9868567585945129, 
		 aux loss2: 0.6111911535263062, total loss: 1.0419931411743164
42th Epoch, 15400th Step, learning rate = 0.008445914608616574 - Loss: 0.5833572149276733, aux loss1: 1.120743989944458, 
		 aux loss2: 0.7268348932266235, total loss: 1.210314393043518
<15400th step>
*************************** Test ***************************
time:3m 11s, 15400th Step, Loss: 0.6419414281845093, Mean IoU = 39.366%
************************************************************
42th Epoch, 15405th Step, learning rate = 0.008445405134848344 - Loss: 0.4469688832759857, aux loss1: 0.9153030514717102, 
		 aux loss2: 0.5455957055091858, total loss: 0.93979811668396
42th Epoch, 15410th Step, learning rate = 0.008444895657665171 - Loss: 0.39457327127456665, aux loss1: 0.8711056709289551, 
		 aux loss2: 0.4910682141780853, total loss: 0.8523322939872742
42th Epoch, 15415th Step, learning rate = 0.008444386177066802 - Loss: 0.49888086318969727, aux loss1: 0.9890809655189514, 
		 aux loss2: 0.5943064093589783, total loss: 1.0333276987075806
42th Epoch, 15420th Step, learning rate = 0.008443876693052986 - Loss: 0.5256651043891907, aux loss1: 0.9889025092124939, 
		 aux loss2: 0.628683865070343, total loss: 1.0738093852996826
42th Epoch, 15425th Step, learning rate = 0.008443367205623468 - Loss: 0.3657902479171753, aux loss1: 0.8913024663925171, 
		 aux loss2: 0.4868518114089966, total loss: 0.8279216885566711
42th Epoch, 15430th Step, learning rate = 0.008442857714778002 - Loss: 0.3714393377304077, aux loss1: 0.8502423167228699, 
		 aux loss2: 0.4621385633945465, total loss: 0.8113675117492676
42th Epoch, 15435th Step, learning rate = 0.008442348220516331 - Loss: 0.45333331823349, aux loss1: 0.8681772351264954, 
		 aux loss2: 0.5455983281135559, total loss: 0.9320257902145386
42th Epoch, 15440th Step, learning rate = 0.008441838722838206 - Loss: 0.42014968395233154, aux loss1: 0.9173195958137512, 
		 aux loss2: 0.522101879119873, total loss: 0.9041863679885864
42th Epoch, 15445th Step, learning rate = 0.008441329221743373 - Loss: 0.3435366153717041, aux loss1: 0.7869028449058533, 
		 aux loss2: 0.45075172185897827, total loss: 0.7599081993103027
42th Epoch, 15450th Step, learning rate = 0.008440819717231582 - Loss: 0.4025035500526428, aux loss1: 0.8945069909095764, 
		 aux loss2: 0.5015032291412354, total loss: 0.8714569211006165
42th Epoch, 15455th Step, learning rate = 0.008440310209302578 - Loss: 0.5149678587913513, aux loss1: 1.1359461545944214, 
		 aux loss2: 0.6459317803382874, total loss: 1.1141245365142822
42th Epoch, 15460th Step, learning rate = 0.008439800697956109 - Loss: 0.4989685118198395, aux loss1: 0.9980778098106384, 
		 aux loss2: 0.6471500992774963, total loss: 1.0572519302368164
42th Epoch, 15465th Step, learning rate = 0.008439291183191927 - Loss: 0.30891257524490356, aux loss1: 0.7963870167732239, 
		 aux loss2: 0.40508532524108887, total loss: 0.7098628282546997
42th Epoch, 15470th Step, learning rate = 0.008438781665009776 - Loss: 0.38268497586250305, aux loss1: 0.8187770247459412, 
		 aux loss2: 0.4849393665790558, total loss: 0.8222938179969788
42th Epoch, 15475th Step, learning rate = 0.008438272143409404 - Loss: 0.5514784455299377, aux loss1: 1.093463659286499, 
		 aux loss2: 0.6791888475418091, total loss: 1.1511931419372559
42th Epoch, 15480th Step, learning rate = 0.008437762618390562 - Loss: 0.39163628220558167, aux loss1: 0.9462487697601318, 
		 aux loss2: 0.5177202224731445, total loss: 0.8825989961624146
42th Epoch, 15485th Step, learning rate = 0.008437253089952993 - Loss: 0.31463369727134705, aux loss1: 0.8921905755996704, 
		 aux loss2: 0.47027215361595154, total loss: 0.7703997492790222
42th Epoch, 15490th Step, learning rate = 0.008436743558096448 - Loss: 0.36487436294555664, aux loss1: 0.8150178790092468, 
		 aux loss2: 0.4688429534435272, total loss: 0.7969169616699219
42th Epoch, 15495th Step, learning rate = 0.008436234022820673 - Loss: 0.3280886709690094, aux loss1: 0.7355126142501831, 
		 aux loss2: 0.4174206852912903, total loss: 0.7157107591629028
42th Epoch, 15500th Step, learning rate = 0.008435724484125417 - Loss: 0.373564213514328, aux loss1: 0.7729819416999817, 
		 aux loss2: 0.45445993542671204, total loss: 0.7872427701950073
<15500th step>
*************************** Test ***************************
time:3m 14s, 15500th Step, Loss: 0.5745611190795898, Mean IoU = 40.116%
************************************************************
42th Epoch, 15505th Step, learning rate = 0.008435214942010428 - Loss: 0.3419840633869171, aux loss1: 0.7649304270744324, 
		 aux loss2: 0.4263847768306732, total loss: 0.7420171499252319
42th Epoch, 15510th Step, learning rate = 0.008434705396475449 - Loss: 0.4877763092517853, aux loss1: 0.9420675039291382, 
		 aux loss2: 0.594901978969574, total loss: 1.0083574056625366
42th Epoch, 15515th Step, learning rate = 0.008434195847520233 - Loss: 0.35446134209632874, aux loss1: 0.8800511956214905, 
		 aux loss2: 0.4608922600746155, total loss: 0.8028336763381958
42th Epoch, 15520th Step, learning rate = 0.008433686295144524 - Loss: 0.39680716395378113, aux loss1: 0.8470496535301208, 
		 aux loss2: 0.48595917224884033, total loss: 0.8453057408332825
42th Epoch, 15525th Step, learning rate = 0.008433176739348071 - Loss: 0.4333804249763489, aux loss1: 1.032606840133667, 
		 aux loss2: 0.5533625483512878, total loss: 0.964507520198822
42th Epoch, 15530th Step, learning rate = 0.008432667180130622 - Loss: 0.609846830368042, aux loss1: 1.1430599689483643, 
		 aux loss2: 0.726055920124054, total loss: 1.2431871891021729
42th Epoch, 15535th Step, learning rate = 0.008432157617491923 - Loss: 0.5742881894111633, aux loss1: 1.196386694908142, 
		 aux loss2: 0.7448203563690186, total loss: 1.2311322689056396
42th Epoch, 15540th Step, learning rate = 0.00843164805143172 - Loss: 0.3293016850948334, aux loss1: 0.7866693139076233, 
		 aux loss2: 0.4241584837436676, total loss: 0.7349659204483032
42th Epoch, 15545th Step, learning rate = 0.008431138481949763 - Loss: 0.37317779660224915, aux loss1: 0.9105193614959717, 
		 aux loss2: 0.4957830607891083, total loss: 0.8446468114852905
42th Epoch, 15550th Step, learning rate = 0.008430628909045798 - Loss: 0.5103095769882202, aux loss1: 0.9471010565757751, 
		 aux loss2: 0.6158807277679443, total loss: 1.0407922267913818
42th Epoch, 15555th Step, learning rate = 0.008430119332719572 - Loss: 0.44793713092803955, aux loss1: 0.9985038042068481, 
		 aux loss2: 0.5395283102989197, total loss: 0.963299572467804
42th Epoch, 15560th Step, learning rate = 0.008429609752970834 - Loss: 0.3617924451828003, aux loss1: 0.8361719250679016, 
		 aux loss2: 0.4576423168182373, total loss: 0.7957010269165039
42th Epoch, 15565th Step, learning rate = 0.008429100169799328 - Loss: 0.5733009576797485, aux loss1: 0.9548681378364563, 
		 aux loss2: 0.6340168714523315, total loss: 1.1133681535720825
42th Epoch, 15570th Step, learning rate = 0.008428590583204802 - Loss: 0.37722063064575195, aux loss1: 0.8353068828582764, 
		 aux loss2: 0.4752350151538849, total loss: 0.8179067373275757
42th Epoch, 15575th Step, learning rate = 0.008428080993187006 - Loss: 0.3374045789241791, aux loss1: 0.7738577127456665, 
		 aux loss2: 0.43747588992118835, total loss: 0.7445522546768188
42th Epoch, 15580th Step, learning rate = 0.008427571399745684 - Loss: 0.493142306804657, aux loss1: 1.0314563512802124, 
		 aux loss2: 0.6045591831207275, total loss: 1.044402837753296
43th Epoch, 15585th Step, learning rate = 0.008427061802880583 - Loss: 0.7242043614387512, aux loss1: 1.2842984199523926, 
		 aux loss2: 0.9147225022315979, total loss: 1.4753830432891846
43th Epoch, 15590th Step, learning rate = 0.008426552202591453 - Loss: 0.48284050822257996, aux loss1: 1.0782145261764526, 
		 aux loss2: 0.57973313331604, total loss: 1.0381981134414673
43th Epoch, 15595th Step, learning rate = 0.008426042598878036 - Loss: 0.4921340346336365, aux loss1: 1.1726795434951782, 
		 aux loss2: 0.6537880897521973, total loss: 1.1054531335830688
43th Epoch, 15600th Step, learning rate = 0.008425532991740082 - Loss: 0.30989590287208557, aux loss1: 0.7548657655715942, 
		 aux loss2: 0.3880789279937744, total loss: 0.6915872097015381
<15600th step>
*************************** Test ***************************
time:3m 14s, 15600th Step, Loss: 0.6545417308807373, Mean IoU = 38.449%
************************************************************
43th Epoch, 15605th Step, learning rate = 0.008425023381177336 - Loss: 0.5200929641723633, aux loss1: 1.1363519430160522, 
		 aux loss2: 0.6690791845321655, total loss: 1.12863028049469
43th Epoch, 15610th Step, learning rate = 0.008424513767189548 - Loss: 0.47106897830963135, aux loss1: 1.0469127893447876, 
		 aux loss2: 0.5983740091323853, total loss: 1.0244925022125244
43th Epoch, 15615th Step, learning rate = 0.008424004149776463 - Loss: 0.40874186158180237, aux loss1: 0.9831733703613281, 
		 aux loss2: 0.5502423048019409, total loss: 0.9237908124923706
43th Epoch, 15620th Step, learning rate = 0.008423494528937828 - Loss: 0.3549676537513733, aux loss1: 0.7852253913879395, 
		 aux loss2: 0.4380532503128052, total loss: 0.7657566070556641
43th Epoch, 15625th Step, learning rate = 0.008422984904673388 - Loss: 0.3765629529953003, aux loss1: 0.9161672592163086, 
		 aux loss2: 0.4989056885242462, total loss: 0.8509753942489624
43th Epoch, 15630th Step, learning rate = 0.008422475276982892 - Loss: 0.44742223620414734, aux loss1: 0.9031120538711548, 
		 aux loss2: 0.5699717402458191, total loss: 0.9463446140289307
43th Epoch, 15635th Step, learning rate = 0.008421965645866085 - Loss: 0.5174392461776733, aux loss1: 1.0352247953414917, 
		 aux loss2: 0.6583817601203918, total loss: 1.0913593769073486
43th Epoch, 15640th Step, learning rate = 0.008421456011322714 - Loss: 0.3643075227737427, aux loss1: 0.7879489064216614, 
		 aux loss2: 0.44801226258277893, total loss: 0.7798970937728882
43th Epoch, 15645th Step, learning rate = 0.008420946373352526 - Loss: 0.4150463938713074, aux loss1: 0.9645230174064636, 
		 aux loss2: 0.5386695265769958, total loss: 0.9198710918426514
43th Epoch, 15650th Step, learning rate = 0.008420436731955269 - Loss: 0.40464696288108826, aux loss1: 0.8926877975463867, 
		 aux loss2: 0.5213629603385925, total loss: 0.8809984922409058
43th Epoch, 15655th Step, learning rate = 0.008419927087130685 - Loss: 0.33765584230422974, aux loss1: 0.7814716100692749, 
		 aux loss2: 0.4227302074432373, total loss: 0.7411893606185913
43th Epoch, 15660th Step, learning rate = 0.008419417438878526 - Loss: 0.44080206751823425, aux loss1: 1.0391576290130615, 
		 aux loss2: 0.5690644979476929, total loss: 0.9801751971244812
43th Epoch, 15665th Step, learning rate = 0.008418907787198534 - Loss: 0.6495930552482605, aux loss1: 1.3367747068405151, 
		 aux loss2: 0.8011794090270996, total loss: 1.371097207069397
43th Epoch, 15670th Step, learning rate = 0.008418398132090457 - Loss: 0.4238491952419281, aux loss1: 0.8866479396820068, 
		 aux loss2: 0.5225294828414917, total loss: 0.8988553881645203
43th Epoch, 15675th Step, learning rate = 0.008417888473554042 - Loss: 0.3715308904647827, aux loss1: 0.8716502785682678, 
		 aux loss2: 0.47597500681877136, total loss: 0.823415994644165
43th Epoch, 15680th Step, learning rate = 0.008417378811589033 - Loss: 0.28918957710266113, aux loss1: 0.7104421854019165, 
		 aux loss2: 0.3661673367023468, total loss: 0.6487891674041748
43th Epoch, 15685th Step, learning rate = 0.008416869146195181 - Loss: 0.41583773493766785, aux loss1: 0.9148591756820679, 
		 aux loss2: 0.5276159048080444, total loss: 0.9013417959213257
43th Epoch, 15690th Step, learning rate = 0.008416359477372227 - Loss: 0.4548304080963135, aux loss1: 1.0421874523162842, 
		 aux loss2: 0.5803593993186951, total loss: 0.9996304512023926
43th Epoch, 15695th Step, learning rate = 0.00841584980511992 - Loss: 0.32822275161743164, aux loss1: 0.7979514598846436, 
		 aux loss2: 0.44231855869293213, total loss: 0.7445356249809265
43th Epoch, 15700th Step, learning rate = 0.008415340129438006 - Loss: 0.3071100413799286, aux loss1: 0.7792567014694214, 
		 aux loss2: 0.40296757221221924, total loss: 0.7020741105079651
<15700th step>
*************************** Test ***************************
time:3m 13s, 15700th Step, Loss: 0.5192503929138184, Mean IoU = 42.223%
************************************************************
43th Epoch, 15705th Step, learning rate = 0.00841483045032623 - Loss: 0.4781325161457062, aux loss1: 1.0434536933898926, 
		 aux loss2: 0.6238373517990112, total loss: 1.040703535079956
43th Epoch, 15710th Step, learning rate = 0.008414320767784337 - Loss: 0.47784167528152466, aux loss1: 0.9979707598686218, 
		 aux loss2: 0.5944702625274658, total loss: 1.0150209665298462
43th Epoch, 15715th Step, learning rate = 0.008413811081812076 - Loss: 0.4068623185157776, aux loss1: 0.8107799887657166, 
		 aux loss2: 0.4960947334766388, total loss: 0.8485342264175415
43th Epoch, 15720th Step, learning rate = 0.008413301392409193 - Loss: 0.34733739495277405, aux loss1: 0.8268017768859863, 
		 aux loss2: 0.43658924102783203, total loss: 0.7700136303901672
43th Epoch, 15725th Step, learning rate = 0.008412791699575432 - Loss: 0.319776326417923, aux loss1: 0.8833350539207458, 
		 aux loss2: 0.4413122832775116, total loss: 0.7613018155097961
43th Epoch, 15730th Step, learning rate = 0.00841228200331054 - Loss: 0.5268290042877197, aux loss1: 1.0826150178909302, 
		 aux loss2: 0.6785274147987366, total loss: 1.1230244636535645
43th Epoch, 15735th Step, learning rate = 0.008411772303614262 - Loss: 0.3938738703727722, aux loss1: 0.9674036502838135, 
		 aux loss2: 0.5030050277709961, total loss: 0.8852970004081726
43th Epoch, 15740th Step, learning rate = 0.008411262600486344 - Loss: 0.433546245098114, aux loss1: 0.872635006904602, 
		 aux loss2: 0.5295473337173462, total loss: 0.9071556925773621
43th Epoch, 15745th Step, learning rate = 0.008410752893926534 - Loss: 0.4873180091381073, aux loss1: 0.9604793787002563, 
		 aux loss2: 0.5937392115592957, total loss: 1.0129574537277222
43th Epoch, 15750th Step, learning rate = 0.008410243183934575 - Loss: 0.46752867102622986, aux loss1: 0.9063397645950317, 
		 aux loss2: 0.5963430404663086, total loss: 0.9779678583145142
43th Epoch, 15755th Step, learning rate = 0.008409733470510215 - Loss: 0.39167141914367676, aux loss1: 0.8447540998458862, 
		 aux loss2: 0.483662873506546, total loss: 0.8385628461837769
43th Epoch, 15760th Step, learning rate = 0.008409223753653198 - Loss: 0.41753774881362915, aux loss1: 0.9538173079490662, 
		 aux loss2: 0.529924213886261, total loss: 0.9156526327133179
43th Epoch, 15765th Step, learning rate = 0.00840871403336327 - Loss: 0.38498586416244507, aux loss1: 0.818035364151001, 
		 aux loss2: 0.4619927406311035, total loss: 0.8151935935020447
43th Epoch, 15770th Step, learning rate = 0.008408204309640179 - Loss: 0.40252476930618286, aux loss1: 0.9712275266647339, 
		 aux loss2: 0.5251889228820801, total loss: 0.9039686322212219
43th Epoch, 15775th Step, learning rate = 0.008407694582483666 - Loss: 0.44616538286209106, aux loss1: 0.9221614599227905, 
		 aux loss2: 0.5384612679481506, total loss: 0.9381983280181885
43th Epoch, 15780th Step, learning rate = 0.008407184851893481 - Loss: 0.5382204651832581, aux loss1: 1.100093960762024, 
		 aux loss2: 0.6756892204284668, total loss: 1.1385244131088257
43th Epoch, 15785th Step, learning rate = 0.008406675117869366 - Loss: 0.3635847568511963, aux loss1: 0.8657750487327576, 
		 aux loss2: 0.46768084168434143, total loss: 0.8103895783424377
43th Epoch, 15790th Step, learning rate = 0.008406165380411069 - Loss: 0.4230496287345886, aux loss1: 0.9289792776107788, 
		 aux loss2: 0.5333044528961182, total loss: 0.9150652289390564
43th Epoch, 15795th Step, learning rate = 0.008405655639518336 - Loss: 0.5620379447937012, aux loss1: 0.9818349480628967, 
		 aux loss2: 0.6433858275413513, total loss: 1.1139428615570068
43th Epoch, 15800th Step, learning rate = 0.008405145895190909 - Loss: 0.42283904552459717, aux loss1: 0.8823992609977722, 
		 aux loss2: 0.5187981724739075, total loss: 0.8950781226158142
<15800th step>
*************************** Test ***************************
time:3m 16s, 15800th Step, Loss: 0.6096059083938599, Mean IoU = 40.713%
************************************************************
43th Epoch, 15805th Step, learning rate = 0.008404636147428536 - Loss: 0.5428218245506287, aux loss1: 1.1322132349014282, 
		 aux loss2: 0.7223517298698425, total loss: 1.17142653465271
43th Epoch, 15810th Step, learning rate = 0.008404126396230963 - Loss: 0.3031756579875946, aux loss1: 0.7324009537696838, 
		 aux loss2: 0.3943912982940674, total loss: 0.6806524395942688
43th Epoch, 15815th Step, learning rate = 0.008403616641597934 - Loss: 0.4706752300262451, aux loss1: 0.9382702112197876, 
		 aux loss2: 0.5922811627388, total loss: 0.9890688061714172
43th Epoch, 15820th Step, learning rate = 0.008403106883529195 - Loss: 0.2854662239551544, aux loss1: 0.7818313837051392, 
		 aux loss2: 0.3804774582386017, total loss: 0.6722066402435303
43th Epoch, 15825th Step, learning rate = 0.00840259712202449 - Loss: 0.4548584818840027, aux loss1: 1.0257657766342163, 
		 aux loss2: 0.5970731973648071, total loss: 1.0014175176620483
43th Epoch, 15830th Step, learning rate = 0.008402087357083567 - Loss: 0.5062575340270996, aux loss1: 0.9957468509674072, 
		 aux loss2: 0.6252753734588623, total loss: 1.0550917387008667
43th Epoch, 15835th Step, learning rate = 0.008401577588706167 - Loss: 0.3907816410064697, aux loss1: 0.8196190595626831, 
		 aux loss2: 0.48856228590011597, total loss: 0.83209228515625
43th Epoch, 15840th Step, learning rate = 0.00840106781689204 - Loss: 0.46358633041381836, aux loss1: 0.9699405431747437, 
		 aux loss2: 0.5817780494689941, total loss: 0.9872797727584839
43th Epoch, 15845th Step, learning rate = 0.008400558041640926 - Loss: 0.4915754795074463, aux loss1: 0.9572599530220032, 
		 aux loss2: 0.5969983339309692, total loss: 1.0175528526306152
43th Epoch, 15850th Step, learning rate = 0.008400048262952573 - Loss: 0.5476931929588318, aux loss1: 1.0177582502365112, 
		 aux loss2: 0.6639706492424011, total loss: 1.1186089515686035
43th Epoch, 15855th Step, learning rate = 0.008399538480826725 - Loss: 0.3166297674179077, aux loss1: 0.7596378326416016, 
		 aux loss2: 0.393299400806427, total loss: 0.701840877532959
43th Epoch, 15860th Step, learning rate = 0.00839902869526313 - Loss: 0.3456462323665619, aux loss1: 0.9072372913360596, 
		 aux loss2: 0.4517673850059509, total loss: 0.7985243797302246
43th Epoch, 15865th Step, learning rate = 0.00839851890626153 - Loss: 0.48649120330810547, aux loss1: 1.0413858890533447, 
		 aux loss2: 0.6108267307281494, total loss: 1.0432376861572266
43th Epoch, 15870th Step, learning rate = 0.00839800911382167 - Loss: 0.4003823399543762, aux loss1: 0.8072285652160645, 
		 aux loss2: 0.4810413122177124, total loss: 0.8349674940109253
43th Epoch, 15875th Step, learning rate = 0.008397499317943296 - Loss: 0.40914514660835266, aux loss1: 0.8611902594566345, 
		 aux loss2: 0.5082710385322571, total loss: 0.8708106279373169
43th Epoch, 15880th Step, learning rate = 0.008396989518626153 - Loss: 0.38778257369995117, aux loss1: 0.8504437804222107, 
		 aux loss2: 0.486236035823822, total loss: 0.8374101519584656
43th Epoch, 15885th Step, learning rate = 0.008396479715869983 - Loss: 0.42341867089271545, aux loss1: 0.9567196369171143, 
		 aux loss2: 0.5461134910583496, total loss: 0.928879976272583
43th Epoch, 15890th Step, learning rate = 0.008395969909674533 - Loss: 0.42708852887153625, aux loss1: 0.8799939155578613, 
		 aux loss2: 0.5175085067749023, total loss: 0.898090124130249
43th Epoch, 15895th Step, learning rate = 0.00839546010003955 - Loss: 0.41225630044937134, aux loss1: 0.9499654769897461, 
		 aux loss2: 0.518707811832428, total loss: 0.9047290682792664
43th Epoch, 15900th Step, learning rate = 0.008394950286964775 - Loss: 0.3731006681919098, aux loss1: 0.7577427625656128, 
		 aux loss2: 0.45112144947052, total loss: 0.780872106552124
<15900th step>
*************************** Test ***************************
time:3m 15s, 15900th Step, Loss: 0.552366316318512, Mean IoU = 40.534%
************************************************************
43th Epoch, 15905th Step, learning rate = 0.008394440470449956 - Loss: 0.5580332279205322, aux loss1: 1.0632797479629517, 
		 aux loss2: 0.6790465116500854, total loss: 1.148635745048523
43th Epoch, 15910th Step, learning rate = 0.008393930650494832 - Loss: 0.49053436517715454, aux loss1: 0.9380607008934021, 
		 aux loss2: 0.5877583026885986, total loss: 1.0070559978485107
43th Epoch, 15915th Step, learning rate = 0.008393420827099153 - Loss: 0.506112277507782, aux loss1: 1.0834041833877563, 
		 aux loss2: 0.6374033093452454, total loss: 1.086094856262207
43th Epoch, 15920th Step, learning rate = 0.008392911000262666 - Loss: 0.3521113097667694, aux loss1: 0.9259849786758423, 
		 aux loss2: 0.4392789304256439, total loss: 0.8056183457374573
43th Epoch, 15925th Step, learning rate = 0.008392401169985107 - Loss: 0.4660608172416687, aux loss1: 0.9126123189926147, 
		 aux loss2: 0.55523681640625, total loss: 0.96193927526474
43th Epoch, 15930th Step, learning rate = 0.008391891336266227 - Loss: 0.3950762450695038, aux loss1: 0.8771603107452393, 
		 aux loss2: 0.5168050527572632, total loss: 0.8649463653564453
43th Epoch, 15935th Step, learning rate = 0.008391381499105769 - Loss: 0.4311167001724243, aux loss1: 0.9422160387039185, 
		 aux loss2: 0.5290625095367432, total loss: 0.9254065752029419
43th Epoch, 15940th Step, learning rate = 0.008390871658503473 - Loss: 0.34635546803474426, aux loss1: 0.7575165033340454, 
		 aux loss2: 0.43863993883132935, total loss: 0.7490664124488831
43th Epoch, 15945th Step, learning rate = 0.008390361814459091 - Loss: 0.3995888829231262, aux loss1: 0.8718489408493042, 
		 aux loss2: 0.510979950428009, total loss: 0.8655354976654053
43th Epoch, 15950th Step, learning rate = 0.008389851966972364 - Loss: 0.3098224103450775, aux loss1: 0.7235953211784363, 
		 aux loss2: 0.3885282278060913, total loss: 0.6823123097419739
44th Epoch, 15955th Step, learning rate = 0.008389342116043034 - Loss: 0.27778711915016174, aux loss1: 0.6761710047721863, 
		 aux loss2: 0.34064048528671265, total loss: 0.6168946623802185
44th Epoch, 15960th Step, learning rate = 0.008388832261670849 - Loss: 0.30478763580322266, aux loss1: 0.7484926581382751, 
		 aux loss2: 0.38629600405693054, total loss: 0.6838538646697998
44th Epoch, 15965th Step, learning rate = 0.008388322403855548 - Loss: 0.33064183592796326, aux loss1: 0.7657719254493713, 
		 aux loss2: 0.4132443368434906, total loss: 0.7256711721420288
44th Epoch, 15970th Step, learning rate = 0.008387812542596884 - Loss: 0.2829493284225464, aux loss1: 0.7360150814056396, 
		 aux loss2: 0.3701915442943573, total loss: 0.6518304347991943
44th Epoch, 15975th Step, learning rate = 0.008387302677894592 - Loss: 0.4152117371559143, aux loss1: 0.9359887838363647, 
		 aux loss2: 0.5259067416191101, total loss: 0.9063711166381836
44th Epoch, 15980th Step, learning rate = 0.00838679280974842 - Loss: 0.3581049144268036, aux loss1: 0.8377326726913452, 
		 aux loss2: 0.4450378119945526, total loss: 0.7874398231506348
44th Epoch, 15985th Step, learning rate = 0.008386282938158114 - Loss: 0.29979297518730164, aux loss1: 0.7497027516365051, 
		 aux loss2: 0.39854997396469116, total loss: 0.6841238141059875
44th Epoch, 15990th Step, learning rate = 0.008385773063123417 - Loss: 0.43866676092147827, aux loss1: 0.9564376473426819, 
		 aux loss2: 0.56397545337677, total loss: 0.9511882662773132
44th Epoch, 15995th Step, learning rate = 0.00838526318464407 - Loss: 0.44327443838119507, aux loss1: 0.9816800355911255, 
		 aux loss2: 0.5684418082237244, total loss: 0.9651551246643066
44th Epoch, 16000th Step, learning rate = 0.00838475330271982 - Loss: 0.36256974935531616, aux loss1: 0.8731963634490967, 
		 aux loss2: 0.45472943782806396, total loss: 0.8064204454421997
<16000th step>
*************************** Test ***************************
time:3m 20s, 16000th Step, Loss: 0.5611339211463928, Mean IoU = 41.157%
************************************************************
44th Epoch, 16005th Step, learning rate = 0.00838424341735041 - Loss: 0.48645734786987305, aux loss1: 1.0039464235305786, 
		 aux loss2: 0.6118147373199463, total loss: 1.03236722946167
44th Epoch, 16010th Step, learning rate = 0.008383733528535586 - Loss: 0.3502689003944397, aux loss1: 0.8918176293373108, 
		 aux loss2: 0.4615956246852875, total loss: 0.8024524450302124
44th Epoch, 16015th Step, learning rate = 0.008383223636275089 - Loss: 0.3814007043838501, aux loss1: 0.8849554061889648, 
		 aux loss2: 0.4670282304286957, total loss: 0.8336986303329468
44th Epoch, 16020th Step, learning rate = 0.008382713740568662 - Loss: 0.3560490608215332, aux loss1: 0.832925021648407, 
		 aux loss2: 0.44413310289382935, total loss: 0.7835798263549805
44th Epoch, 16025th Step, learning rate = 0.008382203841416053 - Loss: 0.34976911544799805, aux loss1: 0.8763369917869568, 
		 aux loss2: 0.451499342918396, total loss: 0.79326993227005
44th Epoch, 16030th Step, learning rate = 0.008381693938817002 - Loss: 0.3410170376300812, aux loss1: 0.7902690172195435, 
		 aux loss2: 0.4138564467430115, total loss: 0.7436403632164001
44th Epoch, 16035th Step, learning rate = 0.008381184032771254 - Loss: 0.32767876982688904, aux loss1: 0.7805126905441284, 
		 aux loss2: 0.42631596326828003, total loss: 0.732358992099762
44th Epoch, 16040th Step, learning rate = 0.008380674123278555 - Loss: 0.3739572763442993, aux loss1: 0.8747378587722778, 
		 aux loss2: 0.47879207134246826, total loss: 0.82789546251297
44th Epoch, 16045th Step, learning rate = 0.008380164210338645 - Loss: 0.39811453223228455, aux loss1: 0.8800616264343262, 
		 aux loss2: 0.4978122115135193, total loss: 0.8612579107284546
44th Epoch, 16050th Step, learning rate = 0.00837965429395127 - Loss: 0.4429287314414978, aux loss1: 0.9399155974388123, 
		 aux loss2: 0.5456193685531616, total loss: 0.9431512355804443
44th Epoch, 16055th Step, learning rate = 0.008379144374116172 - Loss: 0.517609715461731, aux loss1: 1.1988492012023926, 
		 aux loss2: 0.6549960374832153, total loss: 1.1392629146575928
44th Epoch, 16060th Step, learning rate = 0.008378634450833096 - Loss: 0.38429924845695496, aux loss1: 0.8736547231674194, 
		 aux loss2: 0.4960494935512543, total loss: 0.8448154926300049
44th Epoch, 16065th Step, learning rate = 0.008378124524101785 - Loss: 0.3306810259819031, aux loss1: 0.9058244824409485, 
		 aux loss2: 0.4439208209514618, total loss: 0.7799966931343079
44th Epoch, 16070th Step, learning rate = 0.008377614593921981 - Loss: 0.39839333295822144, aux loss1: 0.908631443977356, 
		 aux loss2: 0.4908730387687683, total loss: 0.8673319816589355
44th Epoch, 16075th Step, learning rate = 0.00837710466029343 - Loss: 0.5137825608253479, aux loss1: 0.9330993890762329, 
		 aux loss2: 0.6215275526046753, total loss: 1.042323350906372
44th Epoch, 16080th Step, learning rate = 0.008376594723215875 - Loss: 0.4523884654045105, aux loss1: 0.9066342115402222, 
		 aux loss2: 0.5474541783332825, total loss: 0.9433603882789612
44th Epoch, 16085th Step, learning rate = 0.008376084782689057 - Loss: 0.5680065155029297, aux loss1: 1.0079971551895142, 
		 aux loss2: 0.6738168001174927, total loss: 1.13993239402771
44th Epoch, 16090th Step, learning rate = 0.008375574838712721 - Loss: 0.43087002635002136, aux loss1: 0.9425877332687378, 
		 aux loss2: 0.5276685357093811, total loss: 0.9247137904167175
44th Epoch, 16095th Step, learning rate = 0.008375064891286612 - Loss: 0.5296133756637573, aux loss1: 0.9047141075134277, 
		 aux loss2: 0.6306552290916443, total loss: 1.053289771080017
44th Epoch, 16100th Step, learning rate = 0.008374554940410471 - Loss: 0.4075387418270111, aux loss1: 0.8808403015136719, 
		 aux loss2: 0.5135897994041443, total loss: 0.8772267699241638
<16100th step>
*************************** Test ***************************
time:3m 13s, 16100th Step, Loss: 0.638805627822876, Mean IoU = 38.919%
************************************************************
44th Epoch, 16105th Step, learning rate = 0.00837404498608404 - Loss: 0.3860063850879669, aux loss1: 0.9061298966407776, 
		 aux loss2: 0.5151578783988953, total loss: 0.8639085292816162
44th Epoch, 16110th Step, learning rate = 0.008373535028307065 - Loss: 0.39962753653526306, aux loss1: 0.8776901364326477, 
		 aux loss2: 0.503194272518158, total loss: 0.8642123341560364
44th Epoch, 16115th Step, learning rate = 0.00837302506707929 - Loss: 0.2899653911590576, aux loss1: 0.6896647810935974, 
		 aux loss2: 0.35724174976348877, total loss: 0.6397615671157837
44th Epoch, 16120th Step, learning rate = 0.008372515102400453 - Loss: 0.4587092399597168, aux loss1: 0.9948335886001587, 
		 aux loss2: 0.6051125526428223, total loss: 0.9992043972015381
44th Epoch, 16125th Step, learning rate = 0.008372005134270302 - Loss: 0.33196091651916504, aux loss1: 0.7683502435684204, 
		 aux loss2: 0.41826876997947693, total loss: 0.7297735214233398
44th Epoch, 16130th Step, learning rate = 0.008371495162688578 - Loss: 0.34905382990837097, aux loss1: 0.8375775814056396, 
		 aux loss2: 0.47054073214530945, total loss: 0.7885434627532959
44th Epoch, 16135th Step, learning rate = 0.008370985187655024 - Loss: 0.3309544622898102, aux loss1: 0.8199175000190735, 
		 aux loss2: 0.4270944595336914, total loss: 0.747767448425293
44th Epoch, 16140th Step, learning rate = 0.008370475209169385 - Loss: 0.4149675965309143, aux loss1: 0.9380654692649841, 
		 aux loss2: 0.5044021606445312, total loss: 0.8981481790542603
44th Epoch, 16145th Step, learning rate = 0.008369965227231402 - Loss: 0.5102649927139282, aux loss1: 1.001448631286621, 
		 aux loss2: 0.6498004198074341, total loss: 1.070619821548462
44th Epoch, 16150th Step, learning rate = 0.008369455241840816 - Loss: 0.43529975414276123, aux loss1: 0.9708271622657776, 
		 aux loss2: 0.5550739169120789, total loss: 0.9485775232315063
44th Epoch, 16155th Step, learning rate = 0.008368945252997374 - Loss: 0.32469984889030457, aux loss1: 0.897806704044342, 
		 aux loss2: 0.44005799293518066, total loss: 0.7700650691986084
44th Epoch, 16160th Step, learning rate = 0.008368435260700816 - Loss: 0.401619017124176, aux loss1: 0.9785034656524658, 
		 aux loss2: 0.5385439395904541, total loss: 0.9105876088142395
44th Epoch, 16165th Step, learning rate = 0.008367925264950886 - Loss: 0.3438412845134735, aux loss1: 0.8375718593597412, 
		 aux loss2: 0.45088666677474976, total loss: 0.7754675149917603
44th Epoch, 16170th Step, learning rate = 0.008367415265747326 - Loss: 0.512218713760376, aux loss1: 0.9970710873603821, 
		 aux loss2: 0.5977880358695984, total loss: 1.0504553318023682
44th Epoch, 16175th Step, learning rate = 0.00836690526308988 - Loss: 0.42761296033859253, aux loss1: 0.8806686401367188, 
		 aux loss2: 0.5094538927078247, total loss: 0.895595133304596
44th Epoch, 16180th Step, learning rate = 0.00836639525697829 - Loss: 0.3716479539871216, aux loss1: 0.8303137421607971, 
		 aux loss2: 0.46859249472618103, total loss: 0.8081790804862976
44th Epoch, 16185th Step, learning rate = 0.008365885247412299 - Loss: 0.3426780104637146, aux loss1: 0.7487895488739014, 
		 aux loss2: 0.41328591108322144, total loss: 0.7326292395591736
44th Epoch, 16190th Step, learning rate = 0.008365375234391648 - Loss: 0.4750731587409973, aux loss1: 1.1788647174835205, 
		 aux loss2: 0.6404122114181519, total loss: 1.084897518157959
44th Epoch, 16195th Step, learning rate = 0.00836486521791608 - Loss: 0.39088207483291626, aux loss1: 0.904905378818512, 
		 aux loss2: 0.5265661478042603, total loss: 0.8729801774024963
44th Epoch, 16200th Step, learning rate = 0.008364355197985339 - Loss: 0.39824673533439636, aux loss1: 0.8613460063934326, 
		 aux loss2: 0.4817672371864319, total loss: 0.8493574261665344
<16200th step>
*************************** Test ***************************
time:3m 14s, 16200th Step, Loss: 0.7346833348274231, Mean IoU = 36.069%
************************************************************
44th Epoch, 16205th Step, learning rate = 0.008363845174599167 - Loss: 0.3367721140384674, aux loss1: 0.7572816610336304, 
		 aux loss2: 0.4499998390674591, total loss: 0.7439565658569336
44th Epoch, 16210th Step, learning rate = 0.008363335147757306 - Loss: 0.4559728503227234, aux loss1: 0.8785979151725769, 
		 aux loss2: 0.5466579794883728, total loss: 0.9382154941558838
44th Epoch, 16215th Step, learning rate = 0.008362825117459498 - Loss: 0.5179812908172607, aux loss1: 0.9874898791313171, 
		 aux loss2: 0.6165996789932251, total loss: 1.0608681440353394
44th Epoch, 16220th Step, learning rate = 0.008362315083705486 - Loss: 0.3258225619792938, aux loss1: 0.8463621735572815, 
		 aux loss2: 0.4313207268714905, total loss: 0.7522594928741455
44th Epoch, 16225th Step, learning rate = 0.008361805046495014 - Loss: 0.535613477230072, aux loss1: 1.1100854873657227, 
		 aux loss2: 0.7069807648658752, total loss: 1.1514314413070679
44th Epoch, 16230th Step, learning rate = 0.00836129500582782 - Loss: 0.54653000831604, aux loss1: 1.0635356903076172, 
		 aux loss2: 0.6787987947463989, total loss: 1.1371102333068848
44th Epoch, 16235th Step, learning rate = 0.008360784961703652 - Loss: 0.6529497504234314, aux loss1: 1.1755372285842896, 
		 aux loss2: 0.778461754322052, total loss: 1.316995620727539
44th Epoch, 16240th Step, learning rate = 0.008360274914122248 - Loss: 0.5694160461425781, aux loss1: 1.176750659942627, 
		 aux loss2: 0.7060061097145081, total loss: 1.2048437595367432
44th Epoch, 16245th Step, learning rate = 0.00835976486308335 - Loss: 0.382316529750824, aux loss1: 0.8456985354423523, 
		 aux loss2: 0.4760173559188843, total loss: 0.8264330625534058
44th Epoch, 16250th Step, learning rate = 0.008359254808586701 - Loss: 0.4635680317878723, aux loss1: 1.0906686782836914, 
		 aux loss2: 0.595309853553772, total loss: 1.0288925170898438
44th Epoch, 16255th Step, learning rate = 0.008358744750632047 - Loss: 0.363770455121994, aux loss1: 0.7932459712028503, 
		 aux loss2: 0.45049217343330383, total loss: 0.7819411158561707
44th Epoch, 16260th Step, learning rate = 0.008358234689219124 - Loss: 0.38976261019706726, aux loss1: 0.87453693151474, 
		 aux loss2: 0.4932028651237488, total loss: 0.8494048118591309
44th Epoch, 16265th Step, learning rate = 0.008357724624347678 - Loss: 0.4120270311832428, aux loss1: 0.8122895956039429, 
		 aux loss2: 0.48264962434768677, total loss: 0.8487737774848938
44th Epoch, 16270th Step, learning rate = 0.008357214556017449 - Loss: 0.4856511652469635, aux loss1: 1.0750387907028198, 
		 aux loss2: 0.6307175755500793, total loss: 1.0604498386383057
44th Epoch, 16275th Step, learning rate = 0.00835670448422818 - Loss: 0.3469143211841583, aux loss1: 0.7866827845573425, 
		 aux loss2: 0.44556859135627747, total loss: 0.761146605014801
44th Epoch, 16280th Step, learning rate = 0.008356194408979615 - Loss: 0.5536922216415405, aux loss1: 1.0902612209320068, 
		 aux loss2: 0.6453811526298523, total loss: 1.1389230489730835
44th Epoch, 16285th Step, learning rate = 0.008355684330271491 - Loss: 0.30798912048339844, aux loss1: 0.7284137606620789, 
		 aux loss2: 0.4009254276752472, total loss: 0.6868834495544434
44th Epoch, 16290th Step, learning rate = 0.008355174248103555 - Loss: 0.4491922855377197, aux loss1: 0.9668176770210266, 
		 aux loss2: 0.557409942150116, total loss: 0.9622015953063965
44th Epoch, 16295th Step, learning rate = 0.008354664162475545 - Loss: 0.2995787262916565, aux loss1: 0.795868456363678, 
		 aux loss2: 0.38532790541648865, total loss: 0.6924704313278198
44th Epoch, 16300th Step, learning rate = 0.008354154073387203 - Loss: 0.7936840653419495, aux loss1: 1.4411998987197876, 
		 aux loss2: 0.9846190810203552, total loss: 1.61989164352417
<16300th step>
*************************** Test ***************************
time:3m 21s, 16300th Step, Loss: 0.5594788789749146, Mean IoU = 40.832%
************************************************************
44th Epoch, 16305th Step, learning rate = 0.008353643980838274 - Loss: 0.3601687550544739, aux loss1: 0.9207068085670471, 
		 aux loss2: 0.4616115689277649, total loss: 0.8210254311561584
44th Epoch, 16310th Step, learning rate = 0.008353133884828497 - Loss: 0.4049944579601288, aux loss1: 0.9389134049415588, 
		 aux loss2: 0.5194105505943298, total loss: 0.8944327235221863
44th Epoch, 16315th Step, learning rate = 0.008352623785357614 - Loss: 0.407391220331192, aux loss1: 0.7873055338859558, 
		 aux loss2: 0.4762437641620636, total loss: 0.8340803980827332
44th Epoch, 16320th Step, learning rate = 0.008352113682425368 - Loss: 0.4137919545173645, aux loss1: 0.8346135020256042, 
		 aux loss2: 0.5001306533813477, total loss: 0.8642282485961914
45th Epoch, 16325th Step, learning rate = 0.0083516035760315 - Loss: 0.371489018201828, aux loss1: 0.7896481156349182, 
		 aux loss2: 0.454310804605484, total loss: 0.790107786655426
45th Epoch, 16330th Step, learning rate = 0.00835109346617575 - Loss: 0.3283088803291321, aux loss1: 0.8719746470451355, 
		 aux loss2: 0.4608764350414276, total loss: 0.7742519378662109
45th Epoch, 16335th Step, learning rate = 0.008350583352857861 - Loss: 0.39991337060928345, aux loss1: 0.8850868344306946, 
		 aux loss2: 0.5290520191192627, total loss: 0.8770602345466614
45th Epoch, 16340th Step, learning rate = 0.008350073236077574 - Loss: 0.3601836562156677, aux loss1: 0.8118632435798645, 
		 aux loss2: 0.45916152000427246, total loss: 0.7874072790145874
45th Epoch, 16345th Step, learning rate = 0.008349563115834633 - Loss: 0.3999827802181244, aux loss1: 1.0362416505813599, 
		 aux loss2: 0.5504237413406372, total loss: 0.9310247302055359
45th Epoch, 16350th Step, learning rate = 0.008349052992128776 - Loss: 0.33854103088378906, aux loss1: 0.7550644278526306, 
		 aux loss2: 0.42137613892555237, total loss: 0.7336108684539795
45th Epoch, 16355th Step, learning rate = 0.008348542864959743 - Loss: 0.3076801598072052, aux loss1: 0.7422354221343994, 
		 aux loss2: 0.3946022391319275, total loss: 0.6881917119026184
45th Epoch, 16360th Step, learning rate = 0.008348032734327281 - Loss: 0.3452872633934021, aux loss1: 0.7883639335632324, 
		 aux loss2: 0.45231229066848755, total loss: 0.7627214193344116
45th Epoch, 16365th Step, learning rate = 0.008347522600231128 - Loss: 0.39576786756515503, aux loss1: 0.890338122844696, 
		 aux loss2: 0.5299943089485168, total loss: 0.8748670816421509
45th Epoch, 16370th Step, learning rate = 0.008347012462671026 - Loss: 0.3636282980442047, aux loss1: 0.8555206060409546, 
		 aux loss2: 0.4834587275981903, total loss: 0.8136680126190186
45th Epoch, 16375th Step, learning rate = 0.008346502321646713 - Loss: 0.2523530423641205, aux loss1: 0.7030248641967773, 
		 aux loss2: 0.34010300040245056, total loss: 0.5993017554283142
45th Epoch, 16380th Step, learning rate = 0.008345992177157936 - Loss: 0.35387086868286133, aux loss1: 0.8393915891647339, 
		 aux loss2: 0.4467751979827881, total loss: 0.7843984365463257
45th Epoch, 16385th Step, learning rate = 0.008345482029204432 - Loss: 0.3673195540904999, aux loss1: 1.0582267045974731, 
		 aux loss2: 0.5382895469665527, total loss: 0.9001033902168274
45th Epoch, 16390th Step, learning rate = 0.008344971877785944 - Loss: 0.6645801663398743, aux loss1: 1.2417466640472412, 
		 aux loss2: 0.8397576212882996, total loss: 1.3730071783065796
45th Epoch, 16395th Step, learning rate = 0.008344461722902211 - Loss: 0.40313008427619934, aux loss1: 0.9919672012329102, 
		 aux loss2: 0.5572388768196106, total loss: 0.9236158132553101
45th Epoch, 16400th Step, learning rate = 0.008343951564552978 - Loss: 0.4457191228866577, aux loss1: 1.0330318212509155, 
		 aux loss2: 0.5870688557624817, total loss: 0.990456223487854
<16400th step>
*************************** Test ***************************
time:3m 18s, 16400th Step, Loss: 0.643927812576294, Mean IoU = 40.746%
************************************************************
45th Epoch, 16405th Step, learning rate = 0.008343441402737982 - Loss: 0.43406182527542114, aux loss1: 0.9694178104400635, 
		 aux loss2: 0.5708042979240417, total loss: 0.9532089233398438
45th Epoch, 16410th Step, learning rate = 0.008342931237456965 - Loss: 0.369241863489151, aux loss1: 0.8044055700302124, 
		 aux loss2: 0.4748328626155853, total loss: 0.8004966974258423
45th Epoch, 16415th Step, learning rate = 0.00834242106870967 - Loss: 0.34225788712501526, aux loss1: 0.8965520858764648, 
		 aux loss2: 0.4486548900604248, total loss: 0.7906854748725891
45th Epoch, 16420th Step, learning rate = 0.008341910896495837 - Loss: 0.3402242958545685, aux loss1: 0.824609100818634, 
		 aux loss2: 0.44255444407463074, total loss: 0.7646288275718689
45th Epoch, 16425th Step, learning rate = 0.008341400720815205 - Loss: 0.3456372916698456, aux loss1: 0.8003893494606018, 
		 aux loss2: 0.43808743357658386, total loss: 0.7609890699386597
45th Epoch, 16430th Step, learning rate = 0.008340890541667515 - Loss: 0.3738270103931427, aux loss1: 0.8187164664268494, 
		 aux loss2: 0.4634834825992584, total loss: 0.8048353791236877
45th Epoch, 16435th Step, learning rate = 0.008340380359052511 - Loss: 0.37487366795539856, aux loss1: 0.8868637681007385, 
		 aux loss2: 0.4836066663265228, total loss: 0.8343755006790161
45th Epoch, 16440th Step, learning rate = 0.008339870172969931 - Loss: 0.38841012120246887, aux loss1: 0.8562142252922058, 
		 aux loss2: 0.486160546541214, total loss: 0.8397386074066162
45th Epoch, 16445th Step, learning rate = 0.008339359983419515 - Loss: 0.5668404698371887, aux loss1: 1.1750202178955078, 
		 aux loss2: 0.7508255243301392, total loss: 1.2196767330169678
45th Epoch, 16450th Step, learning rate = 0.008338849790401007 - Loss: 0.3853406608104706, aux loss1: 0.8636661171913147, 
		 aux loss2: 0.47529125213623047, total loss: 0.834557056427002
45th Epoch, 16455th Step, learning rate = 0.008338339593914145 - Loss: 0.6470555663108826, aux loss1: 1.2558163404464722, 
		 aux loss2: 0.8032416105270386, total loss: 1.3450971841812134
45th Epoch, 16460th Step, learning rate = 0.008337829393958671 - Loss: 0.4958699345588684, aux loss1: 0.9866629838943481, 
		 aux loss2: 0.6159181594848633, total loss: 1.0382360219955444
45th Epoch, 16465th Step, learning rate = 0.008337319190534325 - Loss: 0.39411675930023193, aux loss1: 0.8693121075630188, 
		 aux loss2: 0.500214695930481, total loss: 0.8549963235855103
45th Epoch, 16470th Step, learning rate = 0.008336808983640849 - Loss: 0.39900559186935425, aux loss1: 0.914646565914154, 
		 aux loss2: 0.49947860836982727, total loss: 0.8731909990310669
45th Epoch, 16475th Step, learning rate = 0.008336298773277979 - Loss: 0.4726813733577728, aux loss1: 0.9995671510696411, 
		 aux loss2: 0.6332719326019287, total loss: 1.02586030960083
45th Epoch, 16480th Step, learning rate = 0.00833578855944546 - Loss: 0.5108112096786499, aux loss1: 0.8896524906158447, 
		 aux loss2: 0.5992762446403503, total loss: 1.0174174308776855
45th Epoch, 16485th Step, learning rate = 0.00833527834214303 - Loss: 0.4800024628639221, aux loss1: 1.0434212684631348, 
		 aux loss2: 0.598214864730835, total loss: 1.0323147773742676
45th Epoch, 16490th Step, learning rate = 0.008334768121370432 - Loss: 0.35379454493522644, aux loss1: 0.8299754858016968, 
		 aux loss2: 0.4403226375579834, total loss: 0.7789162397384644
45th Epoch, 16495th Step, learning rate = 0.008334257897127405 - Loss: 0.311771959066391, aux loss1: 0.7575638294219971, 
		 aux loss2: 0.3831331729888916, total loss: 0.6922943592071533
45th Epoch, 16500th Step, learning rate = 0.008333747669413688 - Loss: 0.5082074403762817, aux loss1: 1.0469069480895996, 
		 aux loss2: 0.645628035068512, total loss: 1.0805307626724243
<16500th step>
*************************** Test ***************************
time:3m 15s, 16500th Step, Loss: 0.5762622952461243, Mean IoU = 40.251%
************************************************************
45th Epoch, 16505th Step, learning rate = 0.008333237438229023 - Loss: 0.40680640935897827, aux loss1: 0.9136380553245544, 
		 aux loss2: 0.5045459270477295, total loss: 0.882716178894043
45th Epoch, 16510th Step, learning rate = 0.00833272720357315 - Loss: 0.3249339163303375, aux loss1: 0.8106003999710083, 
		 aux loss2: 0.4308861196041107, total loss: 0.7404685020446777
45th Epoch, 16515th Step, learning rate = 0.008332216965445807 - Loss: 0.3587642014026642, aux loss1: 0.7749168276786804, 
		 aux loss2: 0.4446761906147003, total loss: 0.7691097259521484
45th Epoch, 16520th Step, learning rate = 0.008331706723846737 - Loss: 0.3772084712982178, aux loss1: 0.8697483539581299, 
		 aux loss2: 0.4804416298866272, total loss: 0.8303096294403076
45th Epoch, 16525th Step, learning rate = 0.00833119647877568 - Loss: 0.3713139295578003, aux loss1: 0.931964635848999, 
		 aux loss2: 0.4874117970466614, total loss: 0.8458680510520935
45th Epoch, 16530th Step, learning rate = 0.008330686230232373 - Loss: 0.4067601263523102, aux loss1: 0.9348675608634949, 
		 aux loss2: 0.5145434737205505, total loss: 0.8930377960205078
45th Epoch, 16535th Step, learning rate = 0.00833017597821656 - Loss: 0.33646100759506226, aux loss1: 0.7255913019180298, 
		 aux loss2: 0.4205341637134552, total loss: 0.7223520874977112
45th Epoch, 16540th Step, learning rate = 0.00832966572272798 - Loss: 0.5909029841423035, aux loss1: 1.2119754552841187, 
		 aux loss2: 0.7564283013343811, total loss: 1.2570669651031494
45th Epoch, 16545th Step, learning rate = 0.008329155463766372 - Loss: 0.29451578855514526, aux loss1: 0.726667046546936, 
		 aux loss2: 0.3926905393600464, total loss: 0.6695921421051025
45th Epoch, 16550th Step, learning rate = 0.008328645201331475 - Loss: 0.5432144999504089, aux loss1: 1.0655790567398071, 
		 aux loss2: 0.666398823261261, total loss: 1.1294476985931396
45th Epoch, 16555th Step, learning rate = 0.00832813493542303 - Loss: 0.3426351845264435, aux loss1: 0.8391271233558655, 
		 aux loss2: 0.4533868134021759, total loss: 0.7757281064987183
45th Epoch, 16560th Step, learning rate = 0.00832762466604078 - Loss: 0.4155055582523346, aux loss1: 0.9434624910354614, 
		 aux loss2: 0.5221885442733765, total loss: 0.907419741153717
45th Epoch, 16565th Step, learning rate = 0.008327114393184459 - Loss: 0.3786763548851013, aux loss1: 0.745192289352417, 
		 aux loss2: 0.450525164604187, total loss: 0.7824441194534302
45th Epoch, 16570th Step, learning rate = 0.00832660411685381 - Loss: 0.4858721196651459, aux loss1: 1.073468565940857, 
		 aux loss2: 0.6298941373825073, total loss: 1.0598703622817993
45th Epoch, 16575th Step, learning rate = 0.008326093837048573 - Loss: 0.28869354724884033, aux loss1: 0.7886874079704285, 
		 aux loss2: 0.4044119119644165, total loss: 0.687064528465271
45th Epoch, 16580th Step, learning rate = 0.008325583553768487 - Loss: 0.30869144201278687, aux loss1: 0.7225242257118225, 
		 aux loss2: 0.39690250158309937, total loss: 0.6842097640037537
45th Epoch, 16585th Step, learning rate = 0.008325073267013294 - Loss: 0.3489425480365753, aux loss1: 0.7743558883666992, 
		 aux loss2: 0.4536176323890686, total loss: 0.762696385383606
45th Epoch, 16590th Step, learning rate = 0.008324562976782728 - Loss: 0.37266504764556885, aux loss1: 0.9224274158477783, 
		 aux loss2: 0.49682578444480896, total loss: 0.8481236696243286
45th Epoch, 16595th Step, learning rate = 0.008324052683076535 - Loss: 0.4152897596359253, aux loss1: 0.9248193502426147, 
		 aux loss2: 0.5370446443557739, total loss: 0.9075534343719482
45th Epoch, 16600th Step, learning rate = 0.008323542385894452 - Loss: 0.3971850574016571, aux loss1: 0.8067483901977539, 
		 aux loss2: 0.4773820638656616, total loss: 0.8301624059677124
<16600th step>
*************************** Test ***************************
time:3m 15s, 16600th Step, Loss: 0.6009050607681274, Mean IoU = 40.640%
************************************************************
45th Epoch, 16605th Step, learning rate = 0.008323032085236217 - Loss: 0.47228965163230896, aux loss1: 1.0036717653274536, 
		 aux loss2: 0.5971099138259888, total loss: 1.012235164642334
45th Epoch, 16610th Step, learning rate = 0.00832252178110157 - Loss: 0.47626668214797974, aux loss1: 0.913810670375824, 
		 aux loss2: 0.5644652247428894, total loss: 0.9761959910392761
45th Epoch, 16615th Step, learning rate = 0.008322011473490251 - Loss: 0.45390090346336365, aux loss1: 0.9676727652549744, 
		 aux loss2: 0.5675822496414185, total loss: 0.9712356328964233
45th Epoch, 16620th Step, learning rate = 0.008321501162402002 - Loss: 0.39892494678497314, aux loss1: 0.8325392007827759, 
		 aux loss2: 0.4853898584842682, total loss: 0.8428426384925842
45th Epoch, 16625th Step, learning rate = 0.00832099084783656 - Loss: 0.43475547432899475, aux loss1: 0.960476279258728, 
		 aux loss2: 0.539100706577301, total loss: 0.938538670539856
45th Epoch, 16630th Step, learning rate = 0.008320480529793662 - Loss: 0.4070485234260559, aux loss1: 0.8113328814506531, 
		 aux loss2: 0.48560306429862976, total loss: 0.8446896076202393
45th Epoch, 16635th Step, learning rate = 0.008319970208273053 - Loss: 0.3502481281757355, aux loss1: 0.7646070718765259, 
		 aux loss2: 0.42914479970932007, total loss: 0.7512881755828857
45th Epoch, 16640th Step, learning rate = 0.008319459883274465 - Loss: 0.41235989332199097, aux loss1: 0.9024387001991272, 
		 aux loss2: 0.5163021683692932, total loss: 0.8896123766899109
45th Epoch, 16645th Step, learning rate = 0.008318949554797644 - Loss: 0.3757438063621521, aux loss1: 0.8308628797531128, 
		 aux loss2: 0.4686816930770874, total loss: 0.8124753832817078
45th Epoch, 16650th Step, learning rate = 0.008318439222842327 - Loss: 0.3039339482784271, aux loss1: 0.7334933280944824, 
		 aux loss2: 0.3896314203739166, total loss: 0.6798344850540161
45th Epoch, 16655th Step, learning rate = 0.008317928887408253 - Loss: 0.46375539898872375, aux loss1: 0.9391888380050659, 
		 aux loss2: 0.5678690075874329, total loss: 0.972659707069397
45th Epoch, 16660th Step, learning rate = 0.008317418548495159 - Loss: 0.35067689418792725, aux loss1: 0.7572786808013916, 
		 aux loss2: 0.44791433215141296, total loss: 0.757026195526123
45th Epoch, 16665th Step, learning rate = 0.008316908206102787 - Loss: 0.6114612817764282, aux loss1: 1.1532464027404785, 
		 aux loss2: 0.7672441601753235, total loss: 1.264332890510559
45th Epoch, 16670th Step, learning rate = 0.008316397860230874 - Loss: 0.464923620223999, aux loss1: 0.9544188976287842, 
		 aux loss2: 0.5789443254470825, total loss: 0.9828270673751831
45th Epoch, 16675th Step, learning rate = 0.008315887510879161 - Loss: 0.4579806625843048, aux loss1: 0.9462776780128479, 
		 aux loss2: 0.5998648405075073, total loss: 0.9818099141120911
45th Epoch, 16680th Step, learning rate = 0.008315377158047386 - Loss: 0.34568050503730774, aux loss1: 0.7669063210487366, 
		 aux loss2: 0.4299326241016388, total loss: 0.7477254271507263
45th Epoch, 16685th Step, learning rate = 0.008314866801735288 - Loss: 0.3720310628414154, aux loss1: 0.8133524656295776, 
		 aux loss2: 0.46344780921936035, total loss: 0.8014159798622131
45th Epoch, 16690th Step, learning rate = 0.008314356441942606 - Loss: 0.35477516055107117, aux loss1: 0.8597858548164368, 
		 aux loss2: 0.4577004015445709, total loss: 0.7957911491394043
45th Epoch, 16695th Step, learning rate = 0.008313846078669078 - Loss: 0.40256866812705994, aux loss1: 0.8700161576271057, 
		 aux loss2: 0.49686330556869507, total loss: 0.8623188138008118
46th Epoch, 16700th Step, learning rate = 0.008313335711914442 - Loss: 0.47894495725631714, aux loss1: 1.063810110092163, 
		 aux loss2: 0.6123557090759277, total loss: 1.0430302619934082
<16700th step>
*************************** Test ***************************
time:3m 12s, 16700th Step, Loss: 0.6143271923065186, Mean IoU = 41.255%
************************************************************
46th Epoch, 16705th Step, learning rate = 0.008312825341678442 - Loss: 0.3636111915111542, aux loss1: 0.8372751474380493, 
		 aux loss2: 0.4537408947944641, total loss: 0.7962901592254639
46th Epoch, 16710th Step, learning rate = 0.008312314967960812 - Loss: 0.31031882762908936, aux loss1: 0.7725542783737183, 
		 aux loss2: 0.4273618161678314, total loss: 0.7130298614501953
46th Epoch, 16715th Step, learning rate = 0.00831180459076129 - Loss: 0.3639404773712158, aux loss1: 0.837882399559021, 
		 aux loss2: 0.4745500981807709, total loss: 0.8051252365112305
46th Epoch, 16720th Step, learning rate = 0.008311294210079617 - Loss: 0.3534270226955414, aux loss1: 0.9486246705055237, 
		 aux loss2: 0.46542689204216003, total loss: 0.8241851925849915
46th Epoch, 16725th Step, learning rate = 0.008310783825915533 - Loss: 0.3576969802379608, aux loss1: 0.8644440174102783, 
		 aux loss2: 0.47703438997268677, total loss: 0.8078439831733704
46th Epoch, 16730th Step, learning rate = 0.008310273438268774 - Loss: 0.3668725788593292, aux loss1: 0.8769509196281433, 
		 aux loss2: 0.4976699948310852, total loss: 0.8290258646011353
46th Epoch, 16735th Step, learning rate = 0.008309763047139079 - Loss: 0.3374278247356415, aux loss1: 0.7773687839508057, 
		 aux loss2: 0.42045292258262634, total loss: 0.7388196587562561
46th Epoch, 16740th Step, learning rate = 0.008309252652526187 - Loss: 0.3353850543498993, aux loss1: 0.7599087357521057, 
		 aux loss2: 0.42410001158714294, total loss: 0.732997715473175
46th Epoch, 16745th Step, learning rate = 0.008308742254429836 - Loss: 0.28388917446136475, aux loss1: 0.7204252481460571, 
		 aux loss2: 0.3767545521259308, total loss: 0.6507185697555542
46th Epoch, 16750th Step, learning rate = 0.008308231852849764 - Loss: 0.37044939398765564, aux loss1: 0.8612669706344604, 
		 aux loss2: 0.4844732880592346, total loss: 0.8226187825202942
46th Epoch, 16755th Step, learning rate = 0.008307721447785712 - Loss: 0.42321014404296875, aux loss1: 0.8431594967842102, 
		 aux loss2: 0.503619372844696, total loss: 0.8776057958602905
46th Epoch, 16760th Step, learning rate = 0.008307211039237416 - Loss: 0.36679205298423767, aux loss1: 0.8013822436332703, 
		 aux loss2: 0.46345773339271545, total loss: 0.7925897836685181
46th Epoch, 16765th Step, learning rate = 0.008306700627204615 - Loss: 0.3250500559806824, aux loss1: 0.8492052555084229, 
		 aux loss2: 0.42045003175735474, total loss: 0.747991681098938
46th Epoch, 16770th Step, learning rate = 0.008306190211687048 - Loss: 0.5190809369087219, aux loss1: 1.161714792251587, 
		 aux loss2: 0.6896609663963318, total loss: 1.1434597969055176
46th Epoch, 16775th Step, learning rate = 0.008305679792684453 - Loss: 0.42392322421073914, aux loss1: 0.9450787901878357, 
		 aux loss2: 0.5493141412734985, total loss: 0.9271725416183472
46th Epoch, 16780th Step, learning rate = 0.008305169370196566 - Loss: 0.5182949900627136, aux loss1: 1.0002362728118896, 
		 aux loss2: 0.633267343044281, total loss: 1.071672797203064
46th Epoch, 16785th Step, learning rate = 0.008304658944223128 - Loss: 0.30128931999206543, aux loss1: 0.8031175136566162, 
		 aux loss2: 0.39785435795783997, total loss: 0.7013663053512573
46th Epoch, 16790th Step, learning rate = 0.008304148514763876 - Loss: 0.3997073769569397, aux loss1: 0.9199986457824707, 
		 aux loss2: 0.5065057277679443, total loss: 0.8783092498779297
46th Epoch, 16795th Step, learning rate = 0.008303638081818549 - Loss: 0.3885677754878998, aux loss1: 0.980609655380249, 
		 aux loss2: 0.5748606324195862, total loss: 0.9126949310302734
46th Epoch, 16800th Step, learning rate = 0.008303127645386883 - Loss: 0.4152647852897644, aux loss1: 0.9183644652366638, 
		 aux loss2: 0.5368843674659729, total loss: 0.9055278897285461
<16800th step>
*************************** Test ***************************
time:3m 11s, 16800th Step, Loss: 0.7594727277755737, Mean IoU = 37.807%
************************************************************
46th Epoch, 16805th Step, learning rate = 0.00830261720546862 - Loss: 0.432986855506897, aux loss1: 0.9474941492080688, 
		 aux loss2: 0.5377017855644226, total loss: 0.9323158264160156
46th Epoch, 16810th Step, learning rate = 0.008302106762063492 - Loss: 0.3025937080383301, aux loss1: 0.7880799770355225, 
		 aux loss2: 0.40026816725730896, total loss: 0.6991249322891235
46th Epoch, 16815th Step, learning rate = 0.008301596315171243 - Loss: 0.3525308072566986, aux loss1: 0.8737791776657104, 
		 aux loss2: 0.4538128972053528, total loss: 0.7961897253990173
46th Epoch, 16820th Step, learning rate = 0.008301085864791606 - Loss: 0.3711482584476471, aux loss1: 0.8729305267333984, 
		 aux loss2: 0.4822591245174408, total loss: 0.8259310722351074
46th Epoch, 16825th Step, learning rate = 0.008300575410924323 - Loss: 0.35076573491096497, aux loss1: 0.8325098752975464, 
		 aux loss2: 0.4498157501220703, total loss: 0.7804449796676636
46th Epoch, 16830th Step, learning rate = 0.00830006495356913 - Loss: 0.32997211813926697, aux loss1: 0.8690707683563232, 
		 aux loss2: 0.4152747094631195, total loss: 0.7568032741546631
46th Epoch, 16835th Step, learning rate = 0.008299554492725765 - Loss: 0.3853302299976349, aux loss1: 0.8775601387023926, 
		 aux loss2: 0.4913627505302429, total loss: 0.8451434373855591
46th Epoch, 16840th Step, learning rate = 0.008299044028393964 - Loss: 0.46672821044921875, aux loss1: 1.0121358633041382, 
		 aux loss2: 0.5650783181190491, total loss: 0.9964003562927246
46th Epoch, 16845th Step, learning rate = 0.00829853356057347 - Loss: 0.3701075613498688, aux loss1: 0.8904369473457336, 
		 aux loss2: 0.48480984568595886, total loss: 0.8311625719070435
46th Epoch, 16850th Step, learning rate = 0.008298023089264014 - Loss: 0.48937028646469116, aux loss1: 1.019065260887146, 
		 aux loss2: 0.5893159508705139, total loss: 1.0308161973953247
46th Epoch, 16855th Step, learning rate = 0.00829751261446534 - Loss: 0.43800926208496094, aux loss1: 0.9911211729049683, 
		 aux loss2: 0.5745038986206055, total loss: 0.9651471376419067
46th Epoch, 16860th Step, learning rate = 0.008297002136177178 - Loss: 0.5279980897903442, aux loss1: 1.0321561098098755, 
		 aux loss2: 0.650468111038208, total loss: 1.097832202911377
46th Epoch, 16865th Step, learning rate = 0.008296491654399274 - Loss: 0.2971440255641937, aux loss1: 0.7419949769973755, 
		 aux loss2: 0.3880815804004669, total loss: 0.6749751567840576
46th Epoch, 16870th Step, learning rate = 0.00829598116913136 - Loss: 0.6775075197219849, aux loss1: 1.4072214365005493, 
		 aux loss2: 0.8827283382415771, total loss: 1.4527653455734253
46th Epoch, 16875th Step, learning rate = 0.008295470680373175 - Loss: 0.3725268840789795, aux loss1: 0.8600911498069763, 
		 aux loss2: 0.4796890914440155, total loss: 0.8224298357963562
46th Epoch, 16880th Step, learning rate = 0.008294960188124458 - Loss: 0.45623844861984253, aux loss1: 0.9634743332862854, 
		 aux loss2: 0.5776982307434082, total loss: 0.976360023021698
46th Epoch, 16885th Step, learning rate = 0.008294449692384942 - Loss: 0.52736896276474, aux loss1: 1.145637035369873, 
		 aux loss2: 0.6941276788711548, total loss: 1.1487112045288086
46th Epoch, 16890th Step, learning rate = 0.008293939193154371 - Loss: 0.35523849725723267, aux loss1: 0.8215457797050476, 
		 aux loss2: 0.4451589584350586, total loss: 0.779765784740448
46th Epoch, 16895th Step, learning rate = 0.008293428690432477 - Loss: 0.47933098673820496, aux loss1: 1.0141624212265015, 
		 aux loss2: 0.6094386577606201, total loss: 1.0273551940917969
46th Epoch, 16900th Step, learning rate = 0.008292918184219 - Loss: 0.3140905499458313, aux loss1: 0.7261632680892944, 
		 aux loss2: 0.41564857959747314, total loss: 0.6981989145278931
<16900th step>
*************************** Test ***************************
time:3m 13s, 16900th Step, Loss: 0.6452428698539734, Mean IoU = 40.663%
************************************************************
46th Epoch, 16905th Step, learning rate = 0.008292407674513677 - Loss: 0.4146178960800171, aux loss1: 0.8660774230957031, 
		 aux loss2: 0.5511770248413086, total loss: 0.8949118852615356
46th Epoch, 16910th Step, learning rate = 0.008291897161316243 - Loss: 0.3204825520515442, aux loss1: 0.8057612776756287, 
		 aux loss2: 0.4393048584461212, total loss: 0.7379328608512878
46th Epoch, 16915th Step, learning rate = 0.008291386644626437 - Loss: 0.35198974609375, aux loss1: 0.987881600856781, 
		 aux loss2: 0.4884878993034363, total loss: 0.8437494039535522
46th Epoch, 16920th Step, learning rate = 0.008290876124443998 - Loss: 0.401195764541626, aux loss1: 0.8553354740142822, 
		 aux loss2: 0.48294761776924133, total loss: 0.8509754538536072
46th Epoch, 16925th Step, learning rate = 0.00829036560076866 - Loss: 0.45888346433639526, aux loss1: 0.9240747690200806, 
		 aux loss2: 0.5621745586395264, total loss: 0.9609757661819458
46th Epoch, 16930th Step, learning rate = 0.008289855073600161 - Loss: 0.40027350187301636, aux loss1: 0.8967182636260986, 
		 aux loss2: 0.5117827653884888, total loss: 0.8740020990371704
46th Epoch, 16935th Step, learning rate = 0.00828934454293824 - Loss: 0.46481263637542725, aux loss1: 1.0724257230758667, 
		 aux loss2: 0.588765561580658, total loss: 1.0220465660095215
46th Epoch, 16940th Step, learning rate = 0.008288834008782631 - Loss: 0.5523284077644348, aux loss1: 1.1370751857757568, 
		 aux loss2: 0.6864496469497681, total loss: 1.168030858039856
46th Epoch, 16945th Step, learning rate = 0.008288323471133074 - Loss: 0.4194106161594391, aux loss1: 1.0221256017684937, 
		 aux loss2: 0.5665180087089539, total loss: 0.952655553817749
46th Epoch, 16950th Step, learning rate = 0.008287812929989303 - Loss: 0.3209785223007202, aux loss1: 0.8239520192146301, 
		 aux loss2: 0.43278026580810547, total loss: 0.741276204586029
46th Epoch, 16955th Step, learning rate = 0.008287302385351056 - Loss: 0.34440213441848755, aux loss1: 0.7178054451942444, 
		 aux loss2: 0.4340408742427826, total loss: 0.7333601117134094
46th Epoch, 16960th Step, learning rate = 0.00828679183721807 - Loss: 0.32119014859199524, aux loss1: 0.8205080032348633, 
		 aux loss2: 0.4085877537727356, total loss: 0.7307776808738708
46th Epoch, 16965th Step, learning rate = 0.008286281285590084 - Loss: 0.36856696009635925, aux loss1: 0.8118775486946106, 
		 aux loss2: 0.4621696174144745, total loss: 0.7969980835914612
46th Epoch, 16970th Step, learning rate = 0.008285770730466832 - Loss: 0.36605456471443176, aux loss1: 0.7700325846672058, 
		 aux loss2: 0.4471499025821686, total loss: 0.7759243249893188
46th Epoch, 16975th Step, learning rate = 0.008285260171848054 - Loss: 0.29954156279563904, aux loss1: 0.7914873361587524, 
		 aux loss2: 0.37867939472198486, total loss: 0.6884595155715942
46th Epoch, 16980th Step, learning rate = 0.008284749609733482 - Loss: 0.5398852229118347, aux loss1: 1.080277442932129, 
		 aux loss2: 0.6715375781059265, total loss: 1.132583498954773
46th Epoch, 16985th Step, learning rate = 0.008284239044122853 - Loss: 0.4170616865158081, aux loss1: 0.9619276523590088, 
		 aux loss2: 0.5224047303199768, total loss: 0.9146018624305725
46th Epoch, 16990th Step, learning rate = 0.008283728475015911 - Loss: 0.4153865575790405, aux loss1: 0.8680814504623413, 
		 aux loss2: 0.5127225518226624, total loss: 0.8809000253677368
46th Epoch, 16995th Step, learning rate = 0.008283217902412382 - Loss: 0.3738711476325989, aux loss1: 0.8522278070449829, 
		 aux loss2: 0.46730202436447144, total loss: 0.8164603114128113
46th Epoch, 17000th Step, learning rate = 0.00828270732631201 - Loss: 0.30675509572029114, aux loss1: 0.6596502661705017, 
		 aux loss2: 0.37518659234046936, total loss: 0.6547248363494873
<17000th step>
*************************** Test ***************************
time:3m 12s, 17000th Step, Loss: 0.6060160994529724, Mean IoU = 41.722%
************************************************************
46th Epoch, 17005th Step, learning rate = 0.008282196746714529 - Loss: 0.4301520884037018, aux loss1: 0.9280353784561157, 
		 aux loss2: 0.5426287055015564, total loss: 0.9256142377853394
46th Epoch, 17010th Step, learning rate = 0.008281686163619677 - Loss: 0.33814921975135803, aux loss1: 0.7877916693687439, 
		 aux loss2: 0.4441264569759369, total loss: 0.752137303352356
46th Epoch, 17015th Step, learning rate = 0.00828117557702719 - Loss: 0.39751625061035156, aux loss1: 0.8435265421867371, 
		 aux loss2: 0.5100671648979187, total loss: 0.8546010851860046
46th Epoch, 17020th Step, learning rate = 0.008280664986936801 - Loss: 0.35106322169303894, aux loss1: 0.8136401772499084, 
		 aux loss2: 0.442973792552948, total loss: 0.7723448276519775
46th Epoch, 17025th Step, learning rate = 0.008280154393348251 - Loss: 0.45582759380340576, aux loss1: 1.0578365325927734, 
		 aux loss2: 0.6007797122001648, total loss: 1.0134904384613037
46th Epoch, 17030th Step, learning rate = 0.008279643796261275 - Loss: 0.2605840563774109, aux loss1: 0.6537200212478638, 
		 aux loss2: 0.33921247720718384, total loss: 0.5923850536346436
46th Epoch, 17035th Step, learning rate = 0.008279133195675609 - Loss: 0.31688928604125977, aux loss1: 0.7464333772659302, 
		 aux loss2: 0.38990509510040283, total loss: 0.6967813372612
46th Epoch, 17040th Step, learning rate = 0.008278622591590989 - Loss: 0.3341864347457886, aux loss1: 0.7564297914505005, 
		 aux loss2: 0.4146217107772827, total loss: 0.7269640564918518
46th Epoch, 17045th Step, learning rate = 0.008278111984007151 - Loss: 0.3822396397590637, aux loss1: 0.8229956030845642, 
		 aux loss2: 0.4825472831726074, total loss: 0.8221572637557983
46th Epoch, 17050th Step, learning rate = 0.008277601372923831 - Loss: 0.5111673474311829, aux loss1: 1.0212085247039795, 
		 aux loss2: 0.6428617238998413, total loss: 1.0746746063232422
46th Epoch, 17055th Step, learning rate = 0.008277090758340766 - Loss: 0.37943825125694275, aux loss1: 0.7950326204299927, 
		 aux loss2: 0.47774451971054077, total loss: 0.8090458512306213
46th Epoch, 17060th Step, learning rate = 0.008276580140257693 - Loss: 0.3629675805568695, aux loss1: 0.748522162437439, 
		 aux loss2: 0.4195910096168518, total loss: 0.7553606629371643
46th Epoch, 17065th Step, learning rate = 0.008276069518674345 - Loss: 0.29888519644737244, aux loss1: 0.8104852437973022, 
		 aux loss2: 0.4062572121620178, total loss: 0.7045336961746216
47th Epoch, 17070th Step, learning rate = 0.008275558893590461 - Loss: 0.30810895562171936, aux loss1: 0.9303183555603027, 
		 aux loss2: 0.4380841553211212, total loss: 0.7624381184577942
47th Epoch, 17075th Step, learning rate = 0.008275048265005776 - Loss: 0.3256088197231293, aux loss1: 0.759788453578949, 
		 aux loss2: 0.41553351283073425, total loss: 0.7197587490081787
47th Epoch, 17080th Step, learning rate = 0.008274537632920026 - Loss: 0.3360351026058197, aux loss1: 0.7638020515441895, 
		 aux loss2: 0.43094196915626526, total loss: 0.7375525236129761
47th Epoch, 17085th Step, learning rate = 0.008274026997332947 - Loss: 0.34641507267951965, aux loss1: 0.8259832262992859, 
		 aux loss2: 0.4598487317562103, total loss: 0.7781495451927185
47th Epoch, 17090th Step, learning rate = 0.008273516358244274 - Loss: 0.4174027442932129, aux loss1: 1.1213948726654053, 
		 aux loss2: 0.5512329936027527, total loss: 0.9743144512176514
47th Epoch, 17095th Step, learning rate = 0.008273005715653745 - Loss: 0.4631431996822357, aux loss1: 1.111216425895691, 
		 aux loss2: 0.641292929649353, total loss: 1.053025245666504
47th Epoch, 17100th Step, learning rate = 0.008272495069561094 - Loss: 0.3642072379589081, aux loss1: 0.8656022548675537, 
		 aux loss2: 0.47839635610580444, total loss: 0.8152464628219604
<17100th step>
1th Epoch, 17100th Step, learning rate = 0.008272392939922286 - Loss: 0.36466383934020996, aux loss1: 0.8330886960029602, 
		 aux loss2: 0.47967949509620667, total loss: 0.806462287902832
<17100th step>
*************************** Test ***************************
time:3m 14s, 17100th Step, Loss: 0.5109221339225769, Mean IoU = 42.574%
************************************************************
1th Epoch, 17105th Step, learning rate = 0.00827188228962674 - Loss: 0.3696351945400238, aux loss1: 0.8864374756813049, 
		 aux loss2: 0.48209670186042786, total loss: 0.8284051418304443
1th Epoch, 17110th Step, learning rate = 0.008271371635828492 - Loss: 0.37881672382354736, aux loss1: 0.8517595529556274, 
		 aux loss2: 0.4658128023147583, total loss: 0.8206697106361389
1th Epoch, 17115th Step, learning rate = 0.008270860978527276 - Loss: 0.36231058835983276, aux loss1: 0.8810402154922485, 
		 aux loss2: 0.4697495698928833, total loss: 0.8145225048065186
1th Epoch, 17120th Step, learning rate = 0.008270350317722828 - Loss: 0.43053868412971497, aux loss1: 1.0660823583602905, 
		 aux loss2: 0.6288688778877258, total loss: 1.001910924911499
1th Epoch, 17125th Step, learning rate = 0.008269839653414884 - Loss: 0.46324124932289124, aux loss1: 0.9648371934890747, 
		 aux loss2: 0.5770645141601562, total loss: 0.9835182428359985
1th Epoch, 17130th Step, learning rate = 0.008269328985603182 - Loss: 0.44492772221565247, aux loss1: 0.9873394966125488, 
		 aux loss2: 0.5653464794158936, total loss: 0.967268168926239
1th Epoch, 17135th Step, learning rate = 0.008268818314287453 - Loss: 0.40021058917045593, aux loss1: 0.8706538081169128, 
		 aux loss2: 0.5260963439941406, total loss: 0.8718453049659729
1th Epoch, 17140th Step, learning rate = 0.008268307639467435 - Loss: 0.3574918806552887, aux loss1: 0.9126061797142029, 
		 aux loss2: 0.47551605105400085, total loss: 0.8214801549911499
1th Epoch, 17145th Step, learning rate = 0.008267796961142864 - Loss: 0.39907413721084595, aux loss1: 0.9436246752738953, 
		 aux loss2: 0.513439416885376, total loss: 0.8875373601913452
1th Epoch, 17150th Step, learning rate = 0.008267286279313474 - Loss: 0.3871814012527466, aux loss1: 0.8780781626701355, 
		 aux loss2: 0.4906541407108307, total loss: 0.8468664884567261
1th Epoch, 17155th Step, learning rate = 0.008266775593979 - Loss: 0.42053040862083435, aux loss1: 0.9978881478309631, 
		 aux loss2: 0.5495690703392029, total loss: 0.9397245049476624
1th Epoch, 17160th Step, learning rate = 0.00826626490513918 - Loss: 0.3292204439640045, aux loss1: 0.845716118812561, 
		 aux loss2: 0.4409852623939514, total loss: 0.7593294382095337
1th Epoch, 17165th Step, learning rate = 0.008265754212793746 - Loss: 0.49670225381851196, aux loss1: 1.0449986457824707, 
		 aux loss2: 0.6036693453788757, total loss: 1.0516695976257324
1th Epoch, 17170th Step, learning rate = 0.008265243516942437 - Loss: 0.4099040627479553, aux loss1: 0.943352997303009, 
		 aux loss2: 0.5213816165924072, total loss: 0.9014626145362854
1th Epoch, 17175th Step, learning rate = 0.008264732817584984 - Loss: 0.48950737714767456, aux loss1: 1.0055360794067383, 
		 aux loss2: 0.6205613613128662, total loss: 1.0393927097320557
1th Epoch, 17180th Step, learning rate = 0.008264222114721127 - Loss: 0.4049082398414612, aux loss1: 0.9223368167877197, 
		 aux loss2: 0.5312126874923706, total loss: 0.8940943479537964
1th Epoch, 17185th Step, learning rate = 0.008263711408350596 - Loss: 0.4053569734096527, aux loss1: 0.8908067345619202, 
		 aux loss2: 0.5022490620613098, total loss: 0.8734986782073975
1th Epoch, 17190th Step, learning rate = 0.00826320069847313 - Loss: 0.5163284540176392, aux loss1: 0.9844632744789124, 
		 aux loss2: 0.6243987083435059, total loss: 1.0614268779754639
1th Epoch, 17195th Step, learning rate = 0.008262689985088462 - Loss: 0.4180200397968292, aux loss1: 0.9399898052215576, 
		 aux loss2: 0.5400537252426147, total loss: 0.916038453578949
1th Epoch, 17200th Step, learning rate = 0.008262179268196331 - Loss: 0.36240822076797485, aux loss1: 0.8489624261856079, 
		 aux loss2: 0.47074654698371887, total loss: 0.8053956031799316
<17200th step>
*************************** Test ***************************
time:3m 10s, 17200th Step, Loss: 0.5686235427856445, Mean IoU = 40.204%
************************************************************
1th Epoch, 17205th Step, learning rate = 0.008261668547796464 - Loss: 0.37999898195266724, aux loss1: 0.9008685946464539, 
		 aux loss2: 0.5027780532836914, total loss: 0.8513708114624023
1th Epoch, 17210th Step, learning rate = 0.008261157823888603 - Loss: 0.4990265369415283, aux loss1: 1.1559019088745117, 
		 aux loss2: 0.6743124127388, total loss: 1.1155221462249756
1th Epoch, 17215th Step, learning rate = 0.008260647096472482 - Loss: 0.543242335319519, aux loss1: 1.1769353151321411, 
		 aux loss2: 0.6583957672119141, total loss: 1.1596813201904297
1th Epoch, 17220th Step, learning rate = 0.008260136365547833 - Loss: 0.4333799183368683, aux loss1: 0.9005521535873413, 
		 aux loss2: 0.5469492077827454, total loss: 0.9223252534866333
1th Epoch, 17225th Step, learning rate = 0.008259625631114393 - Loss: 0.6240878105163574, aux loss1: 1.0301997661590576, 
		 aux loss2: 0.6768718361854553, total loss: 1.2038965225219727
1th Epoch, 17230th Step, learning rate = 0.008259114893171896 - Loss: 0.3491336703300476, aux loss1: 0.8282414078712463, 
		 aux loss2: 0.44660258293151855, total loss: 0.7762471437454224
1th Epoch, 17235th Step, learning rate = 0.008258604151720077 - Loss: 0.3446153998374939, aux loss1: 0.821492612361908, 
		 aux loss2: 0.4279862940311432, total loss: 0.7622576951980591
1th Epoch, 17240th Step, learning rate = 0.00825809340675867 - Loss: 0.5625227093696594, aux loss1: 1.08376145362854, 
		 aux loss2: 0.7005631327629089, total loss: 1.1678763628005981
1th Epoch, 17245th Step, learning rate = 0.008257582658287412 - Loss: 0.37697920203208923, aux loss1: 0.7740198373794556, 
		 aux loss2: 0.4495971202850342, total loss: 0.7890239953994751
1th Epoch, 17250th Step, learning rate = 0.008257071906306033 - Loss: 0.42658087611198425, aux loss1: 0.9308549165725708, 
		 aux loss2: 0.5594905614852905, total loss: 0.929633617401123
1th Epoch, 17255th Step, learning rate = 0.008256561150814275 - Loss: 0.4096266031265259, aux loss1: 0.9146213531494141, 
		 aux loss2: 0.5124466419219971, total loss: 0.88899165391922
1th Epoch, 17260th Step, learning rate = 0.008256050391811867 - Loss: 0.42200925946235657, aux loss1: 0.8630633354187012, 
		 aux loss2: 0.5235683917999268, total loss: 0.8903555870056152
1th Epoch, 17265th Step, learning rate = 0.008255539629298545 - Loss: 0.40127262473106384, aux loss1: 0.9788965582847595, 
		 aux loss2: 0.5136675238609314, total loss: 0.9004086256027222
1th Epoch, 17270th Step, learning rate = 0.008255028863274042 - Loss: 0.343410462141037, aux loss1: 0.8040938377380371, 
		 aux loss2: 0.445904940366745, total loss: 0.7630006074905396
1th Epoch, 17275th Step, learning rate = 0.008254518093738096 - Loss: 0.4664778411388397, aux loss1: 1.0355347394943237, 
		 aux loss2: 0.6120296120643616, total loss: 1.021950125694275
1th Epoch, 17280th Step, learning rate = 0.008254007320690437 - Loss: 0.4443584382534027, aux loss1: 0.9728438854217529, 
		 aux loss2: 0.5653420090675354, total loss: 0.962348461151123
1th Epoch, 17285th Step, learning rate = 0.008253496544130804 - Loss: 0.41192132234573364, aux loss1: 0.910464346408844, 
		 aux loss2: 0.5194419622421265, total loss: 0.892837405204773
1th Epoch, 17290th Step, learning rate = 0.008252985764058928 - Loss: 0.448336660861969, aux loss1: 0.9172326922416687, 
		 aux loss2: 0.5505834817886353, total loss: 0.9437398314476013
1th Epoch, 17295th Step, learning rate = 0.008252474980474543 - Loss: 0.4048077166080475, aux loss1: 0.8850626349449158, 
		 aux loss2: 0.4829508364200592, total loss: 0.8635068535804749
1th Epoch, 17300th Step, learning rate = 0.008251964193377388 - Loss: 0.39103055000305176, aux loss1: 0.956490159034729, 
		 aux loss2: 0.5074101686477661, total loss: 0.8809416890144348
<17300th step>
*************************** Test ***************************
time:3m 14s, 17300th Step, Loss: 0.5816358327865601, Mean IoU = 40.584%
************************************************************
1th Epoch, 17305th Step, learning rate = 0.00825145340276719 - Loss: 0.43815603852272034, aux loss1: 0.9990515112876892, 
		 aux loss2: 0.5757592916488647, total loss: 0.9681752324104309
1th Epoch, 17310th Step, learning rate = 0.008250942608643692 - Loss: 0.38205596804618835, aux loss1: 0.8980578184127808, 
		 aux loss2: 0.4968155026435852, total loss: 0.8501994609832764
1th Epoch, 17315th Step, learning rate = 0.008250431811006619 - Loss: 0.4217737019062042, aux loss1: 0.9110662341117859, 
		 aux loss2: 0.5239466428756714, total loss: 0.9046722650527954
1th Epoch, 17320th Step, learning rate = 0.00824992100985571 - Loss: 0.4564249813556671, aux loss1: 0.9550759196281433, 
		 aux loss2: 0.5647097826004028, total loss: 0.9688316583633423
1th Epoch, 17325th Step, learning rate = 0.0082494102051907 - Loss: 0.42322176694869995, aux loss1: 0.9970992803573608, 
		 aux loss2: 0.537663459777832, total loss: 0.9374169111251831
1th Epoch, 17330th Step, learning rate = 0.008248899397011322 - Loss: 0.5668658018112183, aux loss1: 0.9903145432472229, 
		 aux loss2: 0.6762107014656067, total loss: 1.1344444751739502
1th Epoch, 17335th Step, learning rate = 0.008248388585317307 - Loss: 0.31623154878616333, aux loss1: 0.7436367869377136, 
		 aux loss2: 0.4150252342224121, total loss: 0.7053326964378357
1th Epoch, 17340th Step, learning rate = 0.008247877770108394 - Loss: 0.5114372372627258, aux loss1: 0.9543633460998535, 
		 aux loss2: 0.6069697141647339, total loss: 1.0405341386795044
1th Epoch, 17345th Step, learning rate = 0.008247366951384314 - Loss: 0.48375359177589417, aux loss1: 1.1194909811019897, 
		 aux loss2: 0.6300817728042603, total loss: 1.0716336965560913
1th Epoch, 17350th Step, learning rate = 0.008246856129144801 - Loss: 0.4282527267932892, aux loss1: 0.8878470659255981, 
		 aux loss2: 0.5200213193893433, total loss: 0.9026154279708862
1th Epoch, 17355th Step, learning rate = 0.008246345303389588 - Loss: 0.3959164321422577, aux loss1: 0.8978226780891418, 
		 aux loss2: 0.5143864154815674, total loss: 0.8710178136825562
1th Epoch, 17360th Step, learning rate = 0.008245834474118413 - Loss: 0.4057016670703888, aux loss1: 0.8237544298171997, 
		 aux loss2: 0.4951168894767761, total loss: 0.8508747220039368
1th Epoch, 17365th Step, learning rate = 0.008245323641331005 - Loss: 0.41210055351257324, aux loss1: 0.9516518712043762, 
		 aux loss2: 0.5182520747184753, total loss: 0.9048969745635986
1th Epoch, 17370th Step, learning rate = 0.0082448128050271 - Loss: 0.283564031124115, aux loss1: 0.6672329902648926, 
		 aux loss2: 0.35973525047302246, total loss: 0.6276280879974365
1th Epoch, 17375th Step, learning rate = 0.00824430196520643 - Loss: 0.4007052183151245, aux loss1: 0.8815712332725525, 
		 aux loss2: 0.5070602297782898, total loss: 0.8680007457733154
1th Epoch, 17380th Step, learning rate = 0.008243791121868732 - Loss: 0.39903712272644043, aux loss1: 0.8300209641456604, 
		 aux loss2: 0.487012654542923, total loss: 0.8428484797477722
1th Epoch, 17385th Step, learning rate = 0.008243280275013736 - Loss: 0.36325475573539734, aux loss1: 0.8359488248825073, 
		 aux loss2: 0.4647860527038574, total loss: 0.799953818321228
1th Epoch, 17390th Step, learning rate = 0.008242769424641177 - Loss: 0.4980761706829071, aux loss1: 1.0043505430221558, 
		 aux loss2: 0.621174693107605, total loss: 1.0478512048721313
1th Epoch, 17395th Step, learning rate = 0.008242258570750791 - Loss: 0.43102899193763733, aux loss1: 0.9586321711540222, 
		 aux loss2: 0.5520554780960083, total loss: 0.9394408464431763
1th Epoch, 17400th Step, learning rate = 0.008241747713342308 - Loss: 0.32557910680770874, aux loss1: 0.7425060868263245, 
		 aux loss2: 0.39437320828437805, total loss: 0.7060802578926086
<17400th step>
*************************** Test ***************************
time:3m 12s, 17400th Step, Loss: 0.5849506258964539, Mean IoU = 39.727%
************************************************************
1th Epoch, 17405th Step, learning rate = 0.008241236852415462 - Loss: 0.385206401348114, aux loss1: 0.8443601727485657, 
		 aux loss2: 0.46855810284614563, total loss: 0.8259376883506775
1th Epoch, 17410th Step, learning rate = 0.008240725987969988 - Loss: 0.5926384925842285, aux loss1: 1.185340404510498, 
		 aux loss2: 0.7566981911659241, total loss: 1.2509199380874634
1th Epoch, 17415th Step, learning rate = 0.008240215120005619 - Loss: 0.3353630602359772, aux loss1: 0.7706305980682373, 
		 aux loss2: 0.4400988221168518, total loss: 0.7425917983055115
1th Epoch, 17420th Step, learning rate = 0.008239704248522087 - Loss: 0.5690755844116211, aux loss1: 1.1186867952346802, 
		 aux loss2: 0.7320300936698914, total loss: 1.1974936723709106
1th Epoch, 17425th Step, learning rate = 0.008239193373519124 - Loss: 0.3583884835243225, aux loss1: 0.7308961153030396, 
		 aux loss2: 0.4290843605995178, total loss: 0.7492910623550415
1th Epoch, 17430th Step, learning rate = 0.008238682494996468 - Loss: 0.5437206625938416, aux loss1: 1.0104727745056152, 
		 aux loss2: 0.6375648975372314, total loss: 1.1018884181976318
1th Epoch, 17435th Step, learning rate = 0.008238171612953852 - Loss: 0.39416101574897766, aux loss1: 0.8088970184326172, 
		 aux loss2: 0.4879376292228699, total loss: 0.8320052027702332
1th Epoch, 17440th Step, learning rate = 0.008237660727391002 - Loss: 0.5005632638931274, aux loss1: 1.1408683061599731, 
		 aux loss2: 0.6459218263626099, total loss: 1.1011924743652344
1th Epoch, 17445th Step, learning rate = 0.008237149838307659 - Loss: 0.40575188398361206, aux loss1: 0.912760853767395, 
		 aux loss2: 0.5034363269805908, total loss: 0.8809546828269958
1th Epoch, 17450th Step, learning rate = 0.008236638945703555 - Loss: 0.4002396762371063, aux loss1: 0.8850108981132507, 
		 aux loss2: 0.5221709609031677, total loss: 0.8746113777160645
1th Epoch, 17455th Step, learning rate = 0.008236128049578417 - Loss: 0.3556480407714844, aux loss1: 0.8027279376983643, 
		 aux loss2: 0.44834136962890625, total loss: 0.7758029699325562
1th Epoch, 17460th Step, learning rate = 0.008235617149931984 - Loss: 0.3608814775943756, aux loss1: 0.8488978743553162, 
		 aux loss2: 0.46582460403442383, total loss: 0.8018807172775269
1th Epoch, 17465th Step, learning rate = 0.008235106246763988 - Loss: 0.4010069966316223, aux loss1: 0.9413614273071289, 
		 aux loss2: 0.5069013833999634, total loss: 0.8861759901046753
1th Epoch, 17470th Step, learning rate = 0.008234595340074162 - Loss: 0.5313594341278076, aux loss1: 1.1130915880203247, 
		 aux loss2: 0.6632609367370605, total loss: 1.1305913925170898
2th Epoch, 17475th Step, learning rate = 0.008234084429862237 - Loss: 0.46534183621406555, aux loss1: 0.9574565291404724, 
		 aux loss2: 0.5723884701728821, total loss: 0.9815341830253601
2th Epoch, 17480th Step, learning rate = 0.008233573516127949 - Loss: 0.4297802150249481, aux loss1: 0.8721433281898499, 
		 aux loss2: 0.503911018371582, total loss: 0.8929876685142517
2th Epoch, 17485th Step, learning rate = 0.008233062598871027 - Loss: 0.4008813202381134, aux loss1: 0.8399801850318909, 
		 aux loss2: 0.510470986366272, total loss: 0.8570638298988342
2th Epoch, 17490th Step, learning rate = 0.008232551678091208 - Loss: 0.41164326667785645, aux loss1: 0.8545185923576355, 
		 aux loss2: 0.5099143981933594, total loss: 0.8719646334648132
2th Epoch, 17495th Step, learning rate = 0.008232040753788219 - Loss: 0.3953757882118225, aux loss1: 0.8520849347114563, 
		 aux loss2: 0.48654523491859436, total loss: 0.8456193804740906
2th Epoch, 17500th Step, learning rate = 0.008231529825961799 - Loss: 0.37874189019203186, aux loss1: 0.835259199142456, 
		 aux loss2: 0.4634491205215454, total loss: 0.8146992921829224
<17500th step>
*************************** Test ***************************
time:3m 19s, 17500th Step, Loss: 0.5648247003555298, Mean IoU = 40.955%
************************************************************
1th Epoch, 17505th Step, learning rate = 0.008231018894611678 - Loss: 0.3383597433567047, aux loss1: 0.8011658787727356, 
		 aux loss2: 0.43724480271339417, total loss: 0.7536073923110962
1th Epoch, 17510th Step, learning rate = 0.008230507959737588 - Loss: 0.4354105293750763, aux loss1: 0.8418266177177429, 
		 aux loss2: 0.537693977355957, total loss: 0.9030361175537109
1th Epoch, 17515th Step, learning rate = 0.008229997021339261 - Loss: 0.35099563002586365, aux loss1: 0.8361552953720093, 
		 aux loss2: 0.4474678635597229, total loss: 0.7808293700218201
1th Epoch, 17520th Step, learning rate = 0.008229486079416435 - Loss: 0.3537044823169708, aux loss1: 0.9538878798484802, 
		 aux loss2: 0.4830784499645233, total loss: 0.833102285861969
1th Epoch, 17525th Step, learning rate = 0.008228975133968834 - Loss: 0.4144957363605499, aux loss1: 0.9472606182098389, 
		 aux loss2: 0.5263288021087646, total loss: 0.9092054963111877
1th Epoch, 17530th Step, learning rate = 0.008228464184996198 - Loss: 0.32235705852508545, aux loss1: 0.8254892230033875, 
		 aux loss2: 0.44378918409347534, total loss: 0.7475195527076721
1th Epoch, 17535th Step, learning rate = 0.008227953232498256 - Loss: 0.6043211817741394, aux loss1: 1.152637243270874, 
		 aux loss2: 0.7507104277610779, total loss: 1.250396490097046
1th Epoch, 17540th Step, learning rate = 0.00822744227647474 - Loss: 0.3865111768245697, aux loss1: 0.8377713561058044, 
		 aux loss2: 0.4802655577659607, total loss: 0.8299488425254822
1th Epoch, 17545th Step, learning rate = 0.008226931316925383 - Loss: 0.36158818006515503, aux loss1: 0.8588277697563171, 
		 aux loss2: 0.47682273387908936, total loss: 0.8099656105041504
1th Epoch, 17550th Step, learning rate = 0.008226420353849918 - Loss: 0.40255582332611084, aux loss1: 0.8643087148666382, 
		 aux loss2: 0.5164721012115479, total loss: 0.8684372901916504
1th Epoch, 17555th Step, learning rate = 0.008225909387248077 - Loss: 0.433940589427948, aux loss1: 0.9212415814399719, 
		 aux loss2: 0.5796024799346924, total loss: 0.942154049873352
1th Epoch, 17560th Step, learning rate = 0.008225398417119592 - Loss: 0.5047255754470825, aux loss1: 1.0817164182662964, 
		 aux loss2: 0.642524778842926, total loss: 1.0862504243850708
1th Epoch, 17565th Step, learning rate = 0.008224887443464196 - Loss: 0.38890573382377625, aux loss1: 0.8564233779907227, 
		 aux loss2: 0.4931565523147583, total loss: 0.8430954217910767
1th Epoch, 17570th Step, learning rate = 0.008224376466281621 - Loss: 0.5027366876602173, aux loss1: 0.9592477679252625, 
		 aux loss2: 0.6191685795783997, total loss: 1.0381784439086914
1th Epoch, 17575th Step, learning rate = 0.008223865485571599 - Loss: 0.5245874524116516, aux loss1: 1.0503675937652588, 
		 aux loss2: 0.6522261500358582, total loss: 1.1005882024765015
1th Epoch, 17580th Step, learning rate = 0.00822335450133386 - Loss: 0.4436277747154236, aux loss1: 1.019957423210144, 
		 aux loss2: 0.5653987526893616, total loss: 0.9757745265960693
1th Epoch, 17585th Step, learning rate = 0.00822284351356814 - Loss: 0.4794193506240845, aux loss1: 1.0336146354675293, 
		 aux loss2: 0.6393741369247437, total loss: 1.0452533960342407
1th Epoch, 17590th Step, learning rate = 0.008222332522274169 - Loss: 0.3955703377723694, aux loss1: 0.9322761297225952, 
		 aux loss2: 0.5103026628494263, total loss: 0.8793742060661316
1th Epoch, 17595th Step, learning rate = 0.008221821527451677 - Loss: 0.4364038407802582, aux loss1: 1.0452253818511963, 
		 aux loss2: 0.5763593316078186, total loss: 0.9805152416229248
1th Epoch, 17600th Step, learning rate = 0.0082213105291004 - Loss: 0.5011796951293945, aux loss1: 0.9086648225784302, 
		 aux loss2: 0.6083499789237976, total loss: 1.0171191692352295
<17600th step>
*************************** Test ***************************
time:3m 11s, 17600th Step, Loss: 0.5688974857330322, Mean IoU = 40.170%
************************************************************
1th Epoch, 17605th Step, learning rate = 0.008220799527220067 - Loss: 0.3993723392486572, aux loss1: 0.831494927406311, 
		 aux loss2: 0.4696992337703705, total loss: 0.8367004990577698
1th Epoch, 17610th Step, learning rate = 0.00822028852181041 - Loss: 0.4540630280971527, aux loss1: 0.9728023409843445, 
		 aux loss2: 0.5780490636825562, total loss: 0.9771233797073364
1th Epoch, 17615th Step, learning rate = 0.008219777512871163 - Loss: 0.5122035145759583, aux loss1: 0.9625804424285889, 
		 aux loss2: 0.6031436920166016, total loss: 1.0422351360321045
1th Epoch, 17620th Step, learning rate = 0.008219266500402056 - Loss: 0.6235170364379883, aux loss1: 1.1081053018569946, 
		 aux loss2: 0.7337741851806641, total loss: 1.2494583129882812
1th Epoch, 17625th Step, learning rate = 0.008218755484402821 - Loss: 0.3571886420249939, aux loss1: 0.800420880317688, 
		 aux loss2: 0.4486824572086334, total loss: 0.7767878770828247
1th Epoch, 17630th Step, learning rate = 0.008218244464873192 - Loss: 0.37567418813705444, aux loss1: 0.8692988753318787, 
		 aux loss2: 0.47237053513526917, total loss: 0.8254120945930481
1th Epoch, 17635th Step, learning rate = 0.008217733441812897 - Loss: 0.40062645077705383, aux loss1: 0.846579372882843, 
		 aux loss2: 0.48662543296813965, total loss: 0.8492504358291626
1th Epoch, 17640th Step, learning rate = 0.008217222415221668 - Loss: 0.48643743991851807, aux loss1: 1.0151853561401367, 
		 aux loss2: 0.6151604652404785, total loss: 1.0370572805404663
1th Epoch, 17645th Step, learning rate = 0.00821671138509924 - Loss: 0.335229754447937, aux loss1: 0.7887030839920044, 
		 aux loss2: 0.42947444319725037, total loss: 0.7436304688453674
1th Epoch, 17650th Step, learning rate = 0.008216200351445341 - Loss: 0.33132004737854004, aux loss1: 0.7989975214004517, 
		 aux loss2: 0.41217413544654846, total loss: 0.7358889579772949
1th Epoch, 17655th Step, learning rate = 0.008215689314259705 - Loss: 0.3744090795516968, aux loss1: 0.9480141401290894, 
		 aux loss2: 0.4935976564884186, total loss: 0.8562524318695068
1th Epoch, 17660th Step, learning rate = 0.008215178273542062 - Loss: 0.41944265365600586, aux loss1: 0.9347254633903503, 
		 aux loss2: 0.5486010909080505, total loss: 0.9193007946014404
1th Epoch, 17665th Step, learning rate = 0.008214667229292144 - Loss: 0.3245234489440918, aux loss1: 0.7009568810462952, 
		 aux loss2: 0.41021019220352173, total loss: 0.6988946199417114
1th Epoch, 17670th Step, learning rate = 0.008214156181509683 - Loss: 0.34426242113113403, aux loss1: 0.7579619288444519, 
		 aux loss2: 0.4339946508407593, total loss: 0.7452488541603088
1th Epoch, 17675th Step, learning rate = 0.00821364513019441 - Loss: 0.2645828425884247, aux loss1: 0.6745058298110962, 
		 aux loss2: 0.3278927206993103, total loss: 0.598091721534729
1th Epoch, 17680th Step, learning rate = 0.008213134075346054 - Loss: 0.40933310985565186, aux loss1: 0.9376044869422913, 
		 aux loss2: 0.5150995850563049, total loss: 0.8966543078422546
1th Epoch, 17685th Step, learning rate = 0.008212623016964352 - Loss: 0.3290782570838928, aux loss1: 0.9007266759872437, 
		 aux loss2: 0.4466703236103058, total loss: 0.7779644131660461
1th Epoch, 17690th Step, learning rate = 0.00821211195504903 - Loss: 0.4294440746307373, aux loss1: 0.9455980062484741, 
		 aux loss2: 0.5424816012382507, total loss: 0.9301161766052246
1th Epoch, 17695th Step, learning rate = 0.00821160088959982 - Loss: 0.48785582184791565, aux loss1: 1.0309621095657349, 
		 aux loss2: 0.6156318783760071, total loss: 1.0433971881866455
1th Epoch, 17700th Step, learning rate = 0.008211089820616455 - Loss: 0.3659021854400635, aux loss1: 0.9332996606826782, 
		 aux loss2: 0.4601469039916992, total loss: 0.8299508690834045
<17700th step>
*************************** Test ***************************
time:3m 22s, 17700th Step, Loss: 0.5934864282608032, Mean IoU = 41.600%
************************************************************
1th Epoch, 17705th Step, learning rate = 0.008210578748098664 - Loss: 0.44967299699783325, aux loss1: 0.9712737798690796, 
		 aux loss2: 0.5769004225730896, total loss: 0.971815288066864
1th Epoch, 17710th Step, learning rate = 0.00821006767204618 - Loss: 0.40355026721954346, aux loss1: 0.9101158380508423, 
		 aux loss2: 0.5141212940216064, total loss: 0.8822335600852966
1th Epoch, 17715th Step, learning rate = 0.008209556592458736 - Loss: 0.38426586985588074, aux loss1: 0.841609001159668, 
		 aux loss2: 0.4927886128425598, total loss: 0.8338639736175537
1th Epoch, 17720th Step, learning rate = 0.008209045509336058 - Loss: 0.31565335392951965, aux loss1: 0.7479345202445984, 
		 aux loss2: 0.41698169708251953, total loss: 0.706826388835907
1th Epoch, 17725th Step, learning rate = 0.008208534422677879 - Loss: 0.6151750087738037, aux loss1: 1.1144938468933105, 
		 aux loss2: 0.7517144083976746, total loss: 1.2502089738845825
1th Epoch, 17730th Step, learning rate = 0.008208023332483931 - Loss: 0.3396696448326111, aux loss1: 0.7743245363235474, 
		 aux loss2: 0.42408403754234314, total loss: 0.7416006326675415
1th Epoch, 17735th Step, learning rate = 0.008207512238753944 - Loss: 0.48270183801651, aux loss1: 1.0530306100845337, 
		 aux loss2: 0.615392804145813, total loss: 1.044768214225769
1th Epoch, 17740th Step, learning rate = 0.008207001141487648 - Loss: 0.2875080406665802, aux loss1: 0.6597225069999695, 
		 aux loss2: 0.3508368730545044, total loss: 0.6257596015930176
1th Epoch, 17745th Step, learning rate = 0.008206490040684777 - Loss: 0.3593691289424896, aux loss1: 0.855467677116394, 
		 aux loss2: 0.4506146013736725, total loss: 0.796255350112915
1th Epoch, 17750th Step, learning rate = 0.00820597893634506 - Loss: 0.3070582449436188, aux loss1: 0.8254140615463257, 
		 aux loss2: 0.40458881855010986, total loss: 0.7165180444717407
1th Epoch, 17755th Step, learning rate = 0.008205467828468227 - Loss: 0.40838825702667236, aux loss1: 0.8170212507247925, 
		 aux loss2: 0.4730961322784424, total loss: 0.8427331447601318
1th Epoch, 17760th Step, learning rate = 0.00820495671705401 - Loss: 0.34374627470970154, aux loss1: 0.9207732081413269, 
		 aux loss2: 0.4325309693813324, total loss: 0.7929906249046326
1th Epoch, 17765th Step, learning rate = 0.008204445602102137 - Loss: 0.37188923358917236, aux loss1: 0.8803151249885559, 
		 aux loss2: 0.4911728799343109, total loss: 0.8324530124664307
1th Epoch, 17770th Step, learning rate = 0.008203934483612342 - Loss: 0.41454166173934937, aux loss1: 0.8419128656387329, 
		 aux loss2: 0.505837082862854, total loss: 0.8694503903388977
1th Epoch, 17775th Step, learning rate = 0.008203423361584354 - Loss: 0.4187123775482178, aux loss1: 0.9280768036842346, 
		 aux loss2: 0.5244532823562622, total loss: 0.9069167375564575
1th Epoch, 17780th Step, learning rate = 0.008202912236017903 - Loss: 0.5413913130760193, aux loss1: 1.0271357297897339, 
		 aux loss2: 0.6595510244369507, total loss: 1.1133524179458618
1th Epoch, 17785th Step, learning rate = 0.00820240110691272 - Loss: 0.3517647683620453, aux loss1: 0.7326791286468506, 
		 aux loss2: 0.4424828588962555, total loss: 0.7485616207122803
1th Epoch, 17790th Step, learning rate = 0.008201889974268536 - Loss: 0.5772144794464111, aux loss1: 1.2004646062850952, 
		 aux loss2: 0.7348769903182983, total loss: 1.23130464553833
1th Epoch, 17795th Step, learning rate = 0.008201378838085083 - Loss: 0.42293649911880493, aux loss1: 0.9970364570617676, 
		 aux loss2: 0.567428708076477, total loss: 0.9490189552307129
1th Epoch, 17800th Step, learning rate = 0.008200867698362087 - Loss: 0.30589497089385986, aux loss1: 0.7874422073364258, 
		 aux loss2: 0.4021832346916199, total loss: 0.7030009031295776
<17800th step>
*************************** Test ***************************
time:3m 15s, 17800th Step, Loss: 0.5634042024612427, Mean IoU = 41.313%
************************************************************
1th Epoch, 17805th Step, learning rate = 0.008200356555099281 - Loss: 0.6152607798576355, aux loss1: 1.2587966918945312, 
		 aux loss2: 0.7974579334259033, total loss: 1.3118829727172852
1th Epoch, 17810th Step, learning rate = 0.008199845408296397 - Loss: 0.6066294312477112, aux loss1: 1.1026322841644287, 
		 aux loss2: 0.7201478481292725, total loss: 1.2254782915115356
1th Epoch, 17815th Step, learning rate = 0.008199334257953163 - Loss: 0.36154621839523315, aux loss1: 0.8412899374961853, 
		 aux loss2: 0.44829151034355164, total loss: 0.7932498455047607
1th Epoch, 17820th Step, learning rate = 0.008198823104069311 - Loss: 0.6066240072250366, aux loss1: 1.0014095306396484, 
		 aux loss2: 0.6527761220932007, total loss: 1.1681573390960693
1th Epoch, 17825th Step, learning rate = 0.008198311946644568 - Loss: 0.3745477497577667, aux loss1: 0.8544514775276184, 
		 aux loss2: 0.4845259189605713, total loss: 0.8246935606002808
1th Epoch, 17830th Step, learning rate = 0.008197800785678668 - Loss: 0.535256028175354, aux loss1: 0.9991456866264343, 
		 aux loss2: 0.6640484929084778, total loss: 1.1006190776824951
1th Epoch, 17835th Step, learning rate = 0.008197289621171338 - Loss: 0.3392221927642822, aux loss1: 0.737749457359314, 
		 aux loss2: 0.4126768410205841, total loss: 0.7256177663803101
1th Epoch, 17840th Step, learning rate = 0.008196778453122309 - Loss: 0.33220282196998596, aux loss1: 0.7550792098045349, 
		 aux loss2: 0.4241826832294464, total loss: 0.7283996939659119
1th Epoch, 17845th Step, learning rate = 0.008196267281531312 - Loss: 0.4974895119667053, aux loss1: 1.0243360996246338, 
		 aux loss2: 0.6436397433280945, total loss: 1.062246322631836
1th Epoch, 17850th Step, learning rate = 0.008195756106398076 - Loss: 0.37281638383865356, aux loss1: 0.9565754532814026, 
		 aux loss2: 0.4823101758956909, total loss: 0.8527131080627441
1th Epoch, 17855th Step, learning rate = 0.008195244927722332 - Loss: 0.3743757903575897, aux loss1: 0.958562433719635, 
		 aux loss2: 0.5182607173919678, total loss: 0.8692488074302673
1th Epoch, 17860th Step, learning rate = 0.008194733745503809 - Loss: 0.622491717338562, aux loss1: 1.1624521017074585, 
		 aux loss2: 0.7435650825500488, total loss: 1.268653392791748
1th Epoch, 17865th Step, learning rate = 0.008194222559742238 - Loss: 0.31013786792755127, aux loss1: 0.7856491208076477, 
		 aux loss2: 0.4241397976875305, total loss: 0.7154885530471802
1th Epoch, 17870th Step, learning rate = 0.008193711370437349 - Loss: 0.5087426900863647, aux loss1: 0.9549444317817688, 
		 aux loss2: 0.6061583757400513, total loss: 1.037689447402954
2th Epoch, 17875th Step, learning rate = 0.008193200177588868 - Loss: 0.376470148563385, aux loss1: 0.8495224714279175, 
		 aux loss2: 0.47929731011390686, total loss: 0.8230458498001099
2th Epoch, 17880th Step, learning rate = 0.00819268898119653 - Loss: 0.49256432056427, aux loss1: 0.9651157855987549, 
		 aux loss2: 0.6191393136978149, total loss: 1.0297547578811646
2th Epoch, 17885th Step, learning rate = 0.00819217778126006 - Loss: 0.429373562335968, aux loss1: 0.9913927316665649, 
		 aux loss2: 0.5849652886390686, total loss: 0.9607775211334229
2th Epoch, 17890th Step, learning rate = 0.008191666577779193 - Loss: 0.4368796646595001, aux loss1: 0.9096487164497375, 
		 aux loss2: 0.5613052845001221, total loss: 0.9342963695526123
2th Epoch, 17895th Step, learning rate = 0.008191155370753654 - Loss: 0.36254459619522095, aux loss1: 0.8162766695022583, 
		 aux loss2: 0.45584481954574585, total loss: 0.7897655367851257
2th Epoch, 17900th Step, learning rate = 0.008190644160183174 - Loss: 0.3734205961227417, aux loss1: 0.8978402018547058, 
		 aux loss2: 0.490139901638031, total loss: 0.8388286232948303
<17900th step>
*************************** Test ***************************
time:3m 17s, 17900th Step, Loss: 0.5670983195304871, Mean IoU = 41.477%
************************************************************
2th Epoch, 17905th Step, learning rate = 0.008190132946067484 - Loss: 0.34110838174819946, aux loss1: 0.7759749293327332, 
		 aux loss2: 0.41558191180229187, total loss: 0.7401336431503296
2th Epoch, 17910th Step, learning rate = 0.008189621728406312 - Loss: 0.4707159996032715, aux loss1: 1.0969041585922241, 
		 aux loss2: 0.6327269673347473, total loss: 1.0528781414031982
2th Epoch, 17915th Step, learning rate = 0.008189110507199388 - Loss: 0.3589121997356415, aux loss1: 0.7811356782913208, 
		 aux loss2: 0.4546279311180115, total loss: 0.7751040458679199
2th Epoch, 17920th Step, learning rate = 0.008188599282446443 - Loss: 0.48074987530708313, aux loss1: 1.1812468767166138, 
		 aux loss2: 0.6808337569236755, total loss: 1.1074573993682861
2th Epoch, 17925th Step, learning rate = 0.008188088054147202 - Loss: 0.4408988952636719, aux loss1: 0.9228986501693726, 
		 aux loss2: 0.5464940667152405, total loss: 0.9363661408424377
2th Epoch, 17930th Step, learning rate = 0.008187576822301397 - Loss: 0.39674538373947144, aux loss1: 0.8025360703468323, 
		 aux loss2: 0.48176872730255127, total loss: 0.830213725566864
2th Epoch, 17935th Step, learning rate = 0.008187065586908761 - Loss: 0.3375464677810669, aux loss1: 0.837761402130127, 
		 aux loss2: 0.43081220984458923, total loss: 0.7611998319625854
2th Epoch, 17940th Step, learning rate = 0.008186554347969017 - Loss: 0.5500215291976929, aux loss1: 1.130743145942688, 
		 aux loss2: 0.6873424649238586, total loss: 1.1641814708709717
2th Epoch, 17945th Step, learning rate = 0.008186043105481898 - Loss: 0.36570578813552856, aux loss1: 0.8730325102806091, 
		 aux loss2: 0.47569480538368225, total loss: 0.8178935050964355
2th Epoch, 17950th Step, learning rate = 0.008185531859447134 - Loss: 0.41238564252853394, aux loss1: 0.8509525060653687, 
		 aux loss2: 0.5149481892585754, total loss: 0.8736507296562195
2th Epoch, 17955th Step, learning rate = 0.00818502060986445 - Loss: 0.4120235741138458, aux loss1: 0.9469118118286133, 
		 aux loss2: 0.5210973024368286, total loss: 0.9045360684394836
2th Epoch, 17960th Step, learning rate = 0.00818450935673358 - Loss: 0.44699934124946594, aux loss1: 0.934819221496582, 
		 aux loss2: 0.5691484808921814, total loss: 0.9551045298576355
2th Epoch, 17965th Step, learning rate = 0.00818399810005425 - Loss: 0.44432252645492554, aux loss1: 0.9418883323669434, 
		 aux loss2: 0.6007157564163208, total loss: 0.967175304889679
2th Epoch, 17970th Step, learning rate = 0.008183486839826188 - Loss: 0.4264964759349823, aux loss1: 1.1100897789001465, 
		 aux loss2: 0.5712822079658508, total loss: 0.9880362749099731
2th Epoch, 17975th Step, learning rate = 0.008182975576049127 - Loss: 0.45234158635139465, aux loss1: 0.9868531227111816, 
		 aux loss2: 0.610327422618866, total loss: 0.99252849817276
2th Epoch, 17980th Step, learning rate = 0.008182464308722794 - Loss: 0.4626483917236328, aux loss1: 1.0084693431854248, 
		 aux loss2: 0.5544303059577942, total loss: 0.986961305141449
2th Epoch, 17985th Step, learning rate = 0.008181953037846917 - Loss: 0.43050453066825867, aux loss1: 0.927255392074585, 
		 aux loss2: 0.5427576303482056, total loss: 0.9257842302322388
2th Epoch, 17990th Step, learning rate = 0.008181441763421225 - Loss: 0.3400205373764038, aux loss1: 0.8341694474220276, 
		 aux loss2: 0.4507092237472534, total loss: 0.7705550193786621
2th Epoch, 17995th Step, learning rate = 0.008180930485445449 - Loss: 0.4068341851234436, aux loss1: 0.8280338048934937, 
		 aux loss2: 0.4846991300582886, total loss: 0.849124014377594
2th Epoch, 18000th Step, learning rate = 0.008180419203919315 - Loss: 0.37768012285232544, aux loss1: 0.8399456739425659, 
		 aux loss2: 0.48056283593177795, total loss: 0.8218889832496643
<18000th step>
*************************** Test ***************************
time:3m 14s, 18000th Step, Loss: 0.6538770198822021, Mean IoU = 39.042%
************************************************************
2th Epoch, 18005th Step, learning rate = 0.008179907918842554 - Loss: 0.36499592661857605, aux loss1: 0.8207424283027649, 
		 aux loss2: 0.4674561619758606, total loss: 0.7982011437416077
2th Epoch, 18010th Step, learning rate = 0.008179396630214894 - Loss: 0.4325391352176666, aux loss1: 1.0330456495285034, 
		 aux loss2: 0.574438750743866, total loss: 0.9722283482551575
2th Epoch, 18015th Step, learning rate = 0.008178885338036065 - Loss: 0.5417540073394775, aux loss1: 1.1620968580245972, 
		 aux loss2: 0.6807146072387695, total loss: 1.1626689434051514
2th Epoch, 18020th Step, learning rate = 0.008178374042305791 - Loss: 0.3498043119907379, aux loss1: 0.8195491433143616, 
		 aux loss2: 0.43489640951156616, total loss: 0.769627571105957
2th Epoch, 18025th Step, learning rate = 0.008177862743023807 - Loss: 0.3714652359485626, aux loss1: 0.8410084843635559, 
		 aux loss2: 0.4618164598941803, total loss: 0.8084943890571594
2th Epoch, 18030th Step, learning rate = 0.008177351440189837 - Loss: 0.5284096598625183, aux loss1: 1.0915290117263794, 
		 aux loss2: 0.6612237095832825, total loss: 1.120357871055603
2th Epoch, 18035th Step, learning rate = 0.008176840133803612 - Loss: 0.5216721296310425, aux loss1: 1.0488717555999756, 
		 aux loss2: 0.6577469706535339, total loss: 1.0994324684143066
2th Epoch, 18040th Step, learning rate = 0.008176328823864858 - Loss: 0.516146719455719, aux loss1: 1.0680238008499146, 
		 aux loss2: 0.6627581715583801, total loss: 1.1016571521759033
2th Epoch, 18045th Step, learning rate = 0.008175817510373306 - Loss: 0.3866801857948303, aux loss1: 0.7967731356620789, 
		 aux loss2: 0.46748578548431396, total loss: 0.812706470489502
2th Epoch, 18050th Step, learning rate = 0.008175306193328685 - Loss: 0.34525197744369507, aux loss1: 0.8438183069229126, 
		 aux loss2: 0.44740042090415955, total loss: 0.7773576974868774
2th Epoch, 18055th Step, learning rate = 0.00817479487273072 - Loss: 0.365614116191864, aux loss1: 0.8441064357757568, 
		 aux loss2: 0.4417755603790283, total loss: 0.7955563068389893
2th Epoch, 18060th Step, learning rate = 0.008174283548579141 - Loss: 0.3438517451286316, aux loss1: 0.7543278932571411, 
		 aux loss2: 0.42929017543792725, total loss: 0.7418662309646606
2th Epoch, 18065th Step, learning rate = 0.008173772220873678 - Loss: 0.3905820846557617, aux loss1: 0.80582594871521, 
		 aux loss2: 0.4629684090614319, total loss: 0.8175172805786133
2th Epoch, 18070th Step, learning rate = 0.008173260889614058 - Loss: 0.3884376883506775, aux loss1: 0.9720069766044617, 
		 aux loss2: 0.5040726661682129, total loss: 0.8816688060760498
2th Epoch, 18075th Step, learning rate = 0.008172749554800008 - Loss: 0.335719496011734, aux loss1: 0.8470824360847473, 
		 aux loss2: 0.43545767664909363, total loss: 0.7640272974967957
2th Epoch, 18080th Step, learning rate = 0.008172238216431258 - Loss: 0.42376908659935, aux loss1: 0.8152345418930054, 
		 aux loss2: 0.4990993142127991, total loss: 0.8679792284965515
2th Epoch, 18085th Step, learning rate = 0.008171726874507535 - Loss: 0.5436831116676331, aux loss1: 1.1268936395645142, 
		 aux loss2: 0.6893641352653503, total loss: 1.1574968099594116
2th Epoch, 18090th Step, learning rate = 0.008171215529028567 - Loss: 0.34292733669281006, aux loss1: 0.8112996816635132, 
		 aux loss2: 0.4552246332168579, total loss: 0.7684071063995361
2th Epoch, 18095th Step, learning rate = 0.008170704179994083 - Loss: 0.3654799461364746, aux loss1: 0.8505938053131104, 
		 aux loss2: 0.48883056640625, total loss: 0.8161903619766235
2th Epoch, 18100th Step, learning rate = 0.00817019282740381 - Loss: 0.42697012424468994, aux loss1: 0.885636568069458, 
		 aux loss2: 0.5390211939811707, total loss: 0.9082695841789246
<18100th step>
*************************** Test ***************************
time:3m 15s, 18100th Step, Loss: 0.5387989282608032, Mean IoU = 42.315%
************************************************************
2th Epoch, 18105th Step, learning rate = 0.008169681471257479 - Loss: 0.35013943910598755, aux loss1: 0.881880521774292, 
		 aux loss2: 0.4594334065914154, total loss: 0.7984769344329834
2th Epoch, 18110th Step, learning rate = 0.008169170111554812 - Loss: 0.48728856444358826, aux loss1: 0.963033139705658, 
		 aux loss2: 0.5869982838630676, total loss: 1.0109977722167969
2th Epoch, 18115th Step, learning rate = 0.008168658748295544 - Loss: 0.40514078736305237, aux loss1: 1.0749404430389404, 
		 aux loss2: 0.5572587847709656, total loss: 0.9505264759063721
2th Epoch, 18120th Step, learning rate = 0.008168147381479397 - Loss: 0.41280221939086914, aux loss1: 0.9753139615058899, 
		 aux loss2: 0.5623742938041687, total loss: 0.9303461313247681
2th Epoch, 18125th Step, learning rate = 0.008167636011106103 - Loss: 0.34480735659599304, aux loss1: 0.7762789130210876, 
		 aux loss2: 0.44198930263519287, total loss: 0.7544867396354675
2th Epoch, 18130th Step, learning rate = 0.008167124637175387 - Loss: 0.38570427894592285, aux loss1: 0.7834293246269226, 
		 aux loss2: 0.46247950196266174, total loss: 0.8057248592376709
2th Epoch, 18135th Step, learning rate = 0.008166613259686978 - Loss: 0.423840194940567, aux loss1: 0.965559720993042, 
		 aux loss2: 0.5415590405464172, total loss: 0.930131733417511
2th Epoch, 18140th Step, learning rate = 0.008166101878640603 - Loss: 0.3957139551639557, aux loss1: 0.8326734304428101, 
		 aux loss2: 0.49490565061569214, total loss: 0.843478262424469
2th Epoch, 18145th Step, learning rate = 0.00816559049403599 - Loss: 0.3957254886627197, aux loss1: 0.8389765024185181, 
		 aux loss2: 0.49512025713920593, total loss: 0.8454665541648865
2th Epoch, 18150th Step, learning rate = 0.008165079105872866 - Loss: 0.34442752599716187, aux loss1: 0.8613569140434265, 
		 aux loss2: 0.4480479955673218, total loss: 0.7820537686347961
2th Epoch, 18155th Step, learning rate = 0.008164567714150962 - Loss: 0.5150240063667297, aux loss1: 1.1192071437835693, 
		 aux loss2: 0.6844922304153442, total loss: 1.1245830059051514
2th Epoch, 18160th Step, learning rate = 0.008164056318870001 - Loss: 0.4762095808982849, aux loss1: 0.9461487531661987, 
		 aux loss2: 0.6023523211479187, total loss: 1.00099515914917
2th Epoch, 18165th Step, learning rate = 0.008163544920029712 - Loss: 0.4728919267654419, aux loss1: 1.0292232036590576, 
		 aux loss2: 0.6387305855751038, total loss: 1.0371510982513428
2th Epoch, 18170th Step, learning rate = 0.008163033517629826 - Loss: 0.5968839526176453, aux loss1: 1.0735739469528198, 
		 aux loss2: 0.7023819088935852, total loss: 1.199908971786499
2th Epoch, 18175th Step, learning rate = 0.008162522111670066 - Loss: 0.4515288770198822, aux loss1: 0.976202666759491, 
		 aux loss2: 0.575013279914856, total loss: 0.9743949770927429
2th Epoch, 18180th Step, learning rate = 0.008162010702150158 - Loss: 0.47225093841552734, aux loss1: 0.9450514912605286, 
		 aux loss2: 0.5591811537742615, total loss: 0.979438841342926
2th Epoch, 18185th Step, learning rate = 0.008161499289069837 - Loss: 0.4287576675415039, aux loss1: 0.9219786524772644, 
		 aux loss2: 0.5410589575767517, total loss: 0.9217748045921326
2th Epoch, 18190th Step, learning rate = 0.008160987872428822 - Loss: 0.3311551809310913, aux loss1: 0.8382498621940613, 
		 aux loss2: 0.43468931317329407, total loss: 0.7565059065818787
2th Epoch, 18195th Step, learning rate = 0.008160476452226844 - Loss: 0.36900410056114197, aux loss1: 0.845798909664154, 
		 aux loss2: 0.4783557057380676, total loss: 0.8140860795974731
2th Epoch, 18200th Step, learning rate = 0.008159965028463632 - Loss: 0.3913401663303375, aux loss1: 0.9066526889801025, 
		 aux loss2: 0.5062028169631958, total loss: 0.865817129611969
<18200th step>
*************************** Test ***************************
time:3m 16s, 18200th Step, Loss: 0.5495392680168152, Mean IoU = 42.598%
************************************************************
2th Epoch, 18205th Step, learning rate = 0.008159453601138908 - Loss: 0.353410929441452, aux loss1: 0.91426682472229, 
		 aux loss2: 0.5053024888038635, total loss: 0.8298120498657227
2th Epoch, 18210th Step, learning rate = 0.008158942170252405 - Loss: 0.49750229716300964, aux loss1: 1.0030168294906616, 
		 aux loss2: 0.6200657486915588, total loss: 1.0464335680007935
2th Epoch, 18215th Step, learning rate = 0.008158430735803846 - Loss: 0.3656298518180847, aux loss1: 0.8129723072052002, 
		 aux loss2: 0.44797107577323914, total loss: 0.7887099981307983
2th Epoch, 18220th Step, learning rate = 0.00815791929779296 - Loss: 0.4035193920135498, aux loss1: 1.0902438163757324, 
		 aux loss2: 0.5280963182449341, total loss: 0.941831111907959
2th Epoch, 18225th Step, learning rate = 0.008157407856219474 - Loss: 0.39151543378829956, aux loss1: 0.866705596446991, 
		 aux loss2: 0.4841079115867615, total loss: 0.8451703190803528
2th Epoch, 18230th Step, learning rate = 0.008156896411083114 - Loss: 0.3727234899997711, aux loss1: 0.8306112289428711, 
		 aux loss2: 0.47076547145843506, total loss: 0.8102130889892578
2th Epoch, 18235th Step, learning rate = 0.008156384962383608 - Loss: 0.545685887336731, aux loss1: 1.1714096069335938, 
		 aux loss2: 0.697450578212738, total loss: 1.1760890483856201
2th Epoch, 18240th Step, learning rate = 0.008155873510120681 - Loss: 0.387136846780777, aux loss1: 0.8775095343589783, 
		 aux loss2: 0.5069611072540283, total loss: 0.8531742095947266
3th Epoch, 18245th Step, learning rate = 0.008155362054294063 - Loss: 0.38809260725975037, aux loss1: 0.9056396484375, 
		 aux loss2: 0.5086794495582581, total loss: 0.8632563352584839
3th Epoch, 18250th Step, learning rate = 0.008154850594903477 - Loss: 0.4352799952030182, aux loss1: 0.790384829044342, 
		 aux loss2: 0.510890543460846, total loss: 0.8767516613006592
3th Epoch, 18255th Step, learning rate = 0.008154339131948655 - Loss: 0.4337623119354248, aux loss1: 1.0004222393035889, 
		 aux loss2: 0.5724577307701111, total loss: 0.9628720879554749
3th Epoch, 18260th Step, learning rate = 0.00815382766542932 - Loss: 0.31690073013305664, aux loss1: 0.8492811918258667, 
		 aux loss2: 0.4118472933769226, total loss: 0.7364239692687988
3th Epoch, 18265th Step, learning rate = 0.008153316195345199 - Loss: 0.3352718651294708, aux loss1: 0.8115164041519165, 
		 aux loss2: 0.4362587630748749, total loss: 0.7532302737236023
3th Epoch, 18270th Step, learning rate = 0.008152804721696019 - Loss: 0.443768709897995, aux loss1: 1.0201380252838135, 
		 aux loss2: 0.5823637247085571, total loss: 0.9827556014060974
3th Epoch, 18275th Step, learning rate = 0.008152293244481504 - Loss: 0.4151042103767395, aux loss1: 0.9173815846443176, 
		 aux loss2: 0.5357887744903564, total loss: 0.9046342372894287
3th Epoch, 18280th Step, learning rate = 0.008151781763701387 - Loss: 0.4733433723449707, aux loss1: 0.9650386571884155, 
		 aux loss2: 0.5863136053085327, total loss: 0.9973804354667664
3th Epoch, 18285th Step, learning rate = 0.00815127027935539 - Loss: 0.39471787214279175, aux loss1: 0.8927369713783264, 
		 aux loss2: 0.52447909116745, total loss: 0.8723306655883789
3th Epoch, 18290th Step, learning rate = 0.00815075879144324 - Loss: 0.38193559646606445, aux loss1: 0.8983428478240967, 
		 aux loss2: 0.4737287759780884, total loss: 0.8409299850463867
3th Epoch, 18295th Step, learning rate = 0.008150247299964665 - Loss: 0.29988980293273926, aux loss1: 0.7047650814056396, 
		 aux loss2: 0.38554516434669495, total loss: 0.665537416934967
3th Epoch, 18300th Step, learning rate = 0.00814973580491939 - Loss: 0.4314269721508026, aux loss1: 0.912605345249176, 
		 aux loss2: 0.5426995158195496, total loss: 0.9222884178161621
<18300th step>
*************************** Test ***************************
time:3m 20s, 18300th Step, Loss: 0.5435398817062378, Mean IoU = 41.845%
************************************************************
3th Epoch, 18305th Step, learning rate = 0.00814922430630714 - Loss: 0.3430180251598358, aux loss1: 0.7980155944824219, 
		 aux loss2: 0.4194674789905548, total loss: 0.7502097487449646
3th Epoch, 18310th Step, learning rate = 0.008148712804127645 - Loss: 0.4439036548137665, aux loss1: 1.0123376846313477, 
		 aux loss2: 0.5797097086906433, total loss: 0.9794888496398926
3th Epoch, 18315th Step, learning rate = 0.00814820129838063 - Loss: 0.36910343170166016, aux loss1: 0.8684081435203552, 
		 aux loss2: 0.46859240531921387, total loss: 0.8170628547668457
3th Epoch, 18320th Step, learning rate = 0.00814768978906582 - Loss: 0.33458203077316284, aux loss1: 0.844616174697876, 
		 aux loss2: 0.46033337712287903, total loss: 0.7721002697944641
3th Epoch, 18325th Step, learning rate = 0.00814717827618294 - Loss: 0.31544727087020874, aux loss1: 0.7235748767852783, 
		 aux loss2: 0.39714863896369934, total loss: 0.691379189491272
3th Epoch, 18330th Step, learning rate = 0.00814666675973172 - Loss: 0.3572632074356079, aux loss1: 0.7864614129066467, 
		 aux loss2: 0.4595519006252289, total loss: 0.7770224213600159
3th Epoch, 18335th Step, learning rate = 0.008146155239711884 - Loss: 0.4463520050048828, aux loss1: 0.9251134991645813, 
		 aux loss2: 0.5690065026283264, total loss: 0.9514886736869812
3th Epoch, 18340th Step, learning rate = 0.008145643716123158 - Loss: 0.42087775468826294, aux loss1: 1.004669189453125, 
		 aux loss2: 0.5622428059577942, total loss: 0.9471756815910339
3th Epoch, 18345th Step, learning rate = 0.00814513218896527 - Loss: 0.3763410449028015, aux loss1: 0.9021158814430237, 
		 aux loss2: 0.499439001083374, total loss: 0.8467514514923096
3th Epoch, 18350th Step, learning rate = 0.008144620658237943 - Loss: 0.45849770307540894, aux loss1: 0.9845215678215027, 
		 aux loss2: 0.6173916459083557, total loss: 1.0008108615875244
3th Epoch, 18355th Step, learning rate = 0.008144109123940906 - Loss: 0.30633071064949036, aux loss1: 0.7866499423980713, 
		 aux loss2: 0.4185446798801422, total loss: 0.7097436189651489
3th Epoch, 18360th Step, learning rate = 0.008143597586073883 - Loss: 0.3826978802680969, aux loss1: 0.8836346864700317, 
		 aux loss2: 0.4937395453453064, total loss: 0.845284104347229
3th Epoch, 18365th Step, learning rate = 0.008143086044636599 - Loss: 0.38932284712791443, aux loss1: 0.8544805645942688, 
		 aux loss2: 0.4933759868144989, total loss: 0.8430173993110657
3th Epoch, 18370th Step, learning rate = 0.008142574499628782 - Loss: 0.30918681621551514, aux loss1: 0.7847907543182373, 
		 aux loss2: 0.3937891125679016, total loss: 0.702139675617218
3th Epoch, 18375th Step, learning rate = 0.008142062951050157 - Loss: 0.3780530095100403, aux loss1: 0.8964718580245972, 
		 aux loss2: 0.488283634185791, total loss: 0.8423080444335938
3th Epoch, 18380th Step, learning rate = 0.008141551398900451 - Loss: 0.41139647364616394, aux loss1: 0.897819459438324, 
		 aux loss2: 0.5105062127113342, total loss: 0.8849447965621948
3th Epoch, 18385th Step, learning rate = 0.008141039843179388 - Loss: 0.2868598699569702, aux loss1: 0.6809789538383484, 
		 aux loss2: 0.3706302046775818, total loss: 0.6394056677818298
3th Epoch, 18390th Step, learning rate = 0.008140528283886695 - Loss: 0.37470245361328125, aux loss1: 0.8407221436500549, 
		 aux loss2: 0.46716567873954773, total loss: 0.8137854337692261
3th Epoch, 18395th Step, learning rate = 0.008140016721022096 - Loss: 0.6543543934822083, aux loss1: 1.1620982885360718, 
		 aux loss2: 0.7773186564445496, total loss: 1.3139114379882812
3th Epoch, 18400th Step, learning rate = 0.008139505154585317 - Loss: 0.576713502407074, aux loss1: 1.04659104347229, 
		 aux loss2: 0.6628578305244446, total loss: 1.1558339595794678
<18400th step>
*************************** Test ***************************
time:3m 17s, 18400th Step, Loss: 0.5767062902450562, Mean IoU = 39.391%
************************************************************
3th Epoch, 18405th Step, learning rate = 0.008138993584576086 - Loss: 0.419889360666275, aux loss1: 0.9465979933738708, 
		 aux loss2: 0.5367588400840759, total loss: 0.9185723066329956
3th Epoch, 18410th Step, learning rate = 0.008138482010994126 - Loss: 0.4361201226711273, aux loss1: 0.9170804619789124, 
		 aux loss2: 0.5399730205535889, total loss: 0.9272335171699524
3th Epoch, 18415th Step, learning rate = 0.008137970433839164 - Loss: 0.4461967945098877, aux loss1: 1.0490033626556396, 
		 aux loss2: 0.5767115950584412, total loss: 0.991582453250885
3th Epoch, 18420th Step, learning rate = 0.008137458853110926 - Loss: 0.37794533371925354, aux loss1: 0.8493657112121582, 
		 aux loss2: 0.4988159239292145, total loss: 0.8322814106941223
3th Epoch, 18425th Step, learning rate = 0.008136947268809133 - Loss: 0.4440397620201111, aux loss1: 1.0092076063156128, 
		 aux loss2: 0.5726227164268494, total loss: 0.9758511781692505
3th Epoch, 18430th Step, learning rate = 0.008136435680933517 - Loss: 0.3113798201084137, aux loss1: 0.7748875617980957, 
		 aux loss2: 0.4012082815170288, total loss: 0.7043294310569763
3th Epoch, 18435th Step, learning rate = 0.0081359240894838 - Loss: 0.44180724024772644, aux loss1: 0.9479855895042419, 
		 aux loss2: 0.5519866943359375, total loss: 0.9469976425170898
3th Epoch, 18440th Step, learning rate = 0.008135412494459706 - Loss: 0.47506800293922424, aux loss1: 0.9210895895957947, 
		 aux loss2: 0.5722391605377197, total loss: 0.9802905321121216
3th Epoch, 18445th Step, learning rate = 0.00813490089586096 - Loss: 0.4001823365688324, aux loss1: 0.8636197447776794, 
		 aux loss2: 0.49650272727012634, total loss: 0.8578693866729736
3th Epoch, 18450th Step, learning rate = 0.00813438929368729 - Loss: 0.4079644978046417, aux loss1: 0.8664706349372864, 
		 aux loss2: 0.5136125087738037, total loss: 0.8733506798744202
3th Epoch, 18455th Step, learning rate = 0.008133877687938421 - Loss: 0.2572402358055115, aux loss1: 0.7213160395622253, 
		 aux loss2: 0.33874350786209106, total loss: 0.6091324687004089
3th Epoch, 18460th Step, learning rate = 0.008133366078614077 - Loss: 0.41854122281074524, aux loss1: 0.8176283240318298, 
		 aux loss2: 0.49879002571105957, total loss: 0.863345742225647
3th Epoch, 18465th Step, learning rate = 0.008132854465713983 - Loss: 0.32703280448913574, aux loss1: 0.819902777671814, 
		 aux loss2: 0.42795684933662415, total loss: 0.7441864013671875
3th Epoch, 18470th Step, learning rate = 0.008132342849237863 - Loss: 0.3508993685245514, aux loss1: 0.8174599409103394, 
		 aux loss2: 0.44583627581596375, total loss: 0.7744718790054321
3th Epoch, 18475th Step, learning rate = 0.008131831229185447 - Loss: 0.40962374210357666, aux loss1: 0.9091458320617676, 
		 aux loss2: 0.512030839920044, total loss: 0.8871798515319824
3th Epoch, 18480th Step, learning rate = 0.008131319605556454 - Loss: 0.3654000759124756, aux loss1: 0.8289304971694946, 
		 aux loss2: 0.4540899097919464, total loss: 0.7957152128219604
3th Epoch, 18485th Step, learning rate = 0.008130807978350611 - Loss: 0.41791030764579773, aux loss1: 0.9314051866531372, 
		 aux loss2: 0.5617176294326782, total loss: 0.9220189452171326
3th Epoch, 18490th Step, learning rate = 0.008130296347567645 - Loss: 0.5607199668884277, aux loss1: 1.1592576503753662, 
		 aux loss2: 0.6959304213523865, total loss: 1.1868693828582764
3th Epoch, 18495th Step, learning rate = 0.008129784713207277 - Loss: 0.4690231382846832, aux loss1: 1.1347321271896362, 
		 aux loss2: 0.6461219787597656, total loss: 1.0678915977478027
3th Epoch, 18500th Step, learning rate = 0.008129273075269236 - Loss: 0.32518455386161804, aux loss1: 0.7784578204154968, 
		 aux loss2: 0.41305220127105713, total loss: 0.723942756652832
<18500th step>
*************************** Test ***************************
time:3m 13s, 18500th Step, Loss: 0.6120254993438721, Mean IoU = 42.041%
************************************************************
3th Epoch, 18505th Step, learning rate = 0.008128761433753243 - Loss: 0.3291570842266083, aux loss1: 0.8058173060417175, 
		 aux loss2: 0.4276764392852783, total loss: 0.7419728636741638
3th Epoch, 18510th Step, learning rate = 0.008128249788659026 - Loss: 0.34734103083610535, aux loss1: 0.8030221462249756, 
		 aux loss2: 0.44385525584220886, total loss: 0.7657897472381592
3th Epoch, 18515th Step, learning rate = 0.008127738139986306 - Loss: 0.3448360562324524, aux loss1: 0.7902469038963318, 
		 aux loss2: 0.44980588555336, total loss: 0.7618324756622314
3th Epoch, 18520th Step, learning rate = 0.008127226487734812 - Loss: 0.3300780951976776, aux loss1: 0.863418459892273, 
		 aux loss2: 0.44258376955986023, total loss: 0.7661371231079102
3th Epoch, 18525th Step, learning rate = 0.008126714831904266 - Loss: 0.39150571823120117, aux loss1: 0.811783492565155, 
		 aux loss2: 0.48599785566329956, total loss: 0.8294398784637451
3th Epoch, 18530th Step, learning rate = 0.008126203172494394 - Loss: 0.30498117208480835, aux loss1: 0.7408695816993713, 
		 aux loss2: 0.3970026969909668, total loss: 0.6860431432723999
3th Epoch, 18535th Step, learning rate = 0.008125691509504918 - Loss: 0.4982430040836334, aux loss1: 0.9489810466766357, 
		 aux loss2: 0.6239100694656372, total loss: 1.0325013399124146
3th Epoch, 18540th Step, learning rate = 0.008125179842935565 - Loss: 0.34025895595550537, aux loss1: 0.7582759261131287, 
		 aux loss2: 0.438577264547348, total loss: 0.7431726455688477
3th Epoch, 18545th Step, learning rate = 0.00812466817278606 - Loss: 0.4604405462741852, aux loss1: 0.859961986541748, 
		 aux loss2: 0.542599081993103, total loss: 0.9354687929153442
3th Epoch, 18550th Step, learning rate = 0.008124156499056123 - Loss: 0.4841267466545105, aux loss1: 1.1498183012008667, 
		 aux loss2: 0.6255587339401245, total loss: 1.0792957544326782
3th Epoch, 18555th Step, learning rate = 0.008123644821745483 - Loss: 0.5805464386940002, aux loss1: 1.1258504390716553, 
		 aux loss2: 0.7288998365402222, total loss: 1.2098615169525146
3th Epoch, 18560th Step, learning rate = 0.008123133140853864 - Loss: 0.4903004467487335, aux loss1: 1.145190715789795, 
		 aux loss2: 0.653977632522583, total loss: 1.0954487323760986
3th Epoch, 18565th Step, learning rate = 0.008122621456380987 - Loss: 0.558576762676239, aux loss1: 1.1312994956970215, 
		 aux loss2: 0.6964350938796997, total loss: 1.1765406131744385
3th Epoch, 18570th Step, learning rate = 0.00812210976832658 - Loss: 0.3502793312072754, aux loss1: 0.7517296671867371, 
		 aux loss2: 0.41955921053886414, total loss: 0.7436219453811646
3th Epoch, 18575th Step, learning rate = 0.008121598076690365 - Loss: 0.4714016020298004, aux loss1: 0.9893720149993896, 
		 aux loss2: 0.6050058007240295, total loss: 1.0102155208587646
3th Epoch, 18580th Step, learning rate = 0.008121086381472065 - Loss: 0.382915735244751, aux loss1: 0.8698102235794067, 
		 aux loss2: 0.4854283630847931, total loss: 0.8380301594734192
3th Epoch, 18585th Step, learning rate = 0.00812057468267141 - Loss: 0.3444007933139801, aux loss1: 0.7939853668212891, 
		 aux loss2: 0.4267805814743042, total loss: 0.7533086538314819
3th Epoch, 18590th Step, learning rate = 0.008120062980288117 - Loss: 0.35105612874031067, aux loss1: 0.9762755632400513, 
		 aux loss2: 0.4843693673610687, total loss: 0.8376865386962891
3th Epoch, 18595th Step, learning rate = 0.008119551274321912 - Loss: 0.39343249797821045, aux loss1: 0.8501531481742859, 
		 aux loss2: 0.49568212032318115, total loss: 0.84675133228302
3th Epoch, 18600th Step, learning rate = 0.008119039564772522 - Loss: 0.47398826479911804, aux loss1: 0.9935922622680664, 
		 aux loss2: 0.608788013458252, total loss: 1.0155812501907349
<18600th step>
*************************** Test ***************************
time:3m 12s, 18600th Step, Loss: 0.53525310754776, Mean IoU = 43.317%
************************************************************
3th Epoch, 18605th Step, learning rate = 0.008118527851639669 - Loss: 0.33365750312805176, aux loss1: 0.7961776852607727, 
		 aux loss2: 0.45125284790992737, total loss: 0.7530120015144348
3th Epoch, 18610th Step, learning rate = 0.008118016134923077 - Loss: 0.4988221526145935, aux loss1: 1.0401763916015625, 
		 aux loss2: 0.6145578622817993, total loss: 1.056698203086853
4th Epoch, 18615th Step, learning rate = 0.00811750441462247 - Loss: 0.2845747172832489, aux loss1: 0.6821334362030029, 
		 aux loss2: 0.3611110746860504, total loss: 0.6336592435836792
4th Epoch, 18620th Step, learning rate = 0.00811699269073757 - Loss: 0.361935555934906, aux loss1: 0.9042413830757141, 
		 aux loss2: 0.47358351945877075, total loss: 0.8226413726806641
4th Epoch, 18625th Step, learning rate = 0.008116480963268103 - Loss: 0.3101640045642853, aux loss1: 0.7888510823249817, 
		 aux loss2: 0.4332771897315979, total loss: 0.720130205154419
4th Epoch, 18630th Step, learning rate = 0.008115969232213794 - Loss: 0.2685695290565491, aux loss1: 0.7273909449577332, 
		 aux loss2: 0.3607793152332306, total loss: 0.6310985684394836
4th Epoch, 18635th Step, learning rate = 0.008115457497574365 - Loss: 0.34272655844688416, aux loss1: 0.8080142736434937, 
		 aux loss2: 0.432594358921051, total loss: 0.758168637752533
4th Epoch, 18640th Step, learning rate = 0.008114945759349538 - Loss: 0.30843761563301086, aux loss1: 0.7317242622375488, 
		 aux loss2: 0.3817203640937805, total loss: 0.6806430816650391
4th Epoch, 18645th Step, learning rate = 0.00811443401753904 - Loss: 0.3421148955821991, aux loss1: 0.9149619936943054, 
		 aux loss2: 0.4584823548793793, total loss: 0.7999964356422424
4th Epoch, 18650th Step, learning rate = 0.008113922272142592 - Loss: 0.32055529952049255, aux loss1: 0.8640809059143066, 
		 aux loss2: 0.43032556772232056, total loss: 0.7519098520278931
4th Epoch, 18655th Step, learning rate = 0.00811341052315992 - Loss: 0.5482309460639954, aux loss1: 1.0273544788360596, 
		 aux loss2: 0.6850225329399109, total loss: 1.1304463148117065
4th Epoch, 18660th Step, learning rate = 0.008112898770590746 - Loss: 0.31417763233184814, aux loss1: 0.7311232089996338, 
		 aux loss2: 0.38812145590782166, total loss: 0.6887632012367249
4th Epoch, 18665th Step, learning rate = 0.008112387014434792 - Loss: 0.3504307270050049, aux loss1: 0.9216833710670471, 
		 aux loss2: 0.4695671796798706, total loss: 0.8147625923156738
4th Epoch, 18670th Step, learning rate = 0.008111875254691784 - Loss: 0.36268603801727295, aux loss1: 0.8538134694099426, 
		 aux loss2: 0.4785638451576233, total loss: 0.8102556467056274
4th Epoch, 18675th Step, learning rate = 0.008111363491361444 - Loss: 0.4531765580177307, aux loss1: 0.9348154067993164, 
		 aux loss2: 0.5523799061775208, total loss: 0.9545731544494629
4th Epoch, 18680th Step, learning rate = 0.008110851724443497 - Loss: 0.5377318859100342, aux loss1: 0.9963299036026001, 
		 aux loss2: 0.6314908266067505, total loss: 1.0892271995544434
4th Epoch, 18685th Step, learning rate = 0.008110339953937664 - Loss: 0.330186665058136, aux loss1: 0.7262457013130188, 
		 aux loss2: 0.4200209081172943, total loss: 0.7160688042640686
4th Epoch, 18690th Step, learning rate = 0.00810982817984367 - Loss: 0.41523194313049316, aux loss1: 0.8803786039352417, 
		 aux loss2: 0.5413448214530945, total loss: 0.8958835005760193
4th Epoch, 18695th Step, learning rate = 0.008109316402161238 - Loss: 0.3425488770008087, aux loss1: 0.801080048084259, 
		 aux loss2: 0.4225517213344574, total loss: 0.7518935799598694
4th Epoch, 18700th Step, learning rate = 0.008108804620890092 - Loss: 0.41389593482017517, aux loss1: 0.9152110815048218, 
		 aux loss2: 0.5209518671035767, total loss: 0.8968400359153748
<18700th step>
*************************** Test ***************************
time:3m 15s, 18700th Step, Loss: 0.6334706544876099, Mean IoU = 39.821%
************************************************************
4th Epoch, 18705th Step, learning rate = 0.008108292836029951 - Loss: 0.364378958940506, aux loss1: 0.865883469581604, 
		 aux loss2: 0.45056265592575073, total loss: 0.8043690919876099
4th Epoch, 18710th Step, learning rate = 0.008107781047580545 - Loss: 0.4826653301715851, aux loss1: 0.8907037973403931, 
		 aux loss2: 0.5667450428009033, total loss: 0.9765745401382446
4th Epoch, 18715th Step, learning rate = 0.00810726925554159 - Loss: 0.36446458101272583, aux loss1: 0.7983945608139038, 
		 aux loss2: 0.45255082845687866, total loss: 0.7850032448768616
4th Epoch, 18720th Step, learning rate = 0.008106757459912814 - Loss: 0.4444202184677124, aux loss1: 0.9661779403686523, 
		 aux loss2: 0.5543921589851379, total loss: 0.9560304880142212
4th Epoch, 18725th Step, learning rate = 0.008106245660693939 - Loss: 0.5283186435699463, aux loss1: 1.1023132801055908, 
		 aux loss2: 0.677936851978302, total loss: 1.1301873922348022
4th Epoch, 18730th Step, learning rate = 0.008105733857884686 - Loss: 0.36724865436553955, aux loss1: 0.8777138590812683, 
		 aux loss2: 0.49588415026664734, total loss: 0.8289164304733276
4th Epoch, 18735th Step, learning rate = 0.00810522205148478 - Loss: 0.3199770152568817, aux loss1: 0.8166213035583496, 
		 aux loss2: 0.4373589754104614, total loss: 0.7399070262908936
4th Epoch, 18740th Step, learning rate = 0.008104710241493942 - Loss: 0.4216271936893463, aux loss1: 0.9947546124458313, 
		 aux loss2: 0.5302013158798218, total loss: 0.9321340918540955
4th Epoch, 18745th Step, learning rate = 0.008104198427911897 - Loss: 0.45697444677352905, aux loss1: 0.8832905888557434, 
		 aux loss2: 0.5877760648727417, total loss: 0.9570720195770264
4th Epoch, 18750th Step, learning rate = 0.008103686610738367 - Loss: 0.3867591619491577, aux loss1: 0.8309308886528015, 
		 aux loss2: 0.4677649736404419, total loss: 0.8231444358825684
4th Epoch, 18755th Step, learning rate = 0.008103174789973074 - Loss: 0.593373715877533, aux loss1: 1.196159839630127, 
		 aux loss2: 0.7879980802536011, total loss: 1.2674208879470825
4th Epoch, 18760th Step, learning rate = 0.00810266296561574 - Loss: 0.39331114292144775, aux loss1: 0.8485739827156067, 
		 aux loss2: 0.5174469351768494, total loss: 0.8548621535301208
4th Epoch, 18765th Step, learning rate = 0.00810215113766609 - Loss: 0.40816521644592285, aux loss1: 0.9269678592681885, 
		 aux loss2: 0.5138859152793884, total loss: 0.8918099403381348
4th Epoch, 18770th Step, learning rate = 0.008101639306123848 - Loss: 0.4561013877391815, aux loss1: 0.9336665868759155, 
		 aux loss2: 0.5583532452583313, total loss: 0.9595426917076111
4th Epoch, 18775th Step, learning rate = 0.00810112747098873 - Loss: 0.3113190829753876, aux loss1: 0.7647172808647156, 
		 aux loss2: 0.40658387541770935, total loss: 0.7033678293228149
4th Epoch, 18780th Step, learning rate = 0.008100615632260465 - Loss: 0.3716033697128296, aux loss1: 0.7888259887695312, 
		 aux loss2: 0.46107786893844604, total loss: 0.7926822900772095
4th Epoch, 18785th Step, learning rate = 0.008100103789938773 - Loss: 0.4416118264198303, aux loss1: 0.8451808094978333, 
		 aux loss2: 0.53675776720047, total loss: 0.9098691940307617
4th Epoch, 18790th Step, learning rate = 0.008099591944023377 - Loss: 0.3178117573261261, aux loss1: 0.7764847874641418, 
		 aux loss2: 0.41326630115509033, total loss: 0.7160636782646179
4th Epoch, 18795th Step, learning rate = 0.008099080094513999 - Loss: 0.48208382725715637, aux loss1: 0.9262718558311462, 
		 aux loss2: 0.5749771595001221, total loss: 0.989956259727478
4th Epoch, 18800th Step, learning rate = 0.008098568241410361 - Loss: 0.3943672478199005, aux loss1: 1.0270674228668213, 
		 aux loss2: 0.5295831561088562, total loss: 0.914320707321167
<18800th step>
*************************** Test ***************************
time:3m 13s, 18800th Step, Loss: 0.5361742973327637, Mean IoU = 42.353%
************************************************************
4th Epoch, 18805th Step, learning rate = 0.008098056384712185 - Loss: 0.38644614815711975, aux loss1: 0.9437664151191711, 
		 aux loss2: 0.5221309661865234, total loss: 0.8784284591674805
4th Epoch, 18810th Step, learning rate = 0.008097544524419195 - Loss: 0.3457697927951813, aux loss1: 0.8462823629379272, 
		 aux loss2: 0.462511271238327, total loss: 0.7846590876579285
4th Epoch, 18815th Step, learning rate = 0.008097032660531111 - Loss: 0.41959425806999207, aux loss1: 0.9701549410820007, 
		 aux loss2: 0.5462707877159119, total loss: 0.9291490912437439
4th Epoch, 18820th Step, learning rate = 0.00809652079304766 - Loss: 0.3929859697818756, aux loss1: 0.8679580092430115, 
		 aux loss2: 0.5063326954841614, total loss: 0.8559064269065857
4th Epoch, 18825th Step, learning rate = 0.008096008921968559 - Loss: 0.4351447522640228, aux loss1: 0.824264645576477, 
		 aux loss2: 0.5103707909584045, total loss: 0.8865724802017212
4th Epoch, 18830th Step, learning rate = 0.00809549704729353 - Loss: 0.4641353487968445, aux loss1: 1.066704273223877, 
		 aux loss2: 0.5972838997840881, total loss: 1.0230602025985718
4th Epoch, 18835th Step, learning rate = 0.0080949851690223 - Loss: 0.4426221549510956, aux loss1: 0.8826496005058289, 
		 aux loss2: 0.558745265007019, total loss: 0.930915117263794
4th Epoch, 18840th Step, learning rate = 0.008094473287154588 - Loss: 0.3806465268135071, aux loss1: 0.7338496446609497, 
		 aux loss2: 0.45368310809135437, total loss: 0.7822746634483337
4th Epoch, 18845th Step, learning rate = 0.008093961401690115 - Loss: 0.34935304522514343, aux loss1: 0.9608762264251709, 
		 aux loss2: 0.48085370659828186, total loss: 0.8299574255943298
4th Epoch, 18850th Step, learning rate = 0.008093449512628605 - Loss: 0.4395296275615692, aux loss1: 0.9961539506912231, 
		 aux loss2: 0.5873317718505859, total loss: 0.9733085036277771
4th Epoch, 18855th Step, learning rate = 0.008092937619969778 - Loss: 0.33610743284225464, aux loss1: 0.7731907367706299, 
		 aux loss2: 0.4480995833873749, total loss: 0.7473045587539673
4th Epoch, 18860th Step, learning rate = 0.008092425723713359 - Loss: 0.343553751707077, aux loss1: 0.7481275796890259, 
		 aux loss2: 0.41919824481010437, total loss: 0.73567134141922
4th Epoch, 18865th Step, learning rate = 0.008091913823859067 - Loss: 0.46041277050971985, aux loss1: 1.0222729444503784, 
		 aux loss2: 0.6100789904594421, total loss: 1.0111262798309326
4th Epoch, 18870th Step, learning rate = 0.008091401920406622 - Loss: 0.35970166325569153, aux loss1: 0.8018089532852173, 
		 aux loss2: 0.46458205580711365, total loss: 0.7860771417617798
4th Epoch, 18875th Step, learning rate = 0.00809089001335575 - Loss: 0.4578102231025696, aux loss1: 1.0049747228622437, 
		 aux loss2: 0.5777108073234558, total loss: 0.990386962890625
4th Epoch, 18880th Step, learning rate = 0.008090378102706172 - Loss: 0.42034173011779785, aux loss1: 0.8291729092597961, 
		 aux loss2: 0.5192500352859497, total loss: 0.876793622970581
4th Epoch, 18885th Step, learning rate = 0.008089866188457608 - Loss: 0.3487004041671753, aux loss1: 0.9074748158454895, 
		 aux loss2: 0.4696879982948303, total loss: 0.8088180422782898
4th Epoch, 18890th Step, learning rate = 0.008089354270609783 - Loss: 0.35381805896759033, aux loss1: 0.8381592631340027, 
		 aux loss2: 0.4601851999759674, total loss: 0.7893399596214294
4th Epoch, 18895th Step, learning rate = 0.008088842349162413 - Loss: 0.3266298770904541, aux loss1: 0.749491810798645, 
		 aux loss2: 0.40393123030662537, total loss: 0.7130499482154846
4th Epoch, 18900th Step, learning rate = 0.008088330424115223 - Loss: 0.33043190836906433, aux loss1: 0.9151899814605713, 
		 aux loss2: 0.4447330832481384, total loss: 0.7828821539878845
<18900th step>
*************************** Test ***************************
time:3m 12s, 18900th Step, Loss: 0.5631287693977356, Mean IoU = 42.862%
************************************************************
4th Epoch, 18905th Step, learning rate = 0.008087818495467936 - Loss: 0.44372856616973877, aux loss1: 0.9086616039276123, 
		 aux loss2: 0.553587794303894, total loss: 0.9377622008323669
4th Epoch, 18910th Step, learning rate = 0.00808730656322027 - Loss: 0.3190463185310364, aux loss1: 0.7343176007270813, 
		 aux loss2: 0.3844357132911682, total loss: 0.6931159496307373
4th Epoch, 18915th Step, learning rate = 0.008086794627371949 - Loss: 0.36398687958717346, aux loss1: 0.8527548909187317, 
		 aux loss2: 0.47386622428894043, total loss: 0.8093597888946533
4th Epoch, 18920th Step, learning rate = 0.008086282687922693 - Loss: 0.2966426908969879, aux loss1: 0.7763397097587585, 
		 aux loss2: 0.38643908500671387, total loss: 0.684120237827301
4th Epoch, 18925th Step, learning rate = 0.008085770744872225 - Loss: 0.38094857335090637, aux loss1: 0.9911931157112122, 
		 aux loss2: 0.49388235807418823, total loss: 0.8758594989776611
4th Epoch, 18930th Step, learning rate = 0.008085258798220264 - Loss: 0.40684032440185547, aux loss1: 0.8993220329284668, 
		 aux loss2: 0.4940432608127594, total loss: 0.8742542266845703
4th Epoch, 18935th Step, learning rate = 0.008084746847966532 - Loss: 0.3730756938457489, aux loss1: 0.8346702456474304, 
		 aux loss2: 0.46561500430107117, total loss: 0.8097227811813354
4th Epoch, 18940th Step, learning rate = 0.008084234894110752 - Loss: 0.30464112758636475, aux loss1: 0.6929831504821777, 
		 aux loss2: 0.37852540612220764, total loss: 0.6639462113380432
4th Epoch, 18945th Step, learning rate = 0.008083722936652646 - Loss: 0.4101419448852539, aux loss1: 0.8584445118904114, 
		 aux loss2: 0.513698399066925, total loss: 0.8731546998023987
4th Epoch, 18950th Step, learning rate = 0.008083210975591929 - Loss: 0.41750264167785645, aux loss1: 0.9298062920570374, 
		 aux loss2: 0.5253129601478577, total loss: 0.9065697193145752
4th Epoch, 18955th Step, learning rate = 0.008082699010928328 - Loss: 0.3563595414161682, aux loss1: 0.7826797962188721, 
		 aux loss2: 0.46973249316215515, total loss: 0.7790565490722656
4th Epoch, 18960th Step, learning rate = 0.008082187042661565 - Loss: 0.554861307144165, aux loss1: 1.105100393295288, 
		 aux loss2: 0.724044919013977, total loss: 1.1760094165802002
4th Epoch, 18965th Step, learning rate = 0.008081675070791354 - Loss: 0.4186636209487915, aux loss1: 0.9442815184593201, 
		 aux loss2: 0.5178603529930115, total loss: 0.9090921878814697
4th Epoch, 18970th Step, learning rate = 0.008081163095317421 - Loss: 0.3259492516517639, aux loss1: 0.7714442610740662, 
		 aux loss2: 0.3914472162723541, total loss: 0.7139614224433899
4th Epoch, 18975th Step, learning rate = 0.00808065111623949 - Loss: 0.5066186189651489, aux loss1: 0.9706335663795471, 
		 aux loss2: 0.6063991785049438, total loss: 1.0403683185577393
4th Epoch, 18980th Step, learning rate = 0.008080139133557273 - Loss: 0.37063542008399963, aux loss1: 0.8654965162277222, 
		 aux loss2: 0.4864650368690491, total loss: 0.8248704671859741
4th Epoch, 18985th Step, learning rate = 0.0080796271472705 - Loss: 0.5251815319061279, aux loss1: 1.0369118452072144, 
		 aux loss2: 0.6432206630706787, total loss: 1.093543291091919
5th Epoch, 18990th Step, learning rate = 0.008079115157378886 - Loss: 0.33771616220474243, aux loss1: 0.7773478627204895, 
		 aux loss2: 0.4224902093410492, total loss: 0.7399166226387024
5th Epoch, 18995th Step, learning rate = 0.008078603163882153 - Loss: 0.33930709958076477, aux loss1: 0.7734400629997253, 
		 aux loss2: 0.4148195683956146, total loss: 0.7372669577598572
5th Epoch, 19000th Step, learning rate = 0.008078091166780025 - Loss: 0.42651814222335815, aux loss1: 0.8895584344863892, 
		 aux loss2: 0.5518132448196411, total loss: 0.9141110181808472
<19000th step>
*************************** Test ***************************
time:3m 10s, 19000th Step, Loss: 0.5339033007621765, Mean IoU = 41.996%
************************************************************
5th Epoch, 19005th Step, learning rate = 0.008077579166072218 - Loss: 0.42716488242149353, aux loss1: 0.9225424528121948, 
		 aux loss2: 0.5526048541069031, total loss: 0.9249695539474487
5th Epoch, 19010th Step, learning rate = 0.008077067161758456 - Loss: 0.3555947244167328, aux loss1: 0.8502034544944763, 
		 aux loss2: 0.474788635969162, total loss: 0.8005712628364563
5th Epoch, 19015th Step, learning rate = 0.008076555153838457 - Loss: 0.4004111886024475, aux loss1: 0.9051284790039062, 
		 aux loss2: 0.5011759996414185, total loss: 0.8724201321601868
5th Epoch, 19020th Step, learning rate = 0.008076043142311943 - Loss: 0.39546260237693787, aux loss1: 0.8531347513198853, 
		 aux loss2: 0.49304091930389404, total loss: 0.8486194610595703
5th Epoch, 19025th Step, learning rate = 0.008075531127178636 - Loss: 0.3383157551288605, aux loss1: 0.8422015309333801, 
		 aux loss2: 0.43262428045272827, total loss: 0.7640259265899658
5th Epoch, 19030th Step, learning rate = 0.008075019108438256 - Loss: 0.3178718090057373, aux loss1: 0.7895491719245911, 
		 aux loss2: 0.435782253742218, total loss: 0.7290494441986084
5th Epoch, 19035th Step, learning rate = 0.00807450708609052 - Loss: 0.3377813696861267, aux loss1: 0.8127832412719727, 
		 aux loss2: 0.4310321509838104, total loss: 0.7540292143821716
5th Epoch, 19040th Step, learning rate = 0.008073995060135153 - Loss: 0.297035813331604, aux loss1: 0.7479860186576843, 
		 aux loss2: 0.40242043137550354, total loss: 0.6823998093605042
5th Epoch, 19045th Step, learning rate = 0.00807348303057187 - Loss: 0.6270424723625183, aux loss1: 1.2783035039901733, 
		 aux loss2: 0.8186622262001038, total loss: 1.3379985094070435
5th Epoch, 19050th Step, learning rate = 0.008072970997400397 - Loss: 0.4083782434463501, aux loss1: 0.8319485187530518, 
		 aux loss2: 0.5021516680717468, total loss: 0.8588234782218933
5th Epoch, 19055th Step, learning rate = 0.008072458960620452 - Loss: 0.3854689300060272, aux loss1: 0.822679340839386, 
		 aux loss2: 0.4766720235347748, total loss: 0.8229415416717529
5th Epoch, 19060th Step, learning rate = 0.008071946920231754 - Loss: 0.40191519260406494, aux loss1: 0.9381389617919922, 
		 aux loss2: 0.5136624574661255, total loss: 0.8888218402862549
5th Epoch, 19065th Step, learning rate = 0.008071434876234025 - Loss: 0.39522644877433777, aux loss1: 0.8812815546989441, 
		 aux loss2: 0.503760039806366, total loss: 0.8611149787902832
5th Epoch, 19070th Step, learning rate = 0.008070922828626986 - Loss: 0.6457565426826477, aux loss1: 1.2764919996261597, 
		 aux loss2: 0.846809446811676, total loss: 1.367427945137024
5th Epoch, 19075th Step, learning rate = 0.008070410777410353 - Loss: 0.6037036180496216, aux loss1: 1.1908745765686035, 
		 aux loss2: 0.7492477893829346, total loss: 1.2606651782989502
5th Epoch, 19080th Step, learning rate = 0.00806989872258385 - Loss: 0.33214449882507324, aux loss1: 0.7337649464607239, 
		 aux loss2: 0.4250063896179199, total loss: 0.7222765684127808
5th Epoch, 19085th Step, learning rate = 0.008069386664147195 - Loss: 0.43625694513320923, aux loss1: 1.0478041172027588, 
		 aux loss2: 0.5668379068374634, total loss: 0.9773333668708801
5th Epoch, 19090th Step, learning rate = 0.00806887460210011 - Loss: 0.38447681069374084, aux loss1: 0.7695073485374451, 
		 aux loss2: 0.47751089930534363, total loss: 0.8063334226608276
5th Epoch, 19095th Step, learning rate = 0.008068362536442313 - Loss: 0.36171871423721313, aux loss1: 0.8736546039581299, 
		 aux loss2: 0.45973020792007446, total loss: 0.8077071905136108
5th Epoch, 19100th Step, learning rate = 0.008067850467173525 - Loss: 0.3680340647697449, aux loss1: 0.7774367928504944, 
		 aux loss2: 0.4478830099105835, total loss: 0.780418336391449
<19100th step>
*************************** Test ***************************
time:3m 12s, 19100th Step, Loss: 0.6033325791358948, Mean IoU = 42.115%
************************************************************
5th Epoch, 19105th Step, learning rate = 0.008067338394293464 - Loss: 0.5026370286941528, aux loss1: 1.1921643018722534, 
		 aux loss2: 0.6723340749740601, total loss: 1.1292200088500977
5th Epoch, 19110th Step, learning rate = 0.008066826317801853 - Loss: 0.4095117151737213, aux loss1: 0.8402859568595886, 
		 aux loss2: 0.493933767080307, total loss: 0.8591710329055786
5th Epoch, 19115th Step, learning rate = 0.00806631423769841 - Loss: 0.3143593966960907, aux loss1: 0.6939239501953125, 
		 aux loss2: 0.3975417912006378, total loss: 0.681553304195404
5th Epoch, 19120th Step, learning rate = 0.008065802153982855 - Loss: 0.35102540254592896, aux loss1: 0.8198814392089844, 
		 aux loss2: 0.45971018075942993, total loss: 0.7808739542961121
5th Epoch, 19125th Step, learning rate = 0.008065290066654907 - Loss: 0.4347207844257355, aux loss1: 0.9813077449798584, 
		 aux loss2: 0.5555183291435242, total loss: 0.9513204097747803
5th Epoch, 19130th Step, learning rate = 0.008064777975714286 - Loss: 0.4549741744995117, aux loss1: 0.999506950378418, 
		 aux loss2: 0.5719217658042908, total loss: 0.9835950136184692
5th Epoch, 19135th Step, learning rate = 0.008064265881160711 - Loss: 0.4071398079395294, aux loss1: 0.9160242080688477, 
		 aux loss2: 0.5070827007293701, total loss: 0.8847801685333252
5th Epoch, 19140th Step, learning rate = 0.008063753782993906 - Loss: 0.34901881217956543, aux loss1: 0.8743963837623596, 
		 aux loss2: 0.4501487910747528, total loss: 0.7913973331451416
5th Epoch, 19145th Step, learning rate = 0.008063241681213584 - Loss: 0.4945051074028015, aux loss1: 1.0472080707550049, 
		 aux loss2: 0.6148207783699036, total loss: 1.0545958280563354
5th Epoch, 19150th Step, learning rate = 0.008062729575819468 - Loss: 0.4047745168209076, aux loss1: 0.9068741798400879, 
		 aux loss2: 0.5338068604469299, total loss: 0.8903595209121704
5th Epoch, 19155th Step, learning rate = 0.008062217466811277 - Loss: 0.5756202936172485, aux loss1: 1.0776076316833496, 
		 aux loss2: 0.7220478057861328, total loss: 1.1877217292785645
5th Epoch, 19160th Step, learning rate = 0.008061705354188733 - Loss: 0.4027602970600128, aux loss1: 0.9484147429466248, 
		 aux loss2: 0.5204358100891113, total loss: 0.8954590559005737
5th Epoch, 19165th Step, learning rate = 0.008061193237951549 - Loss: 0.35153812170028687, aux loss1: 0.8305351138114929, 
		 aux loss2: 0.4567040801048279, total loss: 0.7833802700042725
5th Epoch, 19170th Step, learning rate = 0.008060681118099449 - Loss: 0.4693881571292877, aux loss1: 0.9056656360626221, 
		 aux loss2: 0.5646577477455139, total loss: 0.9669509530067444
5th Epoch, 19175th Step, learning rate = 0.008060168994632154 - Loss: 0.2950774133205414, aux loss1: 0.7513232827186584, 
		 aux loss2: 0.37990716099739075, total loss: 0.672437310218811
5th Epoch, 19180th Step, learning rate = 0.008059656867549378 - Loss: 0.48394709825515747, aux loss1: 1.1161967515945435, 
		 aux loss2: 0.623691737651825, total loss: 1.0682828426361084
5th Epoch, 19185th Step, learning rate = 0.008059144736850843 - Loss: 0.34626418352127075, aux loss1: 0.7905165553092957, 
		 aux loss2: 0.43317896127700806, total loss: 0.7566907405853271
5th Epoch, 19190th Step, learning rate = 0.008058632602536267 - Loss: 0.5022501945495605, aux loss1: 1.1177600622177124, 
		 aux loss2: 0.6602778434753418, total loss: 1.101689338684082
5th Epoch, 19195th Step, learning rate = 0.008058120464605373 - Loss: 0.3355589509010315, aux loss1: 0.8137181997299194, 
		 aux loss2: 0.44663190841674805, total loss: 0.7583271861076355
5th Epoch, 19200th Step, learning rate = 0.008057608323057876 - Loss: 0.40443193912506104, aux loss1: 0.8236929178237915, 
		 aux loss2: 0.5012252926826477, total loss: 0.8520299196243286
<19200th step>
*************************** Test ***************************
time:3m 12s, 19200th Step, Loss: 0.5632690787315369, Mean IoU = 42.200%
************************************************************
5th Epoch, 19205th Step, learning rate = 0.008057096177893497 - Loss: 0.4173458516597748, aux loss1: 0.8479186296463013, 
		 aux loss2: 0.5211572647094727, total loss: 0.8801843523979187
5th Epoch, 19210th Step, learning rate = 0.008056584029111954 - Loss: 0.32311782240867615, aux loss1: 0.8025200366973877, 
		 aux loss2: 0.4276721775531769, total loss: 0.7349426746368408
5th Epoch, 19215th Step, learning rate = 0.008056071876712966 - Loss: 0.3542689383029938, aux loss1: 0.9215443730354309, 
		 aux loss2: 0.4437635540962219, total loss: 0.8082377314567566
5th Epoch, 19220th Step, learning rate = 0.008055559720696251 - Loss: 0.47655731439590454, aux loss1: 0.9649865031242371, 
		 aux loss2: 0.6078686714172363, total loss: 1.0092008113861084
5th Epoch, 19225th Step, learning rate = 0.008055047561061532 - Loss: 0.45601513981819153, aux loss1: 0.935997724533081, 
		 aux loss2: 0.5568658113479614, total loss: 0.9595608115196228
5th Epoch, 19230th Step, learning rate = 0.008054535397808522 - Loss: 0.33164307475090027, aux loss1: 0.7966991662979126, 
		 aux loss2: 0.4200206398963928, total loss: 0.7386611104011536
5th Epoch, 19235th Step, learning rate = 0.008054023230936944 - Loss: 0.40130096673965454, aux loss1: 0.8369031548500061, 
		 aux loss2: 0.4860931932926178, total loss: 0.8468091487884521
5th Epoch, 19240th Step, learning rate = 0.008053511060446515 - Loss: 0.28854265809059143, aux loss1: 0.7098255753517151, 
		 aux loss2: 0.3666496276855469, total loss: 0.6481502056121826
5th Epoch, 19245th Step, learning rate = 0.008052998886336952 - Loss: 0.2982744574546814, aux loss1: 0.783259928226471, 
		 aux loss2: 0.38139578700065613, total loss: 0.6858108043670654
5th Epoch, 19250th Step, learning rate = 0.00805248670860798 - Loss: 0.41168951988220215, aux loss1: 1.0178107023239136, 
		 aux loss2: 0.5328987240791321, total loss: 0.930192232131958
5th Epoch, 19255th Step, learning rate = 0.00805197452725931 - Loss: 0.31988051533699036, aux loss1: 0.8037593364715576, 
		 aux loss2: 0.4170309007167816, total loss: 0.7278206944465637
5th Epoch, 19260th Step, learning rate = 0.008051462342290667 - Loss: 0.3493454158306122, aux loss1: 0.7691991329193115, 
		 aux loss2: 0.4202738404273987, total loss: 0.7482147216796875
5th Epoch, 19265th Step, learning rate = 0.008050950153701766 - Loss: 0.4415058493614197, aux loss1: 0.8799154758453369, 
		 aux loss2: 0.534781277179718, total loss: 0.9193930625915527
5th Epoch, 19270th Step, learning rate = 0.008050437961492326 - Loss: 0.3372834026813507, aux loss1: 0.8698912858963013, 
		 aux loss2: 0.44328558444976807, total loss: 0.7755650281906128
5th Epoch, 19275th Step, learning rate = 0.008049925765662064 - Loss: 0.4548320174217224, aux loss1: 0.970849335193634, 
		 aux loss2: 0.5527552962303162, total loss: 0.9671889543533325
5th Epoch, 19280th Step, learning rate = 0.008049413566210702 - Loss: 0.3808840811252594, aux loss1: 0.8715261816978455, 
		 aux loss2: 0.4965969920158386, total loss: 0.8409807682037354
5th Epoch, 19285th Step, learning rate = 0.008048901363137954 - Loss: 0.4704822301864624, aux loss1: 1.069558024406433, 
		 aux loss2: 0.5912164449691772, total loss: 1.0278362035751343
5th Epoch, 19290th Step, learning rate = 0.008048389156443542 - Loss: 0.3956368565559387, aux loss1: 0.9874635338783264, 
		 aux loss2: 0.5768916606903076, total loss: 0.9226325750350952
5th Epoch, 19295th Step, learning rate = 0.008047876946127182 - Loss: 0.38642722368240356, aux loss1: 0.8838613033294678, 
		 aux loss2: 0.48335057497024536, total loss: 0.8449258804321289
5th Epoch, 19300th Step, learning rate = 0.008047364732188594 - Loss: 0.32642826437950134, aux loss1: 0.8108017444610596, 
		 aux loss2: 0.4320787787437439, total loss: 0.7425003051757812
<19300th step>
*************************** Test ***************************
time:3m 15s, 19300th Step, Loss: 0.5243858098983765, Mean IoU = 42.145%
************************************************************
5th Epoch, 19305th Step, learning rate = 0.008046852514627497 - Loss: 0.3242611587047577, aux loss1: 0.7880414128303528, 
		 aux loss2: 0.4184130132198334, total loss: 0.7280387878417969
5th Epoch, 19310th Step, learning rate = 0.008046340293443605 - Loss: 0.3649252951145172, aux loss1: 0.857481062412262, 
		 aux loss2: 0.47155991196632385, total loss: 0.8107935786247253
5th Epoch, 19315th Step, learning rate = 0.00804582806863664 - Loss: 0.3909262716770172, aux loss1: 0.9471642971038818, 
		 aux loss2: 0.4944436550140381, total loss: 0.8728529810905457
5th Epoch, 19320th Step, learning rate = 0.008045315840206319 - Loss: 0.2985312342643738, aux loss1: 0.7420032620429993, 
		 aux loss2: 0.4033527374267578, total loss: 0.6824733018875122
5th Epoch, 19325th Step, learning rate = 0.00804480360815236 - Loss: 0.36185383796691895, aux loss1: 0.8761100172996521, 
		 aux loss2: 0.4725334048271179, total loss: 0.8137001991271973
5th Epoch, 19330th Step, learning rate = 0.008044291372474479 - Loss: 0.39803528785705566, aux loss1: 0.9759491086006165, 
		 aux loss2: 0.5480056405067444, total loss: 0.9100223183631897
5th Epoch, 19335th Step, learning rate = 0.008043779133172398 - Loss: 0.4669254422187805, aux loss1: 0.8824858665466309, 
		 aux loss2: 0.5296111702919006, total loss: 0.9435156583786011
5th Epoch, 19340th Step, learning rate = 0.00804326689024583 - Loss: 0.46087223291397095, aux loss1: 0.9552437663078308, 
		 aux loss2: 0.5577057600021362, total loss: 0.9705276489257812
5th Epoch, 19345th Step, learning rate = 0.008042754643694498 - Loss: 0.4417499899864197, aux loss1: 0.9790187478065491, 
		 aux loss2: 0.6078889966011047, total loss: 0.9786112308502197
5th Epoch, 19350th Step, learning rate = 0.008042242393518117 - Loss: 0.3316243886947632, aux loss1: 0.7306714653968811, 
		 aux loss2: 0.4162124991416931, total loss: 0.7173108458518982
5th Epoch, 19355th Step, learning rate = 0.008041730139716406 - Loss: 0.29876795411109924, aux loss1: 0.6840715408325195, 
		 aux loss2: 0.37752291560173035, total loss: 0.6549986600875854
6th Epoch, 19360th Step, learning rate = 0.00804121788228908 - Loss: 0.3343425691127777, aux loss1: 0.8580250144004822, 
		 aux loss2: 0.4683035910129547, total loss: 0.7790715098381042
6th Epoch, 19365th Step, learning rate = 0.008040705621235858 - Loss: 0.35520854592323303, aux loss1: 0.8743928670883179, 
		 aux loss2: 0.49265140295028687, total loss: 0.8145869970321655
6th Epoch, 19370th Step, learning rate = 0.00804019335655646 - Loss: 0.3912869393825531, aux loss1: 0.8686974048614502, 
		 aux loss2: 0.5114331841468811, total loss: 0.856469452381134
6th Epoch, 19375th Step, learning rate = 0.008039681088250603 - Loss: 0.35470646619796753, aux loss1: 0.8214852213859558, 
		 aux loss2: 0.4495807886123657, total loss: 0.7809844017028809
6th Epoch, 19380th Step, learning rate = 0.008039168816318002 - Loss: 0.5440073013305664, aux loss1: 1.077400803565979, 
		 aux loss2: 0.6495195627212524, total loss: 1.12703537940979
6th Epoch, 19385th Step, learning rate = 0.008038656540758377 - Loss: 0.3552180230617523, aux loss1: 0.8860365748405457, 
		 aux loss2: 0.4641018509864807, total loss: 0.8066697716712952
6th Epoch, 19390th Step, learning rate = 0.008038144261571446 - Loss: 0.31787389516830444, aux loss1: 0.8702661991119385, 
		 aux loss2: 0.4343723952770233, total loss: 0.7527027130126953
6th Epoch, 19395th Step, learning rate = 0.008037631978756923 - Loss: 0.5282081365585327, aux loss1: 1.0531286001205444, 
		 aux loss2: 0.6465530395507812, total loss: 1.1027679443359375
6th Epoch, 19400th Step, learning rate = 0.008037119692314526 - Loss: 0.41274720430374146, aux loss1: 0.9963299036026001, 
		 aux loss2: 0.5483735799789429, total loss: 0.9309956431388855
<19400th step>
*************************** Test ***************************
time:3m 21s, 19400th Step, Loss: 0.5496290922164917, Mean IoU = 41.694%
************************************************************
6th Epoch, 19405th Step, learning rate = 0.008036607402243975 - Loss: 0.44691964983940125, aux loss1: 0.9988914728164673, 
		 aux loss2: 0.6123715043067932, total loss: 0.9915357232093811
6th Epoch, 19410th Step, learning rate = 0.008036095108544987 - Loss: 0.5422376990318298, aux loss1: 0.9993060827255249, 
		 aux loss2: 0.6546304225921631, total loss: 1.1038817167282104
6th Epoch, 19415th Step, learning rate = 0.008035582811217279 - Loss: 0.40056028962135315, aux loss1: 0.873595118522644, 
		 aux loss2: 0.5055385231971741, total loss: 0.8648542761802673
6th Epoch, 19420th Step, learning rate = 0.008035070510260565 - Loss: 0.5412919521331787, aux loss1: 1.065961480140686, 
		 aux loss2: 0.683333158493042, total loss: 1.134413719177246
6th Epoch, 19425th Step, learning rate = 0.008034558205674567 - Loss: 0.3850500285625458, aux loss1: 0.8152217268943787, 
		 aux loss2: 0.47003835439682007, total loss: 0.8176319003105164
6th Epoch, 19430th Step, learning rate = 0.008034045897459 - Loss: 0.5064325332641602, aux loss1: 1.141133189201355, 
		 aux loss2: 0.6748928427696228, total loss: 1.1187297105789185
6th Epoch, 19435th Step, learning rate = 0.00803353358561358 - Loss: 0.46583127975463867, aux loss1: 1.0674790143966675, 
		 aux loss2: 0.6631112694740295, total loss: 1.0513194799423218
6th Epoch, 19440th Step, learning rate = 0.008033021270138026 - Loss: 0.5605652332305908, aux loss1: 1.1179462671279907, 
		 aux loss2: 0.7047651410102844, total loss: 1.1778552532196045
6th Epoch, 19445th Step, learning rate = 0.008032508951032054 - Loss: 0.41698798537254333, aux loss1: 1.0118861198425293, 
		 aux loss2: 0.5598193407058716, total loss: 0.944481611251831
6th Epoch, 19450th Step, learning rate = 0.008031996628295382 - Loss: 0.6382502913475037, aux loss1: 1.2600778341293335, 
		 aux loss2: 0.7761075496673584, total loss: 1.326716661453247
6th Epoch, 19455th Step, learning rate = 0.008031484301927724 - Loss: 0.3589046597480774, aux loss1: 0.867107093334198, 
		 aux loss2: 0.4740678668022156, total loss: 0.8086639642715454
6th Epoch, 19460th Step, learning rate = 0.008030971971928803 - Loss: 0.3521742820739746, aux loss1: 0.8064229488372803, 
		 aux loss2: 0.43012022972106934, total loss: 0.7661492824554443
6th Epoch, 19465th Step, learning rate = 0.008030459638298328 - Loss: 0.3980371057987213, aux loss1: 0.8470353484153748, 
		 aux loss2: 0.5006453990936279, total loss: 0.8524059057235718
6th Epoch, 19470th Step, learning rate = 0.008029947301036022 - Loss: 0.37886470556259155, aux loss1: 0.916828989982605, 
		 aux loss2: 0.49257150292396545, total loss: 0.8509420156478882
6th Epoch, 19475th Step, learning rate = 0.008029434960141598 - Loss: 0.31514066457748413, aux loss1: 0.7965154647827148, 
		 aux loss2: 0.3919866383075714, total loss: 0.710889995098114
6th Epoch, 19480th Step, learning rate = 0.008028922615614774 - Loss: 0.4912727475166321, aux loss1: 0.9935876131057739, 
		 aux loss2: 0.5900881886482239, total loss: 1.0253843069076538
6th Epoch, 19485th Step, learning rate = 0.00802841026745527 - Loss: 0.47409728169441223, aux loss1: 0.9992671012878418, 
		 aux loss2: 0.5987915992736816, total loss: 1.0133939981460571
6th Epoch, 19490th Step, learning rate = 0.008027897915662798 - Loss: 0.3584801256656647, aux loss1: 0.8703822493553162, 
		 aux loss2: 0.4873645603656769, total loss: 0.8145406246185303
6th Epoch, 19495th Step, learning rate = 0.008027385560237075 - Loss: 0.31471627950668335, aux loss1: 0.8656972646713257, 
		 aux loss2: 0.4154728949069977, total loss: 0.740614652633667
6th Epoch, 19500th Step, learning rate = 0.008026873201177821 - Loss: 0.40005311369895935, aux loss1: 0.8332864046096802, 
		 aux loss2: 0.5028282403945923, total loss: 0.8511703610420227
<19500th step>
*************************** Test ***************************
time:3m 18s, 19500th Step, Loss: 0.5686632394790649, Mean IoU = 41.478%
************************************************************
6th Epoch, 19505th Step, learning rate = 0.00802636083848475 - Loss: 0.3339693546295166, aux loss1: 0.7694106698036194, 
		 aux loss2: 0.40912872552871704, total loss: 0.7284440994262695
6th Epoch, 19510th Step, learning rate = 0.008025848472157577 - Loss: 0.40825551748275757, aux loss1: 0.826866626739502, 
		 aux loss2: 0.5211696624755859, total loss: 0.8647834062576294
6th Epoch, 19515th Step, learning rate = 0.008025336102196022 - Loss: 0.37981224060058594, aux loss1: 0.854952871799469, 
		 aux loss2: 0.46742457151412964, total loss: 0.823267936706543
6th Epoch, 19520th Step, learning rate = 0.0080248237285998 - Loss: 0.36214563250541687, aux loss1: 0.8190042972564697, 
		 aux loss2: 0.45641350746154785, total loss: 0.7904123067855835
6th Epoch, 19525th Step, learning rate = 0.008024311351368626 - Loss: 0.4141601622104645, aux loss1: 0.8459802865982056, 
		 aux loss2: 0.5096395611763, total loss: 0.8718100786209106
6th Epoch, 19530th Step, learning rate = 0.008023798970502219 - Loss: 0.30592066049575806, aux loss1: 0.7024057507514954, 
		 aux loss2: 0.3883782625198364, total loss: 0.6719937324523926
6th Epoch, 19535th Step, learning rate = 0.008023286586000291 - Loss: 0.44642460346221924, aux loss1: 0.9415209293365479, 
		 aux loss2: 0.5756771564483643, total loss: 0.9591517448425293
6th Epoch, 19540th Step, learning rate = 0.008022774197862563 - Loss: 0.5476569533348083, aux loss1: 1.1061102151870728, 
		 aux loss2: 0.6675495505332947, total loss: 1.1465098857879639
6th Epoch, 19545th Step, learning rate = 0.008022261806088747 - Loss: 0.2880210876464844, aux loss1: 0.7238122224807739, 
		 aux loss2: 0.37070780992507935, total loss: 0.6534478664398193
6th Epoch, 19550th Step, learning rate = 0.008021749410678562 - Loss: 0.5221555829048157, aux loss1: 1.080786108970642, 
		 aux loss2: 0.6733526587486267, total loss: 1.1157325506210327
6th Epoch, 19555th Step, learning rate = 0.008021237011631726 - Loss: 0.3311682641506195, aux loss1: 0.863760232925415, 
		 aux loss2: 0.43502432107925415, total loss: 0.7643061280250549
6th Epoch, 19560th Step, learning rate = 0.008020724608947951 - Loss: 0.4608171880245209, aux loss1: 0.9433587789535522, 
		 aux loss2: 0.583855152130127, total loss: 0.9773669242858887
6th Epoch, 19565th Step, learning rate = 0.008020212202626952 - Loss: 0.6558003425598145, aux loss1: 1.2797492742538452, 
		 aux loss2: 0.8235101699829102, total loss: 1.3691293001174927
6th Epoch, 19570th Step, learning rate = 0.00801969979266845 - Loss: 0.4474819600582123, aux loss1: 0.9932534098625183, 
		 aux loss2: 0.5859493017196655, total loss: 0.9798377156257629
6th Epoch, 19575th Step, learning rate = 0.008019187379072156 - Loss: 0.37280961871147156, aux loss1: 0.892750084400177, 
		 aux loss2: 0.5024830102920532, total loss: 0.841627836227417
6th Epoch, 19580th Step, learning rate = 0.00801867496183779 - Loss: 0.44224411249160767, aux loss1: 0.8554159998893738, 
		 aux loss2: 0.5019851922988892, total loss: 0.8996630311012268
6th Epoch, 19585th Step, learning rate = 0.008018162540965067 - Loss: 0.33720940351486206, aux loss1: 0.7687047719955444, 
		 aux loss2: 0.4346000850200653, total loss: 0.7416608929634094
6th Epoch, 19590th Step, learning rate = 0.0080176501164537 - Loss: 0.5156941413879395, aux loss1: 0.9933809638023376, 
		 aux loss2: 0.6360433101654053, total loss: 1.0681257247924805
6th Epoch, 19595th Step, learning rate = 0.008017137688303408 - Loss: 0.39883118867874146, aux loss1: 0.9621359705924988, 
		 aux loss2: 0.5355901122093201, total loss: 0.9017080068588257
6th Epoch, 19600th Step, learning rate = 0.008016625256513903 - Loss: 0.2904801070690155, aux loss1: 0.763746440410614, 
		 aux loss2: 0.3844921588897705, total loss: 0.67340087890625
<19600th step>
*************************** Test ***************************
time:3m 17s, 19600th Step, Loss: 0.555253267288208, Mean IoU = 42.095%
************************************************************
6th Epoch, 19605th Step, learning rate = 0.008016112821084906 - Loss: 0.3274361491203308, aux loss1: 0.7609796524047852, 
		 aux loss2: 0.4155862629413605, total loss: 0.7219645380973816
6th Epoch, 19610th Step, learning rate = 0.008015600382016128 - Loss: 0.3712467551231384, aux loss1: 0.7916039824485779, 
		 aux loss2: 0.45887866616249084, total loss: 0.7922794222831726
6th Epoch, 19615th Step, learning rate = 0.008015087939307287 - Loss: 0.32612696290016174, aux loss1: 0.8050619959831238, 
		 aux loss2: 0.4355018734931946, total loss: 0.7418463230133057
6th Epoch, 19620th Step, learning rate = 0.008014575492958097 - Loss: 0.3418789803981781, aux loss1: 0.8341543078422546, 
		 aux loss2: 0.44618847966194153, total loss: 0.7706006765365601
6th Epoch, 19625th Step, learning rate = 0.008014063042968277 - Loss: 0.3804025948047638, aux loss1: 0.8140996694564819, 
		 aux loss2: 0.4926588535308838, total loss: 0.8216960430145264
6th Epoch, 19630th Step, learning rate = 0.008013550589337537 - Loss: 0.37849071621894836, aux loss1: 0.9220590591430664, 
		 aux loss2: 0.5074706673622131, total loss: 0.858096718788147
6th Epoch, 19635th Step, learning rate = 0.008013038132065595 - Loss: 0.30118754506111145, aux loss1: 0.816002607345581, 
		 aux loss2: 0.4096226394176483, total loss: 0.7098373770713806
6th Epoch, 19640th Step, learning rate = 0.008012525671152168 - Loss: 0.2866193354129791, aux loss1: 0.7643718719482422, 
		 aux loss2: 0.3953620195388794, total loss: 0.674075722694397
6th Epoch, 19645th Step, learning rate = 0.00801201320659697 - Loss: 0.43321454524993896, aux loss1: 0.9152932167053223, 
		 aux loss2: 0.5358325839042664, total loss: 0.922135591506958
6th Epoch, 19650th Step, learning rate = 0.008011500738399716 - Loss: 0.28688719868659973, aux loss1: 0.7390953302383423, 
		 aux loss2: 0.3705943524837494, total loss: 0.6568535566329956
6th Epoch, 19655th Step, learning rate = 0.00801098826656012 - Loss: 0.4029085338115692, aux loss1: 0.8409885168075562, 
		 aux loss2: 0.4985721707344055, total loss: 0.8546339869499207
6th Epoch, 19660th Step, learning rate = 0.0080104757910779 - Loss: 0.3943341076374054, aux loss1: 1.087546467781067, 
		 aux loss2: 0.5520458817481995, total loss: 0.9414164423942566
6th Epoch, 19665th Step, learning rate = 0.008009963311952771 - Loss: 0.36301687359809875, aux loss1: 1.054295301437378, 
		 aux loss2: 0.5001501441001892, total loss: 0.8793655037879944
6th Epoch, 19670th Step, learning rate = 0.008009450829184446 - Loss: 0.3341585397720337, aux loss1: 0.7483189702033997, 
		 aux loss2: 0.4158666431903839, total loss: 0.7250009179115295
6th Epoch, 19675th Step, learning rate = 0.00800893834277264 - Loss: 0.39566269516944885, aux loss1: 1.019237995147705, 
		 aux loss2: 0.5308037996292114, total loss: 0.9137556552886963
6th Epoch, 19680th Step, learning rate = 0.008008425852717072 - Loss: 0.39479148387908936, aux loss1: 0.955439031124115, 
		 aux loss2: 0.5244743824005127, total loss: 0.8912129402160645
6th Epoch, 19685th Step, learning rate = 0.008007913359017453 - Loss: 0.30370673537254333, aux loss1: 0.7911109328269958, 
		 aux loss2: 0.3942103683948517, total loss: 0.6987241506576538
6th Epoch, 19690th Step, learning rate = 0.008007400861673498 - Loss: 0.42927271127700806, aux loss1: 0.9183757901191711, 
		 aux loss2: 0.5467679500579834, total loss: 0.9234926700592041
6th Epoch, 19695th Step, learning rate = 0.008006888360684925 - Loss: 0.4319402277469635, aux loss1: 0.9921799302101135, 
		 aux loss2: 0.5766528248786926, total loss: 0.9602553844451904
6th Epoch, 19700th Step, learning rate = 0.008006375856051445 - Loss: 0.36449912190437317, aux loss1: 0.8284862041473389, 
		 aux loss2: 0.4703359007835388, total loss: 0.8011793494224548
<19700th step>
*************************** Test ***************************
time:3m 16s, 19700th Step, Loss: 0.5856040120124817, Mean IoU = 40.658%
************************************************************
6th Epoch, 19705th Step, learning rate = 0.008005863347772774 - Loss: 0.33587974309921265, aux loss1: 0.8574742674827576, 
		 aux loss2: 0.4352286458015442, total loss: 0.7672134637832642
6th Epoch, 19710th Step, learning rate = 0.008005350835848631 - Loss: 0.33734411001205444, aux loss1: 0.7633503675460815, 
		 aux loss2: 0.41546037793159485, total loss: 0.73253333568573
6th Epoch, 19715th Step, learning rate = 0.008004838320278724 - Loss: 0.39602130651474, aux loss1: 0.9089652895927429, 
		 aux loss2: 0.5057511329650879, total loss: 0.8710113763809204
6th Epoch, 19720th Step, learning rate = 0.008004325801062773 - Loss: 0.39446714520454407, aux loss1: 0.8019195199012756, 
		 aux loss2: 0.47182217240333557, total loss: 0.8237718939781189
6th Epoch, 19725th Step, learning rate = 0.008003813278200489 - Loss: 0.37792056798934937, aux loss1: 0.9209142327308655, 
		 aux loss2: 0.4935263693332672, total loss: 0.8516054153442383
7th Epoch, 19730th Step, learning rate = 0.008003300751691589 - Loss: 0.40642428398132324, aux loss1: 0.9000645875930786, 
		 aux loss2: 0.5223695635795593, total loss: 0.8853915333747864
7th Epoch, 19735th Step, learning rate = 0.008002788221535788 - Loss: 0.29586145281791687, aux loss1: 0.7585306763648987, 
		 aux loss2: 0.3944636285305023, total loss: 0.6812061667442322
7th Epoch, 19740th Step, learning rate = 0.0080022756877328 - Loss: 0.4339785575866699, aux loss1: 0.8940805196762085, 
		 aux loss2: 0.542850136756897, total loss: 0.9193428158760071
7th Epoch, 19745th Step, learning rate = 0.008001763150282335 - Loss: 0.5418021082878113, aux loss1: 0.9695233106613159, 
		 aux loss2: 0.6492413282394409, total loss: 1.092355728149414
7th Epoch, 19750th Step, learning rate = 0.008001250609184116 - Loss: 0.349187433719635, aux loss1: 0.7793928384780884, 
		 aux loss2: 0.46728643774986267, total loss: 0.7699198722839355
7th Epoch, 19755th Step, learning rate = 0.00800073806443785 - Loss: 0.4301782548427582, aux loss1: 0.9267348051071167, 
		 aux loss2: 0.5620188117027283, total loss: 0.9330061674118042
7th Epoch, 19760th Step, learning rate = 0.008000225516043253 - Loss: 0.4179510474205017, aux loss1: 0.9703868627548218, 
		 aux loss2: 0.5374234318733215, total loss: 0.9240365028381348
7th Epoch, 19765th Step, learning rate = 0.007999712964000044 - Loss: 0.3692048192024231, aux loss1: 0.8991033434867859, 
		 aux loss2: 0.4819018840789795, total loss: 0.8316965699195862
7th Epoch, 19770th Step, learning rate = 0.00799920040830793 - Loss: 0.4586295783519745, aux loss1: 1.0287944078445435, 
		 aux loss2: 0.5750724077224731, total loss: 0.997296929359436
7th Epoch, 19775th Step, learning rate = 0.007998687848966632 - Loss: 0.4637403190135956, aux loss1: 1.0206878185272217, 
		 aux loss2: 0.6084071397781372, total loss: 1.0133095979690552
7th Epoch, 19780th Step, learning rate = 0.007998175285975859 - Loss: 0.30002209544181824, aux loss1: 0.7848676443099976, 
		 aux loss2: 0.4014037847518921, total loss: 0.6960439085960388
7th Epoch, 19785th Step, learning rate = 0.007997662719335328 - Loss: 0.3474729359149933, aux loss1: 0.8113029599189758, 
		 aux loss2: 0.4380633234977722, total loss: 0.766089141368866
7th Epoch, 19790th Step, learning rate = 0.007997150149044754 - Loss: 0.4591730237007141, aux loss1: 1.0236138105392456, 
		 aux loss2: 0.6023199558258057, total loss: 1.0071851015090942
7th Epoch, 19795th Step, learning rate = 0.007996637575103847 - Loss: 0.4614700376987457, aux loss1: 0.9991029500961304, 
		 aux loss2: 0.5878522396087646, total loss: 0.9963418245315552
7th Epoch, 19800th Step, learning rate = 0.007996124997512325 - Loss: 0.355670690536499, aux loss1: 0.8986828327178955, 
		 aux loss2: 0.48265862464904785, total loss: 0.8183389902114868
<19800th step>
*************************** Test ***************************
time:3m 17s, 19800th Step, Loss: 0.5255043506622314, Mean IoU = 42.527%
************************************************************
7th Epoch, 19805th Step, learning rate = 0.0079956124162699 - Loss: 0.3475598096847534, aux loss1: 0.784640908241272, 
		 aux loss2: 0.44077059626579285, total loss: 0.7592602968215942
7th Epoch, 19810th Step, learning rate = 0.007995099831376284 - Loss: 0.5185774564743042, aux loss1: 1.0672106742858887, 
		 aux loss2: 0.6944619417190552, total loss: 1.1165255308151245
7th Epoch, 19815th Step, learning rate = 0.007994587242831195 - Loss: 0.41309478878974915, aux loss1: 0.9725496768951416, 
		 aux loss2: 0.5435138940811157, total loss: 0.9222652912139893
7th Epoch, 19820th Step, learning rate = 0.007994074650634347 - Loss: 0.3686622679233551, aux loss1: 0.9790260791778564, 
		 aux loss2: 0.5083040595054626, total loss: 0.8656917214393616
7th Epoch, 19825th Step, learning rate = 0.00799356205478545 - Loss: 0.4376249313354492, aux loss1: 0.9841921329498291, 
		 aux loss2: 0.5552756786346436, total loss: 0.9549928903579712
7th Epoch, 19830th Step, learning rate = 0.00799304945528422 - Loss: 0.27951398491859436, aux loss1: 0.7293944954872131, 
		 aux loss2: 0.36435118317604065, total loss: 0.6440727710723877
7th Epoch, 19835th Step, learning rate = 0.007992536852130371 - Loss: 0.33952128887176514, aux loss1: 0.8354157209396362, 
		 aux loss2: 0.43602100014686584, total loss: 0.7645543813705444
7th Epoch, 19840th Step, learning rate = 0.007992024245323618 - Loss: 0.4985591471195221, aux loss1: 1.038015604019165, 
		 aux loss2: 0.650812029838562, total loss: 1.0702886581420898
7th Epoch, 19845th Step, learning rate = 0.007991511634863668 - Loss: 0.2706155478954315, aux loss1: 0.7216540575027466, 
		 aux loss2: 0.3598063588142395, total loss: 0.6310343146324158
7th Epoch, 19850th Step, learning rate = 0.007990999020750242 - Loss: 0.3466552495956421, aux loss1: 0.7647246718406677, 
		 aux loss2: 0.46260595321655273, total loss: 0.7611150741577148
7th Epoch, 19855th Step, learning rate = 0.007990486402983051 - Loss: 0.4715893268585205, aux loss1: 1.04560124874115, 
		 aux loss2: 0.5936691164970398, total loss: 1.0227373838424683
7th Epoch, 19860th Step, learning rate = 0.007989973781561808 - Loss: 0.46819329261779785, aux loss1: 1.0902804136276245, 
		 aux loss2: 0.6573320031166077, total loss: 1.0582102537155151
7th Epoch, 19865th Step, learning rate = 0.007989461156486227 - Loss: 0.5757692456245422, aux loss1: 1.0382399559020996, 
		 aux loss2: 0.7099125385284424, total loss: 1.1712062358856201
7th Epoch, 19870th Step, learning rate = 0.00798894852775602 - Loss: 0.42881637811660767, aux loss1: 0.9675332903862, 
		 aux loss2: 0.5557013154029846, total loss: 0.941356897354126
7th Epoch, 19875th Step, learning rate = 0.007988435895370903 - Loss: 0.39560288190841675, aux loss1: 0.8574349284172058, 
		 aux loss2: 0.5163151621818542, total loss: 0.8593593835830688
7th Epoch, 19880th Step, learning rate = 0.00798792325933059 - Loss: 0.35114139318466187, aux loss1: 0.8922573924064636, 
		 aux loss2: 0.45843207836151123, total loss: 0.8021914958953857
7th Epoch, 19885th Step, learning rate = 0.007987410619634787 - Loss: 0.43573346734046936, aux loss1: 0.9106521606445312, 
		 aux loss2: 0.5660308003425598, total loss: 0.935341477394104
7th Epoch, 19890th Step, learning rate = 0.007986897976283217 - Loss: 0.35513123869895935, aux loss1: 0.8409189581871033, 
		 aux loss2: 0.4491060972213745, total loss: 0.787049412727356
7th Epoch, 19895th Step, learning rate = 0.007986385329275588 - Loss: 0.36153334379196167, aux loss1: 0.8622207641601562, 
		 aux loss2: 0.4870688021183014, total loss: 0.815027117729187
7th Epoch, 19900th Step, learning rate = 0.007985872678611613 - Loss: 0.35751932859420776, aux loss1: 0.7751653790473938, 
		 aux loss2: 0.42449742555618286, total loss: 0.7598679065704346
<19900th step>
*************************** Test ***************************
time:3m 19s, 19900th Step, Loss: 0.5783858299255371, Mean IoU = 41.281%
************************************************************
7th Epoch, 19905th Step, learning rate = 0.007985360024291004 - Loss: 0.39495155215263367, aux loss1: 1.1456108093261719, 
		 aux loss2: 0.5717670917510986, total loss: 0.9673416614532471
7th Epoch, 19910th Step, learning rate = 0.007984847366313478 - Loss: 0.4992867410182953, aux loss1: 1.1159250736236572, 
		 aux loss2: 0.670672595500946, total loss: 1.1023333072662354
7th Epoch, 19915th Step, learning rate = 0.007984334704678747 - Loss: 0.3674261271953583, aux loss1: 0.8235327005386353, 
		 aux loss2: 0.45764920115470886, total loss: 0.7975456714630127
7th Epoch, 19920th Step, learning rate = 0.007983822039386522 - Loss: 0.47507211565971375, aux loss1: 1.0124247074127197, 
		 aux loss2: 0.5920025110244751, total loss: 1.015600562095642
7th Epoch, 19925th Step, learning rate = 0.007983309370436517 - Loss: 0.32111990451812744, aux loss1: 0.7948989272117615, 
		 aux loss2: 0.4050693213939667, total loss: 0.7216173410415649
7th Epoch, 19930th Step, learning rate = 0.007982796697828446 - Loss: 0.34341368079185486, aux loss1: 0.7703503966331482, 
		 aux loss2: 0.43113046884536743, total loss: 0.7469710111618042
7th Epoch, 19935th Step, learning rate = 0.00798228402156202 - Loss: 0.4508376717567444, aux loss1: 0.842271625995636, 
		 aux loss2: 0.5519286394119263, total loss: 0.924290657043457
7th Epoch, 19940th Step, learning rate = 0.007981771341636953 - Loss: 0.41235795617103577, aux loss1: 0.8097504377365112, 
		 aux loss2: 0.4987156391143799, total loss: 0.8547693490982056
7th Epoch, 19945th Step, learning rate = 0.007981258658052957 - Loss: 0.34534233808517456, aux loss1: 0.8376849889755249, 
		 aux loss2: 0.4610971510410309, total loss: 0.7810867428779602
7th Epoch, 19950th Step, learning rate = 0.007980745970809746 - Loss: 0.2818976938724518, aux loss1: 0.6730596423149109, 
		 aux loss2: 0.3538854420185089, total loss: 0.6253697872161865
7th Epoch, 19955th Step, learning rate = 0.007980233279907031 - Loss: 0.4233296811580658, aux loss1: 0.8711555004119873, 
		 aux loss2: 0.5512586832046509, total loss: 0.9051798582077026
7th Epoch, 19960th Step, learning rate = 0.007979720585344525 - Loss: 0.39578476548194885, aux loss1: 0.8870472311973572, 
		 aux loss2: 0.5200070738792419, total loss: 0.8699017763137817
7th Epoch, 19965th Step, learning rate = 0.007979207887121942 - Loss: 0.3123018145561218, aux loss1: 0.7625535130500793, 
		 aux loss2: 0.405428022146225, total loss: 0.7032390832901001
7th Epoch, 19970th Step, learning rate = 0.007978695185238995 - Loss: 0.4415125250816345, aux loss1: 0.9875941872596741, 
		 aux loss2: 0.5482505559921265, total loss: 0.9570910334587097
7th Epoch, 19975th Step, learning rate = 0.007978182479695393 - Loss: 0.4121631979942322, aux loss1: 0.9240853190422058, 
		 aux loss2: 0.5263214707374573, total loss: 0.8999174237251282
7th Epoch, 19980th Step, learning rate = 0.007977669770490851 - Loss: 0.26836371421813965, aux loss1: 0.7102236151695251, 
		 aux loss2: 0.3627687692642212, total loss: 0.6265383362770081
7th Epoch, 19985th Step, learning rate = 0.007977157057625082 - Loss: 0.3712671101093292, aux loss1: 0.7540178894996643, 
		 aux loss2: 0.4687747359275818, total loss: 0.7849823832511902
7th Epoch, 19990th Step, learning rate = 0.007976644341097796 - Loss: 0.3607066571712494, aux loss1: 0.8405076265335083, 
		 aux loss2: 0.470462828874588, total loss: 0.8010441064834595
7th Epoch, 19995th Step, learning rate = 0.007976131620908707 - Loss: 0.41342800855636597, aux loss1: 0.9182636737823486, 
		 aux loss2: 0.5292968153953552, total loss: 0.9006258845329285
7th Epoch, 20000th Step, learning rate = 0.007975618897057528 - Loss: 0.33290281891822815, aux loss1: 0.8185839653015137, 
		 aux loss2: 0.4283696413040161, total loss: 0.7498258948326111
<20000th step>
*************************** Test ***************************
time:3m 19s, 20000th Step, Loss: 0.5701864361763, Mean IoU = 39.711%
************************************************************
7th Epoch, 20005th Step, learning rate = 0.00797510616954397 - Loss: 0.3214120864868164, aux loss1: 0.7480269074440002, 
		 aux loss2: 0.3953807055950165, total loss: 0.7039724588394165
7th Epoch, 20010th Step, learning rate = 0.007974593438367747 - Loss: 0.3775321841239929, aux loss1: 0.9210866093635559, 
		 aux loss2: 0.5069180727005005, total loss: 0.8566254377365112
7th Epoch, 20015th Step, learning rate = 0.007974080703528568 - Loss: 0.41600802540779114, aux loss1: 0.8434222340583801, 
		 aux loss2: 0.4909205734729767, total loss: 0.8654029369354248
7th Epoch, 20020th Step, learning rate = 0.007973567965026147 - Loss: 0.3439497649669647, aux loss1: 0.819229006767273, 
		 aux loss2: 0.4421274662017822, total loss: 0.7665694355964661
7th Epoch, 20025th Step, learning rate = 0.007973055222860195 - Loss: 0.3967171013355255, aux loss1: 0.9256740212440491, 
		 aux loss2: 0.5360832214355469, total loss: 0.888852596282959
7th Epoch, 20030th Step, learning rate = 0.007972542477030428 - Loss: 0.354900985956192, aux loss1: 0.7905017733573914, 
		 aux loss2: 0.4460233151912689, total loss: 0.770460844039917
7th Epoch, 20035th Step, learning rate = 0.007972029727536552 - Loss: 0.33917397260665894, aux loss1: 0.8058173656463623, 
		 aux loss2: 0.46638423204421997, total loss: 0.7674729228019714
7th Epoch, 20040th Step, learning rate = 0.007971516974378284 - Loss: 0.3105655312538147, aux loss1: 0.7454570531845093, 
		 aux loss2: 0.40702536702156067, total loss: 0.6970127820968628
7th Epoch, 20045th Step, learning rate = 0.007971004217555335 - Loss: 0.3787960708141327, aux loss1: 0.9333583116531372, 
		 aux loss2: 0.5254903435707092, total loss: 0.868999719619751
7th Epoch, 20050th Step, learning rate = 0.007970491457067413 - Loss: 0.31448787450790405, aux loss1: 0.7400438785552979, 
		 aux loss2: 0.4111140966415405, total loss: 0.7009466886520386
7th Epoch, 20055th Step, learning rate = 0.007969978692914234 - Loss: 0.3048906922340393, aux loss1: 0.8116503357887268, 
		 aux loss2: 0.41042640805244446, total loss: 0.7125563621520996
7th Epoch, 20060th Step, learning rate = 0.007969465925095507 - Loss: 0.40635946393013, aux loss1: 0.9845126867294312, 
		 aux loss2: 0.510657548904419, total loss: 0.9059763550758362
7th Epoch, 20065th Step, learning rate = 0.007968953153610946 - Loss: 0.32801640033721924, aux loss1: 0.8098047375679016, 
		 aux loss2: 0.4345173239707947, total loss: 0.7447648048400879
7th Epoch, 20070th Step, learning rate = 0.007968440378460263 - Loss: 0.3553607165813446, aux loss1: 0.88097083568573, 
		 aux loss2: 0.48593199253082275, total loss: 0.814024806022644
7th Epoch, 20075th Step, learning rate = 0.007967927599643168 - Loss: 0.3167717158794403, aux loss1: 0.7770825624465942, 
		 aux loss2: 0.40361708402633667, total loss: 0.7113432884216309
7th Epoch, 20080th Step, learning rate = 0.007967414817159372 - Loss: 0.3603694438934326, aux loss1: 0.8714115619659424, 
		 aux loss2: 0.45772284269332886, total loss: 0.8048820495605469
7th Epoch, 20085th Step, learning rate = 0.007966902031008588 - Loss: 0.5556011199951172, aux loss1: 0.9318875074386597, 
		 aux loss2: 0.6757199764251709, total loss: 1.1054553985595703
7th Epoch, 20090th Step, learning rate = 0.007966389241190527 - Loss: 0.2679041922092438, aux loss1: 0.6938819289207458, 
		 aux loss2: 0.364260196685791, total loss: 0.6217728853225708
7th Epoch, 20095th Step, learning rate = 0.007965876447704901 - Loss: 0.4186013340950012, aux loss1: 0.9545938372612, 
		 aux loss2: 0.5559223890304565, total loss: 0.9273484945297241
8th Epoch, 20100th Step, learning rate = 0.00796536365055142 - Loss: 0.5006359815597534, aux loss1: 1.0558313131332397, 
		 aux loss2: 0.6368734836578369, total loss: 1.0721347332000732
<20100th step>
*************************** Test ***************************
time:3m 19s, 20100th Step, Loss: 0.5843193531036377, Mean IoU = 40.964%
************************************************************
8th Epoch, 20105th Step, learning rate = 0.007964850849729798 - Loss: 0.37464356422424316, aux loss1: 0.9000847935676575, 
		 aux loss2: 0.5151775479316711, total loss: 0.8507400751113892
8th Epoch, 20110th Step, learning rate = 0.007964338045239746 - Loss: 0.44521790742874146, aux loss1: 0.9891546964645386, 
		 aux loss2: 0.5731589198112488, total loss: 0.9712278842926025
8th Epoch, 20115th Step, learning rate = 0.007963825237080972 - Loss: 0.33977726101875305, aux loss1: 0.7387714982032776, 
		 aux loss2: 0.43364253640174866, total loss: 0.7348657250404358
8th Epoch, 20120th Step, learning rate = 0.007963312425253189 - Loss: 0.35080254077911377, aux loss1: 0.8296510577201843, 
		 aux loss2: 0.46994224190711975, total loss: 0.7876747846603394
8th Epoch, 20125th Step, learning rate = 0.00796279960975611 - Loss: 0.5552424788475037, aux loss1: 1.1756831407546997, 
		 aux loss2: 0.7531439065933228, total loss: 1.2092050313949585
8th Epoch, 20130th Step, learning rate = 0.007962286790589444 - Loss: 0.32122471928596497, aux loss1: 0.7573232054710388, 
		 aux loss2: 0.4163474440574646, total loss: 0.7149606943130493
8th Epoch, 20135th Step, learning rate = 0.007961773967752904 - Loss: 0.3432005047798157, aux loss1: 0.7288487553596497, 
		 aux loss2: 0.4222921133041382, total loss: 0.7307720184326172
8th Epoch, 20140th Step, learning rate = 0.007961261141246198 - Loss: 0.32381531596183777, aux loss1: 0.7255501747131348, 
		 aux loss2: 0.40407633781433105, total loss: 0.703110933303833
8th Epoch, 20145th Step, learning rate = 0.00796074831106904 - Loss: 0.3447825610637665, aux loss1: 0.7852077484130859, 
		 aux loss2: 0.43229615688323975, total loss: 0.7532633543014526
8th Epoch, 20150th Step, learning rate = 0.007960235477221142 - Loss: 0.4400617480278015, aux loss1: 0.9304214119911194, 
		 aux loss2: 0.5656580924987793, total loss: 0.9454514384269714
8th Epoch, 20155th Step, learning rate = 0.00795972263970221 - Loss: 0.32821181416511536, aux loss1: 0.7485683560371399, 
		 aux loss2: 0.42296934127807617, total loss: 0.7219700217247009
8th Epoch, 20160th Step, learning rate = 0.00795920979851196 - Loss: 0.36601388454437256, aux loss1: 0.8363103270530701, 
		 aux loss2: 0.49515387415885925, total loss: 0.8149685859680176
8th Epoch, 20165th Step, learning rate = 0.007958696953650101 - Loss: 0.3842441439628601, aux loss1: 0.8811709880828857, 
		 aux loss2: 0.5069481134414673, total loss: 0.8513746857643127
8th Epoch, 20170th Step, learning rate = 0.007958184105116341 - Loss: 0.427663654088974, aux loss1: 0.9557473063468933, 
		 aux loss2: 0.5810772776603699, total loss: 0.9468188285827637
8th Epoch, 20175th Step, learning rate = 0.007957671252910395 - Loss: 0.30237504839897156, aux loss1: 0.7093604207038879, 
		 aux loss2: 0.38777482509613037, total loss: 0.6702931523323059
8th Epoch, 20180th Step, learning rate = 0.007957158397031974 - Loss: 0.3414476811885834, aux loss1: 0.8348095417022705, 
		 aux loss2: 0.47537630796432495, total loss: 0.782041072845459
8th Epoch, 20185th Step, learning rate = 0.007956645537480786 - Loss: 0.38875067234039307, aux loss1: 0.8856837749481201, 
		 aux loss2: 0.5260382890701294, total loss: 0.864871084690094
8th Epoch, 20190th Step, learning rate = 0.00795613267425654 - Loss: 0.38009729981422424, aux loss1: 0.9251555800437927, 
		 aux loss2: 0.534020721912384, total loss: 0.8712522983551025
8th Epoch, 20195th Step, learning rate = 0.007955619807358953 - Loss: 0.29270485043525696, aux loss1: 0.7157381176948547, 
		 aux loss2: 0.36616766452789307, total loss: 0.6538933515548706
8th Epoch, 20200th Step, learning rate = 0.007955106936787729 - Loss: 0.2867518663406372, aux loss1: 0.6655572652816772, 
		 aux loss2: 0.36006593704223633, total loss: 0.6304454207420349
<20200th step>
*************************** Test ***************************
time:3m 19s, 20200th Step, Loss: 0.554503858089447, Mean IoU = 42.644%
************************************************************
8th Epoch, 20205th Step, learning rate = 0.007954594062542581 - Loss: 0.37715381383895874, aux loss1: 0.7751007676124573, 
		 aux loss2: 0.4275148808956146, total loss: 0.7806900143623352
8th Epoch, 20210th Step, learning rate = 0.007954081184623221 - Loss: 0.30979737639427185, aux loss1: 0.7580156922340393, 
		 aux loss2: 0.4144003391265869, total loss: 0.7029622793197632
8th Epoch, 20215th Step, learning rate = 0.007953568303029358 - Loss: 0.3880607783794403, aux loss1: 0.8381365537643433, 
		 aux loss2: 0.4853648543357849, total loss: 0.8336477279663086
8th Epoch, 20220th Step, learning rate = 0.007953055417760703 - Loss: 0.37049296498298645, aux loss1: 0.8129807114601135, 
		 aux loss2: 0.4727349877357483, total loss: 0.8034811615943909
8th Epoch, 20225th Step, learning rate = 0.007952542528816966 - Loss: 0.48183590173721313, aux loss1: 1.0615978240966797, 
		 aux loss2: 0.6521424055099487, total loss: 1.0611722469329834
8th Epoch, 20230th Step, learning rate = 0.007952029636197854 - Loss: 0.3181406855583191, aux loss1: 0.8104193210601807, 
		 aux loss2: 0.42247283458709717, total loss: 0.7302556037902832
8th Epoch, 20235th Step, learning rate = 0.007951516739903085 - Loss: 0.33781957626342773, aux loss1: 0.7507988810539246, 
		 aux loss2: 0.42652153968811035, total loss: 0.7336679100990295
8th Epoch, 20240th Step, learning rate = 0.007951003839932363 - Loss: 0.416251540184021, aux loss1: 1.0465952157974243, 
		 aux loss2: 0.5399516820907593, total loss: 0.9462107419967651
8th Epoch, 20245th Step, learning rate = 0.0079504909362854 - Loss: 0.322723388671875, aux loss1: 0.7218420505523682, 
		 aux loss2: 0.4010775685310364, total loss: 0.69970703125
8th Epoch, 20250th Step, learning rate = 0.007949978028961906 - Loss: 0.29644519090652466, aux loss1: 0.8249014019966125, 
		 aux loss2: 0.4027025103569031, total loss: 0.704996645450592
8th Epoch, 20255th Step, learning rate = 0.00794946511796159 - Loss: 0.30421891808509827, aux loss1: 0.7871026992797852, 
		 aux loss2: 0.39815443754196167, total loss: 0.699611485004425
8th Epoch, 20260th Step, learning rate = 0.007948952203284163 - Loss: 0.37337684631347656, aux loss1: 0.8356842994689941, 
		 aux loss2: 0.48964524269104004, total loss: 0.8199402689933777
8th Epoch, 20265th Step, learning rate = 0.007948439284929337 - Loss: 0.2857361137866974, aux loss1: 0.8121592402458191, 
		 aux loss2: 0.3973201811313629, total loss: 0.6883119940757751
8th Epoch, 20270th Step, learning rate = 0.007947926362896818 - Loss: 0.30358922481536865, aux loss1: 0.7519567608833313, 
		 aux loss2: 0.4095843434333801, total loss: 0.6930099725723267
8th Epoch, 20275th Step, learning rate = 0.00794741343718632 - Loss: 0.28752103447914124, aux loss1: 0.725942075252533, 
		 aux loss2: 0.3805930018424988, total loss: 0.6575409173965454
8th Epoch, 20280th Step, learning rate = 0.00794690050779755 - Loss: 0.3277241289615631, aux loss1: 0.8122773766517639, 
		 aux loss2: 0.4323817193508148, total loss: 0.7443600296974182
8th Epoch, 20285th Step, learning rate = 0.007946387574730217 - Loss: 0.4755740165710449, aux loss1: 1.0029693841934204, 
		 aux loss2: 0.6367993354797363, total loss: 1.0311845541000366
8th Epoch, 20290th Step, learning rate = 0.007945874637984036 - Loss: 0.32091209292411804, aux loss1: 0.782961368560791, 
		 aux loss2: 0.40003806352615356, total loss: 0.7158157229423523
8th Epoch, 20295th Step, learning rate = 0.007945361697558712 - Loss: 0.4323706030845642, aux loss1: 1.0405640602111816, 
		 aux loss2: 0.5759232044219971, total loss: 0.9749091267585754
8th Epoch, 20300th Step, learning rate = 0.007944848753453955 - Loss: 0.4603712558746338, aux loss1: 0.9214974045753479, 
		 aux loss2: 0.5583041310310364, total loss: 0.9601421356201172
<20300th step>
*************************** Test ***************************
time:3m 19s, 20300th Step, Loss: 0.59228515625, Mean IoU = 38.868%
************************************************************
8th Epoch, 20305th Step, learning rate = 0.007944335805669476 - Loss: 0.40644967555999756, aux loss1: 0.9055371284484863, 
		 aux loss2: 0.5381743311882019, total loss: 0.8933805823326111
8th Epoch, 20310th Step, learning rate = 0.007943822854204984 - Loss: 0.43657851219177246, aux loss1: 0.9914191365242004, 
		 aux loss2: 0.586155891418457, total loss: 0.9684666395187378
8th Epoch, 20315th Step, learning rate = 0.00794330989906019 - Loss: 0.3453022837638855, aux loss1: 0.8350986838340759, 
		 aux loss2: 0.4542635381221771, total loss: 0.7775372862815857
8th Epoch, 20320th Step, learning rate = 0.0079427969402348 - Loss: 0.3451393246650696, aux loss1: 0.7852416038513184, 
		 aux loss2: 0.4367177486419678, total loss: 0.7553989291191101
8th Epoch, 20325th Step, learning rate = 0.007942283977728528 - Loss: 0.38587453961372375, aux loss1: 0.8631418943405151, 
		 aux loss2: 0.4919714033603668, total loss: 0.8416056632995605
8th Epoch, 20330th Step, learning rate = 0.007941771011541079 - Loss: 0.34039467573165894, aux loss1: 0.7733651399612427, 
		 aux loss2: 0.4357737898826599, total loss: 0.7467137575149536
8th Epoch, 20335th Step, learning rate = 0.007941258041672165 - Loss: 0.36137983202934265, aux loss1: 0.8994980454444885, 
		 aux loss2: 0.4648330509662628, total loss: 0.8171625137329102
8th Epoch, 20340th Step, learning rate = 0.007940745068121497 - Loss: 0.48715171217918396, aux loss1: 0.8628392219543457, 
		 aux loss2: 0.5925223231315613, total loss: 0.9830124378204346
8th Epoch, 20345th Step, learning rate = 0.007940232090888781 - Loss: 0.34823742508888245, aux loss1: 0.8885561227798462, 
		 aux loss2: 0.463264137506485, total loss: 0.8001099228858948
8th Epoch, 20350th Step, learning rate = 0.007939719109973726 - Loss: 0.3243827223777771, aux loss1: 0.765570342540741, 
		 aux loss2: 0.42313921451568604, total loss: 0.7233095169067383
8th Epoch, 20355th Step, learning rate = 0.007939206125376045 - Loss: 0.47663089632987976, aux loss1: 1.042238712310791, 
		 aux loss2: 0.6265181303024292, total loss: 1.039909839630127
8th Epoch, 20360th Step, learning rate = 0.007938693137095445 - Loss: 0.27669063210487366, aux loss1: 0.6757673621177673, 
		 aux loss2: 0.36174440383911133, total loss: 0.6241186261177063
8th Epoch, 20365th Step, learning rate = 0.007938180145131634 - Loss: 0.39055052399635315, aux loss1: 1.015525221824646, 
		 aux loss2: 0.5247847437858582, total loss: 0.9051219820976257
8th Epoch, 20370th Step, learning rate = 0.007937667149484321 - Loss: 0.3409028947353363, aux loss1: 0.7766892910003662, 
		 aux loss2: 0.444394588470459, total loss: 0.7516675591468811
8th Epoch, 20375th Step, learning rate = 0.007937154150153218 - Loss: 0.42431026697158813, aux loss1: 0.9131118655204773, 
		 aux loss2: 0.516431987285614, total loss: 0.9048166275024414
8th Epoch, 20380th Step, learning rate = 0.00793664114713803 - Loss: 0.43850448727607727, aux loss1: 1.0847402811050415, 
		 aux loss2: 0.572563886642456, total loss: 0.9929521679878235
8th Epoch, 20385th Step, learning rate = 0.00793612814043847 - Loss: 0.3184114694595337, aux loss1: 0.7411799430847168, 
		 aux loss2: 0.4048764407634735, total loss: 0.702716052532196
8th Epoch, 20390th Step, learning rate = 0.007935615130054245 - Loss: 0.3640105724334717, aux loss1: 0.9016910791397095, 
		 aux loss2: 0.4854346513748169, total loss: 0.8286917805671692
8th Epoch, 20395th Step, learning rate = 0.007935102115985063 - Loss: 0.4052644670009613, aux loss1: 0.9591994881629944, 
		 aux loss2: 0.5310418009757996, total loss: 0.9054410457611084
8th Epoch, 20400th Step, learning rate = 0.007934589098230634 - Loss: 0.33052462339401245, aux loss1: 0.7814801931381226, 
		 aux loss2: 0.41524195671081543, total loss: 0.7310655117034912
<20400th step>
*************************** Test ***************************
time:3m 18s, 20400th Step, Loss: 0.532821774482727, Mean IoU = 43.001%
************************************************************
8th Epoch, 20405th Step, learning rate = 0.007934076076790666 - Loss: 0.40090152621269226, aux loss1: 0.8523577451705933, 
		 aux loss2: 0.5082637667655945, total loss: 0.8599143028259277
8th Epoch, 20410th Step, learning rate = 0.007933563051664868 - Loss: 0.3671739995479584, aux loss1: 0.8358921408653259, 
		 aux loss2: 0.45926526188850403, total loss: 0.8016477227210999
8th Epoch, 20415th Step, learning rate = 0.00793305002285295 - Loss: 0.4326508343219757, aux loss1: 1.0292679071426392, 
		 aux loss2: 0.572404682636261, total loss: 0.9703931212425232
8th Epoch, 20420th Step, learning rate = 0.007932536990354618 - Loss: 0.38673749566078186, aux loss1: 0.7617659568786621, 
		 aux loss2: 0.46159711480140686, total loss: 0.7999061346054077
8th Epoch, 20425th Step, learning rate = 0.007932023954169583 - Loss: 0.4018426835536957, aux loss1: 0.872187614440918, 
		 aux loss2: 0.5047317743301392, total loss: 0.865391731262207
8th Epoch, 20430th Step, learning rate = 0.007931510914297554 - Loss: 0.3058924973011017, aux loss1: 0.8085899353027344, 
		 aux loss2: 0.43616876006126404, total loss: 0.7229369878768921
8th Epoch, 20435th Step, learning rate = 0.007930997870738235 - Loss: 0.2753031253814697, aux loss1: 0.7101061940193176, 
		 aux loss2: 0.36882203817367554, total loss: 0.6358638405799866
8th Epoch, 20440th Step, learning rate = 0.00793048482349134 - Loss: 0.5355868339538574, aux loss1: 1.0714738368988037, 
		 aux loss2: 0.6579700708389282, total loss: 1.120216965675354
8th Epoch, 20445th Step, learning rate = 0.007929971772556573 - Loss: 0.3337579369544983, aux loss1: 0.8315994739532471, 
		 aux loss2: 0.44038158655166626, total loss: 0.7593904137611389
8th Epoch, 20450th Step, learning rate = 0.007929458717933645 - Loss: 0.4365321397781372, aux loss1: 0.8833189606666565, 
		 aux loss2: 0.5617506504058838, total loss: 0.9262281060218811
8th Epoch, 20455th Step, learning rate = 0.007928945659622266 - Loss: 0.3818626403808594, aux loss1: 0.872821033000946, 
		 aux loss2: 0.47725650668144226, total loss: 0.8346115350723267
8th Epoch, 20460th Step, learning rate = 0.00792843259762214 - Loss: 0.5446044206619263, aux loss1: 1.0597283840179443, 
		 aux loss2: 0.6589280962944031, total loss: 1.1260942220687866
8th Epoch, 20465th Step, learning rate = 0.007927919531932977 - Loss: 0.3788626790046692, aux loss1: 0.9235926866531372, 
		 aux loss2: 0.5064563155174255, total loss: 0.8585230708122253
9th Epoch, 20470th Step, learning rate = 0.00792740646255449 - Loss: 0.38816216588020325, aux loss1: 0.767899751663208, 
		 aux loss2: 0.4638327956199646, total loss: 0.8040652275085449
9th Epoch, 20475th Step, learning rate = 0.007926893389486376 - Loss: 0.4261905252933502, aux loss1: 0.9817908406257629, 
		 aux loss2: 0.5807772278785706, total loss: 0.9530386924743652
9th Epoch, 20480th Step, learning rate = 0.007926380312728354 - Loss: 0.40735527873039246, aux loss1: 0.8658337593078613, 
		 aux loss2: 0.5059458613395691, total loss: 0.8694837689399719
9th Epoch, 20485th Step, learning rate = 0.007925867232280127 - Loss: 0.42661404609680176, aux loss1: 1.1504013538360596, 
		 aux loss2: 0.5969423055648804, total loss: 1.0105113983154297
9th Epoch, 20490th Step, learning rate = 0.007925354148141404 - Loss: 0.39413130283355713, aux loss1: 1.0206648111343384, 
		 aux loss2: 0.53178870677948, total loss: 0.9130462408065796
9th Epoch, 20495th Step, learning rate = 0.007924841060311891 - Loss: 0.2484109103679657, aux loss1: 0.6973203420639038, 
		 aux loss2: 0.3500293791294098, total loss: 0.597618818283081
9th Epoch, 20500th Step, learning rate = 0.007924327968791299 - Loss: 0.3525357246398926, aux loss1: 0.8157263398170471, 
		 aux loss2: 0.4443368911743164, total loss: 0.7749884128570557
<20500th step>
*************************** Test ***************************
time:3m 16s, 20500th Step, Loss: 0.6143856644630432, Mean IoU = 43.208%
************************************************************
9th Epoch, 20505th Step, learning rate = 0.007923814873579335 - Loss: 0.354255348443985, aux loss1: 0.7831180691719055, 
		 aux loss2: 0.4341835081577301, total loss: 0.7628641724586487
9th Epoch, 20510th Step, learning rate = 0.007923301774675708 - Loss: 0.4173591732978821, aux loss1: 0.947120189666748, 
		 aux loss2: 0.5407611131668091, total loss: 0.917799711227417
9th Epoch, 20515th Step, learning rate = 0.007922788672080123 - Loss: 0.4474107027053833, aux loss1: 0.8078165054321289, 
		 aux loss2: 0.5352977514266968, total loss: 0.9038747549057007
9th Epoch, 20520th Step, learning rate = 0.007922275565792287 - Loss: 0.4050079584121704, aux loss1: 0.9710589051246643, 
		 aux loss2: 0.5205075740814209, total loss: 0.9045286774635315
9th Epoch, 20525th Step, learning rate = 0.007921762455811913 - Loss: 0.36651498079299927, aux loss1: 0.8431292772293091, 
		 aux loss2: 0.4700285494327545, total loss: 0.8074651956558228
9th Epoch, 20530th Step, learning rate = 0.007921249342138705 - Loss: 0.34383508563041687, aux loss1: 0.9163044691085815, 
		 aux loss2: 0.45608144998550415, total loss: 0.8011590242385864
9th Epoch, 20535th Step, learning rate = 0.00792073622477237 - Loss: 0.6258547902107239, aux loss1: 1.3185852766036987, 
		 aux loss2: 0.825982928276062, total loss: 1.3518235683441162
9th Epoch, 20540th Step, learning rate = 0.007920223103712619 - Loss: 0.37916865944862366, aux loss1: 0.836298942565918, 
		 aux loss2: 0.4793349504470825, total loss: 0.8217923641204834
9th Epoch, 20545th Step, learning rate = 0.007919709978959154 - Loss: 0.3719783425331116, aux loss1: 0.7827993035316467, 
		 aux loss2: 0.4659637212753296, total loss: 0.7932036519050598
9th Epoch, 20550th Step, learning rate = 0.007919196850511687 - Loss: 0.4034305214881897, aux loss1: 1.0062646865844727, 
		 aux loss2: 0.5607346296310425, total loss: 0.9296038150787354
9th Epoch, 20555th Step, learning rate = 0.007918683718369925 - Loss: 0.32964688539505005, aux loss1: 0.8208620548248291, 
		 aux loss2: 0.44685035943984985, total loss: 0.7546456456184387
9th Epoch, 20560th Step, learning rate = 0.007918170582533574 - Loss: 0.28996169567108154, aux loss1: 0.6429904103279114, 
		 aux loss2: 0.3653649687767029, total loss: 0.6290048360824585
9th Epoch, 20565th Step, learning rate = 0.007917657443002341 - Loss: 0.3248949348926544, aux loss1: 0.7658635377883911, 
		 aux loss2: 0.41263461112976074, total loss: 0.7197078466415405
9th Epoch, 20570th Step, learning rate = 0.007917144299775936 - Loss: 0.42911237478256226, aux loss1: 0.9639092087745667, 
		 aux loss2: 0.5592344999313354, total loss: 0.941978931427002
9th Epoch, 20575th Step, learning rate = 0.007916631152854063 - Loss: 0.46504902839660645, aux loss1: 0.954505980014801, 
		 aux loss2: 0.5945303440093994, total loss: 0.9892129898071289
9th Epoch, 20580th Step, learning rate = 0.007916118002236433 - Loss: 0.43069639801979065, aux loss1: 0.8753583431243896, 
		 aux loss2: 0.526751697063446, total loss: 0.9040046334266663
9th Epoch, 20585th Step, learning rate = 0.00791560484792275 - Loss: 0.4023374915122986, aux loss1: 0.8829408884048462, 
		 aux loss2: 0.5047993659973145, total loss: 0.8691394925117493
9th Epoch, 20590th Step, learning rate = 0.007915091689912722 - Loss: 0.4269312918186188, aux loss1: 0.9143404364585876, 
		 aux loss2: 0.5446900725364685, total loss: 0.9191094636917114
9th Epoch, 20595th Step, learning rate = 0.007914578528206057 - Loss: 0.48448681831359863, aux loss1: 1.0184061527252197, 
		 aux loss2: 0.6202172040939331, total loss: 1.0380955934524536
9th Epoch, 20600th Step, learning rate = 0.007914065362802461 - Loss: 0.5072879195213318, aux loss1: 1.0838192701339722, 
		 aux loss2: 0.6575730443000793, total loss: 1.0954629182815552
<20600th step>
*************************** Test ***************************
time:3m 17s, 20600th Step, Loss: 0.5881483554840088, Mean IoU = 40.693%
************************************************************
9th Epoch, 20605th Step, learning rate = 0.007913552193701639 - Loss: 0.3552071452140808, aux loss1: 0.7739859223365784, 
		 aux loss2: 0.4712603688240051, total loss: 0.7759070992469788
9th Epoch, 20610th Step, learning rate = 0.007913039020903304 - Loss: 0.38841286301612854, aux loss1: 0.9005759954452515, 
		 aux loss2: 0.5181314945220947, total loss: 0.8658382892608643
9th Epoch, 20615th Step, learning rate = 0.007912525844407157 - Loss: 0.5526273846626282, aux loss1: 1.1600546836853027, 
		 aux loss2: 0.7097806334495544, total loss: 1.1845561265945435
9th Epoch, 20620th Step, learning rate = 0.007912012664212908 - Loss: 0.49720585346221924, aux loss1: 0.9703545570373535, 
		 aux loss2: 0.6123138666152954, total loss: 1.0332376956939697
9th Epoch, 20625th Step, learning rate = 0.007911499480320262 - Loss: 0.32060179114341736, aux loss1: 0.8974006772041321, 
		 aux loss2: 0.449550986289978, total loss: 0.7696424126625061
9th Epoch, 20630th Step, learning rate = 0.007910986292728926 - Loss: 0.312028169631958, aux loss1: 0.8705173134803772, 
		 aux loss2: 0.4269261956214905, total loss: 0.7439538836479187
9th Epoch, 20635th Step, learning rate = 0.007910473101438609 - Loss: 0.39299893379211426, aux loss1: 0.9318910837173462, 
		 aux loss2: 0.51617830991745, total loss: 0.879037618637085
9th Epoch, 20640th Step, learning rate = 0.007909959906449016 - Loss: 0.4379839599132538, aux loss1: 0.9496696591377258, 
		 aux loss2: 0.5546454191207886, total loss: 0.9447430372238159
9th Epoch, 20645th Step, learning rate = 0.007909446707759853 - Loss: 0.4547915756702423, aux loss1: 1.0239235162734985, 
		 aux loss2: 0.5897783637046814, total loss: 0.9978799819946289
9th Epoch, 20650th Step, learning rate = 0.007908933505370828 - Loss: 0.3343254327774048, aux loss1: 0.8486649990081787, 
		 aux loss2: 0.44033282995224, total loss: 0.7650581002235413
9th Epoch, 20655th Step, learning rate = 0.007908420299281647 - Loss: 0.3432483375072479, aux loss1: 0.8344399929046631, 
		 aux loss2: 0.44552215933799744, total loss: 0.7717892527580261
9th Epoch, 20660th Step, learning rate = 0.007907907089492017 - Loss: 0.3754126727581024, aux loss1: 0.8587309122085571, 
		 aux loss2: 0.4840112328529358, total loss: 0.8266364336013794
9th Epoch, 20665th Step, learning rate = 0.007907393876001643 - Loss: 0.45127183198928833, aux loss1: 1.0679805278778076, 
		 aux loss2: 0.6051649451255798, total loss: 1.0137319564819336
9th Epoch, 20670th Step, learning rate = 0.007906880658810232 - Loss: 0.5696929097175598, aux loss1: 1.217444658279419, 
		 aux loss2: 0.7735522389411926, total loss: 1.2443472146987915
9th Epoch, 20675th Step, learning rate = 0.007906367437917491 - Loss: 0.5168991684913635, aux loss1: 0.969804048538208, 
		 aux loss2: 0.641231119632721, total loss: 1.0643328428268433
9th Epoch, 20680th Step, learning rate = 0.007905854213323129 - Loss: 0.3297761082649231, aux loss1: 0.8552417159080505, 
		 aux loss2: 0.4482957124710083, total loss: 0.7656669616699219
9th Epoch, 20685th Step, learning rate = 0.007905340985026847 - Loss: 0.3602360486984253, aux loss1: 0.9057767391204834, 
		 aux loss2: 0.4738800823688507, total loss: 0.8215211629867554
9th Epoch, 20690th Step, learning rate = 0.007904827753028353 - Loss: 0.3059512972831726, aux loss1: 0.7658684253692627, 
		 aux loss2: 0.3996960520744324, total loss: 0.6955902576446533
9th Epoch, 20695th Step, learning rate = 0.007904314517327354 - Loss: 0.3411611020565033, aux loss1: 0.813177227973938, 
		 aux loss2: 0.445934534072876, total loss: 0.7634881138801575
9th Epoch, 20700th Step, learning rate = 0.007903801277923558 - Loss: 0.39830079674720764, aux loss1: 0.983207106590271, 
		 aux loss2: 0.5616891980171204, total loss: 0.9179385900497437
<20700th step>
*************************** Test ***************************
time:3m 20s, 20700th Step, Loss: 0.5299175381660461, Mean IoU = 42.500%
************************************************************
9th Epoch, 20705th Step, learning rate = 0.007903288034816668 - Loss: 0.36671170592308044, aux loss1: 0.8689832091331482, 
		 aux loss2: 0.48137184977531433, total loss: 0.8199554681777954
9th Epoch, 20710th Step, learning rate = 0.007902774788006392 - Loss: 0.40306228399276733, aux loss1: 1.0578011274337769, 
		 aux loss2: 0.5371730327606201, total loss: 0.9352717995643616
9th Epoch, 20715th Step, learning rate = 0.007902261537492433 - Loss: 0.5141306519508362, aux loss1: 0.9765306711196899, 
		 aux loss2: 0.6149200797080994, total loss: 1.0530579090118408
9th Epoch, 20720th Step, learning rate = 0.007901748283274503 - Loss: 0.3302597403526306, aux loss1: 0.7436829805374146, 
		 aux loss2: 0.40119054913520813, total loss: 0.7138408422470093
9th Epoch, 20725th Step, learning rate = 0.007901235025352301 - Loss: 0.39272621273994446, aux loss1: 0.9388545751571655, 
		 aux loss2: 0.5279883146286011, total loss: 0.885577917098999
9th Epoch, 20730th Step, learning rate = 0.007900721763725537 - Loss: 0.34102731943130493, aux loss1: 0.7986319065093994, 
		 aux loss2: 0.4231412708759308, total loss: 0.7498733997344971
9th Epoch, 20735th Step, learning rate = 0.007900208498393917 - Loss: 0.36354029178619385, aux loss1: 0.8423804044723511, 
		 aux loss2: 0.47004789113998413, total loss: 0.8042736053466797
9th Epoch, 20740th Step, learning rate = 0.007899695229357146 - Loss: 0.3604360520839691, aux loss1: 0.7783411741256714, 
		 aux loss2: 0.4246964454650879, total loss: 0.7638170123100281
9th Epoch, 20745th Step, learning rate = 0.007899181956614928 - Loss: 0.45083537697792053, aux loss1: 1.0191621780395508, 
		 aux loss2: 0.5949774980545044, total loss: 0.994575023651123
9th Epoch, 20750th Step, learning rate = 0.00789866868016697 - Loss: 0.21975035965442657, aux loss1: 0.6006643176078796, 
		 aux loss2: 0.29735252261161804, total loss: 0.5188906788825989
9th Epoch, 20755th Step, learning rate = 0.00789815540001298 - Loss: 0.4357341229915619, aux loss1: 0.9815632104873657, 
		 aux loss2: 0.5463398694992065, total loss: 0.9487390518188477
9th Epoch, 20760th Step, learning rate = 0.00789764211615266 - Loss: 0.4324697256088257, aux loss1: 0.9472185969352722, 
		 aux loss2: 0.5478313565254211, total loss: 0.9357678890228271
9th Epoch, 20765th Step, learning rate = 0.007897128828585717 - Loss: 0.38564151525497437, aux loss1: 0.8545364141464233, 
		 aux loss2: 0.4805275499820709, total loss: 0.8342134952545166
9th Epoch, 20770th Step, learning rate = 0.007896615537311859 - Loss: 0.2694505453109741, aux loss1: 0.7109197974205017, 
		 aux loss2: 0.34836819767951965, total loss: 0.622073769569397
9th Epoch, 20775th Step, learning rate = 0.007896102242330788 - Loss: 0.33306747674942017, aux loss1: 0.8740423321723938, 
		 aux loss2: 0.4694306552410126, total loss: 0.7830524444580078
9th Epoch, 20780th Step, learning rate = 0.00789558894364221 - Loss: 0.45693665742874146, aux loss1: 0.8947272896766663, 
		 aux loss2: 0.5578694343566895, total loss: 0.9485026597976685
9th Epoch, 20785th Step, learning rate = 0.007895075641245832 - Loss: 0.40890705585479736, aux loss1: 0.952792227268219, 
		 aux loss2: 0.5391338467597961, total loss: 0.9103982448577881
9th Epoch, 20790th Step, learning rate = 0.007894562335141358 - Loss: 0.4186576008796692, aux loss1: 0.9868249893188477, 
		 aux loss2: 0.5630858540534973, total loss: 0.9399394392967224
9th Epoch, 20795th Step, learning rate = 0.007894049025328493 - Loss: 0.5045101642608643, aux loss1: 1.026232123374939, 
		 aux loss2: 0.6423368453979492, total loss: 1.0693145990371704
9th Epoch, 20800th Step, learning rate = 0.007893535711806943 - Loss: 0.39353397488594055, aux loss1: 0.9214134216308594, 
		 aux loss2: 0.5173224210739136, total loss: 0.8768869638442993
<20800th step>
*************************** Test ***************************
time:3m 15s, 20800th Step, Loss: 0.6585637331008911, Mean IoU = 39.760%
************************************************************
9th Epoch, 20805th Step, learning rate = 0.007893022394576414 - Loss: 0.4118421971797943, aux loss1: 0.9971939325332642, 
		 aux loss2: 0.573733389377594, total loss: 0.9404937624931335
9th Epoch, 20810th Step, learning rate = 0.00789250907363661 - Loss: 0.35201963782310486, aux loss1: 0.8978118896484375, 
		 aux loss2: 0.49539434909820557, total loss: 0.8195209503173828
9th Epoch, 20815th Step, learning rate = 0.00789199574898724 - Loss: 0.375279039144516, aux loss1: 0.8628886342048645, 
		 aux loss2: 0.4851750433444977, total loss: 0.8282156586647034
9th Epoch, 20820th Step, learning rate = 0.007891482420628001 - Loss: 0.3474911153316498, aux loss1: 0.7515833377838135, 
		 aux loss2: 0.4147432744503021, total loss: 0.7388634085655212
9th Epoch, 20825th Step, learning rate = 0.007890969088558604 - Loss: 0.33415767550468445, aux loss1: 0.7069671750068665, 
		 aux loss2: 0.39893531799316406, total loss: 0.7058219909667969
9th Epoch, 20830th Step, learning rate = 0.007890455752778754 - Loss: 0.29199862480163574, aux loss1: 0.7259164452552795, 
		 aux loss2: 0.381054550409317, total loss: 0.6621953845024109
9th Epoch, 20835th Step, learning rate = 0.007889942413288154 - Loss: 0.45307862758636475, aux loss1: 0.9802643656730652, 
		 aux loss2: 0.6393341422080994, total loss: 1.0028915405273438
9th Epoch, 20840th Step, learning rate = 0.00788942907008651 - Loss: 0.35195228457450867, aux loss1: 0.7655858993530273, 
		 aux loss2: 0.44909217953681946, total loss: 0.761264979839325
10th Epoch, 20845th Step, learning rate = 0.007888915723173526 - Loss: 0.45126572251319885, aux loss1: 0.960991382598877, 
		 aux loss2: 0.5975645780563354, total loss: 0.9785889387130737
10th Epoch, 20850th Step, learning rate = 0.007888402372548906 - Loss: 0.3176814615726471, aux loss1: 0.7681275606155396, 
		 aux loss2: 0.4240822196006775, total loss: 0.7177526354789734
10th Epoch, 20855th Step, learning rate = 0.007887889018212357 - Loss: 0.44433313608169556, aux loss1: 1.0124282836914062, 
		 aux loss2: 0.6050832271575928, total loss: 0.9900949597358704
10th Epoch, 20860th Step, learning rate = 0.007887375660163586 - Loss: 0.35167402029037476, aux loss1: 0.8752016425132751, 
		 aux loss2: 0.49362093210220337, total loss: 0.811682939529419
10th Epoch, 20865th Step, learning rate = 0.00788686229840229 - Loss: 0.32772886753082275, aux loss1: 0.8758506774902344, 
		 aux loss2: 0.440582275390625, total loss: 0.7667170166969299
10th Epoch, 20870th Step, learning rate = 0.00788634893292818 - Loss: 0.2972439229488373, aux loss1: 0.7922312617301941, 
		 aux loss2: 0.4217739701271057, total loss: 0.7036228775978088
10th Epoch, 20875th Step, learning rate = 0.00788583556374096 - Loss: 0.3814592957496643, aux loss1: 0.9419447779655457, 
		 aux loss2: 0.5250911712646484, total loss: 0.874079167842865
10th Epoch, 20880th Step, learning rate = 0.00788532219084033 - Loss: 0.34428128600120544, aux loss1: 0.7898720502853394, 
		 aux loss2: 0.4411523938179016, total loss: 0.7577039003372192
10th Epoch, 20885th Step, learning rate = 0.007884808814226001 - Loss: 0.4052698016166687, aux loss1: 1.0450471639633179, 
		 aux loss2: 0.5589594841003418, total loss: 0.9423677921295166
10th Epoch, 20890th Step, learning rate = 0.007884295433897674 - Loss: 0.4048723876476288, aux loss1: 0.9016101956367493, 
		 aux loss2: 0.5131791830062866, total loss: 0.8806270956993103
10th Epoch, 20895th Step, learning rate = 0.007883782049855053 - Loss: 0.36083516478538513, aux loss1: 0.9463715553283691, 
		 aux loss2: 0.5052094459533691, total loss: 0.846830427646637
10th Epoch, 20900th Step, learning rate = 0.007883268662097844 - Loss: 0.30065107345581055, aux loss1: 0.7605589628219604, 
		 aux loss2: 0.38603219389915466, total loss: 0.6832316517829895
<20900th step>
*************************** Test ***************************
time:3m 17s, 20900th Step, Loss: 0.5663899183273315, Mean IoU = 42.835%
************************************************************
10th Epoch, 20905th Step, learning rate = 0.00788275527062575 - Loss: 0.32182684540748596, aux loss1: 0.8476288318634033, 
		 aux loss2: 0.4296979606151581, total loss: 0.7479946613311768
10th Epoch, 20910th Step, learning rate = 0.007882241875438473 - Loss: 0.4115554094314575, aux loss1: 0.9188883900642395, 
		 aux loss2: 0.5206925868988037, total loss: 0.8954989910125732
10th Epoch, 20915th Step, learning rate = 0.007881728476535723 - Loss: 0.3812018632888794, aux loss1: 0.8231478333473206, 
		 aux loss2: 0.47838911414146423, total loss: 0.8195018768310547
10th Epoch, 20920th Step, learning rate = 0.007881215073917201 - Loss: 0.3689012825489044, aux loss1: 1.0358527898788452, 
		 aux loss2: 0.5373210906982422, total loss: 0.8945855498313904
10th Epoch, 20925th Step, learning rate = 0.007880701667582611 - Loss: 0.49306127429008484, aux loss1: 1.1005643606185913, 
		 aux loss2: 0.6358842849731445, total loss: 1.0775843858718872
10th Epoch, 20930th Step, learning rate = 0.007880188257531655 - Loss: 0.2810472548007965, aux loss1: 0.7742978930473328, 
		 aux loss2: 0.38765960931777954, total loss: 0.6684005260467529
10th Epoch, 20935th Step, learning rate = 0.007879674843764043 - Loss: 0.40352925658226013, aux loss1: 0.9322865605354309, 
		 aux loss2: 0.52089524269104, total loss: 0.8915733695030212
10th Epoch, 20940th Step, learning rate = 0.007879161426279476 - Loss: 0.3890511691570282, aux loss1: 0.8577613234519958, 
		 aux loss2: 0.5195004343986511, total loss: 0.8541797399520874
10th Epoch, 20945th Step, learning rate = 0.007878648005077654 - Loss: 0.2657460570335388, aux loss1: 0.7425903081893921, 
		 aux loss2: 0.36252227425575256, total loss: 0.6335320472717285
10th Epoch, 20950th Step, learning rate = 0.007878134580158286 - Loss: 0.39506852626800537, aux loss1: 0.9635592699050903, 
		 aux loss2: 0.5432879328727722, total loss: 0.9014515280723572
10th Epoch, 20955th Step, learning rate = 0.007877621151521077 - Loss: 0.42315903306007385, aux loss1: 0.9151325821876526, 
		 aux loss2: 0.5483769178390503, total loss: 0.9170495867729187
10th Epoch, 20960th Step, learning rate = 0.007877107719165723 - Loss: 0.38399502635002136, aux loss1: 0.9103862047195435, 
		 aux loss2: 0.4828145503997803, total loss: 0.8502367734909058
10th Epoch, 20965th Step, learning rate = 0.007876594283091936 - Loss: 0.37136542797088623, aux loss1: 0.8810900449752808, 
		 aux loss2: 0.47099295258522034, total loss: 0.8240896463394165
10th Epoch, 20970th Step, learning rate = 0.007876080843299419 - Loss: 0.6191124320030212, aux loss1: 1.1067296266555786, 
		 aux loss2: 0.7549821138381958, total loss: 1.2531242370605469
10th Epoch, 20975th Step, learning rate = 0.007875567399787868 - Loss: 0.3499928414821625, aux loss1: 0.9284862279891968, 
		 aux loss2: 0.4999985098838806, total loss: 0.8285381197929382
10th Epoch, 20980th Step, learning rate = 0.007875053952556995 - Loss: 0.37801069021224976, aux loss1: 0.9392897486686707, 
		 aux loss2: 0.5290494561195374, total loss: 0.8714174628257751
10th Epoch, 20985th Step, learning rate = 0.0078745405016065 - Loss: 0.43109267950057983, aux loss1: 0.9038964509963989, 
		 aux loss2: 0.5464777946472168, total loss: 0.920852780342102
10th Epoch, 20990th Step, learning rate = 0.00787402704693609 - Loss: 0.3167042136192322, aux loss1: 0.7634273171424866, 
		 aux loss2: 0.4287092685699463, total loss: 0.7172161340713501
10th Epoch, 20995th Step, learning rate = 0.007873513588545463 - Loss: 0.4646969437599182, aux loss1: 0.9117191433906555, 
		 aux loss2: 0.5605769157409668, total loss: 0.962443470954895
10th Epoch, 21000th Step, learning rate = 0.007873000126434325 - Loss: 0.3310222327709198, aux loss1: 0.7997045516967773, 
		 aux loss2: 0.4358348548412323, total loss: 0.7452675104141235
<21000th step>
*************************** Test ***************************
time:3m 14s, 21000th Step, Loss: 0.5382214784622192, Mean IoU = 42.952%
************************************************************
10th Epoch, 21005th Step, learning rate = 0.00787248666060238 - Loss: 0.356764018535614, aux loss1: 0.849008321762085, 
		 aux loss2: 0.45949044823646545, total loss: 0.7952626943588257
10th Epoch, 21010th Step, learning rate = 0.00787197319104933 - Loss: 0.2794983386993408, aux loss1: 0.7194656729698181, 
		 aux loss2: 0.3689182698726654, total loss: 0.6429053544998169
10th Epoch, 21015th Step, learning rate = 0.007871459717774882 - Loss: 0.4239504337310791, aux loss1: 0.9258620142936707, 
		 aux loss2: 0.5310720205307007, total loss: 0.9141378402709961
10th Epoch, 21020th Step, learning rate = 0.007870946240778734 - Loss: 0.35758352279663086, aux loss1: 0.7917469143867493, 
		 aux loss2: 0.4501861333847046, total loss: 0.7751820683479309
10th Epoch, 21025th Step, learning rate = 0.007870432760060594 - Loss: 0.4946456551551819, aux loss1: 1.0864578485488892, 
		 aux loss2: 0.6400701403617859, total loss: 1.076611042022705
10th Epoch, 21030th Step, learning rate = 0.007869919275620162 - Loss: 0.3952457904815674, aux loss1: 1.0626028776168823, 
		 aux loss2: 0.5720605254173279, total loss: 0.9428508877754211
10th Epoch, 21035th Step, learning rate = 0.007869405787457144 - Loss: 0.28384578227996826, aux loss1: 0.7689247727394104, 
		 aux loss2: 0.3971007466316223, total loss: 0.6733635067939758
10th Epoch, 21040th Step, learning rate = 0.00786889229557124 - Loss: 0.2490662783384323, aux loss1: 0.723971962928772, 
		 aux loss2: 0.3373323678970337, total loss: 0.6011908054351807
10th Epoch, 21045th Step, learning rate = 0.007868378799962154 - Loss: 0.26333731412887573, aux loss1: 0.699985146522522, 
		 aux loss2: 0.3443043529987335, total loss: 0.6110546588897705
10th Epoch, 21050th Step, learning rate = 0.007867865300629589 - Loss: 0.31996333599090576, aux loss1: 0.7679607272148132, 
		 aux loss2: 0.4243813455104828, total loss: 0.7201040983200073
10th Epoch, 21055th Step, learning rate = 0.00786735179757325 - Loss: 0.31499865651130676, aux loss1: 0.8162446618080139, 
		 aux loss2: 0.409333199262619, total loss: 0.7236053347587585
10th Epoch, 21060th Step, learning rate = 0.007866838290792839 - Loss: 0.4319472908973694, aux loss1: 0.9660046100616455, 
		 aux loss2: 0.5714881420135498, total loss: 0.9503439664840698
10th Epoch, 21065th Step, learning rate = 0.007866324780288057 - Loss: 0.3994077444076538, aux loss1: 0.9111521244049072, 
		 aux loss2: 0.5529463291168213, total loss: 0.8939319252967834
10th Epoch, 21070th Step, learning rate = 0.007865811266058608 - Loss: 0.4794624149799347, aux loss1: 0.9813409447669983, 
		 aux loss2: 0.5846905708312988, total loss: 1.0077409744262695
10th Epoch, 21075th Step, learning rate = 0.007865297748104195 - Loss: 0.38561832904815674, aux loss1: 0.8380974531173706, 
		 aux loss2: 0.5100868344306946, total loss: 0.8410823345184326
10th Epoch, 21080th Step, learning rate = 0.007864784226424523 - Loss: 0.29106834530830383, aux loss1: 0.681187629699707, 
		 aux loss2: 0.3669322729110718, total loss: 0.6421975493431091
10th Epoch, 21085th Step, learning rate = 0.007864270701019289 - Loss: 0.294592946767807, aux loss1: 0.7178511619567871, 
		 aux loss2: 0.3769919276237488, total loss: 0.6607450842857361
10th Epoch, 21090th Step, learning rate = 0.0078637571718882 - Loss: 0.3876623511314392, aux loss1: 0.8933297991752625, 
		 aux loss2: 0.5203116536140442, total loss: 0.863785982131958
10th Epoch, 21095th Step, learning rate = 0.00786324363903096 - Loss: 0.5463171601295471, aux loss1: 1.0533684492111206, 
		 aux loss2: 0.6772323250770569, total loss: 1.1332206726074219
10th Epoch, 21100th Step, learning rate = 0.007862730102447268 - Loss: 0.4335247874259949, aux loss1: 1.002148151397705, 
		 aux loss2: 0.5477562546730042, total loss: 0.953271746635437
<21100th step>
*************************** Test ***************************
time:3m 18s, 21100th Step, Loss: 0.562292218208313, Mean IoU = 42.756%
************************************************************
10th Epoch, 21105th Step, learning rate = 0.007862216562136827 - Loss: 0.33512964844703674, aux loss1: 0.8116472363471985, 
		 aux loss2: 0.4432647228240967, total loss: 0.755929708480835
10th Epoch, 21110th Step, learning rate = 0.00786170301809934 - Loss: 0.33523887395858765, aux loss1: 0.7957311868667603, 
		 aux loss2: 0.43593621253967285, total loss: 0.7483327388763428
10th Epoch, 21115th Step, learning rate = 0.00786118947033451 - Loss: 0.32851099967956543, aux loss1: 0.832027792930603, 
		 aux loss2: 0.4499329924583435, total loss: 0.7580925226211548
10th Epoch, 21120th Step, learning rate = 0.00786067591884204 - Loss: 0.3388243317604065, aux loss1: 0.7136366367340088, 
		 aux loss2: 0.42502161860466003, total loss: 0.722923994064331
10th Epoch, 21125th Step, learning rate = 0.007860162363621631 - Loss: 0.3029547333717346, aux loss1: 0.7602993845939636, 
		 aux loss2: 0.41159483790397644, total loss: 0.6956824660301208
10th Epoch, 21130th Step, learning rate = 0.007859648804672987 - Loss: 0.39225125312805176, aux loss1: 0.8981454968452454, 
		 aux loss2: 0.5243561267852783, total loss: 0.8714373111724854
10th Epoch, 21135th Step, learning rate = 0.007859135241995809 - Loss: 0.3858269453048706, aux loss1: 0.923241138458252, 
		 aux loss2: 0.5116282105445862, total loss: 0.8674505949020386
10th Epoch, 21140th Step, learning rate = 0.007858621675589797 - Loss: 0.4387202262878418, aux loss1: 0.979264497756958, 
		 aux loss2: 0.5754257440567017, total loss: 0.9626699090003967
10th Epoch, 21145th Step, learning rate = 0.007858108105454656 - Loss: 0.3255792558193207, aux loss1: 0.941656768321991, 
		 aux loss2: 0.5003910064697266, total loss: 0.8082327246665955
10th Epoch, 21150th Step, learning rate = 0.007857594531590089 - Loss: 0.4608234763145447, aux loss1: 1.0511008501052856, 
		 aux loss2: 0.6282446980476379, total loss: 1.0274516344070435
10th Epoch, 21155th Step, learning rate = 0.007857080953995796 - Loss: 0.35498523712158203, aux loss1: 0.8729156255722046, 
		 aux loss2: 0.47342848777770996, total loss: 0.8062313199043274
10th Epoch, 21160th Step, learning rate = 0.007856567372671479 - Loss: 0.33404091000556946, aux loss1: 0.8956810832023621, 
		 aux loss2: 0.47834888100624084, total loss: 0.7940847873687744
10th Epoch, 21165th Step, learning rate = 0.00785605378761684 - Loss: 0.38032102584838867, aux loss1: 0.9241380095481873, 
		 aux loss2: 0.5195931196212769, total loss: 0.8653997182846069
10th Epoch, 21170th Step, learning rate = 0.007855540198831583 - Loss: 0.32325130701065063, aux loss1: 0.7948588728904724, 
		 aux loss2: 0.4231792092323303, total loss: 0.7309806942939758
10th Epoch, 21175th Step, learning rate = 0.007855026606315407 - Loss: 0.31934797763824463, aux loss1: 0.7407583594322205, 
		 aux loss2: 0.4114626348018646, total loss: 0.7061605453491211
10th Epoch, 21180th Step, learning rate = 0.007854513010068016 - Loss: 0.32253241539001465, aux loss1: 0.7604765295982361, 
		 aux loss2: 0.4197031259536743, total loss: 0.7185566425323486
10th Epoch, 21185th Step, learning rate = 0.00785399941008911 - Loss: 0.4058365523815155, aux loss1: 0.9116626977920532, 
		 aux loss2: 0.5334498286247253, total loss: 0.8927152752876282
10th Epoch, 21190th Step, learning rate = 0.007853485806378395 - Loss: 0.43339163064956665, aux loss1: 1.1206955909729004, 
		 aux loss2: 0.6169800758361816, total loss: 1.0163923501968384
10th Epoch, 21195th Step, learning rate = 0.007852972198935566 - Loss: 0.48494771122932434, aux loss1: 0.9563837051391602, 
		 aux loss2: 0.6001489758491516, total loss: 1.0119224786758423
10th Epoch, 21200th Step, learning rate = 0.00785245858776033 - Loss: 0.44709810614585876, aux loss1: 0.9105126261711121, 
		 aux loss2: 0.5401496291160583, total loss: 0.9363117814064026
<21200th step>
*************************** Test ***************************
time:3m 18s, 21200th Step, Loss: 0.5428831577301025, Mean IoU = 43.506%
************************************************************
10th Epoch, 21205th Step, learning rate = 0.007851944972852387 - Loss: 0.479411244392395, aux loss1: 0.8929024338722229, 
		 aux loss2: 0.5708710551261902, total loss: 0.9756304621696472
10th Epoch, 21210th Step, learning rate = 0.007851431354211439 - Loss: 0.4469662308692932, aux loss1: 0.8926069736480713, 
		 aux loss2: 0.5448318719863892, total loss: 0.9326810836791992
11th Epoch, 21215th Step, learning rate = 0.007850917731837184 - Loss: 0.3347019851207733, aux loss1: 0.9436087608337402, 
		 aux loss2: 0.4828256070613861, total loss: 0.8109148740768433
11th Epoch, 21220th Step, learning rate = 0.00785040410572933 - Loss: 0.34588661789894104, aux loss1: 0.9730616211891174, 
		 aux loss2: 0.490824818611145, total loss: 0.8341350555419922
11th Epoch, 21225th Step, learning rate = 0.007849890475887572 - Loss: 0.41178178787231445, aux loss1: 1.0307587385177612, 
		 aux loss2: 0.5840383172035217, total loss: 0.9546247720718384
11th Epoch, 21230th Step, learning rate = 0.007849376842311614 - Loss: 0.3716070353984833, aux loss1: 0.902711033821106, 
		 aux loss2: 0.5076436996459961, total loss: 0.845477819442749
11th Epoch, 21235th Step, learning rate = 0.00784886320500116 - Loss: 0.346958726644516, aux loss1: 0.8069524765014648, 
		 aux loss2: 0.44321101903915405, total loss: 0.7663288712501526
11th Epoch, 21240th Step, learning rate = 0.007848349563955907 - Loss: 0.3862881064414978, aux loss1: 0.9512229561805725, 
		 aux loss2: 0.5480407476425171, total loss: 0.8908712863922119
11th Epoch, 21245th Step, learning rate = 0.00784783591917556 - Loss: 0.2827763557434082, aux loss1: 0.7229017019271851, 
		 aux loss2: 0.3685300946235657, total loss: 0.64705890417099
11th Epoch, 21250th Step, learning rate = 0.007847322270659816 - Loss: 0.3379659652709961, aux loss1: 0.9015002250671387, 
		 aux loss2: 0.4510135054588318, total loss: 0.7888214588165283
11th Epoch, 21255th Step, learning rate = 0.00784680861840838 - Loss: 0.31135010719299316, aux loss1: 0.7581556439399719, 
		 aux loss2: 0.4161722958087921, total loss: 0.7052657008171082
11th Epoch, 21260th Step, learning rate = 0.007846294962420952 - Loss: 0.3093731701374054, aux loss1: 0.8313366174697876, 
		 aux loss2: 0.4366370737552643, total loss: 0.7334290146827698
11th Epoch, 21265th Step, learning rate = 0.007845781302697233 - Loss: 0.33521002531051636, aux loss1: 0.8280233144760132, 
		 aux loss2: 0.4434872269630432, total loss: 0.7610119581222534
11th Epoch, 21270th Step, learning rate = 0.007845267639236922 - Loss: 0.3560476303100586, aux loss1: 0.8274485468864441, 
		 aux loss2: 0.45215147733688354, total loss: 0.7851427793502808
11th Epoch, 21275th Step, learning rate = 0.007844753972039722 - Loss: 0.4110943675041199, aux loss1: 0.8786298632621765, 
		 aux loss2: 0.5307324528694153, total loss: 0.8869763016700745
11th Epoch, 21280th Step, learning rate = 0.007844240301105336 - Loss: 0.40819522738456726, aux loss1: 0.8700935244560242, 
		 aux loss2: 0.5263825058937073, total loss: 0.8797762989997864
11th Epoch, 21285th Step, learning rate = 0.00784372662643346 - Loss: 0.3600746989250183, aux loss1: 0.8213212490081787, 
		 aux loss2: 0.486247181892395, total loss: 0.8009699583053589
11th Epoch, 21290th Step, learning rate = 0.007843212948023797 - Loss: 0.3870420455932617, aux loss1: 0.9130437970161438, 
		 aux loss2: 0.5028069019317627, total loss: 0.8620779514312744
11th Epoch, 21295th Step, learning rate = 0.007842699265876048 - Loss: 0.35491469502449036, aux loss1: 0.8757176995277405, 
		 aux loss2: 0.4764801859855652, total loss: 0.8082220554351807
11th Epoch, 21300th Step, learning rate = 0.007842185579989917 - Loss: 0.36823442578315735, aux loss1: 0.8308234214782715, 
		 aux loss2: 0.4754612445831299, total loss: 0.8076659440994263
<21300th step>
*************************** Test ***************************
time:3m 20s, 21300th Step, Loss: 0.559537410736084, Mean IoU = 43.573%
************************************************************
11th Epoch, 21305th Step, learning rate = 0.007841671890365099 - Loss: 0.3082168698310852, aux loss1: 0.8247343897819519, 
		 aux loss2: 0.4306308329105377, total loss: 0.7278895378112793
11th Epoch, 21310th Step, learning rate = 0.007841158197001298 - Loss: 0.39187538623809814, aux loss1: 0.9377652406692505, 
		 aux loss2: 0.4971874952316284, total loss: 0.8720799684524536
11th Epoch, 21315th Step, learning rate = 0.007840644499898216 - Loss: 0.30252158641815186, aux loss1: 0.7556660771369934, 
		 aux loss2: 0.40835899114608765, total loss: 0.6925650238990784
11th Epoch, 21320th Step, learning rate = 0.007840130799055548 - Loss: 0.40205609798431396, aux loss1: 0.9728782176971436, 
		 aux loss2: 0.5490293502807617, total loss: 0.9135313034057617
11th Epoch, 21325th Step, learning rate = 0.007839617094472999 - Loss: 0.36323150992393494, aux loss1: 0.8585604429244995, 
		 aux loss2: 0.4957824647426605, total loss: 0.8191126585006714
11th Epoch, 21330th Step, learning rate = 0.00783910338615027 - Loss: 0.3414348363876343, aux loss1: 0.8388032913208008, 
		 aux loss2: 0.44229692220687866, total loss: 0.7699946165084839
11th Epoch, 21335th Step, learning rate = 0.007838589674087057 - Loss: 0.3770257532596588, aux loss1: 0.8104701042175293, 
		 aux loss2: 0.510110080242157, total loss: 0.8242108225822449
11th Epoch, 21340th Step, learning rate = 0.007838075958283066 - Loss: 0.4609774351119995, aux loss1: 0.9737963080406189, 
		 aux loss2: 0.5696191787719727, total loss: 0.9809640645980835
11th Epoch, 21345th Step, learning rate = 0.007837562238737994 - Loss: 0.3835922181606293, aux loss1: 0.9525455832481384, 
		 aux loss2: 0.5297039747238159, total loss: 0.8812374472618103
11th Epoch, 21350th Step, learning rate = 0.007837048515451542 - Loss: 0.3964236080646515, aux loss1: 1.09483003616333, 
		 aux loss2: 0.5396562814712524, total loss: 0.9407351016998291
11th Epoch, 21355th Step, learning rate = 0.007836534788423409 - Loss: 0.38664698600769043, aux loss1: 0.9060609340667725, 
		 aux loss2: 0.48448532819747925, total loss: 0.8522593975067139
11th Epoch, 21360th Step, learning rate = 0.007836021057653296 - Loss: 0.4917457103729248, aux loss1: 1.0188004970550537, 
		 aux loss2: 0.5992801785469055, total loss: 1.0370979309082031
11th Epoch, 21365th Step, learning rate = 0.007835507323140905 - Loss: 0.4921554923057556, aux loss1: 1.0448795557022095, 
		 aux loss2: 0.6110292673110962, total loss: 1.050031065940857
11th Epoch, 21370th Step, learning rate = 0.007834993584885935 - Loss: 0.4009976089000702, aux loss1: 1.044943928718567, 
		 aux loss2: 0.5395113229751587, total loss: 0.9302852749824524
11th Epoch, 21375th Step, learning rate = 0.007834479842888084 - Loss: 0.3715014159679413, aux loss1: 0.7637603878974915, 
		 aux loss2: 0.47246745228767395, total loss: 0.789616584777832
11th Epoch, 21380th Step, learning rate = 0.007833966097147056 - Loss: 0.37425512075424194, aux loss1: 0.9440857768058777, 
		 aux loss2: 0.5080159306526184, total loss: 0.8606871962547302
11th Epoch, 21385th Step, learning rate = 0.007833452347662547 - Loss: 0.5937013030052185, aux loss1: 1.3284144401550293, 
		 aux loss2: 0.7862884402275085, total loss: 1.3067409992218018
11th Epoch, 21390th Step, learning rate = 0.00783293859443426 - Loss: 0.30082884430885315, aux loss1: 0.7541525363922119, 
		 aux loss2: 0.3936880826950073, total loss: 0.684549868106842
11th Epoch, 21395th Step, learning rate = 0.00783242483746189 - Loss: 0.4011283814907074, aux loss1: 0.9667510390281677, 
		 aux loss2: 0.5409299731254578, total loss: 0.9075257182121277
11th Epoch, 21400th Step, learning rate = 0.007831911076745145 - Loss: 0.3359650671482086, aux loss1: 0.8244853615760803, 
		 aux loss2: 0.43283000588417053, total loss: 0.756442666053772
<21400th step>
*************************** Test ***************************
time:3m 16s, 21400th Step, Loss: 0.5700774788856506, Mean IoU = 42.669%
************************************************************
11th Epoch, 21405th Step, learning rate = 0.007831397312283718 - Loss: 0.26952064037323, aux loss1: 0.7313306927680969, 
		 aux loss2: 0.381897509098053, total loss: 0.6416788697242737
11th Epoch, 21410th Step, learning rate = 0.00783088354407731 - Loss: 0.34450241923332214, aux loss1: 0.7394347786903381, 
		 aux loss2: 0.43179890513420105, total loss: 0.739052414894104
11th Epoch, 21415th Step, learning rate = 0.007830369772125622 - Loss: 0.3508036434650421, aux loss1: 0.7734427452087402, 
		 aux loss2: 0.448440819978714, total loss: 0.762212872505188
11th Epoch, 21420th Step, learning rate = 0.007829855996428353 - Loss: 0.5148613452911377, aux loss1: 1.1448121070861816, 
		 aux loss2: 0.6712881326675415, total loss: 1.1268202066421509
11th Epoch, 21425th Step, learning rate = 0.007829342216985205 - Loss: 0.6065378189086914, aux loss1: 1.18346107006073, 
		 aux loss2: 0.7415266036987305, total loss: 1.2581868171691895
11th Epoch, 21430th Step, learning rate = 0.007828828433795872 - Loss: 0.34805285930633545, aux loss1: 0.8415364027023315, 
		 aux loss2: 0.44037488102912903, total loss: 0.7766637802124023
11th Epoch, 21435th Step, learning rate = 0.00782831464686006 - Loss: 0.4421214461326599, aux loss1: 0.9644661545753479, 
		 aux loss2: 0.5547306537628174, total loss: 0.9533535242080688
11th Epoch, 21440th Step, learning rate = 0.007827800856177463 - Loss: 0.3482687473297119, aux loss1: 0.8221381902694702, 
		 aux loss2: 0.4491117298603058, total loss: 0.7745549082756042
11th Epoch, 21445th Step, learning rate = 0.007827287061747786 - Loss: 0.29698967933654785, aux loss1: 0.795680820941925, 
		 aux loss2: 0.40046247839927673, total loss: 0.6958789229393005
11th Epoch, 21450th Step, learning rate = 0.007826773263570721 - Loss: 0.3142450451850891, aux loss1: 0.7492626309394836, 
		 aux loss2: 0.40852952003479004, total loss: 0.7024356722831726
11th Epoch, 21455th Step, learning rate = 0.007826259461645975 - Loss: 0.42862045764923096, aux loss1: 0.9766390919685364, 
		 aux loss2: 0.5837612748146057, total loss: 0.9551167488098145
11th Epoch, 21460th Step, learning rate = 0.007825745655973241 - Loss: 0.3807458281517029, aux loss1: 0.8938567042350769, 
		 aux loss2: 0.5113032460212708, total loss: 0.8534241914749146
11th Epoch, 21465th Step, learning rate = 0.007825231846552223 - Loss: 0.34540775418281555, aux loss1: 0.7953708171844482, 
		 aux loss2: 0.4376164972782135, total loss: 0.7590656280517578
11th Epoch, 21470th Step, learning rate = 0.007824718033382617 - Loss: 0.39250102639198303, aux loss1: 0.9298402667045593, 
		 aux loss2: 0.49417945742607117, total loss: 0.8691248893737793
11th Epoch, 21475th Step, learning rate = 0.007824204216464124 - Loss: 0.43606171011924744, aux loss1: 0.8857232928276062, 
		 aux loss2: 0.5476812720298767, total loss: 0.9208512306213379
11th Epoch, 21480th Step, learning rate = 0.007823690395796442 - Loss: 0.3516627550125122, aux loss1: 0.8427822589874268, 
		 aux loss2: 0.45829999446868896, total loss: 0.7878174185752869
11th Epoch, 21485th Step, learning rate = 0.007823176571379271 - Loss: 0.5208957195281982, aux loss1: 0.9614021182060242, 
		 aux loss2: 0.6629300117492676, total loss: 1.0744884014129639
11th Epoch, 21490th Step, learning rate = 0.007822662743212309 - Loss: 0.5127391219139099, aux loss1: 1.0361343622207642, 
		 aux loss2: 0.6303192377090454, total loss: 1.075707197189331
11th Epoch, 21495th Step, learning rate = 0.007822148911295256 - Loss: 0.3831222355365753, aux loss1: 0.7722108960151672, 
		 aux loss2: 0.4670587182044983, total loss: 0.8016089797019958
11th Epoch, 21500th Step, learning rate = 0.00782163507562781 - Loss: 0.3884965479373932, aux loss1: 0.8642586469650269, 
		 aux loss2: 0.50780189037323, total loss: 0.8508949279785156
<21500th step>
*************************** Test ***************************
time:3m 15s, 21500th Step, Loss: 0.5778378844261169, Mean IoU = 41.499%
************************************************************
11th Epoch, 21505th Step, learning rate = 0.00782112123620967 - Loss: 0.37922969460487366, aux loss1: 0.8333697319030762, 
		 aux loss2: 0.49726247787475586, total loss: 0.8281456232070923
11th Epoch, 21510th Step, learning rate = 0.007820607393040536 - Loss: 0.430548757314682, aux loss1: 0.9049828052520752, 
		 aux loss2: 0.5325603485107422, total loss: 0.9150677919387817
11th Epoch, 21515th Step, learning rate = 0.007820093546120104 - Loss: 0.3793100118637085, aux loss1: 0.8534547686576843, 
		 aux loss2: 0.48355239629745483, total loss: 0.8287673592567444
11th Epoch, 21520th Step, learning rate = 0.007819579695448078 - Loss: 0.5369422435760498, aux loss1: 1.0302164554595947, 
		 aux loss2: 0.6623907089233398, total loss: 1.1109635829925537
11th Epoch, 21525th Step, learning rate = 0.007819065841024151 - Loss: 0.4402259290218353, aux loss1: 0.8869696855545044, 
		 aux loss2: 0.5797301530838013, total loss: 0.9382088780403137
11th Epoch, 21530th Step, learning rate = 0.007818551982848023 - Loss: 0.4725436866283417, aux loss1: 1.0300546884536743, 
		 aux loss2: 0.6747801303863525, total loss: 1.0514721870422363
11th Epoch, 21535th Step, learning rate = 0.007818038120919395 - Loss: 0.36641353368759155, aux loss1: 0.818901538848877, 
		 aux loss2: 0.4632049798965454, total loss: 0.7973660230636597
11th Epoch, 21540th Step, learning rate = 0.007817524255237964 - Loss: 0.3893117308616638, aux loss1: 0.8171842098236084, 
		 aux loss2: 0.485161155462265, total loss: 0.8285315036773682
11th Epoch, 21545th Step, learning rate = 0.007817010385803427 - Loss: 0.38905400037765503, aux loss1: 0.9831592440605164, 
		 aux loss2: 0.5324522852897644, total loss: 0.896982729434967
11th Epoch, 21550th Step, learning rate = 0.007816496512615486 - Loss: 0.4685475826263428, aux loss1: 1.1264153718948364, 
		 aux loss2: 0.6775017380714417, total loss: 1.0774729251861572
11th Epoch, 21555th Step, learning rate = 0.007815982635673836 - Loss: 0.31526562571525574, aux loss1: 0.7542455792427063, 
		 aux loss2: 0.4002385139465332, total loss: 0.7016347050666809
11th Epoch, 21560th Step, learning rate = 0.007815468754978176 - Loss: 0.3692498207092285, aux loss1: 0.8959715962409973, 
		 aux loss2: 0.4770684838294983, total loss: 0.8288687467575073
11th Epoch, 21565th Step, learning rate = 0.007814954870528208 - Loss: 0.2560550570487976, aux loss1: 0.6835160255432129, 
		 aux loss2: 0.3271387219429016, total loss: 0.59196537733078
11th Epoch, 21570th Step, learning rate = 0.007814440982323624 - Loss: 0.38215041160583496, aux loss1: 0.8619184494018555, 
		 aux loss2: 0.47792527079582214, total loss: 0.8318960666656494
11th Epoch, 21575th Step, learning rate = 0.007813927090364128 - Loss: 0.42412590980529785, aux loss1: 1.0076490640640259, 
		 aux loss2: 0.5773823261260986, total loss: 0.9573735594749451
11th Epoch, 21580th Step, learning rate = 0.007813413194649415 - Loss: 0.36390766501426697, aux loss1: 1.0174448490142822, 
		 aux loss2: 0.5046179890632629, total loss: 0.8709883689880371
12th Epoch, 21585th Step, learning rate = 0.007812899295179181 - Loss: 0.27287977933883667, aux loss1: 0.7980146408081055, 
		 aux loss2: 0.38650766015052795, total loss: 0.6668872237205505
12th Epoch, 21590th Step, learning rate = 0.00781238539195313 - Loss: 0.3329981565475464, aux loss1: 0.8316045999526978, 
		 aux loss2: 0.45518016815185547, total loss: 0.7645516395568848
12th Epoch, 21595th Step, learning rate = 0.007811871484970957 - Loss: 0.31644952297210693, aux loss1: 0.794685959815979, 
		 aux loss2: 0.4199312627315521, total loss: 0.7228278517723083
12th Epoch, 21600th Step, learning rate = 0.007811357574232359 - Loss: 0.34225574135780334, aux loss1: 0.9067925810813904, 
		 aux loss2: 0.46917015314102173, total loss: 0.8019616007804871
<21600th step>
*************************** Test ***************************
time:3m 19s, 21600th Step, Loss: 0.5243412256240845, Mean IoU = 42.940%
************************************************************
12th Epoch, 21605th Step, learning rate = 0.0078108436597370354 - Loss: 0.47092437744140625, aux loss1: 0.9220695495605469, 
		 aux loss2: 0.5886479616165161, total loss: 0.9830044507980347
12th Epoch, 21610th Step, learning rate = 0.007810329741484684 - Loss: 0.41858166456222534, aux loss1: 0.9575043320655823, 
		 aux loss2: 0.5486462712287903, total loss: 0.9252914786338806
12th Epoch, 21615th Step, learning rate = 0.007809815819475001 - Loss: 0.339389830827713, aux loss1: 0.9176023602485657, 
		 aux loss2: 0.4679553210735321, total loss: 0.8018526434898376
12th Epoch, 21620th Step, learning rate = 0.007809301893707688 - Loss: 0.26158061623573303, aux loss1: 0.7142553329467773, 
		 aux loss2: 0.34963151812553406, total loss: 0.6157098412513733
12th Epoch, 21625th Step, learning rate = 0.007808787964182438 - Loss: 0.4080723226070404, aux loss1: 0.9232274293899536, 
		 aux loss2: 0.5608663558959961, total loss: 0.9093871116638184
12th Epoch, 21630th Step, learning rate = 0.0078082740308989505 - Loss: 0.2678200900554657, aux loss1: 0.7109604477882385, 
		 aux loss2: 0.36903417110443115, total loss: 0.6287219524383545
12th Epoch, 21635th Step, learning rate = 0.007807760093856925 - Loss: 0.3821038603782654, aux loss1: 0.8762623071670532, 
		 aux loss2: 0.5178873538970947, total loss: 0.8521375060081482
12th Epoch, 21640th Step, learning rate = 0.007807246153056057 - Loss: 0.43983590602874756, aux loss1: 0.9073739647865295, 
		 aux loss2: 0.5775390863418579, total loss: 0.9430637359619141
12th Epoch, 21645th Step, learning rate = 0.0078067322084960445 - Loss: 0.3160879611968994, aux loss1: 0.7738827466964722, 
		 aux loss2: 0.414859801530838, total loss: 0.7141967415809631
12th Epoch, 21650th Step, learning rate = 0.007806218260176585 - Loss: 0.35111215710639954, aux loss1: 0.8083481788635254, 
		 aux loss2: 0.4530676305294037, total loss: 0.774843692779541
12th Epoch, 21655th Step, learning rate = 0.0078057043080973785 - Loss: 0.37274667620658875, aux loss1: 0.9659879803657532, 
		 aux loss2: 0.5307024121284485, total loss: 0.874824047088623
12th Epoch, 21660th Step, learning rate = 0.007805190352258118 - Loss: 0.3815285861492157, aux loss1: 0.7866665124893188, 
		 aux loss2: 0.480602890253067, total loss: 0.8097697496414185
12th Epoch, 21665th Step, learning rate = 0.007804676392658504 - Loss: 0.27530062198638916, aux loss1: 0.7527626752853394, 
		 aux loss2: 0.38330090045928955, total loss: 0.6544498205184937
12th Epoch, 21670th Step, learning rate = 0.007804162429298231 - Loss: 0.3434405028820038, aux loss1: 0.7636660933494568, 
		 aux loss2: 0.45487964153289795, total loss: 0.7544922232627869
12th Epoch, 21675th Step, learning rate = 0.007803648462177002 - Loss: 0.5105292797088623, aux loss1: 1.0843769311904907, 
		 aux loss2: 0.6713202595710754, total loss: 1.1043704748153687
12th Epoch, 21680th Step, learning rate = 0.007803134491294508 - Loss: 0.26858028769493103, aux loss1: 0.6914746165275574, 
		 aux loss2: 0.36476996541023254, total loss: 0.6219306588172913
12th Epoch, 21685th Step, learning rate = 0.007802620516650449 - Loss: 0.2929546535015106, aux loss1: 0.7504491806030273, 
		 aux loss2: 0.3837502598762512, total loss: 0.6715894937515259
12th Epoch, 21690th Step, learning rate = 0.007802106538244522 - Loss: 0.35768744349479675, aux loss1: 0.8123688697814941, 
		 aux loss2: 0.45654723048210144, total loss: 0.784017026424408
12th Epoch, 21695th Step, learning rate = 0.007801592556076423 - Loss: 0.42523807287216187, aux loss1: 1.0342466831207275, 
		 aux loss2: 0.5822186470031738, total loss: 0.9683995246887207
12th Epoch, 21700th Step, learning rate = 0.007801078570145851 - Loss: 0.48640692234039307, aux loss1: 1.1037715673446655, 
		 aux loss2: 0.7079615592956543, total loss: 1.1007230281829834
<21700th step>
*************************** Test ***************************
time:3m 17s, 21700th Step, Loss: 0.5410292148590088, Mean IoU = 43.106%
************************************************************
12th Epoch, 21705th Step, learning rate = 0.007800564580452502 - Loss: 0.3576623201370239, aux loss1: 0.9227072596549988, 
		 aux loss2: 0.4959507882595062, total loss: 0.8328548669815063
12th Epoch, 21710th Step, learning rate = 0.0078000505869960735 - Loss: 0.2846642732620239, aux loss1: 0.6803327202796936, 
		 aux loss2: 0.3642507791519165, total loss: 0.63446444272995
12th Epoch, 21715th Step, learning rate = 0.00779953658977626 - Loss: 0.3474678695201874, aux loss1: 0.8686215877532959, 
		 aux loss2: 0.49071669578552246, total loss: 0.8043410778045654
12th Epoch, 21720th Step, learning rate = 0.007799022588792761 - Loss: 0.3779359757900238, aux loss1: 1.010297417640686, 
		 aux loss2: 0.5056878924369812, total loss: 0.8833003640174866
12th Epoch, 21725th Step, learning rate = 0.007798508584045273 - Loss: 0.4316450357437134, aux loss1: 0.8320093750953674, 
		 aux loss2: 0.5198579430580139, total loss: 0.8891910314559937
12th Epoch, 21730th Step, learning rate = 0.007797994575533493 - Loss: 0.36242958903312683, aux loss1: 0.9388933777809143, 
		 aux loss2: 0.4908885657787323, total loss: 0.840453028678894
12th Epoch, 21735th Step, learning rate = 0.007797480563257117 - Loss: 0.39068281650543213, aux loss1: 0.8580862879753113, 
		 aux loss2: 0.49935466051101685, total loss: 0.8478505611419678
12th Epoch, 21740th Step, learning rate = 0.00779696654721584 - Loss: 0.5027928948402405, aux loss1: 1.0634164810180664, 
		 aux loss2: 0.6094304919242859, total loss: 1.0655900239944458
12th Epoch, 21745th Step, learning rate = 0.007796452527409363 - Loss: 0.3411538600921631, aux loss1: 0.8993773460388184, 
		 aux loss2: 0.48089441657066345, total loss: 0.803324818611145
12th Epoch, 21750th Step, learning rate = 0.007795938503837379 - Loss: 0.3308584988117218, aux loss1: 0.8665699362754822, 
		 aux loss2: 0.48328688740730286, total loss: 0.7841442823410034
12th Epoch, 21755th Step, learning rate = 0.007795424476499584 - Loss: 0.32456809282302856, aux loss1: 0.8300809860229492, 
		 aux loss2: 0.4457279443740845, total loss: 0.7518836259841919
12th Epoch, 21760th Step, learning rate = 0.007794910445395679 - Loss: 0.34513142704963684, aux loss1: 0.7820592522621155, 
		 aux loss2: 0.4382968246936798, total loss: 0.7550679445266724
12th Epoch, 21765th Step, learning rate = 0.007794396410525355 - Loss: 0.36808910965919495, aux loss1: 0.827859103679657, 
		 aux loss2: 0.47311633825302124, total loss: 0.8056933879852295
12th Epoch, 21770th Step, learning rate = 0.007793882371888311 - Loss: 0.31516599655151367, aux loss1: 0.7749581336975098, 
		 aux loss2: 0.40990588068962097, total loss: 0.711615800857544
12th Epoch, 21775th Step, learning rate = 0.007793368329484244 - Loss: 0.3299485146999359, aux loss1: 0.8896140456199646, 
		 aux loss2: 0.4369576871395111, total loss: 0.7716158628463745
12th Epoch, 21780th Step, learning rate = 0.00779285428331285 - Loss: 0.3459097146987915, aux loss1: 0.7191812992095947, 
		 aux loss2: 0.43403464555740356, total loss: 0.7352779507637024
12th Epoch, 21785th Step, learning rate = 0.007792340233373825 - Loss: 0.3334934115409851, aux loss1: 0.8143292665481567, 
		 aux loss2: 0.4495033621788025, total loss: 0.7575935125350952
12th Epoch, 21790th Step, learning rate = 0.007791826179666865 - Loss: 0.28887349367141724, aux loss1: 0.7395069003105164, 
		 aux loss2: 0.38015440106391907, total loss: 0.6627873182296753
12th Epoch, 21795th Step, learning rate = 0.007791312122191665 - Loss: 0.26868194341659546, aux loss1: 0.6560476422309875, 
		 aux loss2: 0.3359018862247467, total loss: 0.599856972694397
12th Epoch, 21800th Step, learning rate = 0.0077907980609479245 - Loss: 0.4048492908477783, aux loss1: 0.9123440980911255, 
		 aux loss2: 0.5084165334701538, total loss: 0.8819191455841064
<21800th step>
*************************** Test ***************************
time:3m 16s, 21800th Step, Loss: 0.5264851450920105, Mean IoU = 43.668%
************************************************************
12th Epoch, 21805th Step, learning rate = 0.007790283995935335 - Loss: 0.3395237624645233, aux loss1: 0.825434148311615, 
		 aux loss2: 0.4428773820400238, total loss: 0.7643049955368042
12th Epoch, 21810th Step, learning rate = 0.007789769927153597 - Loss: 0.4140486717224121, aux loss1: 0.8713471293449402, 
		 aux loss2: 0.49296098947525024, total loss: 0.8726372122764587
12th Epoch, 21815th Step, learning rate = 0.007789255854602404 - Loss: 0.3668123483657837, aux loss1: 0.8125147819519043, 
		 aux loss2: 0.4651414155960083, total loss: 0.7966233491897583
12th Epoch, 21820th Step, learning rate = 0.0077887417782814515 - Loss: 0.3688509464263916, aux loss1: 0.8558866381645203, 
		 aux loss2: 0.492046058177948, total loss: 0.8224353194236755
12th Epoch, 21825th Step, learning rate = 0.007788227698190438 - Loss: 0.37396860122680664, aux loss1: 0.9052225351333618, 
		 aux loss2: 0.5254721641540527, total loss: 0.8557242155075073
12th Epoch, 21830th Step, learning rate = 0.007787713614329056 - Loss: 0.6526709794998169, aux loss1: 1.257089614868164, 
		 aux loss2: 0.857466459274292, total loss: 1.3727844953536987
12th Epoch, 21835th Step, learning rate = 0.0077871995266970044 - Loss: 0.3802913427352905, aux loss1: 1.0529454946517944, 
		 aux loss2: 0.5519488453865051, total loss: 0.916954517364502
12th Epoch, 21840th Step, learning rate = 0.007786685435293977 - Loss: 0.37146806716918945, aux loss1: 0.9032946825027466, 
		 aux loss2: 0.490911602973938, total loss: 0.8388211131095886
12th Epoch, 21845th Step, learning rate = 0.007786171340119669 - Loss: 0.33960065245628357, aux loss1: 0.7768515944480896, 
		 aux loss2: 0.4330280125141144, total loss: 0.7458673715591431
12th Epoch, 21850th Step, learning rate = 0.007785657241173778 - Loss: 0.40242210030555725, aux loss1: 0.8307399153709412, 
		 aux loss2: 0.5049770474433899, total loss: 0.8536349534988403
12th Epoch, 21855th Step, learning rate = 0.007785143138455999 - Loss: 0.29070571064949036, aux loss1: 0.7512535452842712, 
		 aux loss2: 0.376120388507843, total loss: 0.6665299534797668
12th Epoch, 21860th Step, learning rate = 0.0077846290319660266 - Loss: 0.4240339994430542, aux loss1: 0.9387003779411316, 
		 aux loss2: 0.5766311883926392, total loss: 0.9362965822219849
12th Epoch, 21865th Step, learning rate = 0.007784114921703556 - Loss: 0.3518998920917511, aux loss1: 0.7719317674636841, 
		 aux loss2: 0.4427608251571655, total loss: 0.760583758354187
12th Epoch, 21870th Step, learning rate = 0.007783600807668286 - Loss: 0.38127365708351135, aux loss1: 0.8351444005966187, 
		 aux loss2: 0.48122623562812805, total loss: 0.8243075013160706
12th Epoch, 21875th Step, learning rate = 0.007783086689859909 - Loss: 0.47637560963630676, aux loss1: 1.060823678970337, 
		 aux loss2: 0.6019824743270874, total loss: 1.0354156494140625
12th Epoch, 21880th Step, learning rate = 0.0077825725682781205 - Loss: 0.31485724449157715, aux loss1: 0.8001002073287964, 
		 aux loss2: 0.40513432025909424, total loss: 0.7169409990310669
12th Epoch, 21885th Step, learning rate = 0.0077820584429226175 - Loss: 0.3734244704246521, aux loss1: 0.878870964050293, 
		 aux loss2: 0.5199205875396729, total loss: 0.845054030418396
12th Epoch, 21890th Step, learning rate = 0.007781544313793092 - Loss: 0.33753451704978943, aux loss1: 0.8009653687477112, 
		 aux loss2: 0.4589300751686096, total loss: 0.7613961696624756
12th Epoch, 21895th Step, learning rate = 0.007781030180889242 - Loss: 0.33633363246917725, aux loss1: 0.795332670211792, 
		 aux loss2: 0.44172927737236023, total loss: 0.751625120639801
12th Epoch, 21900th Step, learning rate = 0.007780516044210762 - Loss: 0.3184680640697479, aux loss1: 0.8032968640327454, 
		 aux loss2: 0.4491845667362213, total loss: 0.739130973815918
<21900th step>
*************************** Test ***************************
time:3m 19s, 21900th Step, Loss: 0.5381754636764526, Mean IoU = 43.773%
************************************************************
12th Epoch, 21905th Step, learning rate = 0.007780001903757349 - Loss: 0.466918408870697, aux loss1: 0.9474372863769531, 
		 aux loss2: 0.6207541227340698, total loss: 0.9994512796401978
12th Epoch, 21910th Step, learning rate = 0.007779487759528695 - Loss: 0.4206904470920563, aux loss1: 0.9028863310813904, 
		 aux loss2: 0.5513028502464294, total loss: 0.9120774865150452
12th Epoch, 21915th Step, learning rate = 0.007778973611524497 - Loss: 0.5641215443611145, aux loss1: 1.0804650783538818, 
		 aux loss2: 0.716769814491272, total loss: 1.174968957901001
12th Epoch, 21920th Step, learning rate = 0.007778459459744448 - Loss: 0.24391408264636993, aux loss1: 0.7127062678337097, 
		 aux loss2: 0.33004075288772583, total loss: 0.5897423028945923
12th Epoch, 21925th Step, learning rate = 0.007777945304188246 - Loss: 0.31258514523506165, aux loss1: 0.7318339943885803, 
		 aux loss2: 0.4148828983306885, total loss: 0.698088526725769
12th Epoch, 21930th Step, learning rate = 0.007777431144855584 - Loss: 0.27503952383995056, aux loss1: 0.7708448171615601, 
		 aux loss2: 0.3712794780731201, total loss: 0.6548048257827759
12th Epoch, 21935th Step, learning rate = 0.007776916981746156 - Loss: 0.4620440900325775, aux loss1: 1.0314308404922485, 
		 aux loss2: 0.6043683886528015, total loss: 1.0132206678390503
12th Epoch, 21940th Step, learning rate = 0.007776402814859659 - Loss: 0.33980658650398254, aux loss1: 0.8671911954879761, 
		 aux loss2: 0.4456671476364136, total loss: 0.7782308459281921
12th Epoch, 21945th Step, learning rate = 0.007775888644195785 - Loss: 0.4209476411342621, aux loss1: 1.013843297958374, 
		 aux loss2: 0.587016761302948, total loss: 0.9599073529243469
12th Epoch, 21950th Step, learning rate = 0.007775374469754232 - Loss: 0.5534474849700928, aux loss1: 1.1934398412704468, 
		 aux loss2: 0.7751320004463196, total loss: 1.2215323448181152
13th Epoch, 21955th Step, learning rate = 0.007774860291534692 - Loss: 0.32522574067115784, aux loss1: 0.7991195917129517, 
		 aux loss2: 0.42474365234375, total loss: 0.7348591089248657
13th Epoch, 21960th Step, learning rate = 0.007774346109536861 - Loss: 0.40111878514289856, aux loss1: 0.8863741755485535, 
		 aux loss2: 0.5227640867233276, total loss: 0.8761366605758667
13th Epoch, 21965th Step, learning rate = 0.007773831923760434 - Loss: 0.30367422103881836, aux loss1: 0.7385468482971191, 
		 aux loss2: 0.39815717935562134, total loss: 0.6845011711120605
13th Epoch, 21970th Step, learning rate = 0.007773317734205104 - Loss: 0.34450504183769226, aux loss1: 0.7326655387878418, 
		 aux loss2: 0.4407714605331421, total loss: 0.7406132817268372
13th Epoch, 21975th Step, learning rate = 0.007772803540870566 - Loss: 0.33780837059020996, aux loss1: 0.8768637776374817, 
		 aux loss2: 0.4581507444381714, total loss: 0.7841278314590454
13th Epoch, 21980th Step, learning rate = 0.007772289343756517 - Loss: 0.6127250790596008, aux loss1: 1.2049925327301025, 
		 aux loss2: 0.6951320767402649, total loss: 1.2522757053375244
13th Epoch, 21985th Step, learning rate = 0.007771775142862647 - Loss: 0.36132973432540894, aux loss1: 0.8102920055389404, 
		 aux loss2: 0.4717395603656769, total loss: 0.7931131720542908
13th Epoch, 21990th Step, learning rate = 0.007771260938188652 - Loss: 0.27132928371429443, aux loss1: 0.7088941335678101, 
		 aux loss2: 0.3650552034378052, total loss: 0.6300196051597595
13th Epoch, 21995th Step, learning rate = 0.007770746729734228 - Loss: 0.3946361541748047, aux loss1: 0.9420343041419983, 
		 aux loss2: 0.52952641248703, total loss: 0.8890570402145386
13th Epoch, 22000th Step, learning rate = 0.007770232517499067 - Loss: 0.3473670780658722, aux loss1: 0.7600140571594238, 
		 aux loss2: 0.44477447867393494, total loss: 0.7532811164855957
<22000th step>
*************************** Test ***************************
time:3m 19s, 22000th Step, Loss: 0.593014121055603, Mean IoU = 42.555%
************************************************************
13th Epoch, 22005th Step, learning rate = 0.007769718301482864 - Loss: 0.41497117280960083, aux loss1: 1.1085546016693115, 
		 aux loss2: 0.6040030717849731, total loss: 0.9891387820243835
13th Epoch, 22010th Step, learning rate = 0.007769204081685316 - Loss: 0.45633211731910706, aux loss1: 0.9941590428352356, 
		 aux loss2: 0.592619001865387, total loss: 0.9916274547576904
13th Epoch, 22015th Step, learning rate = 0.007768689858106112 - Loss: 0.29680705070495605, aux loss1: 0.7106549143791199, 
		 aux loss2: 0.38805684447288513, total loss: 0.6652263402938843
13th Epoch, 22020th Step, learning rate = 0.007768175630744948 - Loss: 0.35985690355300903, aux loss1: 0.8155465126037598, 
		 aux loss2: 0.4716874063014984, total loss: 0.7931958436965942
13th Epoch, 22025th Step, learning rate = 0.00776766139960152 - Loss: 0.2739066481590271, aux loss1: 0.7566681504249573, 
		 aux loss2: 0.3647034466266632, total loss: 0.646788477897644
13th Epoch, 22030th Step, learning rate = 0.007767147164675519 - Loss: 0.3882087171077728, aux loss1: 0.9486958980560303, 
		 aux loss2: 0.4976162612438202, total loss: 0.8718639612197876
13th Epoch, 22035th Step, learning rate = 0.007766632925966643 - Loss: 0.30413034558296204, aux loss1: 0.7985054850578308, 
		 aux loss2: 0.42413946986198425, total loss: 0.713337779045105
13th Epoch, 22040th Step, learning rate = 0.00776611868347458 - Loss: 0.3509756922721863, aux loss1: 0.7779340744018555, 
		 aux loss2: 0.4670783579349518, total loss: 0.7711873054504395
13th Epoch, 22045th Step, learning rate = 0.0077656044371990285 - Loss: 0.4635638892650604, aux loss1: 1.0648351907730103, 
		 aux loss2: 0.6305427551269531, total loss: 1.035231590270996
13th Epoch, 22050th Step, learning rate = 0.007765090187139682 - Loss: 0.35761386156082153, aux loss1: 0.7776904106140137, 
		 aux loss2: 0.4636653661727905, total loss: 0.7763871550559998
13th Epoch, 22055th Step, learning rate = 0.007764575933296232 - Loss: 0.38469943404197693, aux loss1: 0.9291868805885315, 
		 aux loss2: 0.49337998032569885, total loss: 0.860807478427887
13th Epoch, 22060th Step, learning rate = 0.007764061675668372 - Loss: 0.49836021661758423, aux loss1: 0.9981895089149475, 
		 aux loss2: 0.6294263601303101, total loss: 1.0495877265930176
13th Epoch, 22065th Step, learning rate = 0.0077635474142558 - Loss: 0.4741377830505371, aux loss1: 1.051458477973938, 
		 aux loss2: 0.6306946873664856, total loss: 1.0418531894683838
13th Epoch, 22070th Step, learning rate = 0.007763033149058203 - Loss: 0.326702356338501, aux loss1: 0.7559717893600464, 
		 aux loss2: 0.4250332713127136, total loss: 0.7235072255134583
13th Epoch, 22075th Step, learning rate = 0.00776251888007528 - Loss: 0.29307347536087036, aux loss1: 0.7295491099357605, 
		 aux loss2: 0.3850436806678772, total loss: 0.665955662727356
13th Epoch, 22080th Step, learning rate = 0.007762004607306722 - Loss: 0.4040151834487915, aux loss1: 0.9835426807403564, 
		 aux loss2: 0.565109372138977, total loss: 0.9251217246055603
13th Epoch, 22085th Step, learning rate = 0.007761490330752222 - Loss: 0.40985986590385437, aux loss1: 0.9011966586112976, 
		 aux loss2: 0.5283505320549011, total loss: 0.8915591239929199
13th Epoch, 22090th Step, learning rate = 0.007760976050411477 - Loss: 0.3711908459663391, aux loss1: 0.795093834400177, 
		 aux loss2: 0.46456098556518555, total loss: 0.7955434322357178
13th Epoch, 22095th Step, learning rate = 0.007760461766284175 - Loss: 0.3899632394313812, aux loss1: 0.9548811316490173, 
		 aux loss2: 0.5225359201431274, total loss: 0.8854419589042664
13th Epoch, 22100th Step, learning rate = 0.007759947478370013 - Loss: 0.34452584385871887, aux loss1: 0.7905824780464172, 
		 aux loss2: 0.44784772396087646, total loss: 0.7608396410942078
<22100th step>
*************************** Test ***************************
time:3m 14s, 22100th Step, Loss: 0.5370951890945435, Mean IoU = 42.579%
************************************************************
13th Epoch, 22105th Step, learning rate = 0.0077594331866686845 - Loss: 0.35510504245758057, aux loss1: 0.844762921333313, 
		 aux loss2: 0.4643501043319702, total loss: 0.7942739725112915
13th Epoch, 22110th Step, learning rate = 0.007758918891179879 - Loss: 0.3370812237262726, aux loss1: 0.8757262825965881, 
		 aux loss2: 0.4588512182235718, total loss: 0.7833396196365356
13th Epoch, 22115th Step, learning rate = 0.007758404591903293 - Loss: 0.41373881697654724, aux loss1: 0.8527525067329407, 
		 aux loss2: 0.5207999348640442, total loss: 0.877884566783905
13th Epoch, 22120th Step, learning rate = 0.0077578902888386205 - Loss: 0.33336690068244934, aux loss1: 0.9011552929878235, 
		 aux loss2: 0.4878535866737366, total loss: 0.7988549470901489
13th Epoch, 22125th Step, learning rate = 0.0077573759819855505 - Loss: 0.3624609410762787, aux loss1: 0.8573258519172668, 
		 aux loss2: 0.5021570920944214, total loss: 0.8205215334892273
13th Epoch, 22130th Step, learning rate = 0.007756861671343779 - Loss: 0.4207265079021454, aux loss1: 0.996322512626648, 
		 aux loss2: 0.5189914107322693, total loss: 0.9272198677062988
13th Epoch, 22135th Step, learning rate = 0.0077563473569129985 - Loss: 0.345750093460083, aux loss1: 0.7301971316337585, 
		 aux loss2: 0.41928571462631226, total loss: 0.7325235605239868
13th Epoch, 22140th Step, learning rate = 0.0077558330386929 - Loss: 0.3447246253490448, aux loss1: 0.9466768503189087, 
		 aux loss2: 0.48226433992385864, total loss: 0.8216333985328674
13th Epoch, 22145th Step, learning rate = 0.0077553187166831804 - Loss: 0.28429704904556274, aux loss1: 0.7036330103874207, 
		 aux loss2: 0.378719300031662, total loss: 0.6468746662139893
13th Epoch, 22150th Step, learning rate = 0.00775480439088353 - Loss: 0.2786842882633209, aux loss1: 0.718898355960846, 
		 aux loss2: 0.3709009289741516, total loss: 0.6427141427993774
13th Epoch, 22155th Step, learning rate = 0.007754290061293641 - Loss: 0.4142995774745941, aux loss1: 0.8779189586639404, 
		 aux loss2: 0.5106555819511414, total loss: 0.8819375038146973
13th Epoch, 22160th Step, learning rate = 0.007753775727913207 - Loss: 0.33235591650009155, aux loss1: 0.8787820935249329, 
		 aux loss2: 0.44584617018699646, total loss: 0.7743290066719055
13th Epoch, 22165th Step, learning rate = 0.007753261390741921 - Loss: 0.41189268231391907, aux loss1: 0.8801717758178711, 
		 aux loss2: 0.5354633927345276, total loss: 0.890129566192627
13th Epoch, 22170th Step, learning rate = 0.007752747049779474 - Loss: 0.3207228183746338, aux loss1: 0.778160810470581, 
		 aux loss2: 0.4455263912677765, total loss: 0.7323816418647766
13th Epoch, 22175th Step, learning rate = 0.00775223270502556 - Loss: 0.3905929923057556, aux loss1: 0.9496756792068481, 
		 aux loss2: 0.5103102922439575, total loss: 0.879619836807251
13th Epoch, 22180th Step, learning rate = 0.007751718356479872 - Loss: 0.3703818917274475, aux loss1: 0.9828215837478638, 
		 aux loss2: 0.5118682980537415, total loss: 0.8699756860733032
13th Epoch, 22185th Step, learning rate = 0.007751204004142102 - Loss: 0.4561486542224884, aux loss1: 0.8975908160209656, 
		 aux loss2: 0.5753809809684753, total loss: 0.9555783271789551
13th Epoch, 22190th Step, learning rate = 0.0077506896480119426 - Loss: 0.5698787569999695, aux loss1: 1.089505672454834, 
		 aux loss2: 0.7125998735427856, total loss: 1.1817704439163208
13th Epoch, 22195th Step, learning rate = 0.007750175288089085 - Loss: 0.3674590587615967, aux loss1: 0.8421269059181213, 
		 aux loss2: 0.49310624599456787, total loss: 0.8173396587371826
13th Epoch, 22200th Step, learning rate = 0.007749660924373222 - Loss: 0.44102007150650024, aux loss1: 0.9217013120651245, 
		 aux loss2: 0.5479580163955688, total loss: 0.936713695526123
<22200th step>
*************************** Test ***************************
time:3m 19s, 22200th Step, Loss: 0.5526649951934814, Mean IoU = 44.432%
************************************************************
13th Epoch, 22205th Step, learning rate = 0.007749146556864046 - Loss: 0.38747847080230713, aux loss1: 0.8909974098205566, 
		 aux loss2: 0.4903014898300171, total loss: 0.8508983254432678
13th Epoch, 22210th Step, learning rate = 0.0077486321855612505 - Loss: 0.3242865204811096, aux loss1: 0.7911207675933838, 
		 aux loss2: 0.43198132514953613, total loss: 0.7344152927398682
13th Epoch, 22215th Step, learning rate = 0.007748117810464528 - Loss: 0.414570689201355, aux loss1: 0.9954121112823486, 
		 aux loss2: 0.5664002299308777, total loss: 0.9397544860839844
13th Epoch, 22220th Step, learning rate = 0.007747603431573568 - Loss: 0.37773212790489197, aux loss1: 1.0813623666763306, 
		 aux loss2: 0.5917768478393555, total loss: 0.938851535320282
13th Epoch, 22225th Step, learning rate = 0.007747089048888064 - Loss: 0.3579150140285492, aux loss1: 0.875745952129364, 
		 aux loss2: 0.49352210760116577, total loss: 0.8180477023124695
13th Epoch, 22230th Step, learning rate = 0.007746574662407709 - Loss: 0.35969677567481995, aux loss1: 0.7531299591064453, 
		 aux loss2: 0.4430046081542969, total loss: 0.7628376483917236
13th Epoch, 22235th Step, learning rate = 0.0077460602721321934 - Loss: 0.3032601475715637, aux loss1: 0.7759140729904175, 
		 aux loss2: 0.4139677584171295, total loss: 0.7016214728355408
13th Epoch, 22240th Step, learning rate = 0.00774554587806121 - Loss: 0.4033716917037964, aux loss1: 1.0008773803710938, 
		 aux loss2: 0.5660787224769592, total loss: 0.9300664067268372
13th Epoch, 22245th Step, learning rate = 0.007745031480194451 - Loss: 0.3774181604385376, aux loss1: 0.8835349678993225, 
		 aux loss2: 0.4951123595237732, total loss: 0.8405236601829529
13th Epoch, 22250th Step, learning rate = 0.007744517078531608 - Loss: 0.4272647798061371, aux loss1: 1.013535976409912, 
		 aux loss2: 0.5523285865783691, total loss: 0.9522570371627808
13th Epoch, 22255th Step, learning rate = 0.007744002673072371 - Loss: 0.3268139362335205, aux loss1: 0.871687650680542, 
		 aux loss2: 0.4474416673183441, total loss: 0.7672969102859497
13th Epoch, 22260th Step, learning rate = 0.007743488263816435 - Loss: 0.3078024089336395, aux loss1: 0.7788174748420715, 
		 aux loss2: 0.41114914417266846, total loss: 0.7059072852134705
13th Epoch, 22265th Step, learning rate = 0.007742973850763489 - Loss: 0.4764993190765381, aux loss1: 1.123777151107788, 
		 aux loss2: 0.6687067747116089, total loss: 1.0811152458190918
13th Epoch, 22270th Step, learning rate = 0.007742459433913228 - Loss: 0.3564303517341614, aux loss1: 0.8829607963562012, 
		 aux loss2: 0.4934541881084442, total loss: 0.8187002539634705
13th Epoch, 22275th Step, learning rate = 0.00774194501326534 - Loss: 0.38217926025390625, aux loss1: 0.8311309814453125, 
		 aux loss2: 0.4994281232357025, total loss: 0.8312897682189941
13th Epoch, 22280th Step, learning rate = 0.007741430588819518 - Loss: 0.4268251061439514, aux loss1: 0.9382381439208984, 
		 aux loss2: 0.56999671459198, total loss: 0.936295211315155
13th Epoch, 22285th Step, learning rate = 0.007740916160575455 - Loss: 0.5044341087341309, aux loss1: 1.1212959289550781, 
		 aux loss2: 0.6466147303581238, total loss: 1.0994688272476196
13th Epoch, 22290th Step, learning rate = 0.00774040172853284 - Loss: 0.3201577365398407, aux loss1: 0.7617291212081909, 
		 aux loss2: 0.4169537425041199, total loss: 0.7154579758644104
13th Epoch, 22295th Step, learning rate = 0.007739887292691367 - Loss: 0.4234723746776581, aux loss1: 0.9626065492630005, 
		 aux loss2: 0.5532168745994568, total loss: 0.9335411190986633
13th Epoch, 22300th Step, learning rate = 0.007739372853050724 - Loss: 0.35461825132369995, aux loss1: 0.9363059401512146, 
		 aux loss2: 0.48337382078170776, total loss: 0.8288596272468567
<22300th step>
*************************** Test ***************************
time:3m 20s, 22300th Step, Loss: 0.5352375507354736, Mean IoU = 42.976%
************************************************************
13th Epoch, 22305th Step, learning rate = 0.007738858409610606 - Loss: 0.3942113220691681, aux loss1: 0.9562066793441772, 
		 aux loss2: 0.5347852110862732, total loss: 0.8949874043464661
13th Epoch, 22310th Step, learning rate = 0.007738343962370702 - Loss: 0.426789253950119, aux loss1: 0.946562647819519, 
		 aux loss2: 0.5374695062637329, total loss: 0.9257459044456482
13th Epoch, 22315th Step, learning rate = 0.0077378295113307025 - Loss: 0.36621084809303284, aux loss1: 0.854151725769043, 
		 aux loss2: 0.482854425907135, total loss: 0.8155981302261353
13th Epoch, 22320th Step, learning rate = 0.007737315056490303 - Loss: 0.3893258571624756, aux loss1: 0.8890063762664795, 
		 aux loss2: 0.506884753704071, total loss: 0.8587816953659058
14th Epoch, 22325th Step, learning rate = 0.00773680059784919 - Loss: 0.41995593905448914, aux loss1: 0.9208096265792847, 
		 aux loss2: 0.5682006478309631, total loss: 0.9234790802001953
14th Epoch, 22330th Step, learning rate = 0.0077362861354070556 - Loss: 0.4305253028869629, aux loss1: 1.017040729522705, 
		 aux loss2: 0.600647509098053, total loss: 0.9758965373039246
14th Epoch, 22335th Step, learning rate = 0.007735771669163592 - Loss: 0.486746609210968, aux loss1: 0.9955646991729736, 
		 aux loss2: 0.6049137115478516, total loss: 1.0273815393447876
14th Epoch, 22340th Step, learning rate = 0.007735257199118491 - Loss: 0.2945535182952881, aux loss1: 0.7638245820999146, 
		 aux loss2: 0.4087482988834381, total loss: 0.6872001886367798
14th Epoch, 22345th Step, learning rate = 0.007734742725271442 - Loss: 0.3152943551540375, aux loss1: 0.8063393235206604, 
		 aux loss2: 0.4134344756603241, total loss: 0.7225699424743652
14th Epoch, 22350th Step, learning rate = 0.007734228247622136 - Loss: 0.30707287788391113, aux loss1: 0.72868412733078, 
		 aux loss2: 0.38745853304862976, total loss: 0.6806615591049194
14th Epoch, 22355th Step, learning rate = 0.007733713766170265 - Loss: 0.4075472056865692, aux loss1: 0.963932454586029, 
		 aux loss2: 0.5650932788848877, total loss: 0.922764241695404
14th Epoch, 22360th Step, learning rate = 0.007733199280915517 - Loss: 0.4336090087890625, aux loss1: 0.9034466743469238, 
		 aux loss2: 0.5602139830589294, total loss: 0.9287285804748535
14th Epoch, 22365th Step, learning rate = 0.007732684791857586 - Loss: 0.3864130973815918, aux loss1: 0.8448467254638672, 
		 aux loss2: 0.49156737327575684, total loss: 0.8364940881729126
14th Epoch, 22370th Step, learning rate = 0.007732170298996163 - Loss: 0.4322632849216461, aux loss1: 0.911460816860199, 
		 aux loss2: 0.5535822510719299, total loss: 0.9271344542503357
14th Epoch, 22375th Step, learning rate = 0.007731655802330935 - Loss: 0.4121631979942322, aux loss1: 0.919959306716919, 
		 aux loss2: 0.5128671526908875, total loss: 0.8932978510856628
14th Epoch, 22380th Step, learning rate = 0.007731141301861595 - Loss: 0.2929835319519043, aux loss1: 0.7753972411155701, 
		 aux loss2: 0.37917348742485046, total loss: 0.6772720813751221
14th Epoch, 22385th Step, learning rate = 0.007730626797587834 - Loss: 0.3169790506362915, aux loss1: 0.8853247761726379, 
		 aux loss2: 0.4206133484840393, total loss: 0.7508218288421631
14th Epoch, 22390th Step, learning rate = 0.007730112289509341 - Loss: 0.37577372789382935, aux loss1: 0.9493110179901123, 
		 aux loss2: 0.5000052452087402, total loss: 0.8605691194534302
14th Epoch, 22395th Step, learning rate = 0.007729597777625809 - Loss: 0.2816533148288727, aux loss1: 0.6985453367233276, 
		 aux loss2: 0.3722253441810608, total loss: 0.6401070356369019
14th Epoch, 22400th Step, learning rate = 0.007729083261936926 - Loss: 0.3460422456264496, aux loss1: 0.8180266618728638, 
		 aux loss2: 0.44538623094558716, total loss: 0.7696048021316528
<22400th step>
*************************** Test ***************************
time:3m 15s, 22400th Step, Loss: 0.5499681830406189, Mean IoU = 43.969%
************************************************************
14th Epoch, 22405th Step, learning rate = 0.007728568742442383 - Loss: 0.2942426800727844, aux loss1: 0.7603688836097717, 
		 aux loss2: 0.4079223871231079, total loss: 0.6855223178863525
14th Epoch, 22410th Step, learning rate = 0.007728054219141871 - Loss: 0.456064909696579, aux loss1: 0.9454774856567383, 
		 aux loss2: 0.5958498120307922, total loss: 0.9780480861663818
14th Epoch, 22415th Step, learning rate = 0.00772753969203508 - Loss: 0.3898516893386841, aux loss1: 0.8323490619659424, 
		 aux loss2: 0.505096971988678, total loss: 0.8415951728820801
14th Epoch, 22420th Step, learning rate = 0.007727025161121698 - Loss: 0.4652623236179352, aux loss1: 1.1883137226104736, 
		 aux loss2: 0.6325493454933167, total loss: 1.0747761726379395
14th Epoch, 22425th Step, learning rate = 0.007726510626401419 - Loss: 0.36459577083587646, aux loss1: 0.8849242329597473, 
		 aux loss2: 0.47371095418930054, total loss: 0.8195574283599854
14th Epoch, 22430th Step, learning rate = 0.007725996087873932 - Loss: 0.2934934198856354, aux loss1: 0.7309617400169373, 
		 aux loss2: 0.3694840669631958, total loss: 0.6605756282806396
14th Epoch, 22435th Step, learning rate = 0.007725481545538926 - Loss: 0.23489299416542053, aux loss1: 0.656685471534729, 
		 aux loss2: 0.33042412996292114, total loss: 0.5640683174133301
14th Epoch, 22440th Step, learning rate = 0.00772496699939609 - Loss: 0.2887156903743744, aux loss1: 0.7033230662345886, 
		 aux loss2: 0.385222852230072, total loss: 0.6538017392158508
14th Epoch, 22445th Step, learning rate = 0.007724452449445117 - Loss: 0.5093856453895569, aux loss1: 1.0689640045166016, 
		 aux loss2: 0.6634917259216309, total loss: 1.0954715013504028
14th Epoch, 22450th Step, learning rate = 0.007723937895685697 - Loss: 0.3966667056083679, aux loss1: 0.9564095735549927, 
		 aux loss2: 0.5630747675895691, total loss: 0.9088194966316223
14th Epoch, 22455th Step, learning rate = 0.007723423338117517 - Loss: 0.354744017124176, aux loss1: 0.7735339999198914, 
		 aux loss2: 0.4383363425731659, total loss: 0.7621387243270874
14th Epoch, 22460th Step, learning rate = 0.007722908776740267 - Loss: 0.5601629018783569, aux loss1: 1.001861810684204, 
		 aux loss2: 0.7039974331855774, total loss: 1.1423203945159912
14th Epoch, 22465th Step, learning rate = 0.0077223942115536405 - Loss: 0.39798346161842346, aux loss1: 0.9188637137413025, 
		 aux loss2: 0.5134958028793335, total loss: 0.8790408968925476
14th Epoch, 22470th Step, learning rate = 0.007721879642557323 - Loss: 0.3038414418697357, aux loss1: 0.7058613896369934, 
		 aux loss2: 0.3982803523540497, total loss: 0.6749119758605957
14th Epoch, 22475th Step, learning rate = 0.007721365069751007 - Loss: 0.3461059331893921, aux loss1: 0.7891194820404053, 
		 aux loss2: 0.44912904500961304, total loss: 0.762493371963501
14th Epoch, 22480th Step, learning rate = 0.007720850493134382 - Loss: 0.34228724241256714, aux loss1: 0.8522224426269531, 
		 aux loss2: 0.465064138174057, total loss: 0.7839796543121338
14th Epoch, 22485th Step, learning rate = 0.007720335912707136 - Loss: 0.3047865927219391, aux loss1: 0.6896330118179321, 
		 aux loss2: 0.3993528187274933, total loss: 0.6714175939559937
14th Epoch, 22490th Step, learning rate = 0.007719821328468959 - Loss: 0.32896801829338074, aux loss1: 0.9502227902412415, 
		 aux loss2: 0.4775570333003998, total loss: 0.8050577044487
14th Epoch, 22495th Step, learning rate = 0.007719306740419541 - Loss: 0.3805236518383026, aux loss1: 0.8493438363075256, 
		 aux loss2: 0.5138972401618958, total loss: 0.8408856987953186
14th Epoch, 22500th Step, learning rate = 0.007718792148558571 - Loss: 0.312778115272522, aux loss1: 0.8789606690406799, 
		 aux loss2: 0.4356001913547516, total loss: 0.7507064342498779
<22500th step>
*************************** Test ***************************
time:3m 17s, 22500th Step, Loss: 0.5255814790725708, Mean IoU = 44.471%
************************************************************
14th Epoch, 22505th Step, learning rate = 0.007718277552885741 - Loss: 0.47413185238838196, aux loss1: 0.9427985548973083, 
		 aux loss2: 0.6118098497390747, total loss: 1.0016953945159912
14th Epoch, 22510th Step, learning rate = 0.0077177629534007355 - Loss: 0.29688331484794617, aux loss1: 0.6825255155563354, 
		 aux loss2: 0.40253764390945435, total loss: 0.6626560688018799
14th Epoch, 22515th Step, learning rate = 0.007717248350103248 - Loss: 0.4151057004928589, aux loss1: 1.0399894714355469, 
		 aux loss2: 0.6031616926193237, total loss: 0.9683672189712524
14th Epoch, 22520th Step, learning rate = 0.0077167337429929666 - Loss: 0.46212291717529297, aux loss1: 1.098287582397461, 
		 aux loss2: 0.6572081446647644, total loss: 1.054492473602295
14th Epoch, 22525th Step, learning rate = 0.00771621913206958 - Loss: 0.47931918501853943, aux loss1: 1.0827275514602661, 
		 aux loss2: 0.6286104917526245, total loss: 1.0555816888809204
14th Epoch, 22530th Step, learning rate = 0.007715704517332777 - Loss: 0.2909746766090393, aux loss1: 0.7537404298782349, 
		 aux loss2: 0.38226813077926636, total loss: 0.6700040698051453
14th Epoch, 22535th Step, learning rate = 0.007715189898782248 - Loss: 0.4402046799659729, aux loss1: 0.8821967244148254, 
		 aux loss2: 0.5568544864654541, total loss: 0.9276054501533508
14th Epoch, 22540th Step, learning rate = 0.007714675276417681 - Loss: 0.35316771268844604, aux loss1: 0.7912546992301941, 
		 aux loss2: 0.4143168032169342, total loss: 0.7562708258628845
14th Epoch, 22545th Step, learning rate = 0.007714160650238765 - Loss: 0.348108172416687, aux loss1: 0.8085744380950928, 
		 aux loss2: 0.4400760233402252, total loss: 0.7667108774185181
14th Epoch, 22550th Step, learning rate = 0.007713646020245192 - Loss: 0.4287896752357483, aux loss1: 0.8966060876846313, 
		 aux loss2: 0.5398685336112976, total loss: 0.9137189388275146
14th Epoch, 22555th Step, learning rate = 0.007713131386436645 - Loss: 0.4163399338722229, aux loss1: 0.9422813057899475, 
		 aux loss2: 0.5328200459480286, total loss: 0.9121523499488831
14th Epoch, 22560th Step, learning rate = 0.0077126167488128184 - Loss: 0.39756014943122864, aux loss1: 0.9160915017127991, 
		 aux loss2: 0.4947357475757599, total loss: 0.8702819347381592
14th Epoch, 22565th Step, learning rate = 0.0077121021073734 - Loss: 0.3019604980945587, aux loss1: 0.7216076850891113, 
		 aux loss2: 0.3906038701534271, total loss: 0.6746843457221985
14th Epoch, 22570th Step, learning rate = 0.007711587462118074 - Loss: 0.37887170910835266, aux loss1: 0.8842196464538574, 
		 aux loss2: 0.502505898475647, total loss: 0.8451399803161621
14th Epoch, 22575th Step, learning rate = 0.007711072813046536 - Loss: 0.4501994848251343, aux loss1: 0.9522406458854675, 
		 aux loss2: 0.5763171315193176, total loss: 0.9663985371589661
14th Epoch, 22580th Step, learning rate = 0.00771055816015847 - Loss: 0.3388572633266449, aux loss1: 0.8398066759109497, 
		 aux loss2: 0.4494650065898895, total loss: 0.770585298538208
14th Epoch, 22585th Step, learning rate = 0.007710043503453565 - Loss: 0.35760512948036194, aux loss1: 0.8658721446990967, 
		 aux loss2: 0.4828470051288605, total loss: 0.8105056285858154
14th Epoch, 22590th Step, learning rate = 0.007709528842931512 - Loss: 0.37102609872817993, aux loss1: 0.9002320766448975, 
		 aux loss2: 0.527614951133728, total loss: 0.8521417379379272
14th Epoch, 22595th Step, learning rate = 0.007709014178591999 - Loss: 0.3389495611190796, aux loss1: 0.8110554814338684, 
		 aux loss2: 0.44626253843307495, total loss: 0.7607712149620056
14th Epoch, 22600th Step, learning rate = 0.0077084995104347125 - Loss: 0.43446147441864014, aux loss1: 0.9809690117835999, 
		 aux loss2: 0.6012516021728516, total loss: 0.9692528247833252
<22600th step>
*************************** Test ***************************
time:3m 14s, 22600th Step, Loss: 0.5518355369567871, Mean IoU = 42.782%
************************************************************
14th Epoch, 22605th Step, learning rate = 0.007707984838459343 - Loss: 0.3871460556983948, aux loss1: 0.7859384417533875, 
		 aux loss2: 0.4747006297111511, total loss: 0.8128078579902649
14th Epoch, 22610th Step, learning rate = 0.0077074701626655764 - Loss: 0.2997955083847046, aux loss1: 0.9266149997711182, 
		 aux loss2: 0.39940038323402405, total loss: 0.7375401854515076
14th Epoch, 22615th Step, learning rate = 0.007706955483053104 - Loss: 0.3909786641597748, aux loss1: 0.8401928544044495, 
		 aux loss2: 0.49426591396331787, total loss: 0.8407429456710815
14th Epoch, 22620th Step, learning rate = 0.007706440799621614 - Loss: 0.40397918224334717, aux loss1: 0.8769662976264954, 
		 aux loss2: 0.5035062432289124, total loss: 0.8684715628623962
14th Epoch, 22625th Step, learning rate = 0.00770592611237079 - Loss: 0.27561137080192566, aux loss1: 0.6360546946525574, 
		 aux loss2: 0.3501397371292114, total loss: 0.6064836978912354
14th Epoch, 22630th Step, learning rate = 0.007705411421300327 - Loss: 0.37457743287086487, aux loss1: 0.9754828810691833, 
		 aux loss2: 0.5332355499267578, total loss: 0.880516529083252
14th Epoch, 22635th Step, learning rate = 0.007704896726409908 - Loss: 0.376893550157547, aux loss1: 0.9446750283241272, 
		 aux loss2: 0.5211458802223206, total loss: 0.8687544465065002
14th Epoch, 22640th Step, learning rate = 0.007704382027699222 - Loss: 0.33518052101135254, aux loss1: 0.8605135083198547, 
		 aux loss2: 0.4490968883037567, total loss: 0.7729732990264893
14th Epoch, 22645th Step, learning rate = 0.007703867325167962 - Loss: 0.38754451274871826, aux loss1: 0.9832466840744019, 
		 aux loss2: 0.5184046626091003, total loss: 0.8898804187774658
14th Epoch, 22650th Step, learning rate = 0.007703352618815809 - Loss: 0.27858251333236694, aux loss1: 0.7221118211746216, 
		 aux loss2: 0.34813031554222107, total loss: 0.6344681978225708
14th Epoch, 22655th Step, learning rate = 0.0077028379086424535 - Loss: 0.3786196708679199, aux loss1: 0.8575606942176819, 
		 aux loss2: 0.4740886390209198, total loss: 0.825523316860199
14th Epoch, 22660th Step, learning rate = 0.007702323194647587 - Loss: 0.5110273957252502, aux loss1: 1.0211329460144043, 
		 aux loss2: 0.6549995541572571, total loss: 1.0793671607971191
14th Epoch, 22665th Step, learning rate = 0.007701808476830892 - Loss: 0.31149396300315857, aux loss1: 0.81852787733078, 
		 aux loss2: 0.44732069969177246, total loss: 0.7359806299209595
14th Epoch, 22670th Step, learning rate = 0.007701293755192058 - Loss: 0.36770960688591003, aux loss1: 0.9365416765213013, 
		 aux loss2: 0.5031275749206543, total loss: 0.8499231338500977
14th Epoch, 22675th Step, learning rate = 0.007700779029730776 - Loss: 0.34151965379714966, aux loss1: 0.8150537610054016, 
		 aux loss2: 0.4524630606174469, total loss: 0.7670210003852844
14th Epoch, 22680th Step, learning rate = 0.0077002643004467275 - Loss: 0.3298477232456207, aux loss1: 0.884902834892273, 
		 aux loss2: 0.4564831554889679, total loss: 0.7779118418693542
14th Epoch, 22685th Step, learning rate = 0.007699749567339606 - Loss: 0.44057685136795044, aux loss1: 0.9846187829971313, 
		 aux loss2: 0.5773928761482239, total loss: 0.9669196605682373
14th Epoch, 22690th Step, learning rate = 0.0076992348304090975 - Loss: 0.31046611070632935, aux loss1: 0.7322652339935303, 
		 aux loss2: 0.4158405661582947, total loss: 0.6964819431304932
14th Epoch, 22695th Step, learning rate = 0.007698720089654888 - Loss: 0.3826430141925812, aux loss1: 0.7965006828308105, 
		 aux loss2: 0.46808865666389465, total loss: 0.8088287115097046
15th Epoch, 22700th Step, learning rate = 0.007698205345076667 - Loss: 0.37031495571136475, aux loss1: 0.8311212062835693, 
		 aux loss2: 0.4868456721305847, total loss: 0.8143895864486694
<22700th step>
*************************** Test ***************************
time:3m 17s, 22700th Step, Loss: 0.5570756196975708, Mean IoU = 43.393%
************************************************************
15th Epoch, 22705th Step, learning rate = 0.007697690596674121 - Loss: 0.333003968000412, aux loss1: 0.8793500661849976, 
		 aux loss2: 0.4619233012199402, total loss: 0.7815783619880676
15th Epoch, 22710th Step, learning rate = 0.0076971758444469365 - Loss: 0.3409232497215271, aux loss1: 0.891413688659668, 
		 aux loss2: 0.48688894510269165, total loss: 0.803102970123291
15th Epoch, 22715th Step, learning rate = 0.007696661088394803 - Loss: 0.32978999614715576, aux loss1: 0.7246748208999634, 
		 aux loss2: 0.41953256726264954, total loss: 0.7150055170059204
15th Epoch, 22720th Step, learning rate = 0.007696146328517406 - Loss: 0.3248105049133301, aux loss1: 0.8929489850997925, 
		 aux loss2: 0.44723036885261536, total loss: 0.7715873718261719
15th Epoch, 22725th Step, learning rate = 0.007695631564814434 - Loss: 0.23305712640285492, aux loss1: 0.727847695350647, 
		 aux loss2: 0.3419801890850067, total loss: 0.588203489780426
15th Epoch, 22730th Step, learning rate = 0.007695116797285574 - Loss: 0.3011530637741089, aux loss1: 0.8074460625648499, 
		 aux loss2: 0.41130316257476807, total loss: 0.7079081535339355
15th Epoch, 22735th Step, learning rate = 0.00769460202593051 - Loss: 0.27917248010635376, aux loss1: 0.8710516691207886, 
		 aux loss2: 0.43297621607780457, total loss: 0.7136784791946411
15th Epoch, 22740th Step, learning rate = 0.007694087250748936 - Loss: 0.36727994680404663, aux loss1: 0.8916336297988892, 
		 aux loss2: 0.48469001054763794, total loss: 0.8286460638046265
15th Epoch, 22745th Step, learning rate = 0.007693572471740533 - Loss: 0.33768850564956665, aux loss1: 0.8272060751914978, 
		 aux loss2: 0.4459037780761719, total loss: 0.764211893081665
15th Epoch, 22750th Step, learning rate = 0.00769305768890499 - Loss: 0.30509018898010254, aux loss1: 0.7159390449523926, 
		 aux loss2: 0.3781146705150604, total loss: 0.6711177825927734
15th Epoch, 22755th Step, learning rate = 0.007692542902241996 - Loss: 0.355246365070343, aux loss1: 0.9401623010635376, 
		 aux loss2: 0.49484819173812866, total loss: 0.8352343440055847
15th Epoch, 22760th Step, learning rate = 0.007692028111751233 - Loss: 0.4254900813102722, aux loss1: 0.9113112688064575, 
		 aux loss2: 0.5643627643585205, total loss: 0.9246286153793335
15th Epoch, 22765th Step, learning rate = 0.007691513317432393 - Loss: 0.3618794083595276, aux loss1: 0.9098219275474548, 
		 aux loss2: 0.4964616298675537, total loss: 0.8334106802940369
15th Epoch, 22770th Step, learning rate = 0.007690998519285162 - Loss: 0.25290337204933167, aux loss1: 0.6847470998764038, 
		 aux loss2: 0.3348753750324249, total loss: 0.5922777056694031
15th Epoch, 22775th Step, learning rate = 0.007690483717309224 - Loss: 0.26915526390075684, aux loss1: 0.792147159576416, 
		 aux loss2: 0.3686709403991699, total loss: 0.6542677879333496
15th Epoch, 22780th Step, learning rate = 0.007689968911504267 - Loss: 0.2941265106201172, aux loss1: 0.8765487670898438, 
		 aux loss2: 0.42408812046051025, total loss: 0.7267263531684875
15th Epoch, 22785th Step, learning rate = 0.00768945410186998 - Loss: 0.4827188551425934, aux loss1: 1.0784846544265747, 
		 aux loss2: 0.6388529539108276, total loss: 1.0618054866790771
15th Epoch, 22790th Step, learning rate = 0.007688939288406046 - Loss: 0.3725646138191223, aux loss1: 0.9228576421737671, 
		 aux loss2: 0.5005261898040771, total loss: 0.8496323823928833
15th Epoch, 22795th Step, learning rate = 0.007688424471112155 - Loss: 0.2800835072994232, aux loss1: 0.7767789363861084, 
		 aux loss2: 0.38576221466064453, total loss: 0.6674220561981201
15th Epoch, 22800th Step, learning rate = 0.007687909649987991 - Loss: 0.4046437740325928, aux loss1: 0.8392767310142517, 
		 aux loss2: 0.5031377673149109, total loss: 0.8576818704605103
<22800th step>
*************************** Test ***************************
time:3m 19s, 22800th Step, Loss: 0.5223779678344727, Mean IoU = 45.384%
************************************************************
15th Epoch, 22805th Step, learning rate = 0.007687394825033241 - Loss: 0.3127146363258362, aux loss1: 0.8655996322631836, 
		 aux loss2: 0.42971980571746826, total loss: 0.7442824840545654
15th Epoch, 22810th Step, learning rate = 0.007686879996247592 - Loss: 0.4166813790798187, aux loss1: 0.9160599708557129, 
		 aux loss2: 0.5202523469924927, total loss: 0.8996002674102783
15th Epoch, 22815th Step, learning rate = 0.007686365163630731 - Loss: 0.3726133406162262, aux loss1: 0.8102545738220215, 
		 aux loss2: 0.4862753748893738, total loss: 0.8101999163627625
15th Epoch, 22820th Step, learning rate = 0.007685850327182342 - Loss: 0.2955329716205597, aux loss1: 0.8525703549385071, 
		 aux loss2: 0.445038378238678, total loss: 0.7293194532394409
15th Epoch, 22825th Step, learning rate = 0.007685335486902116 - Loss: 0.417147159576416, aux loss1: 0.9847372770309448, 
		 aux loss2: 0.5779572129249573, total loss: 0.9437512159347534
15th Epoch, 22830th Step, learning rate = 0.007684820642789734 - Loss: 0.33729901909828186, aux loss1: 0.8727145195007324, 
		 aux loss2: 0.47579827904701233, total loss: 0.7894326448440552
15th Epoch, 22835th Step, learning rate = 0.007684305794844883 - Loss: 0.39628297090530396, aux loss1: 0.8429712653160095, 
		 aux loss2: 0.48865023255348206, total loss: 0.8446344137191772
15th Epoch, 22840th Step, learning rate = 0.007683790943067254 - Loss: 0.37392112612724304, aux loss1: 0.9182518124580383, 
		 aux loss2: 0.49286624789237976, total loss: 0.8465431928634644
15th Epoch, 22845th Step, learning rate = 0.007683276087456527 - Loss: 0.38683170080184937, aux loss1: 0.9070736765861511, 
		 aux loss2: 0.49724629521369934, total loss: 0.8578523397445679
15th Epoch, 22850th Step, learning rate = 0.007682761228012393 - Loss: 0.29370585083961487, aux loss1: 0.8250864148139954, 
		 aux loss2: 0.40961411595344543, total loss: 0.7050774097442627
15th Epoch, 22855th Step, learning rate = 0.007682246364734535 - Loss: 0.321870356798172, aux loss1: 0.7840319871902466, 
		 aux loss2: 0.4271213114261627, total loss: 0.7279285192489624
15th Epoch, 22860th Step, learning rate = 0.007681731497622638 - Loss: 0.3791196048259735, aux loss1: 1.011548399925232, 
		 aux loss2: 0.5653817653656006, total loss: 0.9087368845939636
15th Epoch, 22865th Step, learning rate = 0.007681216626676392 - Loss: 0.42901232838630676, aux loss1: 0.9995194673538208, 
		 aux loss2: 0.5858562588691711, total loss: 0.9632107019424438
15th Epoch, 22870th Step, learning rate = 0.007680701751895479 - Loss: 0.37384289503097534, aux loss1: 0.8874635100364685, 
		 aux loss2: 0.49033063650131226, total loss: 0.8362142443656921
15th Epoch, 22875th Step, learning rate = 0.007680186873279587 - Loss: 0.4987105429172516, aux loss1: 1.092705488204956, 
		 aux loss2: 0.6560877561569214, total loss: 1.0889573097229004
15th Epoch, 22880th Step, learning rate = 0.007679671990828402 - Loss: 0.33136385679244995, aux loss1: 0.7355428338050842, 
		 aux loss2: 0.43406233191490173, total loss: 0.7256516814231873
15th Epoch, 22885th Step, learning rate = 0.007679157104541608 - Loss: 0.37739133834838867, aux loss1: 0.7951898574829102, 
		 aux loss2: 0.49143004417419434, total loss: 0.8125203251838684
15th Epoch, 22890th Step, learning rate = 0.007678642214418891 - Loss: 0.35461482405662537, aux loss1: 0.9278075695037842, 
		 aux loss2: 0.47764456272125244, total loss: 0.8240149021148682
15th Epoch, 22895th Step, learning rate = 0.007678127320459938 - Loss: 0.4350756108760834, aux loss1: 1.0275083780288696, 
		 aux loss2: 0.5933229923248291, total loss: 0.9806572794914246
15th Epoch, 22900th Step, learning rate = 0.007677612422664432 - Loss: 0.3038020431995392, aux loss1: 0.8060740828514099, 
		 aux loss2: 0.41457539796829224, total loss: 0.7114543914794922
<22900th step>
*************************** Test ***************************
time:3m 22s, 22900th Step, Loss: 0.5276640057563782, Mean IoU = 44.796%
************************************************************
15th Epoch, 22905th Step, learning rate = 0.007677097521032061 - Loss: 0.3475783169269562, aux loss1: 0.9169089198112488, 
		 aux loss2: 0.4855619966983795, total loss: 0.8168758153915405
15th Epoch, 22910th Step, learning rate = 0.007676582615562511 - Loss: 0.4427506923675537, aux loss1: 0.9551370143890381, 
		 aux loss2: 0.5746252536773682, total loss: 0.9591419100761414
15th Epoch, 22915th Step, learning rate = 0.007676067706255464 - Loss: 0.3962530791759491, aux loss1: 0.8519680500030518, 
		 aux loss2: 0.49756625294685364, total loss: 0.8508700728416443
15th Epoch, 22920th Step, learning rate = 0.00767555279311061 - Loss: 0.31321680545806885, aux loss1: 0.7575669884681702, 
		 aux loss2: 0.4188680052757263, total loss: 0.7080341577529907
15th Epoch, 22925th Step, learning rate = 0.0076750378761276305 - Loss: 0.3234005570411682, aux loss1: 0.8014811873435974, 
		 aux loss2: 0.43852919340133667, total loss: 0.7392566204071045
15th Epoch, 22930th Step, learning rate = 0.007674522955306211 - Loss: 0.3465104103088379, aux loss1: 0.98466557264328, 
		 aux loss2: 0.4617777168750763, total loss: 0.8266211748123169
15th Epoch, 22935th Step, learning rate = 0.00767400803064604 - Loss: 0.4027172029018402, aux loss1: 0.8880692720413208, 
		 aux loss2: 0.4972035884857178, total loss: 0.8680194020271301
15th Epoch, 22940th Step, learning rate = 0.007673493102146799 - Loss: 0.3867572546005249, aux loss1: 1.0629351139068604, 
		 aux loss2: 0.5747541189193726, total loss: 0.9355394840240479
15th Epoch, 22945th Step, learning rate = 0.007672978169808175 - Loss: 0.3559386432170868, aux loss1: 0.9637758135795593, 
		 aux loss2: 0.4806387722492218, total loss: 0.8373268842697144
15th Epoch, 22950th Step, learning rate = 0.0076724632336298525 - Loss: 0.2908403277397156, aux loss1: 0.798285186290741, 
		 aux loss2: 0.3827793300151825, total loss: 0.6834376454353333
15th Epoch, 22955th Step, learning rate = 0.007671948293611517 - Loss: 0.5300205945968628, aux loss1: 1.1343809366226196, 
		 aux loss2: 0.7179664969444275, total loss: 1.1575214862823486
15th Epoch, 22960th Step, learning rate = 0.0076714333497528535 - Loss: 0.358036607503891, aux loss1: 0.8276885747909546, 
		 aux loss2: 0.4520230293273926, total loss: 0.7871524095535278
15th Epoch, 22965th Step, learning rate = 0.007670918402053547 - Loss: 0.433157742023468, aux loss1: 0.8767220973968506, 
		 aux loss2: 0.5471857786178589, total loss: 0.9150487184524536
15th Epoch, 22970th Step, learning rate = 0.0076704034505132804 - Loss: 0.3702801764011383, aux loss1: 0.8796344995498657, 
		 aux loss2: 0.5243894457817078, total loss: 0.8439263105392456
15th Epoch, 22975th Step, learning rate = 0.007669888495131742 - Loss: 0.42467111349105835, aux loss1: 1.0345115661621094, 
		 aux loss2: 0.5927340388298035, total loss: 0.9721181988716125
15th Epoch, 22980th Step, learning rate = 0.007669373535908614 - Loss: 0.30052879452705383, aux loss1: 0.8326863050460815, 
		 aux loss2: 0.40706172585487366, total loss: 0.7131593823432922
15th Epoch, 22985th Step, learning rate = 0.00766885857284358 - Loss: 0.2780395746231079, aux loss1: 0.7869390845298767, 
		 aux loss2: 0.3738909661769867, total loss: 0.6636776924133301
15th Epoch, 22990th Step, learning rate = 0.00766834360593633 - Loss: 0.39553090929985046, aux loss1: 0.9315376281738281, 
		 aux loss2: 0.5157228112220764, total loss: 0.881281316280365
15th Epoch, 22995th Step, learning rate = 0.007667828635186542 - Loss: 0.3563894033432007, aux loss1: 0.8665797710418701, 
		 aux loss2: 0.4528961479663849, total loss: 0.7975218296051025
15th Epoch, 23000th Step, learning rate = 0.007667313660593905 - Loss: 0.400607705116272, aux loss1: 0.8879770040512085, 
		 aux loss2: 0.5065136551856995, total loss: 0.8696063160896301
<23000th step>
*************************** Test ***************************
time:3m 17s, 23000th Step, Loss: 0.6129618287086487, Mean IoU = 42.219%
************************************************************
15th Epoch, 23005th Step, learning rate = 0.007666798682158104 - Loss: 0.5025115609169006, aux loss1: 1.019730567932129, 
		 aux loss2: 0.6217576265335083, total loss: 1.0571337938308716
15th Epoch, 23010th Step, learning rate = 0.00766628369987882 - Loss: 0.35924145579338074, aux loss1: 0.9019047021865845, 
		 aux loss2: 0.47468477487564087, total loss: 0.819686770439148
15th Epoch, 23015th Step, learning rate = 0.007665768713755739 - Loss: 0.3754238188266754, aux loss1: 0.9516009092330933, 
		 aux loss2: 0.557805061340332, total loss: 0.8840261697769165
15th Epoch, 23020th Step, learning rate = 0.007665253723788548 - Loss: 0.3643568754196167, aux loss1: 0.8783159255981445, 
		 aux loss2: 0.5032073855400085, total loss: 0.8291346430778503
15th Epoch, 23025th Step, learning rate = 0.007664738729976927 - Loss: 0.34667491912841797, aux loss1: 0.744074285030365, 
		 aux loss2: 0.4371854364871979, total loss: 0.744771420955658
15th Epoch, 23030th Step, learning rate = 0.007664223732320562 - Loss: 0.4729672074317932, aux loss1: 1.0532877445220947, 
		 aux loss2: 0.6183936595916748, total loss: 1.0363110303878784
15th Epoch, 23035th Step, learning rate = 0.007663708730819139 - Loss: 0.3094513416290283, aux loss1: 0.7668436169624329, 
		 aux loss2: 0.4106142222881317, total loss: 0.7037501335144043
15th Epoch, 23040th Step, learning rate = 0.007663193725472338 - Loss: 0.34918054938316345, aux loss1: 0.754340648651123, 
		 aux loss2: 0.44202375411987305, total loss: 0.7522922158241272
15th Epoch, 23045th Step, learning rate = 0.007662678716279848 - Loss: 0.47117453813552856, aux loss1: 1.0933901071548462, 
		 aux loss2: 0.6895431876182556, total loss: 1.0750088691711426
15th Epoch, 23050th Step, learning rate = 0.007662163703241352 - Loss: 0.2991625666618347, aux loss1: 0.7137165069580078, 
		 aux loss2: 0.3758668899536133, total loss: 0.6636242866516113
15th Epoch, 23055th Step, learning rate = 0.007661648686356529 - Loss: 0.3139474093914032, aux loss1: 0.8310173749923706, 
		 aux loss2: 0.3985462188720703, total loss: 0.7226711511611938
15th Epoch, 23060th Step, learning rate = 0.00766113366562507 - Loss: 0.3565298616886139, aux loss1: 0.8355141282081604, 
		 aux loss2: 0.47638875246047974, total loss: 0.7977396249771118
15th Epoch, 23065th Step, learning rate = 0.007660618641046656 - Loss: 0.4401354193687439, aux loss1: 1.0501582622528076, 
		 aux loss2: 0.5945204496383667, total loss: 0.9929910898208618
16th Epoch, 23070th Step, learning rate = 0.007660103612620969 - Loss: 0.34615248441696167, aux loss1: 0.7858626842498779, 
		 aux loss2: 0.46645596623420715, total loss: 0.7684937119483948
16th Epoch, 23075th Step, learning rate = 0.007659588580347697 - Loss: 0.26916828751564026, aux loss1: 0.7139565348625183, 
		 aux loss2: 0.3625393509864807, total loss: 0.628371000289917
16th Epoch, 23080th Step, learning rate = 0.0076590735442265195 - Loss: 0.2649206519126892, aux loss1: 0.7432593703269958, 
		 aux loss2: 0.35371530055999756, total loss: 0.6293845772743225
16th Epoch, 23085th Step, learning rate = 0.007658558504257122 - Loss: 0.3496011197566986, aux loss1: 0.7976821660995483, 
		 aux loss2: 0.4631703794002533, total loss: 0.7741739749908447
16th Epoch, 23090th Step, learning rate = 0.00765804346043919 - Loss: 0.3538127541542053, aux loss1: 0.9048381447792053, 
		 aux loss2: 0.5000515580177307, total loss: 0.8252847790718079
16th Epoch, 23095th Step, learning rate = 0.007657528412772405 - Loss: 0.2393227517604828, aux loss1: 0.6269349455833435, 
		 aux loss2: 0.3138330280780792, total loss: 0.5529364347457886
16th Epoch, 23100th Step, learning rate = 0.007657013361256451 - Loss: 0.35020968317985535, aux loss1: 0.9791737198829651, 
		 aux loss2: 0.5842540264129639, total loss: 0.8776633739471436
<23100th step>
*************************** Test ***************************
time:3m 14s, 23100th Step, Loss: 0.5456215143203735, Mean IoU = 43.448%
************************************************************
16th Epoch, 23105th Step, learning rate = 0.0076564983058910125 - Loss: 0.38449886441230774, aux loss1: 0.9165394902229309, 
		 aux loss2: 0.5132166147232056, total loss: 0.8647474050521851
16th Epoch, 23110th Step, learning rate = 0.007655983246675768 - Loss: 0.3244136571884155, aux loss1: 0.7742810845375061, 
		 aux loss2: 0.41822001338005066, total loss: 0.7239859700202942
16th Epoch, 23115th Step, learning rate = 0.00765546818361041 - Loss: 0.3352845013141632, aux loss1: 0.8310638070106506, 
		 aux loss2: 0.4489283561706543, total loss: 0.7641749978065491
16th Epoch, 23120th Step, learning rate = 0.007654953116694614 - Loss: 0.3335452377796173, aux loss1: 0.859462559223175, 
		 aux loss2: 0.465554416179657, total loss: 0.7776058316230774
16th Epoch, 23125th Step, learning rate = 0.007654438045928067 - Loss: 0.41127797961235046, aux loss1: 0.9909326434135437, 
		 aux loss2: 0.5598461627960205, total loss: 0.9324962496757507
16th Epoch, 23130th Step, learning rate = 0.007653922971310453 - Loss: 0.3259841799736023, aux loss1: 0.7850337028503418, 
		 aux loss2: 0.4265851080417633, total loss: 0.7321283221244812
16th Epoch, 23135th Step, learning rate = 0.007653407892841453 - Loss: 0.4779442846775055, aux loss1: 1.052137017250061, 
		 aux loss2: 0.6553425788879395, total loss: 1.0557224750518799
16th Epoch, 23140th Step, learning rate = 0.007652892810520751 - Loss: 0.28323599696159363, aux loss1: 0.7692981958389282, 
		 aux loss2: 0.38169607520103455, total loss: 0.6667038798332214
16th Epoch, 23145th Step, learning rate = 0.0076523777243480305 - Loss: 0.31286096572875977, aux loss1: 0.8894263505935669, 
		 aux loss2: 0.45270830392837524, total loss: 0.7607722282409668
16th Epoch, 23150th Step, learning rate = 0.007651862634322975 - Loss: 0.330687016248703, aux loss1: 0.7806463837623596, 
		 aux loss2: 0.43476781249046326, total loss: 0.7387881278991699
16th Epoch, 23155th Step, learning rate = 0.007651347540445265 - Loss: 0.2819490432739258, aux loss1: 0.6885892748832703, 
		 aux loss2: 0.3743925988674164, total loss: 0.6382828950881958
16th Epoch, 23160th Step, learning rate = 0.007650832442714587 - Loss: 0.42171043157577515, aux loss1: 0.9806082248687744, 
		 aux loss2: 0.5709745287895203, total loss: 0.9442827105522156
16th Epoch, 23165th Step, learning rate = 0.0076503173411306205 - Loss: 0.4741862416267395, aux loss1: 1.0862258672714233, 
		 aux loss2: 0.6688993573188782, total loss: 1.0676137208938599
16th Epoch, 23170th Step, learning rate = 0.007649802235693052 - Loss: 0.30340006947517395, aux loss1: 0.7562680840492249, 
		 aux loss2: 0.40752723813056946, total loss: 0.6932913661003113
16th Epoch, 23175th Step, learning rate = 0.007649287126401561 - Loss: 0.3489282429218292, aux loss1: 0.8422694206237793, 
		 aux loss2: 0.4782150089740753, total loss: 0.7928951382637024
16th Epoch, 23180th Step, learning rate = 0.007648772013255833 - Loss: 0.4099951982498169, aux loss1: 1.1046762466430664, 
		 aux loss2: 0.5720339417457581, total loss: 0.9702116847038269
16th Epoch, 23185th Step, learning rate = 0.00764825689625555 - Loss: 0.30320072174072266, aux loss1: 0.7262909412384033, 
		 aux loss2: 0.40461426973342896, total loss: 0.6829336881637573
16th Epoch, 23190th Step, learning rate = 0.007647741775400393 - Loss: 0.27234962582588196, aux loss1: 0.7198805212974548, 
		 aux loss2: 0.37171685695648193, total loss: 0.637000560760498
16th Epoch, 23195th Step, learning rate = 0.007647226650690047 - Loss: 0.38125187158584595, aux loss1: 0.8919598460197449, 
		 aux loss2: 0.5076174736022949, total loss: 0.8518868088722229
16th Epoch, 23200th Step, learning rate = 0.007646711522124193 - Loss: 0.4100998640060425, aux loss1: 0.9277478456497192, 
		 aux loss2: 0.5659157037734985, total loss: 0.9147905111312866
<23200th step>
*************************** Test ***************************
time:3m 21s, 23200th Step, Loss: 0.6180668473243713, Mean IoU = 40.242%
************************************************************
16th Epoch, 23205th Step, learning rate = 0.007646196389702514 - Loss: 0.44282057881355286, aux loss1: 0.9111039042472839, 
		 aux loss2: 0.5935842394828796, total loss: 0.9535855054855347
16th Epoch, 23210th Step, learning rate = 0.007645681253424693 - Loss: 0.4402308166027069, aux loss1: 1.0326707363128662, 
		 aux loss2: 0.5650283098220825, total loss: 0.9760434031486511
16th Epoch, 23215th Step, learning rate = 0.007645166113290413 - Loss: 0.4176727533340454, aux loss1: 0.9114158749580383, 
		 aux loss2: 0.539888858795166, total loss: 0.9070530533790588
16th Epoch, 23220th Step, learning rate = 0.007644650969299353 - Loss: 0.4087294042110443, aux loss1: 1.013833999633789, 
		 aux loss2: 0.5719128847122192, total loss: 0.9416447877883911
16th Epoch, 23225th Step, learning rate = 0.0076441358214512 - Loss: 0.3193739652633667, aux loss1: 0.8338308334350586, 
		 aux loss2: 0.4379117786884308, total loss: 0.7446879148483276
16th Epoch, 23230th Step, learning rate = 0.007643620669745633 - Loss: 0.29912522435188293, aux loss1: 0.8159884214401245, 
		 aux loss2: 0.40403538942337036, total loss: 0.7055359482765198
16th Epoch, 23235th Step, learning rate = 0.007643105514182335 - Loss: 0.39934834837913513, aux loss1: 0.9293853640556335, 
		 aux loss2: 0.5332489013671875, total loss: 0.891463577747345
16th Epoch, 23240th Step, learning rate = 0.00764259035476099 - Loss: 0.27323994040489197, aux loss1: 0.6636403203010559, 
		 aux loss2: 0.36594271659851074, total loss: 0.618709146976471
16th Epoch, 23245th Step, learning rate = 0.007642075191481278 - Loss: 0.4297652840614319, aux loss1: 0.9482499361038208, 
		 aux loss2: 0.5648688077926636, total loss: 0.9401878118515015
16th Epoch, 23250th Step, learning rate = 0.007641560024342881 - Loss: 0.37431442737579346, aux loss1: 0.8866722583770752, 
		 aux loss2: 0.48841238021850586, total loss: 0.8356810808181763
16th Epoch, 23255th Step, learning rate = 0.007641044853345483 - Loss: 0.3034357726573944, aux loss1: 0.8437576293945312, 
		 aux loss2: 0.4141973555088043, total loss: 0.722241997718811
16th Epoch, 23260th Step, learning rate = 0.007640529678488764 - Loss: 0.3398049473762512, aux loss1: 0.8880486488342285, 
		 aux loss2: 0.467600017786026, total loss: 0.7932595610618591
16th Epoch, 23265th Step, learning rate = 0.007640014499772407 - Loss: 0.3682328462600708, aux loss1: 1.0846941471099854, 
		 aux loss2: 0.5096952319145203, total loss: 0.8975191712379456
16th Epoch, 23270th Step, learning rate = 0.007639499317196096 - Loss: 0.3737500011920929, aux loss1: 0.8272826671600342, 
		 aux loss2: 0.48807018995285034, total loss: 0.8171629309654236
16th Epoch, 23275th Step, learning rate = 0.007638984130759508 - Loss: 0.4186129868030548, aux loss1: 0.9098352193832397, 
		 aux loss2: 0.5395618677139282, total loss: 0.9073883295059204
16th Epoch, 23280th Step, learning rate = 0.007638468940462328 - Loss: 0.49106624722480774, aux loss1: 1.0609116554260254, 
		 aux loss2: 0.6813684701919556, total loss: 1.081887125968933
16th Epoch, 23285th Step, learning rate = 0.0076379537463042374 - Loss: 0.34138089418411255, aux loss1: 0.7899936437606812, 
		 aux loss2: 0.4270944595336914, total loss: 0.7492167949676514
16th Epoch, 23290th Step, learning rate = 0.007637438548284915 - Loss: 0.44955965876579285, aux loss1: 0.9082295894622803, 
		 aux loss2: 0.5262857675552368, total loss: 0.9325428605079651
16th Epoch, 23295th Step, learning rate = 0.007636923346404048 - Loss: 0.340863436460495, aux loss1: 0.8117987513542175, 
		 aux loss2: 0.4303073585033417, total loss: 0.756525993347168
16th Epoch, 23300th Step, learning rate = 0.007636408140661314 - Loss: 0.3862176537513733, aux loss1: 0.9494118094444275, 
		 aux loss2: 0.5340417623519897, total loss: 0.8846579790115356
<23300th step>
*************************** Test ***************************
time:3m 16s, 23300th Step, Loss: 0.5255937576293945, Mean IoU = 44.930%
************************************************************
16th Epoch, 23305th Step, learning rate = 0.007635892931056396 - Loss: 0.32748445868492126, aux loss1: 0.7762492299079895, 
		 aux loss2: 0.42603203654289246, total loss: 0.730772078037262
16th Epoch, 23310th Step, learning rate = 0.007635377717588975 - Loss: 0.40639829635620117, aux loss1: 0.8834860920906067, 
		 aux loss2: 0.5359472036361694, total loss: 0.8858230710029602
16th Epoch, 23315th Step, learning rate = 0.007634862500258732 - Loss: 0.35046103596687317, aux loss1: 0.9526735544204712, 
		 aux loss2: 0.49464887380599976, total loss: 0.8341226577758789
16th Epoch, 23320th Step, learning rate = 0.00763434727906535 - Loss: 0.32512614130973816, aux loss1: 0.8938745856285095, 
		 aux loss2: 0.44281071424484253, total loss: 0.770412802696228
16th Epoch, 23325th Step, learning rate = 0.00763383205400851 - Loss: 0.2760581970214844, aux loss1: 0.88801109790802, 
		 aux loss2: 0.42938175797462463, total loss: 0.7142142057418823
16th Epoch, 23330th Step, learning rate = 0.007633316825087891 - Loss: 0.2861749529838562, aux loss1: 0.745313286781311, 
		 aux loss2: 0.38254544138908386, total loss: 0.662787139415741
16th Epoch, 23335th Step, learning rate = 0.007632801592303176 - Loss: 0.21929524838924408, aux loss1: 0.7105041742324829, 
		 aux loss2: 0.3244675397872925, total loss: 0.5622335076332092
16th Epoch, 23340th Step, learning rate = 0.007632286355654046 - Loss: 0.319897323846817, aux loss1: 0.8116370439529419, 
		 aux loss2: 0.4359389543533325, total loss: 0.7377640604972839
16th Epoch, 23345th Step, learning rate = 0.007631771115140181 - Loss: 0.38356322050094604, aux loss1: 0.9409977793693542, 
		 aux loss2: 0.5278356671333313, total loss: 0.8769968152046204
16th Epoch, 23350th Step, learning rate = 0.007631255870761266 - Loss: 0.4417065680027008, aux loss1: 1.0091590881347656, 
		 aux loss2: 0.6209894418716431, total loss: 0.9928500652313232
16th Epoch, 23355th Step, learning rate = 0.007630740622516978 - Loss: 0.33284568786621094, aux loss1: 0.826370120048523, 
		 aux loss2: 0.4545886814594269, total loss: 0.7625921964645386
16th Epoch, 23360th Step, learning rate = 0.007630225370406999 - Loss: 0.2847546637058258, aux loss1: 0.9110437631607056, 
		 aux loss2: 0.4333893656730652, total loss: 0.731423556804657
16th Epoch, 23365th Step, learning rate = 0.007629710114431011 - Loss: 0.37058359384536743, aux loss1: 0.8680708408355713, 
		 aux loss2: 0.485076367855072, total loss: 0.8250354528427124
16th Epoch, 23370th Step, learning rate = 0.007629194854588694 - Loss: 0.38118216395378113, aux loss1: 0.9222956895828247, 
		 aux loss2: 0.5248352885246277, total loss: 0.867805004119873
16th Epoch, 23375th Step, learning rate = 0.007628679590879728 - Loss: 0.3166171908378601, aux loss1: 0.7720273733139038, 
		 aux loss2: 0.43044567108154297, total loss: 0.7204036712646484
16th Epoch, 23380th Step, learning rate = 0.007628164323303797 - Loss: 0.3576936721801758, aux loss1: 0.9048556685447693, 
		 aux loss2: 0.5069161653518677, total loss: 0.831916868686676
16th Epoch, 23385th Step, learning rate = 0.007627649051860578 - Loss: 0.4198776185512543, aux loss1: 0.9168756008148193, 
		 aux loss2: 0.5598630905151367, total loss: 0.9188855886459351
16th Epoch, 23390th Step, learning rate = 0.007627133776549753 - Loss: 0.44352987408638, aux loss1: 0.9451682567596436, 
		 aux loss2: 0.5686741471290588, total loss: 0.95455002784729
16th Epoch, 23395th Step, learning rate = 0.007626618497371004 - Loss: 0.2924726605415344, aux loss1: 0.7300679683685303, 
		 aux loss2: 0.39382898807525635, total loss: 0.6690247058868408
16th Epoch, 23400th Step, learning rate = 0.007626103214324009 - Loss: 0.36865076422691345, aux loss1: 0.8659557700157166, 
		 aux loss2: 0.48852142691612244, total loss: 0.8238461017608643
<23400th step>
*************************** Test ***************************
time:3m 19s, 23400th Step, Loss: 0.5181005001068115, Mean IoU = 44.882%
************************************************************
16th Epoch, 23405th Step, learning rate = 0.007625587927408452 - Loss: 0.281904011964798, aux loss1: 0.7344062328338623, 
		 aux loss2: 0.37732550501823425, total loss: 0.6531561017036438
16th Epoch, 23410th Step, learning rate = 0.0076250726366240106 - Loss: 0.24063369631767273, aux loss1: 0.6091538667678833, 
		 aux loss2: 0.31236112117767334, total loss: 0.5483243465423584
16th Epoch, 23415th Step, learning rate = 0.007624557341970365 - Loss: 0.3355621099472046, aux loss1: 0.8191402554512024, 
		 aux loss2: 0.4514305293560028, total loss: 0.7618764042854309
16th Epoch, 23420th Step, learning rate = 0.007624042043447198 - Loss: 0.27218809723854065, aux loss1: 0.7093825936317444, 
		 aux loss2: 0.39694929122924805, total loss: 0.6437826156616211
16th Epoch, 23425th Step, learning rate = 0.007623526741054189 - Loss: 0.3143555223941803, aux loss1: 0.767072319984436, 
		 aux loss2: 0.40666916966438293, total loss: 0.7071449160575867
16th Epoch, 23430th Step, learning rate = 0.007623011434791017 - Loss: 0.32009920477867126, aux loss1: 0.8535477519035339, 
		 aux loss2: 0.4517122507095337, total loss: 0.7568484544754028
16th Epoch, 23435th Step, learning rate = 0.007622496124657365 - Loss: 0.42469775676727295, aux loss1: 1.0022368431091309, 
		 aux loss2: 0.6192232370376587, total loss: 0.9730581641197205
17th Epoch, 23440th Step, learning rate = 0.00762198081065291 - Loss: 0.3234691619873047, aux loss1: 0.82554030418396, 
		 aux loss2: 0.44816863536834717, total loss: 0.7503986954689026
17th Epoch, 23445th Step, learning rate = 0.007621465492777333 - Loss: 0.3056384027004242, aux loss1: 0.7814258933067322, 
		 aux loss2: 0.38866108655929565, total loss: 0.6955306529998779
17th Epoch, 23450th Step, learning rate = 0.007620950171030316 - Loss: 0.3160114288330078, aux loss1: 0.8903334140777588, 
		 aux loss2: 0.43983185291290283, total loss: 0.7590442299842834
17th Epoch, 23455th Step, learning rate = 0.007620434845411538 - Loss: 0.36882132291793823, aux loss1: 1.0018616914749146, 
		 aux loss2: 0.5351064205169678, total loss: 0.8834223747253418
17th Epoch, 23460th Step, learning rate = 0.007619919515920677 - Loss: 0.2559029161930084, aux loss1: 0.6271308660507202, 
		 aux loss2: 0.3423939347267151, total loss: 0.5809997916221619
17th Epoch, 23465th Step, learning rate = 0.007619404182557417 - Loss: 0.41768431663513184, aux loss1: 0.938724935054779, 
		 aux loss2: 0.5809057354927063, total loss: 0.9316641092300415
17th Epoch, 23470th Step, learning rate = 0.0076188888453214325 - Loss: 0.3466251790523529, aux loss1: 0.8269232511520386, 
		 aux loss2: 0.4764935374259949, total loss: 0.7852995991706848
17th Epoch, 23475th Step, learning rate = 0.007618373504212409 - Loss: 0.3314096927642822, aux loss1: 0.7321581840515137, 
		 aux loss2: 0.4476016163825989, total loss: 0.7300978302955627
17th Epoch, 23480th Step, learning rate = 0.007617858159230022 - Loss: 0.3083575665950775, aux loss1: 0.7722223401069641, 
		 aux loss2: 0.41178351640701294, total loss: 0.704737663269043
17th Epoch, 23485th Step, learning rate = 0.007617342810373953 - Loss: 0.32802319526672363, aux loss1: 0.858922004699707, 
		 aux loss2: 0.44995418190956116, total loss: 0.7656815052032471
17th Epoch, 23490th Step, learning rate = 0.007616827457643883 - Loss: 0.4523654878139496, aux loss1: 0.915655255317688, 
		 aux loss2: 0.5652118921279907, total loss: 0.9531468749046326
17th Epoch, 23495th Step, learning rate = 0.00761631210103949 - Loss: 0.3142740726470947, aux loss1: 0.7381283044815063, 
		 aux loss2: 0.4218723177909851, total loss: 0.7044615149497986
17th Epoch, 23500th Step, learning rate = 0.007615796740560453 - Loss: 0.37529462575912476, aux loss1: 0.8314131498336792, 
		 aux loss2: 0.4825271964073181, total loss: 0.8177294135093689
<23500th step>
*************************** Test ***************************
time:3m 18s, 23500th Step, Loss: 0.5421348810195923, Mean IoU = 43.544%
************************************************************
17th Epoch, 23505th Step, learning rate = 0.007615281376206452 - Loss: 0.3361389636993408, aux loss1: 0.837958574295044, 
		 aux loss2: 0.4577663838863373, total loss: 0.7706331014633179
17th Epoch, 23510th Step, learning rate = 0.007614766007977168 - Loss: 0.3664117157459259, aux loss1: 0.9783040881156921, 
		 aux loss2: 0.5554726123809814, total loss: 0.8820919990539551
17th Epoch, 23515th Step, learning rate = 0.007614250635872277 - Loss: 0.4120911955833435, aux loss1: 0.8921377658843994, 
		 aux loss2: 0.5539558529853821, total loss: 0.901314914226532
17th Epoch, 23520th Step, learning rate = 0.007613735259891463 - Loss: 0.4419068396091461, aux loss1: 0.9719310998916626, 
		 aux loss2: 0.5655397772789001, total loss: 0.9597020745277405
17th Epoch, 23525th Step, learning rate = 0.007613219880034402 - Loss: 0.39595404267311096, aux loss1: 0.881658673286438, 
		 aux loss2: 0.5143594741821289, total loss: 0.8661954402923584
17th Epoch, 23530th Step, learning rate = 0.007612704496300775 - Loss: 0.35124489665031433, aux loss1: 0.8556487560272217, 
		 aux loss2: 0.4716532826423645, total loss: 0.796600878238678
17th Epoch, 23535th Step, learning rate = 0.007612189108690259 - Loss: 0.3053743243217468, aux loss1: 0.7806695699691772, 
		 aux loss2: 0.40459537506103516, total loss: 0.7014133930206299
17th Epoch, 23540th Step, learning rate = 0.007611673717202536 - Loss: 0.33211755752563477, aux loss1: 0.7781636714935303, 
		 aux loss2: 0.4392244815826416, total loss: 0.7412564754486084
17th Epoch, 23545th Step, learning rate = 0.007611158321837284 - Loss: 0.3078988492488861, aux loss1: 0.8891653418540955, 
		 aux loss2: 0.45605090260505676, total loss: 0.7570688724517822
17th Epoch, 23550th Step, learning rate = 0.007610642922594181 - Loss: 0.37669089436531067, aux loss1: 1.043686032295227, 
		 aux loss2: 0.5651206970214844, total loss: 0.9158449769020081
17th Epoch, 23555th Step, learning rate = 0.007610127519472907 - Loss: 0.3602936863899231, aux loss1: 0.9536356925964355, 
		 aux loss2: 0.4849262237548828, total loss: 0.8403549194335938
17th Epoch, 23560th Step, learning rate = 0.007609612112473142 - Loss: 0.31282761693000793, aux loss1: 0.7486109137535095, 
		 aux loss2: 0.4353795051574707, total loss: 0.7115627527236938
17th Epoch, 23565th Step, learning rate = 0.007609096701594562 - Loss: 0.39824485778808594, aux loss1: 0.9117305874824524, 
		 aux loss2: 0.5186870694160461, total loss: 0.8792388439178467
17th Epoch, 23570th Step, learning rate = 0.007608581286836849 - Loss: 0.32473334670066833, aux loss1: 0.7994206547737122, 
		 aux loss2: 0.4495547115802765, total loss: 0.7443814873695374
17th Epoch, 23575th Step, learning rate = 0.00760806586819968 - Loss: 0.3588833808898926, aux loss1: 0.8123268485069275, 
		 aux loss2: 0.4583304524421692, total loss: 0.7859136462211609
17th Epoch, 23580th Step, learning rate = 0.007607550445682734 - Loss: 0.35207149386405945, aux loss1: 0.8637842535972595, 
		 aux loss2: 0.4913123548030853, total loss: 0.8077317476272583
17th Epoch, 23585th Step, learning rate = 0.007607035019285691 - Loss: 0.34202584624290466, aux loss1: 0.8348440527915955, 
		 aux loss2: 0.4752677381038666, total loss: 0.7825862169265747
17th Epoch, 23590th Step, learning rate = 0.007606519589008228 - Loss: 0.291164368391037, aux loss1: 0.7482893466949463, 
		 aux loss2: 0.37672942876815796, total loss: 0.6663429737091064
17th Epoch, 23595th Step, learning rate = 0.007606004154850022 - Loss: 0.3025382459163666, aux loss1: 0.8354130387306213, 
		 aux loss2: 0.4501069486141205, total loss: 0.7332049608230591
17th Epoch, 23600th Step, learning rate = 0.007605488716810758 - Loss: 0.5472632050514221, aux loss1: 1.1471127271652222, 
		 aux loss2: 0.6807120442390442, total loss: 1.1636818647384644
<23600th step>
*************************** Test ***************************
time:3m 19s, 23600th Step, Loss: 0.5512087941169739, Mean IoU = 45.103%
************************************************************
17th Epoch, 23605th Step, learning rate = 0.007604973274890108 - Loss: 0.2998673915863037, aux loss1: 0.7592051029205322, 
		 aux loss2: 0.3871869444847107, total loss: 0.6825037002563477
17th Epoch, 23610th Step, learning rate = 0.007604457829087753 - Loss: 0.37017738819122314, aux loss1: 0.9183909296989441, 
		 aux loss2: 0.510664701461792, total loss: 0.8499605655670166
17th Epoch, 23615th Step, learning rate = 0.007603942379403372 - Loss: 0.3669130504131317, aux loss1: 0.8532645106315613, 
		 aux loss2: 0.48396730422973633, total loss: 0.8164793252944946
17th Epoch, 23620th Step, learning rate = 0.0076034269258366425 - Loss: 0.35750454664230347, aux loss1: 0.839952290058136, 
		 aux loss2: 0.47277334332466125, total loss: 0.7985996007919312
17th Epoch, 23625th Step, learning rate = 0.007602911468387243 - Loss: 0.42767688632011414, aux loss1: 0.9803586006164551, 
		 aux loss2: 0.5788674354553223, total loss: 0.953331470489502
17th Epoch, 23630th Step, learning rate = 0.007602396007054852 - Loss: 0.3176605999469757, aux loss1: 0.6994297504425049, 
		 aux loss2: 0.3969431221485138, total loss: 0.6862667798995972
17th Epoch, 23635th Step, learning rate = 0.0076018805418391466 - Loss: 0.42001408338546753, aux loss1: 1.0454273223876953, 
		 aux loss2: 0.6129441857337952, total loss: 0.9788199663162231
17th Epoch, 23640th Step, learning rate = 0.007601365072739807 - Loss: 0.3716505765914917, aux loss1: 0.8713067173957825, 
		 aux loss2: 0.5075843930244446, total loss: 0.8360763192176819
17th Epoch, 23645th Step, learning rate = 0.00760084959975651 - Loss: 0.3580476641654968, aux loss1: 0.9309984445571899, 
		 aux loss2: 0.5224764943122864, total loss: 0.8463377952575684
17th Epoch, 23650th Step, learning rate = 0.007600334122888931 - Loss: 0.304752916097641, aux loss1: 0.7818922996520996, 
		 aux loss2: 0.41538724303245544, total loss: 0.7054755091667175
17th Epoch, 23655th Step, learning rate = 0.007599818642136755 - Loss: 0.2672375738620758, aux loss1: 0.7506031394004822, 
		 aux loss2: 0.36755526065826416, total loss: 0.639440655708313
17th Epoch, 23660th Step, learning rate = 0.007599303157499652 - Loss: 0.36660337448120117, aux loss1: 0.8483225107192993, 
		 aux loss2: 0.4627605676651001, total loss: 0.8062043786048889
17th Epoch, 23665th Step, learning rate = 0.007598787668977305 - Loss: 0.3836664855480194, aux loss1: 0.9913370609283447, 
		 aux loss2: 0.5485880374908447, total loss: 0.9005028009414673
17th Epoch, 23670th Step, learning rate = 0.007598272176569392 - Loss: 0.3089478611946106, aux loss1: 0.7620362043380737, 
		 aux loss2: 0.4385252296924591, total loss: 0.7129688262939453
17th Epoch, 23675th Step, learning rate = 0.007597756680275588 - Loss: 0.4429497718811035, aux loss1: 1.0938940048217773, 
		 aux loss2: 0.6277228593826294, total loss: 1.0222071409225464
17th Epoch, 23680th Step, learning rate = 0.007597241180095572 - Loss: 0.5784960389137268, aux loss1: 1.2319811582565308, 
		 aux loss2: 0.7720507383346558, total loss: 1.256910800933838
17th Epoch, 23685th Step, learning rate = 0.007596725676029023 - Loss: 0.3372252583503723, aux loss1: 0.9134452939033508, 
		 aux loss2: 0.49811846017837524, total loss: 0.8105062246322632
17th Epoch, 23690th Step, learning rate = 0.007596210168075616 - Loss: 0.5272310376167297, aux loss1: 0.9930782318115234, 
		 aux loss2: 0.6286664009094238, total loss: 1.0766210556030273
17th Epoch, 23695th Step, learning rate = 0.007595694656235031 - Loss: 0.31088224053382874, aux loss1: 0.9270044565200806, 
		 aux loss2: 0.4810580909252167, total loss: 0.781406819820404
17th Epoch, 23700th Step, learning rate = 0.007595179140506943 - Loss: 0.2915576994419098, aux loss1: 0.727925717830658, 
		 aux loss2: 0.38178393244743347, total loss: 0.6626490354537964
<23700th step>
*************************** Test ***************************
time:3m 18s, 23700th Step, Loss: 0.5584937334060669, Mean IoU = 44.574%
************************************************************
17th Epoch, 23705th Step, learning rate = 0.007594663620891033 - Loss: 0.3678610324859619, aux loss1: 0.9402381181716919, 
		 aux loss2: 0.5282981395721436, total loss: 0.8612517714500427
17th Epoch, 23710th Step, learning rate = 0.007594148097386976 - Loss: 0.331262469291687, aux loss1: 0.8479872345924377, 
		 aux loss2: 0.46081626415252686, total loss: 0.7699851989746094
17th Epoch, 23715th Step, learning rate = 0.0075936325699944495 - Loss: 0.38286682963371277, aux loss1: 0.9155629873275757, 
		 aux loss2: 0.5258609652519226, total loss: 0.86788010597229
17th Epoch, 23720th Step, learning rate = 0.007593117038713131 - Loss: 0.2618400454521179, aux loss1: 0.7469276785850525, 
		 aux loss2: 0.3698108494281769, total loss: 0.6338427066802979
17th Epoch, 23725th Step, learning rate = 0.0075926015035427 - Loss: 0.41472920775413513, aux loss1: 0.9638895988464355, 
		 aux loss2: 0.5873038172721863, total loss: 0.9388176202774048
17th Epoch, 23730th Step, learning rate = 0.00759208596448283 - Loss: 0.43300265073776245, aux loss1: 1.251679539680481, 
		 aux loss2: 0.6628100275993347, total loss: 1.0736305713653564
17th Epoch, 23735th Step, learning rate = 0.0075915704215332004 - Loss: 0.3267427384853363, aux loss1: 0.8535505533218384, 
		 aux loss2: 0.4553352892398834, total loss: 0.7649420499801636
17th Epoch, 23740th Step, learning rate = 0.0075910548746934885 - Loss: 0.3125286400318146, aux loss1: 0.8288777470588684, 
		 aux loss2: 0.44451871514320374, total loss: 0.7389994859695435
17th Epoch, 23745th Step, learning rate = 0.00759053932396337 - Loss: 0.4142299294471741, aux loss1: 0.9852848649024963, 
		 aux loss2: 0.5783378481864929, total loss: 0.9411505460739136
17th Epoch, 23750th Step, learning rate = 0.007590023769342523 - Loss: 0.35172927379608154, aux loss1: 0.8417373299598694, 
		 aux loss2: 0.46116459369659424, total loss: 0.7887163162231445
17th Epoch, 23755th Step, learning rate = 0.0075895082108306255 - Loss: 0.44107502698898315, aux loss1: 0.9543981552124023, 
		 aux loss2: 0.590936005115509, total loss: 0.9637688398361206
17th Epoch, 23760th Step, learning rate = 0.007588992648427353 - Loss: 0.3619982898235321, aux loss1: 0.8505406975746155, 
		 aux loss2: 0.4819321632385254, total loss: 0.8099333643913269
17th Epoch, 23765th Step, learning rate = 0.007588477082132381 - Loss: 0.36828577518463135, aux loss1: 0.7462084293365479, 
		 aux loss2: 0.4472675919532776, total loss: 0.7710553407669067
17th Epoch, 23770th Step, learning rate = 0.00758796151194539 - Loss: 0.45781898498535156, aux loss1: 0.8570388555526733, 
		 aux loss2: 0.5642200112342834, total loss: 0.940618634223938
17th Epoch, 23775th Step, learning rate = 0.007587445937866053 - Loss: 0.4557057321071625, aux loss1: 1.093260645866394, 
		 aux loss2: 0.6064901351928711, total loss: 1.0262799263000488
17th Epoch, 23780th Step, learning rate = 0.00758693035989405 - Loss: 0.3089035153388977, aux loss1: 0.7913609743118286, 
		 aux loss2: 0.424807608127594, total loss: 0.7162348628044128
17th Epoch, 23785th Step, learning rate = 0.007586414778029055 - Loss: 0.3785400986671448, aux loss1: 0.9138122200965881, 
		 aux loss2: 0.48491159081459045, total loss: 0.8466483950614929
17th Epoch, 23790th Step, learning rate = 0.007585899192270746 - Loss: 0.2867576777935028, aux loss1: 0.864967942237854, 
		 aux loss2: 0.4349020719528198, total loss: 0.7202088832855225
17th Epoch, 23795th Step, learning rate = 0.007585383602618801 - Loss: 0.4178057312965393, aux loss1: 0.9539566040039062, 
		 aux loss2: 0.55888432264328, total loss: 0.9275464415550232
17th Epoch, 23800th Step, learning rate = 0.007584868009072892 - Loss: 0.3271147906780243, aux loss1: 0.8068600296974182, 
		 aux loss2: 0.43531930446624756, total loss: 0.7433005571365356
<23800th step>
*************************** Test ***************************
time:3m 17s, 23800th Step, Loss: 0.5605371594429016, Mean IoU = 43.416%
************************************************************
17th Epoch, 23805th Step, learning rate = 0.0075843524116327 - Loss: 0.3382395803928375, aux loss1: 0.7530131340026855, 
		 aux loss2: 0.42006731033325195, total loss: 0.7321704626083374
18th Epoch, 23810th Step, learning rate = 0.007583836810297902 - Loss: 0.4263842701911926, aux loss1: 1.009463906288147, 
		 aux loss2: 0.5853511691093445, total loss: 0.9633639454841614
18th Epoch, 23815th Step, learning rate = 0.007583321205068169 - Loss: 0.3495217263698578, aux loss1: 0.9384880065917969, 
		 aux loss2: 0.48624423146247864, total loss: 0.8255658149719238
18th Epoch, 23820th Step, learning rate = 0.007582805595943181 - Loss: 0.34714391827583313, aux loss1: 0.801041841506958, 
		 aux loss2: 0.4439331591129303, total loss: 0.7650297284126282
18th Epoch, 23825th Step, learning rate = 0.0075822899829226156 - Loss: 0.34500518441200256, aux loss1: 0.8943802714347839, 
		 aux loss2: 0.44493481516838074, total loss: 0.791293203830719
18th Epoch, 23830th Step, learning rate = 0.007581774366006144 - Loss: 0.3932647407054901, aux loss1: 0.9433838725090027, 
		 aux loss2: 0.5407332181930542, total loss: 0.8925731778144836
18th Epoch, 23835th Step, learning rate = 0.007581258745193448 - Loss: 0.401366263628006, aux loss1: 1.0134644508361816, 
		 aux loss2: 0.5565152168273926, total loss: 0.9280116558074951
18th Epoch, 23840th Step, learning rate = 0.007580743120484201 - Loss: 0.27042311429977417, aux loss1: 0.7343358993530273, 
		 aux loss2: 0.3695611357688904, total loss: 0.6385483741760254
18th Epoch, 23845th Step, learning rate = 0.007580227491878079 - Loss: 0.3414885103702545, aux loss1: 0.8922342658042908, 
		 aux loss2: 0.4809011220932007, total loss: 0.8015192747116089
18th Epoch, 23850th Step, learning rate = 0.007579711859374759 - Loss: 0.31513628363609314, aux loss1: 0.7321879267692566, 
		 aux loss2: 0.42034950852394104, total loss: 0.7029324769973755
18th Epoch, 23855th Step, learning rate = 0.007579196222973915 - Loss: 0.3621004521846771, aux loss1: 0.8811722993850708, 
		 aux loss2: 0.48712316155433655, total loss: 0.8213014006614685
18th Epoch, 23860th Step, learning rate = 0.007578680582675226 - Loss: 0.5904214382171631, aux loss1: 1.355389952659607, 
		 aux loss2: 0.8953739404678345, total loss: 1.3551881313323975
18th Epoch, 23865th Step, learning rate = 0.007578164938478365 - Loss: 0.3015851676464081, aux loss1: 0.7581391930580139, 
		 aux loss2: 0.42014366388320923, total loss: 0.6970844268798828
18th Epoch, 23870th Step, learning rate = 0.00757764929038301 - Loss: 0.32590770721435547, aux loss1: 0.8466697335243225, 
		 aux loss2: 0.4508730471134186, total loss: 0.7602578401565552
18th Epoch, 23875th Step, learning rate = 0.007577133638388834 - Loss: 0.3307720422744751, aux loss1: 0.7937036752700806, 
		 aux loss2: 0.44692263007164, total loss: 0.7476522326469421
18th Epoch, 23880th Step, learning rate = 0.007576617982495516 - Loss: 0.4326159358024597, aux loss1: 1.0445010662078857, 
		 aux loss2: 0.6165518164634705, total loss: 0.9925869703292847
18th Epoch, 23885th Step, learning rate = 0.007576102322702728 - Loss: 0.303458034992218, aux loss1: 0.7982805967330933, 
		 aux loss2: 0.4384177029132843, total loss: 0.7183092832565308
18th Epoch, 23890th Step, learning rate = 0.00757558665901015 - Loss: 0.3470544219017029, aux loss1: 0.9135702848434448, 
		 aux loss2: 0.48872110247612, total loss: 0.8166139721870422
18th Epoch, 23895th Step, learning rate = 0.007575070991417454 - Loss: 0.4830658733844757, aux loss1: 1.0291094779968262, 
		 aux loss2: 0.6628098487854004, total loss: 1.0569226741790771
18th Epoch, 23900th Step, learning rate = 0.0075745553199243155 - Loss: 0.4736301004886627, aux loss1: 1.1776243448257446, 
		 aux loss2: 0.6607000827789307, total loss: 1.0911974906921387
<23900th step>
*************************** Test ***************************
time:3m 17s, 23900th Step, Loss: 0.5445521473884583, Mean IoU = 43.963%
************************************************************
18th Epoch, 23905th Step, learning rate = 0.007574039644530414 - Loss: 0.30116698145866394, aux loss1: 0.793563187122345, 
		 aux loss2: 0.4141841530799866, total loss: 0.70490962266922
18th Epoch, 23910th Step, learning rate = 0.007573523965235419 - Loss: 0.37139904499053955, aux loss1: 0.8656452894210815, 
		 aux loss2: 0.4802955389022827, total loss: 0.8232108950614929
18th Epoch, 23915th Step, learning rate = 0.007573008282039011 - Loss: 0.3293546438217163, aux loss1: 0.7853566408157349, 
		 aux loss2: 0.43158072233200073, total loss: 0.737593948841095
18th Epoch, 23920th Step, learning rate = 0.007572492594940863 - Loss: 0.29817357659339905, aux loss1: 0.784134566783905, 
		 aux loss2: 0.416223406791687, total loss: 0.6999033093452454
18th Epoch, 23925th Step, learning rate = 0.007571976903940649 - Loss: 0.45074018836021423, aux loss1: 1.0867801904678345, 
		 aux loss2: 0.616690456867218, total loss: 1.023450493812561
18th Epoch, 23930th Step, learning rate = 0.007571461209038047 - Loss: 0.4185011088848114, aux loss1: 1.036137580871582, 
		 aux loss2: 0.5759178400039673, total loss: 0.9597095251083374
18th Epoch, 23935th Step, learning rate = 0.007570945510232732 - Loss: 0.3514195680618286, aux loss1: 0.8489113450050354, 
		 aux loss2: 0.47966253757476807, total loss: 0.7979580163955688
18th Epoch, 23940th Step, learning rate = 0.007570429807524375 - Loss: 0.5454285740852356, aux loss1: 1.184434175491333, 
		 aux loss2: 0.7406060695648193, total loss: 1.197001338005066
18th Epoch, 23945th Step, learning rate = 0.007569914100912655 - Loss: 0.3660071790218353, aux loss1: 0.9419211745262146, 
		 aux loss2: 0.5391193628311157, total loss: 0.864231288433075
18th Epoch, 23950th Step, learning rate = 0.007569398390397247 - Loss: 0.3257303237915039, aux loss1: 0.8873745203018188, 
		 aux loss2: 0.4685414135456085, total loss: 0.7793592214584351
18th Epoch, 23955th Step, learning rate = 0.007568882675977823 - Loss: 0.37362760305404663, aux loss1: 0.9183571338653564, 
		 aux loss2: 0.4932899475097656, total loss: 0.8464507460594177
18th Epoch, 23960th Step, learning rate = 0.00756836695765406 - Loss: 0.4080629050731659, aux loss1: 0.9965953230857849, 
		 aux loss2: 0.608123242855072, total loss: 0.9502907991409302
18th Epoch, 23965th Step, learning rate = 0.007567851235425633 - Loss: 0.3174101710319519, aux loss1: 0.81464022397995, 
		 aux loss2: 0.4174531400203705, total loss: 0.7287835478782654
18th Epoch, 23970th Step, learning rate = 0.007567335509292216 - Loss: 0.3157207667827606, aux loss1: 0.8214013576507568, 
		 aux loss2: 0.43090617656707764, total loss: 0.7345036268234253
18th Epoch, 23975th Step, learning rate = 0.007566819779253485 - Loss: 0.3285866379737854, aux loss1: 0.9299158453941345, 
		 aux loss2: 0.47781240940093994, total loss: 0.7986863851547241
18th Epoch, 23980th Step, learning rate = 0.007566304045309113 - Loss: 0.3939347565174103, aux loss1: 0.8551567196846008, 
		 aux loss2: 0.500285804271698, total loss: 0.8505961298942566
18th Epoch, 23985th Step, learning rate = 0.007565788307458775 - Loss: 0.3877710998058319, aux loss1: 0.9988099336624146, 
		 aux loss2: 0.5534816384315491, total loss: 0.9088066816329956
18th Epoch, 23990th Step, learning rate = 0.007565272565702147 - Loss: 0.3215264678001404, aux loss1: 0.7885656952857971, 
		 aux loss2: 0.4239529073238373, total loss: 0.7276773452758789
18th Epoch, 23995th Step, learning rate = 0.007564756820038902 - Loss: 0.41226255893707275, aux loss1: 0.9041306376457214, 
		 aux loss2: 0.535016655921936, total loss: 0.8975083827972412
18th Epoch, 24000th Step, learning rate = 0.0075642410704687135 - Loss: 0.31308767199516296, aux loss1: 0.7505212426185608, 
		 aux loss2: 0.42370596528053284, total loss: 0.7077264785766602
<24000th step>
*************************** Test ***************************
time:3m 19s, 24000th Step, Loss: 0.5421826243400574, Mean IoU = 43.440%
************************************************************
18th Epoch, 24005th Step, learning rate = 0.007563725316991259 - Loss: 0.3182121515274048, aux loss1: 0.7949665188789368, 
		 aux loss2: 0.4027882218360901, total loss: 0.7178174257278442
18th Epoch, 24010th Step, learning rate = 0.007563209559606209 - Loss: 0.3375295400619507, aux loss1: 0.7837811708450317, 
		 aux loss2: 0.4449518322944641, total loss: 0.7506446242332458
18th Epoch, 24015th Step, learning rate = 0.007562693798313242 - Loss: 0.30088841915130615, aux loss1: 0.7275667190551758, 
		 aux loss2: 0.399247407913208, total loss: 0.6788573861122131
18th Epoch, 24020th Step, learning rate = 0.00756217803311203 - Loss: 0.3423679769039154, aux loss1: 0.8532076478004456, 
		 aux loss2: 0.4624996483325958, total loss: 0.7833301424980164
18th Epoch, 24025th Step, learning rate = 0.007561662264002246 - Loss: 0.370738685131073, aux loss1: 0.9165565371513367, 
		 aux loss2: 0.5089845657348633, total loss: 0.8492995500564575
18th Epoch, 24030th Step, learning rate = 0.007561146490983567 - Loss: 0.33292070031166077, aux loss1: 0.7149251103401184, 
		 aux loss2: 0.43211209774017334, total loss: 0.7202430367469788
18th Epoch, 24035th Step, learning rate = 0.007560630714055665 - Loss: 0.3802446722984314, aux loss1: 0.9088110327720642, 
		 aux loss2: 0.5192698836326599, total loss: 0.8605959415435791
18th Epoch, 24040th Step, learning rate = 0.007560114933218215 - Loss: 0.35444876551628113, aux loss1: 0.963491678237915, 
		 aux loss2: 0.531127393245697, total loss: 0.8559472560882568
18th Epoch, 24045th Step, learning rate = 0.007559599148470891 - Loss: 0.3581784963607788, aux loss1: 1.0424638986587524, 
		 aux loss2: 0.4832547605037689, total loss: 0.864219605922699
18th Epoch, 24050th Step, learning rate = 0.007559083359813366 - Loss: 0.33367595076560974, aux loss1: 0.8042689561843872, 
		 aux loss2: 0.4521450996398926, total loss: 0.7558146715164185
18th Epoch, 24055th Step, learning rate = 0.0075585675672453145 - Loss: 0.3352115750312805, aux loss1: 0.8094192743301392, 
		 aux loss2: 0.4461950361728668, total loss: 0.756515383720398
18th Epoch, 24060th Step, learning rate = 0.007558051770766412 - Loss: 0.5122008919715881, aux loss1: 0.9987041354179382, 
		 aux loss2: 0.6672760844230652, total loss: 1.078722596168518
18th Epoch, 24065th Step, learning rate = 0.007557535970376328 - Loss: 0.35942816734313965, aux loss1: 0.8339839577674866, 
		 aux loss2: 0.48355016112327576, total loss: 0.8030434250831604
18th Epoch, 24070th Step, learning rate = 0.007557020166074742 - Loss: 0.4054718315601349, aux loss1: 0.9115603566169739, 
		 aux loss2: 0.5366377234458923, total loss: 0.8935950398445129
18th Epoch, 24075th Step, learning rate = 0.007556504357861323 - Loss: 0.3621674180030823, aux loss1: 0.9239975810050964, 
		 aux loss2: 0.4977095425128937, total loss: 0.83845055103302
18th Epoch, 24080th Step, learning rate = 0.007555988545735746 - Loss: 0.25661909580230713, aux loss1: 0.7753315567970276, 
		 aux loss2: 0.352019339799881, total loss: 0.6300263404846191
18th Epoch, 24085th Step, learning rate = 0.007555472729697686 - Loss: 0.3528495132923126, aux loss1: 0.8940434455871582, 
		 aux loss2: 0.5021152496337891, total loss: 0.8219085931777954
18th Epoch, 24090th Step, learning rate = 0.007554956909746814 - Loss: 0.40781188011169434, aux loss1: 0.8413528800010681, 
		 aux loss2: 0.514504075050354, total loss: 0.8660193681716919
18th Epoch, 24095th Step, learning rate = 0.007554441085882806 - Loss: 0.35899618268013, aux loss1: 0.9417417049407959, 
		 aux loss2: 0.4883773624897003, total loss: 0.8368696570396423
18th Epoch, 24100th Step, learning rate = 0.007553925258105334 - Loss: 0.3280372619628906, aux loss1: 0.884125292301178, 
		 aux loss2: 0.4619678556919098, total loss: 0.7780619859695435
<24100th step>
*************************** Test ***************************
time:3m 17s, 24100th Step, Loss: 0.5541900992393494, Mean IoU = 43.186%
************************************************************
18th Epoch, 24105th Step, learning rate = 0.007553409426414072 - Loss: 0.41926607489585876, aux loss1: 0.8728320002555847, 
		 aux loss2: 0.5235347747802734, total loss: 0.8905296325683594
18th Epoch, 24110th Step, learning rate = 0.0075528935908086925 - Loss: 0.27698060870170593, aux loss1: 0.7401348948478699, 
		 aux loss2: 0.3684532940387726, total loss: 0.6464024186134338
18th Epoch, 24115th Step, learning rate = 0.00755237775128887 - Loss: 0.34716036915779114, aux loss1: 0.7928944230079651, 
		 aux loss2: 0.45771950483322144, total loss: 0.7681165337562561
18th Epoch, 24120th Step, learning rate = 0.007551861907854276 - Loss: 0.3930976986885071, aux loss1: 0.8326153755187988, 
		 aux loss2: 0.49853935837745667, total loss: 0.8422980904579163
18th Epoch, 24125th Step, learning rate = 0.007551346060504584 - Loss: 0.4049096703529358, aux loss1: 0.8574953079223633, 
		 aux loss2: 0.5319767594337463, total loss: 0.8749489784240723
18th Epoch, 24130th Step, learning rate = 0.007550830209239471 - Loss: 0.3581898808479309, aux loss1: 0.8259802460670471, 
		 aux loss2: 0.4694555699825287, total loss: 0.79376620054245
18th Epoch, 24135th Step, learning rate = 0.007550314354058604 - Loss: 0.3218315541744232, aux loss1: 0.8880199193954468, 
		 aux loss2: 0.44869059324264526, total loss: 0.7677137851715088
18th Epoch, 24140th Step, learning rate = 0.007549798494961659 - Loss: 0.4398384392261505, aux loss1: 0.9804217219352722, 
		 aux loss2: 0.5765701532363892, total loss: 0.9645930528640747
18th Epoch, 24145th Step, learning rate = 0.00754928263194831 - Loss: 0.3398517966270447, aux loss1: 0.7592838406562805, 
		 aux loss2: 0.4382439851760864, total loss: 0.7429345846176147
18th Epoch, 24150th Step, learning rate = 0.007548766765018228 - Loss: 0.2758583724498749, aux loss1: 0.6718251705169678, 
		 aux loss2: 0.3608299791812897, total loss: 0.6217379570007324
18th Epoch, 24155th Step, learning rate = 0.007548250894171088 - Loss: 0.5641288757324219, aux loss1: 1.151015281677246, 
		 aux loss2: 0.7670386433601379, total loss: 1.2162489891052246
18th Epoch, 24160th Step, learning rate = 0.0075477350194065596 - Loss: 0.301622211933136, aux loss1: 0.7804772257804871, 
		 aux loss2: 0.39355894923210144, total loss: 0.6931890249252319
18th Epoch, 24165th Step, learning rate = 0.0075472191407243185 - Loss: 0.27721914649009705, aux loss1: 0.7114739418029785, 
		 aux loss2: 0.38016805052757263, total loss: 0.6427285671234131
18th Epoch, 24170th Step, learning rate = 0.007546703258124036 - Loss: 0.31988558173179626, aux loss1: 0.7889726161956787, 
		 aux loss2: 0.4405268728733063, total loss: 0.7327881455421448
18th Epoch, 24175th Step, learning rate = 0.007546187371605384 - Loss: 0.3707551956176758, aux loss1: 0.9168659448623657, 
		 aux loss2: 0.5023526549339294, total loss: 0.846756100654602
19th Epoch, 24180th Step, learning rate = 0.007545671481168037 - Loss: 0.32832080125808716, aux loss1: 0.7327001690864563, 
		 aux loss2: 0.430571585893631, total loss: 0.7203595042228699
19th Epoch, 24185th Step, learning rate = 0.007545155586811667 - Loss: 0.44028836488723755, aux loss1: 0.9712691903114319, 
		 aux loss2: 0.5826853513717651, total loss: 0.9647432565689087
19th Epoch, 24190th Step, learning rate = 0.007544639688535945 - Loss: 0.3242812156677246, aux loss1: 0.8088129758834839, 
		 aux loss2: 0.43188008666038513, total loss: 0.7396771311759949
19th Epoch, 24195th Step, learning rate = 0.007544123786340545 - Loss: 0.4687454402446747, aux loss1: 1.0384228229522705, 
		 aux loss2: 0.6345728039741516, total loss: 1.0341014862060547
19th Epoch, 24200th Step, learning rate = 0.007543607880225141 - Loss: 0.3723810017108917, aux loss1: 0.9475957751274109, 
		 aux loss2: 0.5216025114059448, total loss: 0.865300714969635
<24200th step>
*************************** Test ***************************
time:3m 18s, 24200th Step, Loss: 0.559203028678894, Mean IoU = 43.790%
************************************************************
19th Epoch, 24205th Step, learning rate = 0.007543091970189399 - Loss: 0.4356141686439514, aux loss1: 1.1979488134384155, 
		 aux loss2: 0.6789828538894653, total loss: 1.0665919780731201
19th Epoch, 24210th Step, learning rate = 0.007542576056233 - Loss: 0.43958672881126404, aux loss1: 0.9608137607574463, 
		 aux loss2: 0.587586522102356, total loss: 0.9628654718399048
19th Epoch, 24215th Step, learning rate = 0.007542060138355609 - Loss: 0.29574844241142273, aux loss1: 0.7246171832084656, 
		 aux loss2: 0.38583463430404663, total loss: 0.667467474937439
19th Epoch, 24220th Step, learning rate = 0.007541544216556902 - Loss: 0.3499297797679901, aux loss1: 0.9137622714042664, 
		 aux loss2: 0.49652719497680664, total loss: 0.8226693868637085
19th Epoch, 24225th Step, learning rate = 0.00754102829083655 - Loss: 0.33784836530685425, aux loss1: 0.78263258934021, 
		 aux loss2: 0.4418420195579529, total loss: 0.7493749856948853
19th Epoch, 24230th Step, learning rate = 0.007540512361194225 - Loss: 0.35700780153274536, aux loss1: 0.8680353164672852, 
		 aux loss2: 0.4619916081428528, total loss: 0.802215039730072
19th Epoch, 24235th Step, learning rate = 0.007539996427629599 - Loss: 0.25750288367271423, aux loss1: 0.6745831966400146, 
		 aux loss2: 0.34200039505958557, total loss: 0.5966780185699463
19th Epoch, 24240th Step, learning rate = 0.007539480490142345 - Loss: 0.3139703869819641, aux loss1: 0.8107866048812866, 
		 aux loss2: 0.4191051721572876, total loss: 0.7248484492301941
19th Epoch, 24245th Step, learning rate = 0.007538964548732133 - Loss: 0.30538639426231384, aux loss1: 0.7342563271522522, 
		 aux loss2: 0.4109244644641876, total loss: 0.6900330781936646
19th Epoch, 24250th Step, learning rate = 0.007538448603398636 - Loss: 0.4250006675720215, aux loss1: 0.9880448579788208, 
		 aux loss2: 0.5997238755226135, total loss: 0.9613037109375
19th Epoch, 24255th Step, learning rate = 0.007537932654141527 - Loss: 0.35390347242355347, aux loss1: 0.8400782346725464, 
		 aux loss2: 0.5130460858345032, total loss: 0.8111454248428345
19th Epoch, 24260th Step, learning rate = 0.0075374167009604745 - Loss: 0.3145515024662018, aux loss1: 0.8083018064498901, 
		 aux loss2: 0.42540591955184937, total loss: 0.727204442024231
19th Epoch, 24265th Step, learning rate = 0.007536900743855154 - Loss: 0.35122162103652954, aux loss1: 0.8088126182556152, 
		 aux loss2: 0.48346418142318726, total loss: 0.7872510552406311
19th Epoch, 24270th Step, learning rate = 0.007536384782825235 - Loss: 0.49315008521080017, aux loss1: 0.9434989094734192, 
		 aux loss2: 0.61479651927948, total loss: 1.022118330001831
19th Epoch, 24275th Step, learning rate = 0.007535868817870388 - Loss: 0.3463173806667328, aux loss1: 0.8525009751319885, 
		 aux loss2: 0.4715096652507782, total loss: 0.7906715869903564
19th Epoch, 24280th Step, learning rate = 0.007535352848990289 - Loss: 0.4714175760746002, aux loss1: 1.1121594905853271, 
		 aux loss2: 0.6752060651779175, total loss: 1.0751478672027588
19th Epoch, 24285th Step, learning rate = 0.0075348368761846045 - Loss: 0.30970263481140137, aux loss1: 0.8587160110473633, 
		 aux loss2: 0.4527137875556946, total loss: 0.748403012752533
19th Epoch, 24290th Step, learning rate = 0.0075343208994530075 - Loss: 0.25533556938171387, aux loss1: 0.7108790874481201, 
		 aux loss2: 0.36383959650993347, total loss: 0.6141351461410522
19th Epoch, 24295th Step, learning rate = 0.007533804918795171 - Loss: 0.4346030056476593, aux loss1: 0.9945722222328186, 
		 aux loss2: 0.5827623009681702, total loss: 0.966079592704773
19th Epoch, 24300th Step, learning rate = 0.007533288934210764 - Loss: 0.27559545636177063, aux loss1: 0.702684223651886, 
		 aux loss2: 0.3764250576496124, total loss: 0.6369707584381104
<24300th step>
*************************** Test ***************************
time:3m 17s, 24300th Step, Loss: 0.5444103479385376, Mean IoU = 44.825%
************************************************************
19th Epoch, 24305th Step, learning rate = 0.00753277294569946 - Loss: 0.3223100006580353, aux loss1: 0.7503247261047363, 
		 aux loss2: 0.4159659743309021, total loss: 0.7137938737869263
19th Epoch, 24310th Step, learning rate = 0.00753225695326093 - Loss: 0.2774244546890259, aux loss1: 0.7222115993499756, 
		 aux loss2: 0.35958942770957947, total loss: 0.6379237174987793
19th Epoch, 24315th Step, learning rate = 0.0075317409568948415 - Loss: 0.3164961040019989, aux loss1: 0.7774668335914612, 
		 aux loss2: 0.416729599237442, total loss: 0.7164279818534851
19th Epoch, 24320th Step, learning rate = 0.007531224956600871 - Loss: 0.3437049388885498, aux loss1: 0.8073285818099976, 
		 aux loss2: 0.45656025409698486, total loss: 0.768527626991272
19th Epoch, 24325th Step, learning rate = 0.007530708952378685 - Loss: 0.31459927558898926, aux loss1: 0.8692654967308044, 
		 aux loss2: 0.46524712443351746, total loss: 0.7614777684211731
19th Epoch, 24330th Step, learning rate = 0.007530192944227959 - Loss: 0.3257134258747101, aux loss1: 0.6999334096908569, 
		 aux loss2: 0.4183254837989807, total loss: 0.7030236721038818
19th Epoch, 24335th Step, learning rate = 0.00752967693214836 - Loss: 0.5351296067237854, aux loss1: 1.2677521705627441, 
		 aux loss2: 0.8007538914680481, total loss: 1.2357568740844727
19th Epoch, 24340th Step, learning rate = 0.007529160916139561 - Loss: 0.31825757026672363, aux loss1: 0.795734167098999, 
		 aux loss2: 0.40520840883255005, total loss: 0.7190611958503723
19th Epoch, 24345th Step, learning rate = 0.007528644896201232 - Loss: 0.3695582151412964, aux loss1: 0.8576458692550659, 
		 aux loss2: 0.4926649332046509, total loss: 0.8239179849624634
19th Epoch, 24350th Step, learning rate = 0.0075281288723330455 - Loss: 0.3469247817993164, aux loss1: 0.7081459760665894, 
		 aux loss2: 0.42476174235343933, total loss: 0.7292733192443848
19th Epoch, 24355th Step, learning rate = 0.007527612844534669 - Loss: 0.32161495089530945, aux loss1: 0.8982157111167908, 
		 aux loss2: 0.4604256749153137, total loss: 0.7752499580383301
19th Epoch, 24360th Step, learning rate = 0.007527096812805776 - Loss: 0.40957602858543396, aux loss1: 0.9459169507026672, 
		 aux loss2: 0.5450419783592224, total loss: 0.9113679528236389
19th Epoch, 24365th Step, learning rate = 0.007526580777146037 - Loss: 0.46258342266082764, aux loss1: 0.9602473378181458, 
		 aux loss2: 0.6004632711410522, total loss: 0.9908429980278015
19th Epoch, 24370th Step, learning rate = 0.007526064737555121 - Loss: 0.3779487907886505, aux loss1: 0.9058434367179871, 
		 aux loss2: 0.5095036625862122, total loss: 0.8535032868385315
19th Epoch, 24375th Step, learning rate = 0.0075255486940327 - Loss: 0.28759294748306274, aux loss1: 0.696667492389679, 
		 aux loss2: 0.36662811040878296, total loss: 0.6432444453239441
19th Epoch, 24380th Step, learning rate = 0.0075250326465784445 - Loss: 0.35082077980041504, aux loss1: 0.9176806211471558, 
		 aux loss2: 0.49786579608917236, total loss: 0.8252713084220886
19th Epoch, 24385th Step, learning rate = 0.007524516595192022 - Loss: 0.45314332842826843, aux loss1: 1.0404081344604492, 
		 aux loss2: 0.6116248369216919, total loss: 1.0099157094955444
19th Epoch, 24390th Step, learning rate = 0.0075240005398731075 - Loss: 0.3353721797466278, aux loss1: 0.906498372554779, 
		 aux loss2: 0.5016672611236572, total loss: 0.8079886436462402
19th Epoch, 24395th Step, learning rate = 0.007523484480621368 - Loss: 0.3840370178222656, aux loss1: 0.9027220606803894, 
		 aux loss2: 0.4905748665332794, total loss: 0.8510835766792297
19th Epoch, 24400th Step, learning rate = 0.007522968417436474 - Loss: 0.36905595660209656, aux loss1: 0.8795837163925171, 
		 aux loss2: 0.4925794303417206, total loss: 0.8299629092216492
<24400th step>
*************************** Test ***************************
time:3m 16s, 24400th Step, Loss: 0.560508131980896, Mean IoU = 43.752%
************************************************************
19th Epoch, 24405th Step, learning rate = 0.0075224523503181 - Loss: 0.35414502024650574, aux loss1: 0.8437818288803101, 
		 aux loss2: 0.4646568298339844, total loss: 0.7931422591209412
19th Epoch, 24410th Step, learning rate = 0.00752193627926591 - Loss: 0.3558841347694397, aux loss1: 1.0106360912322998, 
		 aux loss2: 0.49526748061180115, total loss: 0.857181966304779
19th Epoch, 24415th Step, learning rate = 0.007521420204279577 - Loss: 0.24160341918468475, aux loss1: 0.6539915800094604, 
		 aux loss2: 0.3263133466243744, total loss: 0.5683262348175049
19th Epoch, 24420th Step, learning rate = 0.007520904125358772 - Loss: 0.33134016394615173, aux loss1: 0.7830471992492676, 
		 aux loss2: 0.42702871561050415, total loss: 0.7370657920837402
19th Epoch, 24425th Step, learning rate = 0.0075203880425031636 - Loss: 0.3486415147781372, aux loss1: 0.7603330016136169, 
		 aux loss2: 0.44598913192749023, total loss: 0.7551370859146118
19th Epoch, 24430th Step, learning rate = 0.0075198719557124215 - Loss: 0.33777469396591187, aux loss1: 0.8567532896995544, 
		 aux loss2: 0.4577288329601288, total loss: 0.7778922319412231
19th Epoch, 24435th Step, learning rate = 0.007519355864986218 - Loss: 0.36362507939338684, aux loss1: 0.8595525026321411, 
		 aux loss2: 0.484940767288208, total loss: 0.815467119216919
19th Epoch, 24440th Step, learning rate = 0.00751883977032422 - Loss: 0.3239658772945404, aux loss1: 0.8342530727386475, 
		 aux loss2: 0.44575628638267517, total loss: 0.7525443434715271
19th Epoch, 24445th Step, learning rate = 0.007518323671726099 - Loss: 0.3559848368167877, aux loss1: 0.7962673902511597, 
		 aux loss2: 0.47689563035964966, total loss: 0.78562331199646
19th Epoch, 24450th Step, learning rate = 0.007517807569191523 - Loss: 0.27653968334198, aux loss1: 0.6639453768730164, 
		 aux loss2: 0.37427300214767456, total loss: 0.625432550907135
19th Epoch, 24455th Step, learning rate = 0.007517291462720165 - Loss: 0.4335589110851288, aux loss1: 0.9830337762832642, 
		 aux loss2: 0.582966148853302, total loss: 0.9616554975509644
19th Epoch, 24460th Step, learning rate = 0.007516775352311692 - Loss: 0.30360177159309387, aux loss1: 0.6731966733932495, 
		 aux loss2: 0.3759150803089142, total loss: 0.6559268236160278
19th Epoch, 24465th Step, learning rate = 0.007516259237965774 - Loss: 0.2698063850402832, aux loss1: 0.7485365271568298, 
		 aux loss2: 0.3656424582004547, total loss: 0.6406243443489075
19th Epoch, 24470th Step, learning rate = 0.00751574311968208 - Loss: 0.3196846842765808, aux loss1: 0.8353803157806396, 
		 aux loss2: 0.42625126242637634, total loss: 0.7407993078231812
19th Epoch, 24475th Step, learning rate = 0.007515226997460283 - Loss: 0.28768184781074524, aux loss1: 0.7442872524261475, 
		 aux loss2: 0.37591317296028137, total loss: 0.6613333225250244
19th Epoch, 24480th Step, learning rate = 0.007514710871300048 - Loss: 0.3054080009460449, aux loss1: 0.8944218158721924, 
		 aux loss2: 0.46142593026161194, total loss: 0.7583048939704895
19th Epoch, 24485th Step, learning rate = 0.007514194741201046 - Loss: 0.3668474853038788, aux loss1: 0.9683715105056763, 
		 aux loss2: 0.5302337408065796, total loss: 0.8694524765014648
19th Epoch, 24490th Step, learning rate = 0.007513678607162947 - Loss: 0.29881393909454346, aux loss1: 0.7715247869491577, 
		 aux loss2: 0.4017878472805023, total loss: 0.6909865736961365
19th Epoch, 24495th Step, learning rate = 0.007513162469185418 - Loss: 0.25513550639152527, aux loss1: 0.6712855100631714, 
		 aux loss2: 0.3465001583099365, total loss: 0.5951212048530579
19th Epoch, 24500th Step, learning rate = 0.007512646327268132 - Loss: 0.3406829535961151, aux loss1: 0.8444064259529114, 
		 aux loss2: 0.4549984335899353, total loss: 0.7760042548179626
<24500th step>
*************************** Test ***************************
time:3m 16s, 24500th Step, Loss: 0.5331426858901978, Mean IoU = 44.194%
************************************************************
19th Epoch, 24505th Step, learning rate = 0.007512130181410756 - Loss: 0.321879506111145, aux loss1: 0.7351595163345337, 
		 aux loss2: 0.41704317927360535, total loss: 0.7092446088790894
19th Epoch, 24510th Step, learning rate = 0.007511614031612959 - Loss: 0.37178272008895874, aux loss1: 0.83987957239151, 
		 aux loss2: 0.4846310615539551, total loss: 0.8175990581512451
19th Epoch, 24515th Step, learning rate = 0.007511097877874411 - Loss: 0.2852541208267212, aux loss1: 0.7800962924957275, 
		 aux loss2: 0.3963729739189148, total loss: 0.6778321862220764
19th Epoch, 24520th Step, learning rate = 0.007510581720194779 - Loss: 0.304168164730072, aux loss1: 0.7494006752967834, 
		 aux loss2: 0.3996697664260864, total loss: 0.6888562440872192
19th Epoch, 24525th Step, learning rate = 0.007510065558573734 - Loss: 0.37490224838256836, aux loss1: 0.9016685485839844, 
		 aux loss2: 0.5057432651519775, total loss: 0.8477001190185547
19th Epoch, 24530th Step, learning rate = 0.007509549393010945 - Loss: 0.23738151788711548, aux loss1: 0.6147434711456299, 
		 aux loss2: 0.3127507269382477, total loss: 0.5469048619270325
19th Epoch, 24535th Step, learning rate = 0.007509033223506079 - Loss: 0.45200449228286743, aux loss1: 0.9993645548820496, 
		 aux loss2: 0.6082924604415894, total loss: 0.9951308965682983
19th Epoch, 24540th Step, learning rate = 0.007508517050058806 - Loss: 0.342184454202652, aux loss1: 0.7852998971939087, 
		 aux loss2: 0.4226224422454834, total loss: 0.7468233704566956
19th Epoch, 24545th Step, learning rate = 0.0075080008726687965 - Loss: 0.28539177775382996, aux loss1: 0.7017919421195984, 
		 aux loss2: 0.3928641080856323, total loss: 0.6530749797821045
19th Epoch, 24550th Step, learning rate = 0.007507484691335714 - Loss: 0.4252854585647583, aux loss1: 1.0175063610076904, 
		 aux loss2: 0.5670146942138672, total loss: 0.9573432803153992
20th Epoch, 24555th Step, learning rate = 0.007506968506059233 - Loss: 0.4125203490257263, aux loss1: 0.9060739874839783, 
		 aux loss2: 0.5384965538978577, total loss: 0.8997411727905273
20th Epoch, 24560th Step, learning rate = 0.00750645231683902 - Loss: 0.3124810755252838, aux loss1: 0.7832481861114502, 
		 aux loss2: 0.4157737195491791, total loss: 0.713765025138855
20th Epoch, 24565th Step, learning rate = 0.00750593612367474 - Loss: 0.3144129812717438, aux loss1: 0.8169024586677551, 
		 aux loss2: 0.4401661157608032, total loss: 0.7355501651763916
20th Epoch, 24570th Step, learning rate = 0.007505419926566067 - Loss: 0.3530387282371521, aux loss1: 0.9468991756439209, 
		 aux loss2: 0.5086037516593933, total loss: 0.8405500054359436
20th Epoch, 24575th Step, learning rate = 0.007504903725512668 - Loss: 0.4663369655609131, aux loss1: 1.205404281616211, 
		 aux loss2: 0.7118596434593201, total loss: 1.1127021312713623
20th Epoch, 24580th Step, learning rate = 0.007504387520514208 - Loss: 0.39981839060783386, aux loss1: 1.0006405115127563, 
		 aux loss2: 0.590957522392273, total loss: 0.9363935589790344
20th Epoch, 24585th Step, learning rate = 0.007503871311570359 - Loss: 0.5562779903411865, aux loss1: 1.0413951873779297, 
		 aux loss2: 0.7293515801429749, total loss: 1.1604372262954712
20th Epoch, 24590th Step, learning rate = 0.007503355098680787 - Loss: 0.3847990036010742, aux loss1: 0.9629364609718323, 
		 aux loss2: 0.5189155340194702, total loss: 0.8812461495399475
20th Epoch, 24595th Step, learning rate = 0.007502838881845162 - Loss: 0.28520315885543823, aux loss1: 0.7594581842422485, 
		 aux loss2: 0.38985806703567505, total loss: 0.6689838171005249
20th Epoch, 24600th Step, learning rate = 0.007502322661063153 - Loss: 0.30956169962882996, aux loss1: 0.8408588767051697, 
		 aux loss2: 0.44444170594215393, total loss: 0.7395960688591003
<24600th step>
*************************** Test ***************************
time:3m 19s, 24600th Step, Loss: 0.5710706114768982, Mean IoU = 44.364%
************************************************************
20th Epoch, 24605th Step, learning rate = 0.007501806436334424 - Loss: 0.3229074776172638, aux loss1: 0.8769692182540894, 
		 aux loss2: 0.4596846401691437, total loss: 0.7698721885681152
20th Epoch, 24610th Step, learning rate = 0.007501290207658646 - Loss: 0.3137393891811371, aux loss1: 0.748343825340271, 
		 aux loss2: 0.4268602728843689, total loss: 0.7089866995811462
20th Epoch, 24615th Step, learning rate = 0.007500773975035488 - Loss: 0.3498501479625702, aux loss1: 0.9122227430343628, 
		 aux loss2: 0.5211748480796814, total loss: 0.8319869041442871
20th Epoch, 24620th Step, learning rate = 0.007500257738464614 - Loss: 0.3106931746006012, aux loss1: 0.7329545021057129, 
		 aux loss2: 0.42331647872924805, total loss: 0.6999061703681946
20th Epoch, 24625th Step, learning rate = 0.007499741497945697 - Loss: 0.30702367424964905, aux loss1: 0.8504642248153687, 
		 aux loss2: 0.42129844427108765, total loss: 0.730682373046875
20th Epoch, 24630th Step, learning rate = 0.0074992252534784015 - Loss: 0.350984126329422, aux loss1: 0.9622043371200562, 
		 aux loss2: 0.5400270819664001, total loss: 0.8556562662124634
20th Epoch, 24635th Step, learning rate = 0.007498709005062394 - Loss: 0.5113735198974609, aux loss1: 1.1308921575546265, 
		 aux loss2: 0.7073937058448792, total loss: 1.1335986852645874
20th Epoch, 24640th Step, learning rate = 0.007498192752697347 - Loss: 0.4435103237628937, aux loss1: 0.9012532234191895, 
		 aux loss2: 0.5509322285652161, total loss: 0.9342591762542725
20th Epoch, 24645th Step, learning rate = 0.007497676496382924 - Loss: 0.3083396553993225, aux loss1: 0.818144679069519, 
		 aux loss2: 0.4216306209564209, total loss: 0.7224352955818176
20th Epoch, 24650th Step, learning rate = 0.007497160236118795 - Loss: 0.36937615275382996, aux loss1: 0.9934115409851074, 
		 aux loss2: 0.5488681197166443, total loss: 0.8869469165802002
20th Epoch, 24655th Step, learning rate = 0.007496643971904626 - Loss: 0.3443809151649475, aux loss1: 0.8176660537719727, 
		 aux loss2: 0.4566744565963745, total loss: 0.772350549697876
20th Epoch, 24660th Step, learning rate = 0.007496127703740085 - Loss: 0.6142000555992126, aux loss1: 1.3358203172683716, 
		 aux loss2: 0.8878456950187683, total loss: 1.370084524154663
20th Epoch, 24665th Step, learning rate = 0.00749561143162484 - Loss: 0.31698617339134216, aux loss1: 0.8053755760192871, 
		 aux loss2: 0.4239897131919861, total loss: 0.7281947731971741
20th Epoch, 24670th Step, learning rate = 0.00749509515555856 - Loss: 0.46561604738235474, aux loss1: 1.1071968078613281, 
		 aux loss2: 0.6521173119544983, total loss: 1.0586220026016235
20th Epoch, 24675th Step, learning rate = 0.007494578875540907 - Loss: 0.39491015672683716, aux loss1: 0.8679137825965881, 
		 aux loss2: 0.5112988948822021, total loss: 0.8598038554191589
20th Epoch, 24680th Step, learning rate = 0.007494062591571554 - Loss: 0.3101072311401367, aux loss1: 0.8423330187797546, 
		 aux loss2: 0.44068557024002075, total loss: 0.7390813827514648
20th Epoch, 24685th Step, learning rate = 0.007493546303650165 - Loss: 0.5171512961387634, aux loss1: 0.9821642637252808, 
		 aux loss2: 0.6235176920890808, total loss: 1.06120765209198
20th Epoch, 24690th Step, learning rate = 0.007493030011776408 - Loss: 0.4791715443134308, aux loss1: 0.9575808048248291, 
		 aux loss2: 0.6066893935203552, total loss: 1.0091215372085571
20th Epoch, 24695th Step, learning rate = 0.007492513715949952 - Loss: 0.29444462060928345, aux loss1: 0.720507025718689, 
		 aux loss2: 0.38165003061294556, total loss: 0.6632567644119263
20th Epoch, 24700th Step, learning rate = 0.007491997416170462 - Loss: 0.41591569781303406, aux loss1: 0.9284468293190002, 
		 aux loss2: 0.5334364771842957, total loss: 0.9078243970870972
<24700th step>
*************************** Test ***************************
time:3m 19s, 24700th Step, Loss: 0.5657661557197571, Mean IoU = 43.844%
************************************************************
20th Epoch, 24705th Step, learning rate = 0.007491481112437604 - Loss: 0.6051396727561951, aux loss1: 1.149188756942749, 
		 aux loss2: 0.7835857272148132, total loss: 1.2633306980133057
20th Epoch, 24710th Step, learning rate = 0.007490964804751048 - Loss: 0.45840057730674744, aux loss1: 0.9917802214622498, 
		 aux loss2: 0.5781746506690979, total loss: 0.9872045516967773
20th Epoch, 24715th Step, learning rate = 0.007490448493110459 - Loss: 0.2879371643066406, aux loss1: 0.7526085376739502, 
		 aux loss2: 0.3832613229751587, total loss: 0.6670242547988892
20th Epoch, 24720th Step, learning rate = 0.0074899321775155035 - Loss: 0.4677189886569977, aux loss1: 1.0843836069107056, 
		 aux loss2: 0.6478549838066101, total loss: 1.0521761178970337
20th Epoch, 24725th Step, learning rate = 0.007489415857965851 - Loss: 0.25070998072624207, aux loss1: 0.6875444650650024, 
		 aux loss2: 0.33080804347991943, total loss: 0.5892965197563171
20th Epoch, 24730th Step, learning rate = 0.007488899534461164 - Loss: 0.2762722969055176, aux loss1: 0.7298170924186707, 
		 aux loss2: 0.3729308545589447, total loss: 0.644389808177948
20th Epoch, 24735th Step, learning rate = 0.007488383207001114 - Loss: 0.2969425916671753, aux loss1: 0.7204457521438599, 
		 aux loss2: 0.3741292953491211, total loss: 0.6627280116081238
20th Epoch, 24740th Step, learning rate = 0.007487866875585365 - Loss: 0.28680408000946045, aux loss1: 0.7647998929023743, 
		 aux loss2: 0.4048025906085968, total loss: 0.678165078163147
20th Epoch, 24745th Step, learning rate = 0.007487350540213581 - Loss: 0.39618033170700073, aux loss1: 0.8448991775512695, 
		 aux loss2: 0.5087705254554749, total loss: 0.8531582951545715
20th Epoch, 24750th Step, learning rate = 0.007486834200885435 - Loss: 0.293795645236969, aux loss1: 0.7326487302780151, 
		 aux loss2: 0.383171945810318, total loss: 0.6668590307235718
20th Epoch, 24755th Step, learning rate = 0.007486317857600589 - Loss: 0.29131850600242615, aux loss1: 0.738069474697113, 
		 aux loss2: 0.389679491519928, total loss: 0.6686111688613892
20th Epoch, 24760th Step, learning rate = 0.0074858015103587095 - Loss: 0.40351107716560364, aux loss1: 0.9805018901824951, 
		 aux loss2: 0.5216096043586731, total loss: 0.9063054919242859
20th Epoch, 24765th Step, learning rate = 0.007485285159159465 - Loss: 0.41086483001708984, aux loss1: 0.8698303699493408, 
		 aux loss2: 0.537911057472229, total loss: 0.8869783878326416
20th Epoch, 24770th Step, learning rate = 0.00748476880400252 - Loss: 0.35830068588256836, aux loss1: 0.8069937229156494, 
		 aux loss2: 0.4816013276576996, total loss: 0.7930393218994141
20th Epoch, 24775th Step, learning rate = 0.007484252444887541 - Loss: 0.43181174993515015, aux loss1: 0.8703734278678894, 
		 aux loss2: 0.5336940288543701, total loss: 0.9064013957977295
20th Epoch, 24780th Step, learning rate = 0.007483736081814196 - Loss: 0.29364290833473206, aux loss1: 0.8180447220802307, 
		 aux loss2: 0.41021034121513367, total loss: 0.7031404376029968
20th Epoch, 24785th Step, learning rate = 0.007483219714782149 - Loss: 0.29623809456825256, aux loss1: 0.80030357837677, 
		 aux loss2: 0.4498680531978607, total loss: 0.7162764072418213
20th Epoch, 24790th Step, learning rate = 0.007482703343791067 - Loss: 0.4165467917919159, aux loss1: 1.003765344619751, 
		 aux loss2: 0.5751015543937683, total loss: 0.947717010974884
20th Epoch, 24795th Step, learning rate = 0.007482186968840617 - Loss: 0.27770835161209106, aux loss1: 0.706015408039093, 
		 aux loss2: 0.37467148900032043, total loss: 0.6393815875053406
20th Epoch, 24800th Step, learning rate = 0.007481670589930462 - Loss: 0.2740698456764221, aux loss1: 0.6685513257980347, 
		 aux loss2: 0.3523954451084137, total loss: 0.615593433380127
<24800th step>
*************************** Test ***************************
time:3m 16s, 24800th Step, Loss: 0.5698439478874207, Mean IoU = 43.454%
************************************************************
20th Epoch, 24805th Step, learning rate = 0.007481154207060274 - Loss: 0.30571049451828003, aux loss1: 0.7860939502716064, 
		 aux loss2: 0.43774816393852234, total loss: 0.7166379690170288
20th Epoch, 24810th Step, learning rate = 0.007480637820229711 - Loss: 0.3415052592754364, aux loss1: 0.8771405816078186, 
		 aux loss2: 0.4968447983264923, total loss: 0.8033853769302368
20th Epoch, 24815th Step, learning rate = 0.007480121429438444 - Loss: 0.3118906021118164, aux loss1: 0.81290602684021, 
		 aux loss2: 0.43013134598731995, total loss: 0.7278149724006653
20th Epoch, 24820th Step, learning rate = 0.00747960503468614 - Loss: 0.4340839087963104, aux loss1: 1.0623623132705688, 
		 aux loss2: 0.5973760485649109, total loss: 0.9917430281639099
20th Epoch, 24825th Step, learning rate = 0.00747908863597246 - Loss: 0.31253498792648315, aux loss1: 0.8408395051956177, 
		 aux loss2: 0.44321081042289734, total loss: 0.7420711517333984
20th Epoch, 24830th Step, learning rate = 0.007478572233297073 - Loss: 0.4619247317314148, aux loss1: 1.0442038774490356, 
		 aux loss2: 0.6329848766326904, total loss: 1.0283799171447754
20th Epoch, 24835th Step, learning rate = 0.007478055826659644 - Loss: 0.483564555644989, aux loss1: 1.105462670326233, 
		 aux loss2: 0.6600210666656494, total loss: 1.0792118310928345
20th Epoch, 24840th Step, learning rate = 0.007477539416059838 - Loss: 0.3730279505252838, aux loss1: 0.9780423045158386, 
		 aux loss2: 0.49983352422714233, total loss: 0.8663740754127502
20th Epoch, 24845th Step, learning rate = 0.007477023001497321 - Loss: 0.4379270076751709, aux loss1: 1.0253558158874512, 
		 aux loss2: 0.5866130590438843, total loss: 0.9801790118217468
20th Epoch, 24850th Step, learning rate = 0.0074765065829717585 - Loss: 0.39170265197753906, aux loss1: 0.8408749103546143, 
		 aux loss2: 0.5183316469192505, total loss: 0.8512977957725525
20th Epoch, 24855th Step, learning rate = 0.0074759901604828155 - Loss: 0.2748696208000183, aux loss1: 0.763586699962616, 
		 aux loss2: 0.3633531332015991, total loss: 0.6492869257926941
20th Epoch, 24860th Step, learning rate = 0.0074754737340301585 - Loss: 0.3343150317668915, aux loss1: 0.7978708148002625, 
		 aux loss2: 0.45471155643463135, total loss: 0.7555609345436096
20th Epoch, 24865th Step, learning rate = 0.007474957303613451 - Loss: 0.5451446175575256, aux loss1: 1.156856894493103, 
		 aux loss2: 0.7068122029304504, total loss: 1.174926519393921
20th Epoch, 24870th Step, learning rate = 0.007474440869232359 - Loss: 0.3252168297767639, aux loss1: 0.8206127882003784, 
		 aux loss2: 0.4402211010456085, total loss: 0.7474890947341919
20th Epoch, 24875th Step, learning rate = 0.007473924430886549 - Loss: 0.45065826177597046, aux loss1: 0.992172360420227, 
		 aux loss2: 0.6020480990409851, total loss: 0.9891291856765747
20th Epoch, 24880th Step, learning rate = 0.007473407988575685 - Loss: 0.3565240204334259, aux loss1: 0.8149797916412354, 
		 aux loss2: 0.44788479804992676, total loss: 0.7801718711853027
20th Epoch, 24885th Step, learning rate = 0.0074728915422994325 - Loss: 0.37493661046028137, aux loss1: 1.0074704885482788, 
		 aux loss2: 0.5978043079376221, total loss: 0.9162995219230652
20th Epoch, 24890th Step, learning rate = 0.007472375092057456 - Loss: 0.5904760956764221, aux loss1: 1.1816449165344238, 
		 aux loss2: 0.7705119848251343, total loss: 1.2531744241714478
20th Epoch, 24895th Step, learning rate = 0.007471858637849421 - Loss: 0.3281586766242981, aux loss1: 0.8268440961837769, 
		 aux loss2: 0.4586840271949768, total loss: 0.7596855163574219
20th Epoch, 24900th Step, learning rate = 0.0074713421796749925 - Loss: 0.3325171172618866, aux loss1: 0.8066883087158203, 
		 aux loss2: 0.43721669912338257, total loss: 0.7494103312492371
<24900th step>
*************************** Test ***************************
time:3m 17s, 24900th Step, Loss: 0.5692797899246216, Mean IoU = 43.803%
************************************************************
20th Epoch, 24905th Step, learning rate = 0.007470825717533836 - Loss: 0.2957254946231842, aux loss1: 0.7309139370918274, 
		 aux loss2: 0.39036354422569275, total loss: 0.6711450815200806
20th Epoch, 24910th Step, learning rate = 0.007470309251425614 - Loss: 0.3049028515815735, aux loss1: 0.8316579461097717, 
		 aux loss2: 0.4308196008205414, total loss: 0.726728081703186
20th Epoch, 24915th Step, learning rate = 0.007469792781349994 - Loss: 0.3019481897354126, aux loss1: 0.8234703540802002, 
		 aux loss2: 0.417517751455307, total loss: 0.7159963846206665
20th Epoch, 24920th Step, learning rate = 0.007469276307306638 - Loss: 0.36029836535453796, aux loss1: 0.8984760642051697, 
		 aux loss2: 0.508744478225708, total loss: 0.8333389759063721
21th Epoch, 24925th Step, learning rate = 0.007468759829295212 - Loss: 0.41946476697921753, aux loss1: 1.0111734867095947, 
		 aux loss2: 0.6384567618370056, total loss: 0.9781995415687561
21th Epoch, 24930th Step, learning rate = 0.007468243347315383 - Loss: 0.3389280438423157, aux loss1: 0.8482245802879333, 
		 aux loss2: 0.47546717524528503, total loss: 0.783582329750061
21th Epoch, 24935th Step, learning rate = 0.007467726861366811 - Loss: 0.32774850726127625, aux loss1: 0.7491379976272583, 
		 aux loss2: 0.4232426881790161, total loss: 0.7217870354652405
21th Epoch, 24940th Step, learning rate = 0.007467210371449165 - Loss: 0.3626020848751068, aux loss1: 0.8972815871238708, 
		 aux loss2: 0.4950219988822937, total loss: 0.8297953605651855
21th Epoch, 24945th Step, learning rate = 0.007466693877562107 - Loss: 0.3469764292240143, aux loss1: 0.82967609167099, 
		 aux loss2: 0.46770331263542175, total loss: 0.7829605937004089
21th Epoch, 24950th Step, learning rate = 0.007466177379705301 - Loss: 0.3209550678730011, aux loss1: 0.8237494826316833, 
		 aux loss2: 0.45167362689971924, total loss: 0.7487493753433228
21th Epoch, 24955th Step, learning rate = 0.007465660877878412 - Loss: 0.41062578558921814, aux loss1: 0.929237425327301, 
		 aux loss2: 0.5224734544754028, total loss: 0.8983864188194275
21th Epoch, 24960th Step, learning rate = 0.007465144372081106 - Loss: 0.31123703718185425, aux loss1: 0.8035458326339722, 
		 aux loss2: 0.4108148217201233, total loss: 0.716626763343811
21th Epoch, 24965th Step, learning rate = 0.007464627862313044 - Loss: 0.3204532563686371, aux loss1: 0.8131968975067139, 
		 aux loss2: 0.4371418356895447, total loss: 0.7392690777778625
21th Epoch, 24970th Step, learning rate = 0.007464111348573892 - Loss: 0.4117226302623749, aux loss1: 0.9222838878631592, 
		 aux loss2: 0.5551118850708008, total loss: 0.9104525446891785
21th Epoch, 24975th Step, learning rate = 0.007463594830863315 - Loss: 0.30527621507644653, aux loss1: 0.8177292346954346, 
		 aux loss2: 0.4223032593727112, total loss: 0.7195162773132324
21th Epoch, 24980th Step, learning rate = 0.007463078309180974 - Loss: 0.3547056019306183, aux loss1: 0.8700963258743286, 
		 aux loss2: 0.4971902072429657, total loss: 0.8146106004714966
21th Epoch, 24985th Step, learning rate = 0.007462561783526538 - Loss: 0.2572210729122162, aux loss1: 0.7514240145683289, 
		 aux loss2: 0.37539049983024597, total loss: 0.6328045129776001
21th Epoch, 24990th Step, learning rate = 0.007462045253899666 - Loss: 0.2741827964782715, aux loss1: 0.7716916799545288, 
		 aux loss2: 0.39059165120124817, total loss: 0.6619269847869873
21th Epoch, 24995th Step, learning rate = 0.007461528720300024 - Loss: 0.4065452218055725, aux loss1: 0.8373150825500488, 
		 aux loss2: 0.5352188944816589, total loss: 0.8718273043632507
21th Epoch, 25000th Step, learning rate = 0.007461012182727277 - Loss: 0.28719690442085266, aux loss1: 0.7447500228881836, 
		 aux loss2: 0.38659313321113586, total loss: 0.6652591824531555
<25000th step>
*************************** Test ***************************
time:3m 19s, 25000th Step, Loss: 0.5336020588874817, Mean IoU = 44.194%
************************************************************
21th Epoch, 25005th Step, learning rate = 0.007460495641181087 - Loss: 0.3465457558631897, aux loss1: 0.8442153334617615, 
		 aux loss2: 0.5033499598503113, total loss: 0.8011503219604492
21th Epoch, 25010th Step, learning rate = 0.007459979095661118 - Loss: 0.3867776393890381, aux loss1: 0.8512566685676575, 
		 aux loss2: 0.48346927762031555, total loss: 0.8355424404144287
21th Epoch, 25015th Step, learning rate = 0.007459462546167035 - Loss: 0.3531222939491272, aux loss1: 0.8606573939323425, 
		 aux loss2: 0.4736173748970032, total loss: 0.8007664680480957
21th Epoch, 25020th Step, learning rate = 0.0074589459926985005 - Loss: 0.39128634333610535, aux loss1: 0.963772714138031, 
		 aux loss2: 0.5841025114059448, total loss: 0.9140591621398926
21th Epoch, 25025th Step, learning rate = 0.007458429435255177 - Loss: 0.5579139590263367, aux loss1: 1.1957998275756836, 
		 aux loss2: 0.7800003290176392, total loss: 1.2286540269851685
21th Epoch, 25030th Step, learning rate = 0.007457912873836732 - Loss: 0.2708997428417206, aux loss1: 0.6986263394355774, 
		 aux loss2: 0.3589750826358795, total loss: 0.6240776777267456
21th Epoch, 25035th Step, learning rate = 0.007457396308442823 - Loss: 0.2845945656299591, aux loss1: 0.7566295266151428, 
		 aux loss2: 0.38832518458366394, total loss: 0.6669135093688965
21th Epoch, 25040th Step, learning rate = 0.007456879739073119 - Loss: 0.30598020553588867, aux loss1: 0.8380087018013, 
		 aux loss2: 0.41944220662117004, total loss: 0.7251597046852112
21th Epoch, 25045th Step, learning rate = 0.007456363165727281 - Loss: 0.30770599842071533, aux loss1: 0.786515474319458, 
		 aux loss2: 0.4157719016075134, total loss: 0.7099694013595581
21th Epoch, 25050th Step, learning rate = 0.007455846588404971 - Loss: 0.29423394799232483, aux loss1: 0.7434387803077698, 
		 aux loss2: 0.38755548000335693, total loss: 0.6722877621650696
21th Epoch, 25055th Step, learning rate = 0.007455330007105856 - Loss: 0.30216890573501587, aux loss1: 0.8017107248306274, 
		 aux loss2: 0.42758992314338684, total loss: 0.713718056678772
21th Epoch, 25060th Step, learning rate = 0.007454813421829595 - Loss: 0.36334529519081116, aux loss1: 1.0596489906311035, 
		 aux loss2: 0.5286449193954468, total loss: 0.8926979303359985
21th Epoch, 25065th Step, learning rate = 0.007454296832575855 - Loss: 0.33055612444877625, aux loss1: 0.9640621542930603, 
		 aux loss2: 0.5415810346603394, total loss: 0.8364072442054749
21th Epoch, 25070th Step, learning rate = 0.007453780239344295 - Loss: 0.34836345911026, aux loss1: 0.9807577729225159, 
		 aux loss2: 0.528221845626831, total loss: 0.8538795113563538
21th Epoch, 25075th Step, learning rate = 0.0074532636421345815 - Loss: 0.2712760269641876, aux loss1: 0.8189520835876465, 
		 aux loss2: 0.3932510316371918, total loss: 0.6742621064186096
21th Epoch, 25080th Step, learning rate = 0.007452747040946376 - Loss: 0.36780837178230286, aux loss1: 0.8891124129295349, 
		 aux loss2: 0.5381903648376465, total loss: 0.849818229675293
21th Epoch, 25085th Step, learning rate = 0.007452230435779342 - Loss: 0.27828317880630493, aux loss1: 0.6716299057006836, 
		 aux loss2: 0.3723404109477997, total loss: 0.6287083029747009
21th Epoch, 25090th Step, learning rate = 0.007451713826633142 - Loss: 0.26580002903938293, aux loss1: 0.8334851264953613, 
		 aux loss2: 0.4141221046447754, total loss: 0.6814943552017212
21th Epoch, 25095th Step, learning rate = 0.007451197213507438 - Loss: 0.30389779806137085, aux loss1: 0.7789796590805054, 
		 aux loss2: 0.42343515157699585, total loss: 0.7069657444953918
21th Epoch, 25100th Step, learning rate = 0.007450680596401895 - Loss: 0.3805757761001587, aux loss1: 0.9428693056106567, 
		 aux loss2: 0.5174990296363831, total loss: 0.8704361915588379
<25100th step>
*************************** Test ***************************
time:3m 17s, 25100th Step, Loss: 0.5252013206481934, Mean IoU = 44.005%
************************************************************
21th Epoch, 25105th Step, learning rate = 0.007450163975316172 - Loss: 0.5372661352157593, aux loss1: 1.1552624702453613, 
		 aux loss2: 0.7617960572242737, total loss: 1.188563346862793
21th Epoch, 25110th Step, learning rate = 0.007449647350249937 - Loss: 0.34198281168937683, aux loss1: 0.7672042846679688, 
		 aux loss2: 0.4630088806152344, total loss: 0.7573476433753967
21th Epoch, 25115th Step, learning rate = 0.007449130721202848 - Loss: 0.25307443737983704, aux loss1: 0.6599063873291016, 
		 aux loss2: 0.33579811453819275, total loss: 0.5853655934333801
21th Epoch, 25120th Step, learning rate = 0.007448614088174569 - Loss: 0.3105471134185791, aux loss1: 0.7063664793968201, 
		 aux loss2: 0.41370704770088196, total loss: 0.6879398822784424
21th Epoch, 25125th Step, learning rate = 0.007448097451164763 - Loss: 0.32840028405189514, aux loss1: 0.8589136004447937, 
		 aux loss2: 0.4695432186126709, total loss: 0.7738916277885437
21th Epoch, 25130th Step, learning rate = 0.007447580810173093 - Loss: 0.5441967844963074, aux loss1: 1.2251182794570923, 
		 aux loss2: 0.781321108341217, total loss: 1.2242608070373535
21th Epoch, 25135th Step, learning rate = 0.0074470641651992195 - Loss: 0.30683255195617676, aux loss1: 0.724280059337616, 
		 aux loss2: 0.3999267518520355, total loss: 0.6840872764587402
21th Epoch, 25140th Step, learning rate = 0.007446547516242808 - Loss: 0.3713372051715851, aux loss1: 0.9606046676635742, 
		 aux loss2: 0.5159086585044861, total loss: 0.8658820390701294
21th Epoch, 25145th Step, learning rate = 0.007446030863303516 - Loss: 0.3645595908164978, aux loss1: 0.8747288584709167, 
		 aux loss2: 0.49022507667541504, total loss: 0.8230683207511902
21th Epoch, 25150th Step, learning rate = 0.007445514206381009 - Loss: 0.3033383786678314, aux loss1: 0.7485878467559814, 
		 aux loss2: 0.41041553020477295, total loss: 0.6920809745788574
21th Epoch, 25155th Step, learning rate = 0.00744499754547495 - Loss: 0.2957404553890228, aux loss1: 0.8051404356956482, 
		 aux loss2: 0.40841302275657654, total loss: 0.7006478309631348
21th Epoch, 25160th Step, learning rate = 0.007444480880584996 - Loss: 0.32234907150268555, aux loss1: 0.8344119787216187, 
		 aux loss2: 0.4306876063346863, total loss: 0.7449477314949036
21th Epoch, 25165th Step, learning rate = 0.007443964211710816 - Loss: 0.2645346522331238, aux loss1: 0.7982683777809143, 
		 aux loss2: 0.3952842354774475, total loss: 0.6621289253234863
21th Epoch, 25170th Step, learning rate = 0.007443447538852069 - Loss: 0.3638785183429718, aux loss1: 0.9685284495353699, 
		 aux loss2: 0.509545087814331, total loss: 0.8582550883293152
21th Epoch, 25175th Step, learning rate = 0.007442930862008415 - Loss: 0.29903700947761536, aux loss1: 0.8036119937896729, 
		 aux loss2: 0.40740373730659485, total loss: 0.7030820846557617
21th Epoch, 25180th Step, learning rate = 0.007442414181179519 - Loss: 0.3226170539855957, aux loss1: 0.9114012122154236, 
		 aux loss2: 0.4832151532173157, total loss: 0.7893234491348267
21th Epoch, 25185th Step, learning rate = 0.00744189749636504 - Loss: 0.3030126392841339, aux loss1: 0.8035997748374939, 
		 aux loss2: 0.43634432554244995, total loss: 0.718630313873291
21th Epoch, 25190th Step, learning rate = 0.007441380807564642 - Loss: 0.34262463450431824, aux loss1: 0.8280250430107117, 
		 aux loss2: 0.4736332893371582, total loss: 0.7804854512214661
21th Epoch, 25195th Step, learning rate = 0.007440864114777987 - Loss: 0.3611413836479187, aux loss1: 0.8872557878494263, 
		 aux loss2: 0.49065133929252625, total loss: 0.8235787153244019
21th Epoch, 25200th Step, learning rate = 0.007440347418004734 - Loss: 0.28365659713745117, aux loss1: 0.8289470672607422, 
		 aux loss2: 0.3941705524921417, total loss: 0.6900089383125305
<25200th step>
*************************** Test ***************************
time:3m 18s, 25200th Step, Loss: 0.5595299005508423, Mean IoU = 43.377%
************************************************************
21th Epoch, 25205th Step, learning rate = 0.0074398307172445464 - Loss: 0.3279779255390167, aux loss1: 0.7397446036338806, 
		 aux loss2: 0.421884685754776, total loss: 0.7186551690101624
21th Epoch, 25210th Step, learning rate = 0.007439314012497087 - Loss: 0.5393550395965576, aux loss1: 1.0297352075576782, 
		 aux loss2: 0.6689202785491943, total loss: 1.1158437728881836
21th Epoch, 25215th Step, learning rate = 0.007438797303762013 - Loss: 0.4465254247188568, aux loss1: 0.9607818126678467, 
		 aux loss2: 0.6111724972724915, total loss: 0.9792289733886719
21th Epoch, 25220th Step, learning rate = 0.007438280591038991 - Loss: 0.29198217391967773, aux loss1: 0.8182964324951172, 
		 aux loss2: 0.42610520124435425, total loss: 0.7079132199287415
21th Epoch, 25225th Step, learning rate = 0.007437763874327682 - Loss: 0.3859170973300934, aux loss1: 0.9480624794960022, 
		 aux loss2: 0.5271018743515015, total loss: 0.8811766505241394
21th Epoch, 25230th Step, learning rate = 0.007437247153627742 - Loss: 0.46574676036834717, aux loss1: 1.0110828876495361, 
		 aux loss2: 0.6247148513793945, total loss: 1.0189576148986816
21th Epoch, 25235th Step, learning rate = 0.007436730428938838 - Loss: 0.3030703365802765, aux loss1: 0.8060709834098816, 
		 aux loss2: 0.4028083086013794, total loss: 0.7060149908065796
21th Epoch, 25240th Step, learning rate = 0.007436213700260629 - Loss: 0.3091457486152649, aux loss1: 0.7799640893936157, 
		 aux loss2: 0.413208544254303, total loss: 0.7084184288978577
21th Epoch, 25245th Step, learning rate = 0.007435696967592775 - Loss: 0.3316478431224823, aux loss1: 0.780717134475708, 
		 aux loss2: 0.41783735156059265, total loss: 0.7329979538917542
21th Epoch, 25250th Step, learning rate = 0.00743518023093494 - Loss: 0.29934099316596985, aux loss1: 0.75602126121521, 
		 aux loss2: 0.4205482602119446, total loss: 0.6943666934967041
21th Epoch, 25255th Step, learning rate = 0.007434663490286783 - Loss: 0.3978903293609619, aux loss1: 1.0103378295898438, 
		 aux loss2: 0.5505254864692688, total loss: 0.9212018847465515
21th Epoch, 25260th Step, learning rate = 0.007434146745647965 - Loss: 0.5179516077041626, aux loss1: 1.1499959230422974, 
		 aux loss2: 0.6833816766738892, total loss: 1.1363030672073364
21th Epoch, 25265th Step, learning rate = 0.007433629997018148 - Loss: 0.3180837631225586, aux loss1: 0.8004028797149658, 
		 aux loss2: 0.43790215253829956, total loss: 0.733365535736084
21th Epoch, 25270th Step, learning rate = 0.007433113244396993 - Loss: 0.3527637720108032, aux loss1: 0.864197850227356, 
		 aux loss2: 0.48483482003211975, total loss: 0.8059570789337158
21th Epoch, 25275th Step, learning rate = 0.007432596487784159 - Loss: 0.31479865312576294, aux loss1: 0.812200665473938, 
		 aux loss2: 0.422437459230423, total loss: 0.7274338603019714
21th Epoch, 25280th Step, learning rate = 0.007432079727179309 - Loss: 0.3039588928222656, aux loss1: 0.7970496416091919, 
		 aux loss2: 0.4278292655944824, total loss: 0.7142055034637451
21th Epoch, 25285th Step, learning rate = 0.007431562962582101 - Loss: 0.3103332817554474, aux loss1: 0.8632164001464844, 
		 aux loss2: 0.4510791003704071, total loss: 0.7497298717498779
21th Epoch, 25290th Step, learning rate = 0.0074310461939922 - Loss: 0.4400750398635864, aux loss1: 0.8743540644645691, 
		 aux loss2: 0.5699282288551331, total loss: 0.9303525686264038
22th Epoch, 25295th Step, learning rate = 0.0074305294214092625 - Loss: 0.35753345489501953, aux loss1: 0.9977750182151794, 
		 aux loss2: 0.5314275026321411, total loss: 0.8694369792938232
22th Epoch, 25300th Step, learning rate = 0.007430012644832951 - Loss: 0.34557342529296875, aux loss1: 0.8050217628479004, 
		 aux loss2: 0.4723344147205353, total loss: 0.7760137319564819
<25300th step>
*************************** Test ***************************
time:3m 16s, 25300th Step, Loss: 0.5165561437606812, Mean IoU = 45.482%
************************************************************
22th Epoch, 25305th Step, learning rate = 0.007429495864262926 - Loss: 0.2677513659000397, aux loss1: 0.7676106095314026, 
		 aux loss2: 0.37192192673683167, total loss: 0.6468033194541931
22th Epoch, 25310th Step, learning rate = 0.007428979079698848 - Loss: 0.30520105361938477, aux loss1: 0.9322922825813293, 
		 aux loss2: 0.5024803876876831, total loss: 0.7858809232711792
22th Epoch, 25315th Step, learning rate = 0.007428462291140377 - Loss: 0.27758488059043884, aux loss1: 0.7789822816848755, 
		 aux loss2: 0.39795172214508057, total loss: 0.6704602837562561
22th Epoch, 25320th Step, learning rate = 0.007427945498587173 - Loss: 0.26312255859375, aux loss1: 0.7071403861045837, 
		 aux loss2: 0.37383317947387695, total loss: 0.6247979402542114
22th Epoch, 25325th Step, learning rate = 0.007427428702038897 - Loss: 0.31731507182121277, aux loss1: 0.8041942715644836, 
		 aux loss2: 0.44349920749664307, total loss: 0.735973060131073
22th Epoch, 25330th Step, learning rate = 0.007426911901495209 - Loss: 0.39069709181785583, aux loss1: 1.1167373657226562, 
		 aux loss2: 0.5829285383224487, total loss: 0.9588897228240967
22th Epoch, 25335th Step, learning rate = 0.00742639509695577 - Loss: 0.28832197189331055, aux loss1: 0.7795243859291077, 
		 aux loss2: 0.4094966948032379, total loss: 0.6859779953956604
22th Epoch, 25340th Step, learning rate = 0.007425878288420237 - Loss: 0.28792762756347656, aux loss1: 0.7764427661895752, 
		 aux loss2: 0.4084226191043854, total loss: 0.6842294931411743
22th Epoch, 25345th Step, learning rate = 0.007425361475888275 - Loss: 0.27516305446624756, aux loss1: 0.8076373338699341, 
		 aux loss2: 0.4150433838367462, total loss: 0.6834716200828552
22th Epoch, 25350th Step, learning rate = 0.007424844659359541 - Loss: 0.29786416888237, aux loss1: 0.7637382745742798, 
		 aux loss2: 0.42679041624069214, total loss: 0.6977018117904663
22th Epoch, 25355th Step, learning rate = 0.007424327838833694 - Loss: 0.3617129921913147, aux loss1: 0.8530573844909668, 
		 aux loss2: 0.4881424009799957, total loss: 0.8128871917724609
22th Epoch, 25360th Step, learning rate = 0.007423811014310397 - Loss: 0.381640762090683, aux loss1: 0.9296385645866394, 
		 aux loss2: 0.5385908484458923, total loss: 0.8759686946868896
22th Epoch, 25365th Step, learning rate = 0.007423294185789308 - Loss: 0.2956187129020691, aux loss1: 0.7116276621818542, 
		 aux loss2: 0.38434118032455444, total loss: 0.6628434658050537
22th Epoch, 25370th Step, learning rate = 0.007422777353270086 - Loss: 0.3243768811225891, aux loss1: 0.8284627199172974, 
		 aux loss2: 0.45284852385520935, total loss: 0.7540550827980042
22th Epoch, 25375th Step, learning rate = 0.0074222605167523934 - Loss: 0.3062583804130554, aux loss1: 0.7957621812820435, 
		 aux loss2: 0.403027206659317, total loss: 0.7061979174613953
22th Epoch, 25380th Step, learning rate = 0.007421743676235887 - Loss: 0.3994511663913727, aux loss1: 0.9345676898956299, 
		 aux loss2: 0.5579084753990173, total loss: 0.9029848575592041
22th Epoch, 25385th Step, learning rate = 0.007421226831720228 - Loss: 0.3041580319404602, aux loss1: 0.7740579843521118, 
		 aux loss2: 0.4126751124858856, total loss: 0.701445460319519
22th Epoch, 25390th Step, learning rate = 0.007420709983205077 - Loss: 0.3574821949005127, aux loss1: 0.9199934005737305, 
		 aux loss2: 0.5252417922019958, total loss: 0.8435769081115723
22th Epoch, 25395th Step, learning rate = 0.007420193130690089 - Loss: 0.4921245574951172, aux loss1: 1.10866117477417, 
		 aux loss2: 0.7090448141098022, total loss: 1.108340859413147
22th Epoch, 25400th Step, learning rate = 0.00741967627417493 - Loss: 0.4311920404434204, aux loss1: 0.9752398729324341, 
		 aux loss2: 0.5978244543075562, total loss: 0.9628937840461731
<25400th step>
*************************** Test ***************************
time:3m 17s, 25400th Step, Loss: 0.5994331240653992, Mean IoU = 43.626%
************************************************************
22th Epoch, 25405th Step, learning rate = 0.007419159413659257 - Loss: 0.3318710923194885, aux loss1: 0.7765296697616577, 
		 aux loss2: 0.42983588576316833, total loss: 0.7367643713951111
22th Epoch, 25410th Step, learning rate = 0.007418642549142725 - Loss: 0.27884840965270996, aux loss1: 0.730847179889679, 
		 aux loss2: 0.3812895715236664, total loss: 0.6506184339523315
22th Epoch, 25415th Step, learning rate = 0.0074181256806249984 - Loss: 0.45247742533683777, aux loss1: 0.9452736377716064, 
		 aux loss2: 0.5849977731704712, total loss: 0.9700586795806885
22th Epoch, 25420th Step, learning rate = 0.007417608808105734 - Loss: 0.23579438030719757, aux loss1: 0.6672808527946472, 
		 aux loss2: 0.3331488072872162, total loss: 0.5692381858825684
22th Epoch, 25425th Step, learning rate = 0.007417091931584593 - Loss: 0.3556097745895386, aux loss1: 0.9351614713668823, 
		 aux loss2: 0.5246785283088684, total loss: 0.8460296392440796
22th Epoch, 25430th Step, learning rate = 0.007416575051061235 - Loss: 0.268686980009079, aux loss1: 0.7020865082740784, 
		 aux loss2: 0.3725970685482025, total loss: 0.6283518075942993
22th Epoch, 25435th Step, learning rate = 0.007416058166535316 - Loss: 0.32772842049598694, aux loss1: 0.8679068088531494, 
		 aux loss2: 0.4563958942890167, total loss: 0.7706587910652161
22th Epoch, 25440th Step, learning rate = 0.007415541278006496 - Loss: 0.3673044741153717, aux loss1: 0.9092527031898499, 
		 aux loss2: 0.534774899482727, total loss: 0.8539903163909912
22th Epoch, 25445th Step, learning rate = 0.007415024385474435 - Loss: 0.46527934074401855, aux loss1: 1.1007267236709595, 
		 aux loss2: 0.6381853222846985, total loss: 1.0507714748382568
22th Epoch, 25450th Step, learning rate = 0.007414507488938791 - Loss: 0.2900847792625427, aux loss1: 0.7632249593734741, 
		 aux loss2: 0.41451847553253174, total loss: 0.6848596334457397
22th Epoch, 25455th Step, learning rate = 0.007413990588399223 - Loss: 0.2543545067310333, aux loss1: 0.6647814512252808, 
		 aux loss2: 0.3399425745010376, total loss: 0.5897659659385681
22th Epoch, 25460th Step, learning rate = 0.007413473683855392 - Loss: 0.32864728569984436, aux loss1: 0.8627300262451172, 
		 aux loss2: 0.4523991346359253, total loss: 0.7684259414672852
22th Epoch, 25465th Step, learning rate = 0.007412956775306952 - Loss: 0.2961507737636566, aux loss1: 0.7394898533821106, 
		 aux loss2: 0.38551759719848633, total loss: 0.6722047924995422
22th Epoch, 25470th Step, learning rate = 0.007412439862753567 - Loss: 0.27091988921165466, aux loss1: 0.7667451500892639, 
		 aux loss2: 0.3762550950050354, total loss: 0.6514454483985901
22th Epoch, 25475th Step, learning rate = 0.007411922946194892 - Loss: 0.3079124987125397, aux loss1: 0.6964660286903381, 
		 aux loss2: 0.3910897970199585, total loss: 0.6732882261276245
22th Epoch, 25480th Step, learning rate = 0.0074114060256305885 - Loss: 0.3829115331172943, aux loss1: 1.0123875141143799, 
		 aux loss2: 0.5724600553512573, total loss: 0.9156118631362915
22th Epoch, 25485th Step, learning rate = 0.007410889101060313 - Loss: 0.3036631941795349, aux loss1: 0.7067404389381409, 
		 aux loss2: 0.3873540163040161, total loss: 0.6706269383430481
22th Epoch, 25490th Step, learning rate = 0.007410372172483723 - Loss: 0.4181242883205414, aux loss1: 0.9731073975563049, 
		 aux loss2: 0.5870905518531799, total loss: 0.9448927640914917
22th Epoch, 25495th Step, learning rate = 0.007409855239900478 - Loss: 0.26005983352661133, aux loss1: 0.7099215388298035, 
		 aux loss2: 0.3579361140727997, total loss: 0.6162107586860657
22th Epoch, 25500th Step, learning rate = 0.0074093383033102395 - Loss: 0.28501319885253906, aux loss1: 0.7626360058784485, 
		 aux loss2: 0.3879792094230652, total loss: 0.66899573802948
<25500th step>
*************************** Test ***************************
time:3m 20s, 25500th Step, Loss: 0.5732089281082153, Mean IoU = 43.273%
************************************************************
22th Epoch, 25505th Step, learning rate = 0.00740882136271266 - Loss: 0.38207000494003296, aux loss1: 0.8777949213981628, 
		 aux loss2: 0.5327363610267639, total loss: 0.8585030436515808
22th Epoch, 25510th Step, learning rate = 0.007408304418107401 - Loss: 0.27154475450515747, aux loss1: 0.8961439728736877, 
		 aux loss2: 0.40575769543647766, total loss: 0.7026910781860352
22th Epoch, 25515th Step, learning rate = 0.007407787469494121 - Loss: 0.5257072448730469, aux loss1: 1.045397162437439, 
		 aux loss2: 0.6476240754127502, total loss: 1.0983760356903076
22th Epoch, 25520th Step, learning rate = 0.007407270516872478 - Loss: 0.31680265069007874, aux loss1: 0.8118202090263367, 
		 aux loss2: 0.4359048008918762, total loss: 0.734710693359375
22th Epoch, 25525th Step, learning rate = 0.007406753560242129 - Loss: 0.38234347105026245, aux loss1: 0.9771760106086731, 
		 aux loss2: 0.5302121043205261, total loss: 0.8875811100006104
22th Epoch, 25530th Step, learning rate = 0.007406236599602734 - Loss: 0.37578630447387695, aux loss1: 0.9126061201095581, 
		 aux loss2: 0.5107506513595581, total loss: 0.8538684248924255
22th Epoch, 25535th Step, learning rate = 0.007405719634953947 - Loss: 0.33354446291923523, aux loss1: 0.7733290791511536, 
		 aux loss2: 0.4352627098560333, total loss: 0.7396482825279236
22th Epoch, 25540th Step, learning rate = 0.007405202666295431 - Loss: 0.38735026121139526, aux loss1: 1.0261573791503906, 
		 aux loss2: 0.5595605969429016, total loss: 0.919021725654602
22th Epoch, 25545th Step, learning rate = 0.00740468569362684 - Loss: 0.28469181060791016, aux loss1: 0.8134977221488953, 
		 aux loss2: 0.4121098518371582, total loss: 0.6935850381851196
22th Epoch, 25550th Step, learning rate = 0.007404168716947834 - Loss: 0.2966379225254059, aux loss1: 0.7399047017097473, 
		 aux loss2: 0.3734475076198578, total loss: 0.6679883599281311
22th Epoch, 25555th Step, learning rate = 0.00740365173625807 - Loss: 0.2865813970565796, aux loss1: 0.7315200567245483, 
		 aux loss2: 0.3905577063560486, total loss: 0.6622605323791504
22th Epoch, 25560th Step, learning rate = 0.007403134751557206 - Loss: 0.3056039810180664, aux loss1: 0.7589352130889893, 
		 aux loss2: 0.4115753769874573, total loss: 0.697914719581604
22th Epoch, 25565th Step, learning rate = 0.007402617762844898 - Loss: 0.3378041386604309, aux loss1: 0.9779570698738098, 
		 aux loss2: 0.5114617347717285, total loss: 0.8357759714126587
22th Epoch, 25570th Step, learning rate = 0.0074021007701208065 - Loss: 0.3946346044540405, aux loss1: 0.9585219025611877, 
		 aux loss2: 0.533859133720398, total loss: 0.8957348465919495
22th Epoch, 25575th Step, learning rate = 0.007401583773384587 - Loss: 0.25643429160118103, aux loss1: 0.6767082214355469, 
		 aux loss2: 0.3353612422943115, total loss: 0.5935912728309631
22th Epoch, 25580th Step, learning rate = 0.007401066772635896 - Loss: 0.31096309423446655, aux loss1: 0.745417594909668, 
		 aux loss2: 0.41232922673225403, total loss: 0.6995201110839844
22th Epoch, 25585th Step, learning rate = 0.007400549767874395 - Loss: 0.3363848328590393, aux loss1: 0.825192928314209, 
		 aux loss2: 0.4585815370082855, total loss: 0.7673753499984741
22th Epoch, 25590th Step, learning rate = 0.007400032759099735 - Loss: 0.32771965861320496, aux loss1: 0.9168996214866638, 
		 aux loss2: 0.4818873107433319, total loss: 0.795544445514679
22th Epoch, 25595th Step, learning rate = 0.00739951574631158 - Loss: 0.3374814987182617, aux loss1: 0.7656469941139221, 
		 aux loss2: 0.43165072798728943, total loss: 0.7398359179496765
22th Epoch, 25600th Step, learning rate = 0.007398998729509584 - Loss: 0.2717253863811493, aux loss1: 0.7607343792915344, 
		 aux loss2: 0.37129488587379456, total loss: 0.6484636664390564
<25600th step>
*************************** Test ***************************
time:3m 18s, 25600th Step, Loss: 0.5310744643211365, Mean IoU = 45.365%
************************************************************
22th Epoch, 25605th Step, learning rate = 0.007398481708693403 - Loss: 0.32655763626098633, aux loss1: 0.8934997916221619, 
		 aux loss2: 0.4601522982120514, total loss: 0.7786685228347778
22th Epoch, 25610th Step, learning rate = 0.007397964683862698 - Loss: 0.4126312732696533, aux loss1: 1.0346213579177856, 
		 aux loss2: 0.5421559810638428, total loss: 0.9398800730705261
22th Epoch, 25615th Step, learning rate = 0.007397447655017122 - Loss: 0.3157554268836975, aux loss1: 0.8445447087287903, 
		 aux loss2: 0.44392165541648865, total loss: 0.7466875314712524
22th Epoch, 25620th Step, learning rate = 0.007396930622156334 - Loss: 0.33768442273139954, aux loss1: 0.8340367674827576, 
		 aux loss2: 0.43912896513938904, total loss: 0.7635470628738403
22th Epoch, 25625th Step, learning rate = 0.00739641358527999 - Loss: 0.40980973839759827, aux loss1: 0.9343796372413635, 
		 aux loss2: 0.5743975043296814, total loss: 0.9198826551437378
22th Epoch, 25630th Step, learning rate = 0.007395896544387749 - Loss: 0.3023340404033661, aux loss1: 0.756466269493103, 
		 aux loss2: 0.4081803262233734, total loss: 0.6925460696220398
22th Epoch, 25635th Step, learning rate = 0.007395379499479266 - Loss: 0.31656721234321594, aux loss1: 0.743246853351593, 
		 aux loss2: 0.4125950038433075, total loss: 0.70457923412323
22th Epoch, 25640th Step, learning rate = 0.007394862450554198 - Loss: 0.36868512630462646, aux loss1: 0.8778997659683228, 
		 aux loss2: 0.4838462769985199, total loss: 0.8255935907363892
22th Epoch, 25645th Step, learning rate = 0.007394345397612202 - Loss: 0.35157376527786255, aux loss1: 0.7501482963562012, 
		 aux loss2: 0.454911470413208, total loss: 0.7585828304290771
22th Epoch, 25650th Step, learning rate = 0.0073938283406529345 - Loss: 0.49312451481819153, aux loss1: 1.0950806140899658, 
		 aux loss2: 0.6906817555427551, total loss: 1.097921371459961
22th Epoch, 25655th Step, learning rate = 0.007393311279676054 - Loss: 0.3305438458919525, aux loss1: 0.818688154220581, 
		 aux loss2: 0.4424453377723694, total loss: 0.7531284093856812
22th Epoch, 25660th Step, learning rate = 0.007392794214681213 - Loss: 0.36064496636390686, aux loss1: 0.9914987087249756, 
		 aux loss2: 0.5380803346633911, total loss: 0.8733267188072205
23th Epoch, 25665th Step, learning rate = 0.007392277145668072 - Loss: 0.37817034125328064, aux loss1: 0.8334468603134155, 
		 aux loss2: 0.49642857909202576, total loss: 0.826775848865509
23th Epoch, 25670th Step, learning rate = 0.007391760072636286 - Loss: 0.2852475941181183, aux loss1: 0.80135178565979, 
		 aux loss2: 0.3950931429862976, total loss: 0.6836903691291809
23th Epoch, 25675th Step, learning rate = 0.007391242995585511 - Loss: 0.2639879584312439, aux loss1: 0.7454908490180969, 
		 aux loss2: 0.3683964014053345, total loss: 0.6349937915802002
23th Epoch, 25680th Step, learning rate = 0.007390725914515403 - Loss: 0.2777820825576782, aux loss1: 0.7239342927932739, 
		 aux loss2: 0.3870540261268616, total loss: 0.6497840285301208
23th Epoch, 25685th Step, learning rate = 0.007390208829425621 - Loss: 0.27488675713539124, aux loss1: 0.7074032425880432, 
		 aux loss2: 0.3749450445175171, total loss: 0.6370857954025269
23th Epoch, 25690th Step, learning rate = 0.007389691740315817 - Loss: 0.3783244490623474, aux loss1: 0.9317488074302673, 
		 aux loss2: 0.5102739930152893, total loss: 0.8619586825370789
23th Epoch, 25695th Step, learning rate = 0.0073891746471856515 - Loss: 0.2659773826599121, aux loss1: 0.7704228758811951, 
		 aux loss2: 0.3932608962059021, total loss: 0.6544086337089539
23th Epoch, 25700th Step, learning rate = 0.007388657550034775 - Loss: 0.29703229665756226, aux loss1: 0.7602193355560303, 
		 aux loss2: 0.412864625453949, total loss: 0.6902439594268799
<25700th step>
*************************** Test ***************************
time:3m 15s, 25700th Step, Loss: 0.5394755601882935, Mean IoU = 44.646%
************************************************************
23th Epoch, 25705th Step, learning rate = 0.007388140448862851 - Loss: 0.361349880695343, aux loss1: 0.8813422322273254, 
		 aux loss2: 0.5092236995697021, total loss: 0.829442024230957
23th Epoch, 25710th Step, learning rate = 0.007387623343669531 - Loss: 0.2892569899559021, aux loss1: 0.7358446717262268, 
		 aux loss2: 0.4065971374511719, total loss: 0.6726492643356323
23th Epoch, 25715th Step, learning rate = 0.007387106234454469 - Loss: 0.3319946229457855, aux loss1: 0.7840739488601685, 
		 aux loss2: 0.4349084496498108, total loss: 0.7411801815032959
23th Epoch, 25720th Step, learning rate = 0.007386589121217327 - Loss: 0.2777799069881439, aux loss1: 0.6864031553268433, 
		 aux loss2: 0.3654811978340149, total loss: 0.6298933625221252
23th Epoch, 25725th Step, learning rate = 0.007386072003957756 - Loss: 0.30694618821144104, aux loss1: 0.6997373104095459, 
		 aux loss2: 0.40997570753097534, total loss: 0.6808576583862305
23th Epoch, 25730th Step, learning rate = 0.007385554882675412 - Loss: 0.38454779982566833, aux loss1: 1.132909893989563, 
		 aux loss2: 0.6134149432182312, total loss: 0.9697867631912231
23th Epoch, 25735th Step, learning rate = 0.007385037757369954 - Loss: 0.38794177770614624, aux loss1: 1.0776162147521973, 
		 aux loss2: 0.5886333584785461, total loss: 0.9466800093650818
23th Epoch, 25740th Step, learning rate = 0.0073845206280410336 - Loss: 0.3608323335647583, aux loss1: 0.8380462527275085, 
		 aux loss2: 0.472747266292572, total loss: 0.8013451099395752
23th Epoch, 25745th Step, learning rate = 0.0073840034946883095 - Loss: 0.42101725935935974, aux loss1: 0.9282346963882446, 
		 aux loss2: 0.5579396486282349, total loss: 0.9226635694503784
23th Epoch, 25750th Step, learning rate = 0.007383486357311436 - Loss: 0.2720791697502136, aux loss1: 0.7224428057670593, 
		 aux loss2: 0.3665645122528076, total loss: 0.6354378461837769
23th Epoch, 25755th Step, learning rate = 0.007382969215910069 - Loss: 0.3620939254760742, aux loss1: 0.8609362840652466, 
		 aux loss2: 0.49230945110321045, total loss: 0.8172985911369324
23th Epoch, 25760th Step, learning rate = 0.007382452070483864 - Loss: 0.34466734528541565, aux loss1: 0.826244056224823, 
		 aux loss2: 0.48051804304122925, total loss: 0.7847477793693542
23th Epoch, 25765th Step, learning rate = 0.007381934921032476 - Loss: 0.3526361584663391, aux loss1: 0.8770673274993896, 
		 aux loss2: 0.47849270701408386, total loss: 0.8071534633636475
23th Epoch, 25770th Step, learning rate = 0.007381417767555559 - Loss: 0.3840874135494232, aux loss1: 0.9719396829605103, 
		 aux loss2: 0.5223682522773743, total loss: 0.8846166133880615
23th Epoch, 25775th Step, learning rate = 0.007380900610052772 - Loss: 0.3046400845050812, aux loss1: 0.8524211645126343, 
		 aux loss2: 0.4340810179710388, total loss: 0.7339988946914673
23th Epoch, 25780th Step, learning rate = 0.007380383448523767 - Loss: 0.29935792088508606, aux loss1: 0.6568199992179871, 
		 aux loss2: 0.36941471695899963, total loss: 0.644169807434082
23th Epoch, 25785th Step, learning rate = 0.0073798662829682 - Loss: 0.3074818551540375, aux loss1: 0.8822618722915649, 
		 aux loss2: 0.46232062578201294, total loss: 0.7570886611938477
23th Epoch, 25790th Step, learning rate = 0.007379349113385727 - Loss: 0.5958564281463623, aux loss1: 1.148181676864624, 
		 aux loss2: 0.7213066816329956, total loss: 1.2288336753845215
23th Epoch, 25795th Step, learning rate = 0.007378831939776002 - Loss: 0.40487271547317505, aux loss1: 0.9085415005683899, 
		 aux loss2: 0.5248870849609375, total loss: 0.8873900175094604
23th Epoch, 25800th Step, learning rate = 0.007378314762138681 - Loss: 0.3331146240234375, aux loss1: 0.7442875504493713, 
		 aux loss2: 0.4245665669441223, total loss: 0.7262275218963623
<25800th step>
*************************** Test ***************************
time:3m 16s, 25800th Step, Loss: 0.5485972166061401, Mean IoU = 41.759%
************************************************************
23th Epoch, 25805th Step, learning rate = 0.007377797580473418 - Loss: 0.2666444182395935, aux loss1: 0.6586417555809021, 
		 aux loss2: 0.3617798089981079, total loss: 0.6089488863945007
23th Epoch, 25810th Step, learning rate = 0.007377280394779868 - Loss: 0.30998697876930237, aux loss1: 0.8065427541732788, 
		 aux loss2: 0.4089488089084625, total loss: 0.7155293226242065
23th Epoch, 25815th Step, learning rate = 0.007376763205057685 - Loss: 0.4567503035068512, aux loss1: 1.036878228187561, 
		 aux loss2: 0.6358045339584351, total loss: 1.022135615348816
23th Epoch, 25820th Step, learning rate = 0.007376246011306528 - Loss: 0.29549434781074524, aux loss1: 0.7826454043388367, 
		 aux loss2: 0.38144785165786743, total loss: 0.6828671097755432
23th Epoch, 25825th Step, learning rate = 0.007375728813526045 - Loss: 0.3268144428730011, aux loss1: 0.8546234965324402, 
		 aux loss2: 0.46627312898635864, total loss: 0.7697107791900635
23th Epoch, 25830th Step, learning rate = 0.007375211611715896 - Loss: 0.337672621011734, aux loss1: 0.8256756067276001, 
		 aux loss2: 0.44082024693489075, total loss: 0.7617034316062927
23th Epoch, 25835th Step, learning rate = 0.007374694405875733 - Loss: 0.3026047348976135, aux loss1: 0.8247643709182739, 
		 aux loss2: 0.40786731243133545, total loss: 0.7131809592247009
23th Epoch, 25840th Step, learning rate = 0.007374177196005213 - Loss: 0.47252222895622253, aux loss1: 1.0953956842422485, 
		 aux loss2: 0.6621689200401306, total loss: 1.066008448600769
23th Epoch, 25845th Step, learning rate = 0.007373659982103989 - Loss: 0.3756033480167389, aux loss1: 0.9125259518623352, 
		 aux loss2: 0.4907493591308594, total loss: 0.8456608653068542
23th Epoch, 25850th Step, learning rate = 0.007373142764171713 - Loss: 0.38589298725128174, aux loss1: 0.8381285667419434, 
		 aux loss2: 0.471622496843338, total loss: 0.8259806036949158
23th Epoch, 25855th Step, learning rate = 0.007372625542208043 - Loss: 0.2733679413795471, aux loss1: 0.7356773614883423, 
		 aux loss2: 0.3692411780357361, total loss: 0.6417676210403442
23th Epoch, 25860th Step, learning rate = 0.007372108316212634 - Loss: 0.42018890380859375, aux loss1: 0.9962605237960815, 
		 aux loss2: 0.5765314102172852, total loss: 0.9496796727180481
23th Epoch, 25865th Step, learning rate = 0.007371591086185136 - Loss: 0.31079456210136414, aux loss1: 0.7813376188278198, 
		 aux loss2: 0.39852553606033325, total loss: 0.7046061158180237
23th Epoch, 25870th Step, learning rate = 0.007371073852125205 - Loss: 0.3586931824684143, aux loss1: 0.8947299122810364, 
		 aux loss2: 0.4744683504104614, total loss: 0.8168994784355164
23th Epoch, 25875th Step, learning rate = 0.007370556614032499 - Loss: 0.45805639028549194, aux loss1: 1.0061930418014526, 
		 aux loss2: 0.5987018942832947, total loss: 0.9993950128555298
23th Epoch, 25880th Step, learning rate = 0.007370039371906665 - Loss: 0.362721711397171, aux loss1: 0.9056230783462524, 
		 aux loss2: 0.5375683307647705, total loss: 0.8494359850883484
23th Epoch, 25885th Step, learning rate = 0.007369522125747363 - Loss: 0.34185224771499634, aux loss1: 0.8858976364135742, 
		 aux loss2: 0.47967755794525146, total loss: 0.799492597579956
23th Epoch, 25890th Step, learning rate = 0.007369004875554245 - Loss: 0.3863030970096588, aux loss1: 1.0162315368652344, 
		 aux loss2: 0.5484997630119324, total loss: 0.9105725288391113
23th Epoch, 25895th Step, learning rate = 0.007368487621326962 - Loss: 0.30511778593063354, aux loss1: 0.7533934116363525, 
		 aux loss2: 0.4136582612991333, total loss: 0.6965991258621216
23th Epoch, 25900th Step, learning rate = 0.007367970363065174 - Loss: 0.24531133472919464, aux loss1: 0.6796568036079407, 
		 aux loss2: 0.3513602018356323, total loss: 0.5897524356842041
<25900th step>
*************************** Test ***************************
time:3m 15s, 25900th Step, Loss: 0.5573219060897827, Mean IoU = 43.168%
************************************************************
23th Epoch, 25905th Step, learning rate = 0.007367453100768531 - Loss: 0.3593962490558624, aux loss1: 0.996271014213562, 
		 aux loss2: 0.5341496467590332, total loss: 0.8719374537467957
23th Epoch, 25910th Step, learning rate = 0.007366935834436685 - Loss: 0.3021940290927887, aux loss1: 0.852780818939209, 
		 aux loss2: 0.4003593325614929, total loss: 0.718172013759613
23th Epoch, 25915th Step, learning rate = 0.007366418564069295 - Loss: 0.3600098490715027, aux loss1: 1.1084738969802856, 
		 aux loss2: 0.5718791484832764, total loss: 0.9213036894798279
23th Epoch, 25920th Step, learning rate = 0.00736590128966601 - Loss: 0.30121567845344543, aux loss1: 0.8024500012397766, 
		 aux loss2: 0.41908106207847595, total loss: 0.7095831632614136
23th Epoch, 25925th Step, learning rate = 0.007365384011226485 - Loss: 0.3648953437805176, aux loss1: 1.0207146406173706, 
		 aux loss2: 0.5067322850227356, total loss: 0.873802661895752
23th Epoch, 25930th Step, learning rate = 0.007364866728750375 - Loss: 0.3369739055633545, aux loss1: 0.7958992123603821, 
		 aux loss2: 0.43912044167518616, total loss: 0.7513918876647949
23th Epoch, 25935th Step, learning rate = 0.00736434944223733 - Loss: 0.4241759479045868, aux loss1: 0.9437761306762695, 
		 aux loss2: 0.5764937400817871, total loss: 0.9379062652587891
23th Epoch, 25940th Step, learning rate = 0.007363832151687007 - Loss: 0.37477532029151917, aux loss1: 0.84812992811203, 
		 aux loss2: 0.5029252171516418, total loss: 0.830384373664856
23th Epoch, 25945th Step, learning rate = 0.007363314857099059 - Loss: 0.33371883630752563, aux loss1: 0.8742203116416931, 
		 aux loss2: 0.4611026644706726, total loss: 0.780426025390625
23th Epoch, 25950th Step, learning rate = 0.007362797558473136 - Loss: 0.2801263630390167, aux loss1: 0.7088500261306763, 
		 aux loss2: 0.38827791810035706, total loss: 0.6480925679206848
23th Epoch, 25955th Step, learning rate = 0.0073622802558088955 - Loss: 0.3035515546798706, aux loss1: 0.7806890606880188, 
		 aux loss2: 0.43803709745407104, total loss: 0.7129731178283691
23th Epoch, 25960th Step, learning rate = 0.0073617629491059865 - Loss: 0.3483419120311737, aux loss1: 0.8469993472099304, 
		 aux loss2: 0.4913521409034729, total loss: 0.7989826202392578
23th Epoch, 25965th Step, learning rate = 0.007361245638364065 - Loss: 0.37539827823638916, aux loss1: 0.9697903990745544, 
		 aux loss2: 0.5294182896614075, total loss: 0.878102719783783
23th Epoch, 25970th Step, learning rate = 0.007360728323582786 - Loss: 0.32715147733688354, aux loss1: 0.8723136782646179, 
		 aux loss2: 0.4868091940879822, total loss: 0.7835692763328552
23th Epoch, 25975th Step, learning rate = 0.007360211004761799 - Loss: 0.2801818251609802, aux loss1: 0.7371899485588074, 
		 aux loss2: 0.3901030421257019, total loss: 0.6573800444602966
23th Epoch, 25980th Step, learning rate = 0.007359693681900757 - Loss: 0.26739779114723206, aux loss1: 0.7870136499404907, 
		 aux loss2: 0.38483935594558716, total loss: 0.6574376225471497
23th Epoch, 25985th Step, learning rate = 0.007359176354999314 - Loss: 0.28618213534355164, aux loss1: 0.8265550136566162, 
		 aux loss2: 0.4061202108860016, total loss: 0.6965967416763306
23th Epoch, 25990th Step, learning rate = 0.007358659024057123 - Loss: 0.34452709555625916, aux loss1: 0.8796151876449585, 
		 aux loss2: 0.4969027042388916, total loss: 0.8071727752685547
23th Epoch, 25995th Step, learning rate = 0.007358141689073835 - Loss: 0.2555254399776459, aux loss1: 0.8996315598487854, 
		 aux loss2: 0.3984427750110626, total loss: 0.6847920417785645
23th Epoch, 26000th Step, learning rate = 0.007357624350049107 - Loss: 0.3136783540248871, aux loss1: 0.7898403406143188, 
		 aux loss2: 0.4567846953868866, total loss: 0.733344316482544
<26000th step>
*************************** Test ***************************
time:3m 17s, 26000th Step, Loss: 0.5254999399185181, Mean IoU = 45.878%
************************************************************
23th Epoch, 26005th Step, learning rate = 0.007357107006982585 - Loss: 0.3072134256362915, aux loss1: 0.7503100037574768, 
		 aux loss2: 0.42729049921035767, total loss: 0.7032226324081421
23th Epoch, 26010th Step, learning rate = 0.007356589659873929 - Loss: 0.2678201198577881, aux loss1: 0.7393097281455994, 
		 aux loss2: 0.3731577396392822, total loss: 0.6388761401176453
23th Epoch, 26015th Step, learning rate = 0.007356072308722787 - Loss: 0.3943242132663727, aux loss1: 0.9392041563987732, 
		 aux loss2: 0.5692557692527771, total loss: 0.9037877917289734
23th Epoch, 26020th Step, learning rate = 0.007355554953528813 - Loss: 0.3556766211986542, aux loss1: 0.9249083399772644, 
		 aux loss2: 0.5439733862876892, total loss: 0.850738525390625
23th Epoch, 26025th Step, learning rate = 0.007355037594291659 - Loss: 0.2961834967136383, aux loss1: 0.7183284163475037, 
		 aux loss2: 0.3835998475551605, total loss: 0.6651219725608826
23th Epoch, 26030th Step, learning rate = 0.0073545202310109775 - Loss: 0.34958985447883606, aux loss1: 0.9336439371109009, 
		 aux loss2: 0.4960269033908844, total loss: 0.8280937671661377
24th Epoch, 26035th Step, learning rate = 0.007354002863686419 - Loss: 0.31286734342575073, aux loss1: 0.8440069556236267, 
		 aux loss2: 0.4578484892845154, total loss: 0.7492088675498962
24th Epoch, 26040th Step, learning rate = 0.0073534854923176405 - Loss: 0.3196987509727478, aux loss1: 0.8653302192687988, 
		 aux loss2: 0.4811475872993469, total loss: 0.7717568874359131
24th Epoch, 26045th Step, learning rate = 0.00735296811690429 - Loss: 0.42024070024490356, aux loss1: 0.9656707048416138, 
		 aux loss2: 0.5833316445350647, total loss: 0.9432746171951294
24th Epoch, 26050th Step, learning rate = 0.00735245073744602 - Loss: 0.43790122866630554, aux loss1: 1.0391260385513306, 
		 aux loss2: 0.5999677181243896, total loss: 0.9896261096000671
24th Epoch, 26055th Step, learning rate = 0.007351933353942486 - Loss: 0.5231748819351196, aux loss1: 1.0903658866882324, 
		 aux loss2: 0.6731736660003662, total loss: 1.1195541620254517
24th Epoch, 26060th Step, learning rate = 0.007351415966393334 - Loss: 0.3085119128227234, aux loss1: 0.8243276476860046, 
		 aux loss2: 0.4597295820713043, total loss: 0.739702045917511
24th Epoch, 26065th Step, learning rate = 0.007350898574798224 - Loss: 0.3148218095302582, aux loss1: 0.9898908734321594, 
		 aux loss2: 0.5006620287895203, total loss: 0.812053918838501
24th Epoch, 26070th Step, learning rate = 0.007350381179156802 - Loss: 0.3591134250164032, aux loss1: 1.0288279056549072, 
		 aux loss2: 0.5323951840400696, total loss: 0.8807199001312256
24th Epoch, 26075th Step, learning rate = 0.0073498637794687195 - Loss: 0.472216933965683, aux loss1: 1.0980137586593628, 
		 aux loss2: 0.6556774973869324, total loss: 1.063892126083374
24th Epoch, 26080th Step, learning rate = 0.007349346375733632 - Loss: 0.3372243046760559, aux loss1: 0.8360344767570496, 
		 aux loss2: 0.4618406295776367, total loss: 0.772770881652832
24th Epoch, 26085th Step, learning rate = 0.00734882896795119 - Loss: 0.33348873257637024, aux loss1: 0.9635079503059387, 
		 aux loss2: 0.4747160077095032, total loss: 0.8124275207519531
24th Epoch, 26090th Step, learning rate = 0.007348311556121043 - Loss: 0.2924858033657074, aux loss1: 0.7880139946937561, 
		 aux loss2: 0.41827842593193054, total loss: 0.6962013840675354
24th Epoch, 26095th Step, learning rate = 0.007347794140242847 - Loss: 0.289336234331131, aux loss1: 0.7606109380722046, 
		 aux loss2: 0.40339088439941406, total loss: 0.6788759231567383
24th Epoch, 26100th Step, learning rate = 0.007347276720316249 - Loss: 0.2716558277606964, aux loss1: 0.8096222281455994, 
		 aux loss2: 0.3992927372455597, total loss: 0.674259603023529
<26100th step>
*************************** Test ***************************
time:3m 16s, 26100th Step, Loss: 0.521464467048645, Mean IoU = 43.666%
************************************************************
24th Epoch, 26105th Step, learning rate = 0.007346759296340903 - Loss: 0.3389533460140228, aux loss1: 0.8495867252349854, 
		 aux loss2: 0.49210673570632935, total loss: 0.7906720638275146
24th Epoch, 26110th Step, learning rate = 0.007346241868316461 - Loss: 0.3617599606513977, aux loss1: 0.8933654427528381, 
		 aux loss2: 0.49163541197776794, total loss: 0.8264237642288208
24th Epoch, 26115th Step, learning rate = 0.007345724436242572 - Loss: 0.32625895738601685, aux loss1: 0.8366232514381409, 
		 aux loss2: 0.445976585149765, total loss: 0.7556365728378296
24th Epoch, 26120th Step, learning rate = 0.00734520700011889 - Loss: 0.30059492588043213, aux loss1: 0.8549734354019165, 
		 aux loss2: 0.46894964575767517, total loss: 0.7446668148040771
24th Epoch, 26125th Step, learning rate = 0.007344689559945065 - Loss: 0.30065691471099854, aux loss1: 0.8017638921737671, 
		 aux loss2: 0.42739179730415344, total loss: 0.712142825126648
24th Epoch, 26130th Step, learning rate = 0.007344172115720747 - Loss: 0.33710038661956787, aux loss1: 0.8735735416412354, 
		 aux loss2: 0.4588721990585327, total loss: 0.7827213406562805
24th Epoch, 26135th Step, learning rate = 0.007343654667445591 - Loss: 0.29603293538093567, aux loss1: 0.7602118253707886, 
		 aux loss2: 0.40767279267311096, total loss: 0.6871656179428101
24th Epoch, 26140th Step, learning rate = 0.007343137215119243 - Loss: 0.350679874420166, aux loss1: 0.9435642957687378, 
		 aux loss2: 0.47005999088287354, total loss: 0.8217731714248657
24th Epoch, 26145th Step, learning rate = 0.007342619758741359 - Loss: 0.27461835741996765, aux loss1: 0.7978371381759644, 
		 aux loss2: 0.4130364656448364, total loss: 0.6791841387748718
24th Epoch, 26150th Step, learning rate = 0.007342102298311587 - Loss: 0.30498331785202026, aux loss1: 0.7576459646224976, 
		 aux loss2: 0.4428231418132782, total loss: 0.7094063758850098
24th Epoch, 26155th Step, learning rate = 0.007341584833829579 - Loss: 0.273560494184494, aux loss1: 0.6855709552764893, 
		 aux loss2: 0.369308739900589, total loss: 0.6269552707672119
24th Epoch, 26160th Step, learning rate = 0.007341067365294986 - Loss: 0.4235447943210602, aux loss1: 0.9714025855064392, 
		 aux loss2: 0.5336492657661438, total loss: 0.9284253120422363
24th Epoch, 26165th Step, learning rate = 0.007340549892707458 - Loss: 0.27427148818969727, aux loss1: 0.9517036080360413, 
		 aux loss2: 0.4392414093017578, total loss: 0.7354791760444641
24th Epoch, 26170th Step, learning rate = 0.007340032416066646 - Loss: 0.28741520643234253, aux loss1: 0.7762125730514526, 
		 aux loss2: 0.409919798374176, total loss: 0.6842468976974487
24th Epoch, 26175th Step, learning rate = 0.0073395149353722025 - Loss: 0.35665369033813477, aux loss1: 0.8742485642433167, 
		 aux loss2: 0.5189559459686279, total loss: 0.8265106678009033
24th Epoch, 26180th Step, learning rate = 0.007338997450623777 - Loss: 0.3182801902294159, aux loss1: 0.8109105825424194, 
		 aux loss2: 0.44665002822875977, total loss: 0.7402133941650391
24th Epoch, 26185th Step, learning rate = 0.007338479961821017 - Loss: 0.29501864314079285, aux loss1: 0.7739777565002441, 
		 aux loss2: 0.41133320331573486, total loss: 0.6917452812194824
24th Epoch, 26190th Step, learning rate = 0.00733796246896358 - Loss: 0.3366498649120331, aux loss1: 0.9183035492897034, 
		 aux loss2: 0.46504896879196167, total loss: 0.7981605529785156
24th Epoch, 26195th Step, learning rate = 0.007337444972051111 - Loss: 0.3872419595718384, aux loss1: 0.8996269702911377, 
		 aux loss2: 0.5205167531967163, total loss: 0.8653367757797241
24th Epoch, 26200th Step, learning rate = 0.007336927471083259 - Loss: 0.3097634017467499, aux loss1: 0.9784607291221619, 
		 aux loss2: 0.4840848445892334, total loss: 0.7969355583190918
<26200th step>
*************************** Test ***************************
time:3m 15s, 26200th Step, Loss: 0.5400521159172058, Mean IoU = 45.127%
************************************************************
24th Epoch, 26205th Step, learning rate = 0.0073364099660596805 - Loss: 0.27206218242645264, aux loss1: 0.7352222204208374, 
		 aux loss2: 0.37628719210624695, total loss: 0.6431437730789185
24th Epoch, 26210th Step, learning rate = 0.007335892456980021 - Loss: 0.258041650056839, aux loss1: 0.7615240812301636, 
		 aux loss2: 0.34804072976112366, total loss: 0.6257151961326599
24th Epoch, 26215th Step, learning rate = 0.007335374943843933 - Loss: 0.3926440477371216, aux loss1: 0.9719055891036987, 
		 aux loss2: 0.5928307771682739, total loss: 0.9213480353355408
24th Epoch, 26220th Step, learning rate = 0.007334857426651067 - Loss: 0.313515305519104, aux loss1: 0.8304873704910278, 
		 aux loss2: 0.45388826727867126, total loss: 0.7442168593406677
24th Epoch, 26225th Step, learning rate = 0.0073343399054010714 - Loss: 0.5069190263748169, aux loss1: 1.1048946380615234, 
		 aux loss2: 0.6506799459457397, total loss: 1.0986593961715698
24th Epoch, 26230th Step, learning rate = 0.0073338223800935975 - Loss: 0.2646169662475586, aux loss1: 0.7980131506919861, 
		 aux loss2: 0.38024258613586426, total loss: 0.6561179757118225
24th Epoch, 26235th Step, learning rate = 0.007333304850728295 - Loss: 0.3208671808242798, aux loss1: 0.8702529668807983, 
		 aux loss2: 0.4349134862422943, total loss: 0.7559084892272949
24th Epoch, 26240th Step, learning rate = 0.007332787317304815 - Loss: 0.3153511881828308, aux loss1: 0.8189052939414978, 
		 aux loss2: 0.4382797181606293, total loss: 0.7363346815109253
24th Epoch, 26245th Step, learning rate = 0.007332269779822804 - Loss: 0.40918201208114624, aux loss1: 0.9782648682594299, 
		 aux loss2: 0.54892897605896, total loss: 0.9222331047058105
24th Epoch, 26250th Step, learning rate = 0.007331752238281917 - Loss: 0.32002487778663635, aux loss1: 0.7455223798751831, 
		 aux loss2: 0.4412463307380676, total loss: 0.7201801538467407
24th Epoch, 26255th Step, learning rate = 0.007331234692681797 - Loss: 0.210598886013031, aux loss1: 0.6656298637390137, 
		 aux loss2: 0.3122235834598541, total loss: 0.5351772904396057
24th Epoch, 26260th Step, learning rate = 0.007330717143022102 - Loss: 0.34476664662361145, aux loss1: 0.8475035429000854, 
		 aux loss2: 0.47933098673820496, total loss: 0.7907501459121704
24th Epoch, 26265th Step, learning rate = 0.007330199589302476 - Loss: 0.3529585301876068, aux loss1: 0.8748037219047546, 
		 aux loss2: 0.4758848249912262, total loss: 0.8057535886764526
24th Epoch, 26270th Step, learning rate = 0.00732968203152257 - Loss: 0.34035080671310425, aux loss1: 1.1262234449386597, 
		 aux loss2: 0.548954427242279, total loss: 0.8977996706962585
24th Epoch, 26275th Step, learning rate = 0.007329164469682035 - Loss: 0.517751932144165, aux loss1: 1.2469232082366943, 
		 aux loss2: 0.773017168045044, total loss: 1.201035737991333
24th Epoch, 26280th Step, learning rate = 0.007328646903780517 - Loss: 0.28589680790901184, aux loss1: 0.7182983160018921, 
		 aux loss2: 0.40844854712486267, total loss: 0.6647657155990601
24th Epoch, 26285th Step, learning rate = 0.007328129333817669 - Loss: 0.2664998173713684, aux loss1: 0.7057221531867981, 
		 aux loss2: 0.3647193908691406, total loss: 0.6241042613983154
24th Epoch, 26290th Step, learning rate = 0.007327611759793139 - Loss: 0.3544909358024597, aux loss1: 0.7925270199775696, 
		 aux loss2: 0.4781460165977478, total loss: 0.7835074663162231
24th Epoch, 26295th Step, learning rate = 0.007327094181706577 - Loss: 0.356240838766098, aux loss1: 0.8540302515029907, 
		 aux loss2: 0.47035568952560425, total loss: 0.8005921840667725
24th Epoch, 26300th Step, learning rate = 0.0073265765995576305 - Loss: 0.25324875116348267, aux loss1: 0.6906887888908386, 
		 aux loss2: 0.3513586223125458, total loss: 0.6009988784790039
<26300th step>
*************************** Test ***************************
time:3m 17s, 26300th Step, Loss: 0.5390995740890503, Mean IoU = 44.781%
************************************************************
24th Epoch, 26305th Step, learning rate = 0.007326059013345951 - Loss: 0.3876068890094757, aux loss1: 0.9735071063041687, 
		 aux loss2: 0.554762601852417, total loss: 0.9015640616416931
24th Epoch, 26310th Step, learning rate = 0.007325541423071186 - Loss: 0.319821298122406, aux loss1: 0.9536641836166382, 
		 aux loss2: 0.5061764121055603, total loss: 0.8083910942077637
24th Epoch, 26315th Step, learning rate = 0.007325023828732988 - Loss: 0.40826350450515747, aux loss1: 1.0009465217590332, 
		 aux loss2: 0.6053370833396912, total loss: 0.9506822824478149
24th Epoch, 26320th Step, learning rate = 0.0073245062303310005 - Loss: 0.38423749804496765, aux loss1: 1.0429779291152954, 
		 aux loss2: 0.5686715841293335, total loss: 0.9245995283126831
24th Epoch, 26325th Step, learning rate = 0.007323988627864876 - Loss: 0.39523279666900635, aux loss1: 1.0828304290771484, 
		 aux loss2: 0.5901210904121399, total loss: 0.9561303853988647
24th Epoch, 26330th Step, learning rate = 0.007323471021334264 - Loss: 0.28676602244377136, aux loss1: 0.7366465330123901, 
		 aux loss2: 0.39779946208000183, total loss: 0.6668797731399536
24th Epoch, 26335th Step, learning rate = 0.007322953410738811 - Loss: 0.3688376545906067, aux loss1: 0.9150606393814087, 
		 aux loss2: 0.49349018931388855, total loss: 0.8407519459724426
24th Epoch, 26340th Step, learning rate = 0.007322435796078167 - Loss: 0.3481205999851227, aux loss1: 0.994428813457489, 
		 aux loss2: 0.5617183446884155, total loss: 0.8711366057395935
24th Epoch, 26345th Step, learning rate = 0.007321918177351981 - Loss: 0.36229437589645386, aux loss1: 0.9848755598068237, 
		 aux loss2: 0.5266352891921997, total loss: 0.8684111833572388
24th Epoch, 26350th Step, learning rate = 0.007321400554559903 - Loss: 0.3930482566356659, aux loss1: 0.8941444754600525, 
		 aux loss2: 0.5309344530105591, total loss: 0.8736653923988342
24th Epoch, 26355th Step, learning rate = 0.007320882927701579 - Loss: 0.27751782536506653, aux loss1: 0.7401940822601318, 
		 aux loss2: 0.3781979978084564, total loss: 0.6508552432060242
24th Epoch, 26360th Step, learning rate = 0.0073203652967766585 - Loss: 0.3897523581981659, aux loss1: 0.934477686882019, 
		 aux loss2: 0.5778478384017944, total loss: 0.9012348055839539
24th Epoch, 26365th Step, learning rate = 0.00731984766178479 - Loss: 0.39236512780189514, aux loss1: 0.9161897897720337, 
		 aux loss2: 0.5332478284835815, total loss: 0.8805212378501892
24th Epoch, 26370th Step, learning rate = 0.007319330022725624 - Loss: 0.29499587416648865, aux loss1: 0.7918325662612915, 
		 aux loss2: 0.4047299027442932, total loss: 0.6944376230239868
24th Epoch, 26375th Step, learning rate = 0.007318812379598807 - Loss: 0.32628577947616577, aux loss1: 0.8130404353141785, 
		 aux loss2: 0.459663987159729, total loss: 0.7540635466575623
24th Epoch, 26380th Step, learning rate = 0.007318294732403986 - Loss: 0.3100734055042267, aux loss1: 0.7089970111846924, 
		 aux loss2: 0.3863275945186615, total loss: 0.6773036122322083
24th Epoch, 26385th Step, learning rate = 0.007317777081140814 - Loss: 0.2656683027744293, aux loss1: 0.7029988765716553, 
		 aux loss2: 0.3608449101448059, total loss: 0.6209059357643127
24th Epoch, 26390th Step, learning rate = 0.007317259425808933 - Loss: 0.27144384384155273, aux loss1: 0.7635245323181152, 
		 aux loss2: 0.4040728807449341, total loss: 0.6621303558349609
24th Epoch, 26395th Step, learning rate = 0.007316741766407996 - Loss: 0.3332269489765167, aux loss1: 0.8220959901809692, 
		 aux loss2: 0.44295576214790344, total loss: 0.7570380568504333
24th Epoch, 26400th Step, learning rate = 0.007316224102937649 - Loss: 0.3859446346759796, aux loss1: 0.9013468623161316, 
		 aux loss2: 0.5090930461883545, total loss: 0.8599859476089478
<26400th step>
*************************** Test ***************************
time:3m 18s, 26400th Step, Loss: 0.5348954796791077, Mean IoU = 45.513%
************************************************************
24th Epoch, 26405th Step, learning rate = 0.007315706435397543 - Loss: 0.27237415313720703, aux loss1: 0.7550288438796997, 
		 aux loss2: 0.3650173842906952, total loss: 0.644889771938324
25th Epoch, 26410th Step, learning rate = 0.00731518876378732 - Loss: 0.29204845428466797, aux loss1: 0.7797157168388367, 
		 aux loss2: 0.4298466444015503, total loss: 0.6979018449783325
25th Epoch, 26415th Step, learning rate = 0.007314671088106635 - Loss: 0.265883207321167, aux loss1: 0.7028127312660217, 
		 aux loss2: 0.34910356998443604, total loss: 0.6163684725761414
25th Epoch, 26420th Step, learning rate = 0.0073141534083551295 - Loss: 0.3077506721019745, aux loss1: 0.7927698493003845, 
		 aux loss2: 0.4245726764202118, total loss: 0.7154107093811035
25th Epoch, 26425th Step, learning rate = 0.0073136357245324555 - Loss: 0.2558400630950928, aux loss1: 0.8397720456123352, 
		 aux loss2: 0.3945724368095398, total loss: 0.6656007170677185
25th Epoch, 26430th Step, learning rate = 0.007313118036638261 - Loss: 0.23771537840366364, aux loss1: 0.7507821917533875, 
		 aux loss2: 0.3661195933818817, total loss: 0.6093978881835938
25th Epoch, 26435th Step, learning rate = 0.00731260034467219 - Loss: 0.28065037727355957, aux loss1: 0.7671682238578796, 
		 aux loss2: 0.39565664529800415, total loss: 0.6690635085105896
25th Epoch, 26440th Step, learning rate = 0.007312082648633894 - Loss: 0.3923589289188385, aux loss1: 0.9549431204795837, 
		 aux loss2: 0.5498473644256592, total loss: 0.8987808227539062
25th Epoch, 26445th Step, learning rate = 0.007311564948523019 - Loss: 0.42465725541114807, aux loss1: 0.9164795875549316, 
		 aux loss2: 0.5864737629890442, total loss: 0.9341906905174255
25th Epoch, 26450th Step, learning rate = 0.007311047244339213 - Loss: 0.4156288504600525, aux loss1: 1.0453951358795166, 
		 aux loss2: 0.6114164590835571, total loss: 0.9738140106201172
25th Epoch, 26455th Step, learning rate = 0.007310529536082124 - Loss: 0.3772886097431183, aux loss1: 0.96560138463974, 
		 aux loss2: 0.5115339159965515, total loss: 0.8715826272964478
25th Epoch, 26460th Step, learning rate = 0.007310011823751397 - Loss: 0.31281518936157227, aux loss1: 0.7344518303871155, 
		 aux loss2: 0.4316530227661133, total loss: 0.7058119773864746
25th Epoch, 26465th Step, learning rate = 0.007309494107346682 - Loss: 0.3124614357948303, aux loss1: 0.7968938946723938, 
		 aux loss2: 0.41884517669677734, total loss: 0.7190676927566528
25th Epoch, 26470th Step, learning rate = 0.007308976386867625 - Loss: 0.2383062243461609, aux loss1: 0.7093712687492371, 
		 aux loss2: 0.3579905033111572, total loss: 0.5943138599395752
25th Epoch, 26475th Step, learning rate = 0.007308458662313874 - Loss: 0.3788513243198395, aux loss1: 1.0511243343353271, 
		 aux loss2: 0.6036427617073059, total loss: 0.9356456995010376
25th Epoch, 26480th Step, learning rate = 0.007307940933685074 - Loss: 0.36530831456184387, aux loss1: 0.8498042225837708, 
		 aux loss2: 0.47977882623672485, total loss: 0.8121611475944519
25th Epoch, 26485th Step, learning rate = 0.007307423200980877 - Loss: 0.31467291712760925, aux loss1: 0.7741383910179138, 
		 aux loss2: 0.43951916694641113, total loss: 0.7227221131324768
25th Epoch, 26490th Step, learning rate = 0.007306905464200923 - Loss: 0.2546466886997223, aux loss1: 0.6997201442718506, 
		 aux loss2: 0.3326900005340576, total loss: 0.597638726234436
25th Epoch, 26495th Step, learning rate = 0.007306387723344868 - Loss: 0.3089711368083954, aux loss1: 0.7579907774925232, 
		 aux loss2: 0.4518243670463562, total loss: 0.7170981168746948
25th Epoch, 26500th Step, learning rate = 0.007305869978412351 - Loss: 0.391984760761261, aux loss1: 1.0374149084091187, 
		 aux loss2: 0.5229867696762085, total loss: 0.9124040007591248
<26500th step>
*************************** Test ***************************
time:3m 16s, 26500th Step, Loss: 0.552689790725708, Mean IoU = 44.000%
************************************************************
25th Epoch, 26505th Step, learning rate = 0.007305352229403022 - Loss: 0.2343120276927948, aux loss1: 0.6575866937637329, 
		 aux loss2: 0.3240562677383423, total loss: 0.561210572719574
25th Epoch, 26510th Step, learning rate = 0.00730483447631653 - Loss: 0.30132585763931274, aux loss1: 0.7406490445137024, 
		 aux loss2: 0.4007554352283478, total loss: 0.683822751045227
25th Epoch, 26515th Step, learning rate = 0.007304316719152517 - Loss: 0.3811616897583008, aux loss1: 0.9608490467071533, 
		 aux loss2: 0.5673636198043823, total loss: 0.8963618874549866
25th Epoch, 26520th Step, learning rate = 0.007303798957910633 - Loss: 0.4497143626213074, aux loss1: 0.9419693946838379, 
		 aux loss2: 0.5865449905395508, total loss: 0.966923177242279
25th Epoch, 26525th Step, learning rate = 0.007303281192590526 - Loss: 0.30931639671325684, aux loss1: 0.8428278565406799, 
		 aux loss2: 0.4608115553855896, total loss: 0.746489405632019
25th Epoch, 26530th Step, learning rate = 0.0073027634231918395 - Loss: 0.24851113557815552, aux loss1: 0.7227669954299927, 
		 aux loss2: 0.3729838728904724, total loss: 0.6145347952842712
25th Epoch, 26535th Step, learning rate = 0.0073022456497142205 - Loss: 0.3144344687461853, aux loss1: 0.7989510297775269, 
		 aux loss2: 0.4509871006011963, total loss: 0.734514594078064
25th Epoch, 26540th Step, learning rate = 0.007301727872157318 - Loss: 0.2860567271709442, aux loss1: 0.7002328038215637, 
		 aux loss2: 0.3618650734424591, total loss: 0.640872597694397
25th Epoch, 26545th Step, learning rate = 0.007301210090520774 - Loss: 0.2828969359397888, aux loss1: 0.8330910801887512, 
		 aux loss2: 0.4130539000034332, total loss: 0.6980458498001099
25th Epoch, 26550th Step, learning rate = 0.007300692304804239 - Loss: 0.26687225699424744, aux loss1: 0.7688685655593872, 
		 aux loss2: 0.3998410403728485, total loss: 0.6574692726135254
25th Epoch, 26555th Step, learning rate = 0.007300174515007359 - Loss: 0.38729819655418396, aux loss1: 1.1094242334365845, 
		 aux loss2: 0.5599890351295471, total loss: 0.9441210627555847
25th Epoch, 26560th Step, learning rate = 0.007299656721129777 - Loss: 0.3432379961013794, aux loss1: 0.8492343425750732, 
		 aux loss2: 0.4483664035797119, total loss: 0.7773548364639282
25th Epoch, 26565th Step, learning rate = 0.007299138923171144 - Loss: 0.252848744392395, aux loss1: 0.7750308513641357, 
		 aux loss2: 0.374302476644516, total loss: 0.635079026222229
25th Epoch, 26570th Step, learning rate = 0.007298621121131102 - Loss: 0.366896390914917, aux loss1: 0.8769168853759766, 
		 aux loss2: 0.5071594715118408, total loss: 0.83283531665802
25th Epoch, 26575th Step, learning rate = 0.0072981033150092975 - Loss: 0.32674890756607056, aux loss1: 0.8608530759811401, 
		 aux loss2: 0.4657652676105499, total loss: 0.7713109254837036
25th Epoch, 26580th Step, learning rate = 0.00729758550480538 - Loss: 0.38835597038269043, aux loss1: 0.9338281154632568, 
		 aux loss2: 0.5294256806373596, total loss: 0.8802747130393982
25th Epoch, 26585th Step, learning rate = 0.007297067690518993 - Loss: 0.3241647183895111, aux loss1: 0.8504629135131836, 
		 aux loss2: 0.4434424042701721, total loss: 0.7566806077957153
25th Epoch, 26590th Step, learning rate = 0.0072965498721497815 - Loss: 0.3254985213279724, aux loss1: 0.800766110420227, 
		 aux loss2: 0.4399368464946747, total loss: 0.7417030930519104
25th Epoch, 26595th Step, learning rate = 0.007296032049697393 - Loss: 0.31403517723083496, aux loss1: 0.7315957546234131, 
		 aux loss2: 0.40981754660606384, total loss: 0.6974409222602844
25th Epoch, 26600th Step, learning rate = 0.007295514223161472 - Loss: 0.43620559573173523, aux loss1: 0.9759887456893921, 
		 aux loss2: 0.6166207194328308, total loss: 0.9756505489349365
<26600th step>
*************************** Test ***************************
time:3m 18s, 26600th Step, Loss: 0.5728208422660828, Mean IoU = 45.141%
************************************************************
25th Epoch, 26605th Step, learning rate = 0.007294996392541665 - Loss: 0.37611714005470276, aux loss1: 1.0301334857940674, 
		 aux loss2: 0.5325233340263367, total loss: 0.8981665372848511
25th Epoch, 26610th Step, learning rate = 0.007294478557837619 - Loss: 0.39973750710487366, aux loss1: 1.0956884622573853, 
		 aux loss2: 0.6168990731239319, total loss: 0.9752037525177002
25th Epoch, 26615th Step, learning rate = 0.007293960719048976 - Loss: 0.2556746304035187, aux loss1: 0.7350185513496399, 
		 aux loss2: 0.3734036684036255, total loss: 0.6255416870117188
25th Epoch, 26620th Step, learning rate = 0.007293442876175386 - Loss: 0.38454827666282654, aux loss1: 0.914667010307312, 
		 aux loss2: 0.5307134985923767, total loss: 0.8712338209152222
25th Epoch, 26625th Step, learning rate = 0.007292925029216492 - Loss: 0.34006467461586, aux loss1: 0.7954450845718384, 
		 aux loss2: 0.43808525800704956, total loss: 0.7539323568344116
25th Epoch, 26630th Step, learning rate = 0.007292407178171939 - Loss: 0.40871530771255493, aux loss1: 0.9203521609306335, 
		 aux loss2: 0.5434576272964478, total loss: 0.9022040367126465
25th Epoch, 26635th Step, learning rate = 0.007291889323041374 - Loss: 0.3290388286113739, aux loss1: 0.8091748356819153, 
		 aux loss2: 0.44614118337631226, total loss: 0.7502477765083313
25th Epoch, 26640th Step, learning rate = 0.007291371463824441 - Loss: 0.2981005012989044, aux loss1: 0.6645545363426208, 
		 aux loss2: 0.38068825006484985, total loss: 0.6497421860694885
25th Epoch, 26645th Step, learning rate = 0.007290853600520786 - Loss: 0.3192138969898224, aux loss1: 0.8381026387214661, 
		 aux loss2: 0.44537001848220825, total loss: 0.7487927675247192
25th Epoch, 26650th Step, learning rate = 0.007290335733130056 - Loss: 0.30324840545654297, aux loss1: 0.786479115486145, 
		 aux loss2: 0.4058064818382263, total loss: 0.701514720916748
25th Epoch, 26655th Step, learning rate = 0.007289817861651892 - Loss: 0.3152720630168915, aux loss1: 0.814274251461029, 
		 aux loss2: 0.44255590438842773, total loss: 0.7365766763687134
25th Epoch, 26660th Step, learning rate = 0.007289299986085941 - Loss: 0.37670958042144775, aux loss1: 0.9730185866355896, 
		 aux loss2: 0.5611147284507751, total loss: 0.8930610418319702
25th Epoch, 26665th Step, learning rate = 0.007288782106431849 - Loss: 0.3703119456768036, aux loss1: 1.0975019931793213, 
		 aux loss2: 0.5755816102027893, total loss: 0.9297952055931091
25th Epoch, 26670th Step, learning rate = 0.007288264222689259 - Loss: 0.29056841135025024, aux loss1: 0.7773281335830688, 
		 aux loss2: 0.3984941244125366, total loss: 0.6831645369529724
25th Epoch, 26675th Step, learning rate = 0.00728774633485782 - Loss: 0.31780698895454407, aux loss1: 0.9134384393692017, 
		 aux loss2: 0.46690213680267334, total loss: 0.7785993814468384
25th Epoch, 26680th Step, learning rate = 0.007287228442937172 - Loss: 0.3199944496154785, aux loss1: 0.8677398562431335, 
		 aux loss2: 0.48803648352622986, total loss: 0.7755310535430908
25th Epoch, 26685th Step, learning rate = 0.007286710546926962 - Loss: 0.3046479821205139, aux loss1: 0.7749588489532471, 
		 aux loss2: 0.4131118357181549, total loss: 0.7023804187774658
25th Epoch, 26690th Step, learning rate = 0.0072861926468268355 - Loss: 0.5067132711410522, aux loss1: 1.1393311023712158, 
		 aux loss2: 0.6744688749313354, total loss: 1.118300199508667
25th Epoch, 26695th Step, learning rate = 0.007285674742636436 - Loss: 0.31853991746902466, aux loss1: 0.759520947933197, 
		 aux loss2: 0.4414524435997009, total loss: 0.7229771614074707
25th Epoch, 26700th Step, learning rate = 0.007285156834355408 - Loss: 0.41474711894989014, aux loss1: 1.0468693971633911, 
		 aux loss2: 0.6096676588058472, total loss: 0.9726749658584595
<26700th step>
*************************** Test ***************************
time:3m 15s, 26700th Step, Loss: 0.5735599994659424, Mean IoU = 43.399%
************************************************************
25th Epoch, 26705th Step, learning rate = 0.007284638921983397 - Loss: 0.3403097689151764, aux loss1: 0.8079275488853455, 
		 aux loss2: 0.462837815284729, total loss: 0.7678231596946716
25th Epoch, 26710th Step, learning rate = 0.007284121005520047 - Loss: 0.34647518396377563, aux loss1: 0.8536826968193054, 
		 aux loss2: 0.45970433950424194, total loss: 0.7864617705345154
25th Epoch, 26715th Step, learning rate = 0.0072836030849650025 - Loss: 0.32093414664268494, aux loss1: 0.7493440508842468, 
		 aux loss2: 0.4055190086364746, total loss: 0.7079449892044067
25th Epoch, 26720th Step, learning rate = 0.007283085160317908 - Loss: 0.26218271255493164, aux loss1: 0.7301520705223083, 
		 aux loss2: 0.33818286657333374, total loss: 0.61650151014328
25th Epoch, 26725th Step, learning rate = 0.007282567231578408 - Loss: 0.46511390805244446, aux loss1: 1.0925719738006592, 
		 aux loss2: 0.6165805459022522, total loss: 1.0395177602767944
25th Epoch, 26730th Step, learning rate = 0.007282049298746145 - Loss: 0.35627567768096924, aux loss1: 0.902091383934021, 
		 aux loss2: 0.4888935685157776, total loss: 0.8224605321884155
25th Epoch, 26735th Step, learning rate = 0.007281531361820767 - Loss: 0.35447919368743896, aux loss1: 0.9085220098495483, 
		 aux loss2: 0.500571608543396, total loss: 0.8272644281387329
25th Epoch, 26740th Step, learning rate = 0.007281013420801913 - Loss: 0.3583432734012604, aux loss1: 0.8612540364265442, 
		 aux loss2: 0.4899214208126068, total loss: 0.8126880526542664
25th Epoch, 26745th Step, learning rate = 0.007280495475689232 - Loss: 0.2837647497653961, aux loss1: 0.7141894698143005, 
		 aux loss2: 0.3910967707633972, total loss: 0.6544603109359741
25th Epoch, 26750th Step, learning rate = 0.007279977526482365 - Loss: 0.2974793016910553, aux loss1: 0.7605693936347961, 
		 aux loss2: 0.436699241399765, total loss: 0.7003298401832581
25th Epoch, 26755th Step, learning rate = 0.007279459573180956 - Loss: 0.4699251353740692, aux loss1: 1.0296350717544556, 
		 aux loss2: 0.6356343030929565, total loss: 1.033069372177124
25th Epoch, 26760th Step, learning rate = 0.007278941615784652 - Loss: 0.33092278242111206, aux loss1: 0.756952702999115, 
		 aux loss2: 0.3993246853351593, total loss: 0.7177385091781616
25th Epoch, 26765th Step, learning rate = 0.007278423654293094 - Loss: 0.3051614761352539, aux loss1: 0.7155243754386902, 
		 aux loss2: 0.40649768710136414, total loss: 0.6824178695678711
25th Epoch, 26770th Step, learning rate = 0.007277905688705926 - Loss: 0.306734174489975, aux loss1: 0.8672106862068176, 
		 aux loss2: 0.4354579448699951, total loss: 0.7410805821418762
25th Epoch, 26775th Step, learning rate = 0.007277387719022793 - Loss: 0.37399953603744507, aux loss1: 0.8965693712234497, 
		 aux loss2: 0.5549481511116028, total loss: 0.8649495840072632
26th Epoch, 26780th Step, learning rate = 0.007276869745243338 - Loss: 0.47422605752944946, aux loss1: 1.1603444814682007, 
		 aux loss2: 0.6829302310943604, total loss: 1.0955015420913696
26th Epoch, 26785th Step, learning rate = 0.007276351767367204 - Loss: 0.28552258014678955, aux loss1: 0.7396624088287354, 
		 aux loss2: 0.4028230309486389, total loss: 0.6685505509376526
26th Epoch, 26790th Step, learning rate = 0.007275833785394036 - Loss: 0.28544938564300537, aux loss1: 0.7810190320014954, 
		 aux loss2: 0.4168701767921448, total loss: 0.6865031719207764
26th Epoch, 26795th Step, learning rate = 0.007275315799323474 - Loss: 0.3468453884124756, aux loss1: 0.8249216079711914, 
		 aux loss2: 0.46001747250556946, total loss: 0.7783288359642029
26th Epoch, 26800th Step, learning rate = 0.007274797809155167 - Loss: 0.2989560067653656, aux loss1: 0.8365216851234436, 
		 aux loss2: 0.4361964464187622, total loss: 0.7243911027908325
<26800th step>
*************************** Test ***************************
time:3m 15s, 26800th Step, Loss: 0.544026255607605, Mean IoU = 44.913%
************************************************************
26th Epoch, 26805th Step, learning rate = 0.007274279814888754 - Loss: 0.2349012792110443, aux loss1: 0.7076842188835144, 
		 aux loss2: 0.33397072553634644, total loss: 0.5807948708534241
26th Epoch, 26810th Step, learning rate = 0.00727376181652388 - Loss: 0.24473971128463745, aux loss1: 0.6980286240577698, 
		 aux loss2: 0.32608872652053833, total loss: 0.5845837593078613
26th Epoch, 26815th Step, learning rate = 0.007273243814060189 - Loss: 0.2701212465763092, aux loss1: 0.6568068265914917, 
		 aux loss2: 0.3489554226398468, total loss: 0.6067454814910889
26th Epoch, 26820th Step, learning rate = 0.007272725807497322 - Loss: 0.2881760895252228, aux loss1: 0.8037161827087402, 
		 aux loss2: 0.4132173955440521, total loss: 0.6945779323577881
26th Epoch, 26825th Step, learning rate = 0.007272207796834925 - Loss: 0.34929192066192627, aux loss1: 0.9030318260192871, 
		 aux loss2: 0.5342431664466858, total loss: 0.8338987231254578
26th Epoch, 26830th Step, learning rate = 0.007271689782072638 - Loss: 0.3472847640514374, aux loss1: 0.7859787344932556, 
		 aux loss2: 0.45717161893844604, total loss: 0.7659470438957214
26th Epoch, 26835th Step, learning rate = 0.007271171763210106 - Loss: 0.26314157247543335, aux loss1: 0.7357956171035767, 
		 aux loss2: 0.3762218654155731, total loss: 0.6343690156936646
26th Epoch, 26840th Step, learning rate = 0.007270653740246971 - Loss: 0.2520063817501068, aux loss1: 0.7105182409286499, 
		 aux loss2: 0.363468736410141, total loss: 0.6105493307113647
26th Epoch, 26845th Step, learning rate = 0.007270135713182877 - Loss: 0.2984057664871216, aux loss1: 0.8196326494216919, 
		 aux loss2: 0.4319840669631958, total loss: 0.7170891761779785
26th Epoch, 26850th Step, learning rate = 0.007269617682017465 - Loss: 0.3627730906009674, aux loss1: 0.9567480683326721, 
		 aux loss2: 0.5283178687095642, total loss: 0.8611246943473816
26th Epoch, 26855th Step, learning rate = 0.007269099646750381 - Loss: 0.25512728095054626, aux loss1: 0.776370644569397, 
		 aux loss2: 0.383339524269104, total loss: 0.6413742899894714
26th Epoch, 26860th Step, learning rate = 0.0072685816073812665 - Loss: 0.26038774847984314, aux loss1: 0.7002826929092407, 
		 aux loss2: 0.37076741456985474, total loss: 0.6187795400619507
26th Epoch, 26865th Step, learning rate = 0.007268063563909759 - Loss: 0.274785578250885, aux loss1: 0.8391395807266235, 
		 aux loss2: 0.4254204034805298, total loss: 0.6966956257820129
26th Epoch, 26870th Step, learning rate = 0.007267545516335509 - Loss: 0.3062626123428345, aux loss1: 0.9996489882469177, 
		 aux loss2: 0.46180346608161926, total loss: 0.7908787131309509
26th Epoch, 26875th Step, learning rate = 0.007267027464658155 - Loss: 0.35518842935562134, aux loss1: 0.9785408973693848, 
		 aux loss2: 0.5267517566680908, total loss: 0.859451413154602
26th Epoch, 26880th Step, learning rate = 0.007266509408877341 - Loss: 0.2913813591003418, aux loss1: 0.774042546749115, 
		 aux loss2: 0.4300316870212555, total loss: 0.6956068277359009
26th Epoch, 26885th Step, learning rate = 0.007265991348992707 - Loss: 0.3739449381828308, aux loss1: 0.8898085355758667, 
		 aux loss2: 0.5164888501167297, total loss: 0.8474830389022827
26th Epoch, 26890th Step, learning rate = 0.007265473285003899 - Loss: 0.35442134737968445, aux loss1: 0.9583516120910645, 
		 aux loss2: 0.4964632987976074, total loss: 0.840512216091156
26th Epoch, 26895th Step, learning rate = 0.007264955216910555 - Loss: 0.34494748711586, aux loss1: 0.8524817228317261, 
		 aux loss2: 0.4564771354198456, total loss: 0.7832828760147095
26th Epoch, 26900th Step, learning rate = 0.0072644371447123214 - Loss: 0.32780519127845764, aux loss1: 0.8367761969566345, 
		 aux loss2: 0.4691091775894165, total loss: 0.7664817571640015
<26900th step>
*************************** Test ***************************
time:3m 14s, 26900th Step, Loss: 0.5514440536499023, Mean IoU = 44.874%
************************************************************
26th Epoch, 26905th Step, learning rate = 0.0072639190684088365 - Loss: 0.2817298471927643, aux loss1: 0.8650655746459961, 
		 aux loss2: 0.42256730794906616, total loss: 0.7102764248847961
26th Epoch, 26910th Step, learning rate = 0.007263400987999745 - Loss: 0.35416337847709656, aux loss1: 0.8964180946350098, 
		 aux loss2: 0.5200521945953369, total loss: 0.8311097025871277
26th Epoch, 26915th Step, learning rate = 0.00726288290348469 - Loss: 0.3217834532260895, aux loss1: 0.8899552226066589, 
		 aux loss2: 0.46935003995895386, total loss: 0.7765100598335266
26th Epoch, 26920th Step, learning rate = 0.007262364814863309 - Loss: 0.42772024869918823, aux loss1: 0.9586469531059265, 
		 aux loss2: 0.5726898312568665, total loss: 0.9443902969360352
26th Epoch, 26925th Step, learning rate = 0.00726184672213525 - Loss: 0.2716432511806488, aux loss1: 0.7558960914611816, 
		 aux loss2: 0.42420580983161926, total loss: 0.6680943965911865
26th Epoch, 26930th Step, learning rate = 0.007261328625300149 - Loss: 0.346484899520874, aux loss1: 0.7656297087669373, 
		 aux loss2: 0.4537751376628876, total loss: 0.7576838731765747
26th Epoch, 26935th Step, learning rate = 0.007260810524357653 - Loss: 0.2910623252391815, aux loss1: 0.8703001737594604, 
		 aux loss2: 0.4194137454032898, total loss: 0.719917893409729
26th Epoch, 26940th Step, learning rate = 0.007260292419307402 - Loss: 0.23740673065185547, aux loss1: 0.7040318250656128, 
		 aux loss2: 0.335275262594223, total loss: 0.5827263593673706
26th Epoch, 26945th Step, learning rate = 0.007259774310149034 - Loss: 0.3363225758075714, aux loss1: 0.901634931564331, 
		 aux loss2: 0.49673521518707275, total loss: 0.8055071830749512
26th Epoch, 26950th Step, learning rate = 0.007259256196882196 - Loss: 0.27776673436164856, aux loss1: 0.7776974439620972, 
		 aux loss2: 0.3922489583492279, total loss: 0.6679755449295044
26th Epoch, 26955th Step, learning rate = 0.007258738079506527 - Loss: 0.3996131718158722, aux loss1: 0.9389371275901794, 
		 aux loss2: 0.5496277213096619, total loss: 0.9011453986167908
26th Epoch, 26960th Step, learning rate = 0.007258219958021669 - Loss: 0.3124101758003235, aux loss1: 0.8119198679924011, 
		 aux loss2: 0.4362565875053406, total loss: 0.7304887771606445
26th Epoch, 26965th Step, learning rate = 0.007257701832427263 - Loss: 0.30508899688720703, aux loss1: 0.7552048563957214, 
		 aux loss2: 0.40489524602890015, total loss: 0.6936085820198059
26th Epoch, 26970th Step, learning rate = 0.007257183702722951 - Loss: 0.29634734988212585, aux loss1: 0.8747308254241943, 
		 aux loss2: 0.4339369833469391, total loss: 0.7323414087295532
26th Epoch, 26975th Step, learning rate = 0.0072566655689083725 - Loss: 0.4048008918762207, aux loss1: 1.0770049095153809, 
		 aux loss2: 0.5632612109184265, total loss: 0.9532068967819214
26th Epoch, 26980th Step, learning rate = 0.007256147430983173 - Loss: 0.4051699936389923, aux loss1: 1.104171872138977, 
		 aux loss2: 0.6523158550262451, total loss: 0.9973479509353638
26th Epoch, 26985th Step, learning rate = 0.007255629288946991 - Loss: 0.34064486622810364, aux loss1: 0.8920831084251404, 
		 aux loss2: 0.4673610031604767, total loss: 0.7952142357826233
26th Epoch, 26990th Step, learning rate = 0.0072551111427994665 - Loss: 0.3676668107509613, aux loss1: 0.9999842643737793, 
		 aux loss2: 0.5677953362464905, total loss: 0.8947802782058716
26th Epoch, 26995th Step, learning rate = 0.007254592992540244 - Loss: 0.3923567533493042, aux loss1: 0.9327326416969299, 
		 aux loss2: 0.5411069989204407, total loss: 0.8886194229125977
26th Epoch, 27000th Step, learning rate = 0.007254074838168961 - Loss: 0.30870798230171204, aux loss1: 0.8744202852249146, 
		 aux loss2: 0.46065255999565125, total loss: 0.7552950978279114
<27000th step>
*************************** Test ***************************
time:3m 20s, 27000th Step, Loss: 0.532758891582489, Mean IoU = 44.469%
************************************************************
26th Epoch, 27005th Step, learning rate = 0.007253556679685261 - Loss: 0.31266507506370544, aux loss1: 0.791733980178833, 
		 aux loss2: 0.44277286529541016, total loss: 0.7272944450378418
26th Epoch, 27010th Step, learning rate = 0.007253038517088784 - Loss: 0.4395141899585724, aux loss1: 1.075261116027832, 
		 aux loss2: 0.6438713073730469, total loss: 1.0196410417556763
26th Epoch, 27015th Step, learning rate = 0.00725252035037917 - Loss: 0.38277581334114075, aux loss1: 0.9490365982055664, 
		 aux loss2: 0.557642936706543, total loss: 0.8905439376831055
26th Epoch, 27020th Step, learning rate = 0.007252002179556062 - Loss: 0.3988231122493744, aux loss1: 0.975744366645813, 
		 aux loss2: 0.5474920272827148, total loss: 0.9105432629585266
26th Epoch, 27025th Step, learning rate = 0.007251484004619099 - Loss: 0.31624147295951843, aux loss1: 0.8423035740852356, 
		 aux loss2: 0.45083537697792053, total loss: 0.7492666840553284
26th Epoch, 27030th Step, learning rate = 0.007250965825567921 - Loss: 0.3612558841705322, aux loss1: 0.9977047443389893, 
		 aux loss2: 0.5473074316978455, total loss: 0.8794902563095093
26th Epoch, 27035th Step, learning rate = 0.007250447642402172 - Loss: 0.3908117115497589, aux loss1: 0.9230961799621582, 
		 aux loss2: 0.5242663621902466, total loss: 0.8774471282958984
26th Epoch, 27040th Step, learning rate = 0.00724992945512149 - Loss: 0.32540011405944824, aux loss1: 0.8266259431838989, 
		 aux loss2: 0.46101653575897217, total loss: 0.7577945590019226
26th Epoch, 27045th Step, learning rate = 0.007249411263725515 - Loss: 0.2910517454147339, aux loss1: 0.7735916376113892, 
		 aux loss2: 0.42206016182899475, total loss: 0.6919533014297485
26th Epoch, 27050th Step, learning rate = 0.00724889306821389 - Loss: 0.3804224133491516, aux loss1: 0.8598334193229675, 
		 aux loss2: 0.5069575905799866, total loss: 0.841155469417572
26th Epoch, 27055th Step, learning rate = 0.007248374868586252 - Loss: 0.24822688102722168, aux loss1: 0.7273889183998108, 
		 aux loss2: 0.3550322651863098, total loss: 0.6084564924240112
26th Epoch, 27060th Step, learning rate = 0.007247856664842244 - Loss: 0.5044439435005188, aux loss1: 1.105455994606018, 
		 aux loss2: 0.7280210256576538, total loss: 1.1272891759872437
26th Epoch, 27065th Step, learning rate = 0.007247338456981506 - Loss: 0.25502172112464905, aux loss1: 0.5779701471328735, 
		 aux loss2: 0.32574036717414856, total loss: 0.558708906173706
26th Epoch, 27070th Step, learning rate = 0.007246820245003677 - Loss: 0.37181803584098816, aux loss1: 0.8093904256820679, 
		 aux loss2: 0.49128296971321106, total loss: 0.8111483454704285
26th Epoch, 27075th Step, learning rate = 0.007246302028908398 - Loss: 0.35509833693504333, aux loss1: 0.7676867842674255, 
		 aux loss2: 0.45290812849998474, total loss: 0.7665676474571228
26th Epoch, 27080th Step, learning rate = 0.00724578380869531 - Loss: 0.2801341116428375, aux loss1: 0.7941151857376099, 
		 aux loss2: 0.391781747341156, total loss: 0.6750813722610474
26th Epoch, 27085th Step, learning rate = 0.007245265584364051 - Loss: 0.3449113965034485, aux loss1: 0.833687961101532, 
		 aux loss2: 0.4803457260131836, total loss: 0.7871561050415039
26th Epoch, 27090th Step, learning rate = 0.007244747355914262 - Loss: 0.3041168451309204, aux loss1: 0.8202307820320129, 
		 aux loss2: 0.4216431677341461, total loss: 0.7188433408737183
26th Epoch, 27095th Step, learning rate = 0.007244229123345583 - Loss: 0.3462775945663452, aux loss1: 0.9554640054702759, 
		 aux loss2: 0.4987606704235077, total loss: 0.832421064376831
26th Epoch, 27100th Step, learning rate = 0.007243710886657654 - Loss: 0.3640860319137573, aux loss1: 0.7423643469810486, 
		 aux loss2: 0.4692974090576172, total loss: 0.7745143175125122
<27100th step>
*************************** Test ***************************
time:3m 15s, 27100th Step, Loss: 0.5433458089828491, Mean IoU = 45.407%
************************************************************
26th Epoch, 27105th Step, learning rate = 0.0072431926458501154 - Loss: 0.376896470785141, aux loss1: 0.8276989459991455, 
		 aux loss2: 0.4792174696922302, total loss: 0.8168931603431702
26th Epoch, 27110th Step, learning rate = 0.007242674400922604 - Loss: 0.31316259503364563, aux loss1: 0.7982145547866821, 
		 aux loss2: 0.43642187118530273, total loss: 0.7271957397460938
26th Epoch, 27115th Step, learning rate = 0.007242156151874763 - Loss: 0.30834946036338806, aux loss1: 0.731678307056427, 
		 aux loss2: 0.4131079316139221, total loss: 0.6930961608886719
26th Epoch, 27120th Step, learning rate = 0.007241637898706231 - Loss: 0.30378463864326477, aux loss1: 0.780163586139679, 
		 aux loss2: 0.4116801917552948, total loss: 0.7025057673454285
26th Epoch, 27125th Step, learning rate = 0.007241119641416647 - Loss: 0.5020069479942322, aux loss1: 1.0625929832458496, 
		 aux loss2: 0.6399222612380981, total loss: 1.0767537355422974
26th Epoch, 27130th Step, learning rate = 0.00724060138000565 - Loss: 0.3358142375946045, aux loss1: 0.8951583504676819, 
		 aux loss2: 0.4982587397098541, total loss: 0.803665280342102
26th Epoch, 27135th Step, learning rate = 0.007240083114472882 - Loss: 0.3372211456298828, aux loss1: 0.9108607172966003, 
		 aux loss2: 0.4786037802696228, total loss: 0.8019208908081055
26th Epoch, 27140th Step, learning rate = 0.007239564844817978 - Loss: 0.33853888511657715, aux loss1: 0.797386884689331, 
		 aux loss2: 0.459928035736084, total loss: 0.7617262005805969
26th Epoch, 27145th Step, learning rate = 0.007239046571040582 - Loss: 0.2876269221305847, aux loss1: 0.7173715233802795, 
		 aux loss2: 0.3792979121208191, total loss: 0.6545575261116028
27th Epoch, 27150th Step, learning rate = 0.007238528293140331 - Loss: 0.257448673248291, aux loss1: 0.7735622525215149, 
		 aux loss2: 0.40804094076156616, total loss: 0.6527337431907654
27th Epoch, 27155th Step, learning rate = 0.007238010011116862 - Loss: 0.31770628690719604, aux loss1: 0.9061896204948425, 
		 aux loss2: 0.44760802388191223, total loss: 0.768606424331665
27th Epoch, 27160th Step, learning rate = 0.007237491724969819 - Loss: 0.3419393002986908, aux loss1: 0.8442535996437073, 
		 aux loss2: 0.4912411868572235, total loss: 0.7917118668556213
27th Epoch, 27165th Step, learning rate = 0.007236973434698837 - Loss: 0.42009344696998596, aux loss1: 0.9767977595329285, 
		 aux loss2: 0.5568256378173828, total loss: 0.9358630776405334
27th Epoch, 27170th Step, learning rate = 0.007236455140303557 - Loss: 0.3813164532184601, aux loss1: 1.0901800394058228, 
		 aux loss2: 0.5574723482131958, total loss: 0.9313594102859497
27th Epoch, 27175th Step, learning rate = 0.007235936841783618 - Loss: 0.27192315459251404, aux loss1: 0.8685274720191956, 
		 aux loss2: 0.40904930233955383, total loss: 0.696101188659668
27th Epoch, 27180th Step, learning rate = 0.007235418539138659 - Loss: 0.31224849820137024, aux loss1: 0.8507601022720337, 
		 aux loss2: 0.4804824888706207, total loss: 0.7596695423126221
27th Epoch, 27185th Step, learning rate = 0.007234900232368316 - Loss: 0.2870086431503296, aux loss1: 0.7955159544944763, 
		 aux loss2: 0.44510430097579956, total loss: 0.7037051916122437
27th Epoch, 27190th Step, learning rate = 0.0072343819214722325 - Loss: 0.42486849427223206, aux loss1: 1.1010620594024658, 
		 aux loss2: 0.6322738528251648, total loss: 1.008096694946289
27th Epoch, 27195th Step, learning rate = 0.007233863606450044 - Loss: 0.31107839941978455, aux loss1: 0.7632225751876831, 
		 aux loss2: 0.4334415793418884, total loss: 0.7134218215942383
27th Epoch, 27200th Step, learning rate = 0.00723334528730139 - Loss: 0.31778684258461, aux loss1: 0.7782953381538391, 
		 aux loss2: 0.442935049533844, total loss: 0.7284494638442993
<27200th step>
*************************** Test ***************************
time:3m 17s, 27200th Step, Loss: 0.5225622057914734, Mean IoU = 44.062%
************************************************************
27th Epoch, 27205th Step, learning rate = 0.007232826964025909 - Loss: 0.2706294357776642, aux loss1: 0.723138689994812, 
		 aux loss2: 0.37077397108078003, total loss: 0.6358806490898132
27th Epoch, 27210th Step, learning rate = 0.007232308636623238 - Loss: 0.3286246657371521, aux loss1: 0.9251232147216797, 
		 aux loss2: 0.4896896183490753, total loss: 0.8020374774932861
27th Epoch, 27215th Step, learning rate = 0.007231790305093019 - Loss: 0.28483855724334717, aux loss1: 0.7955004572868347, 
		 aux loss2: 0.4057358205318451, total loss: 0.6857830286026001
27th Epoch, 27220th Step, learning rate = 0.007231271969434889 - Loss: 0.32255658507347107, aux loss1: 0.82436203956604, 
		 aux loss2: 0.4421638548374176, total loss: 0.7467308044433594
27th Epoch, 27225th Step, learning rate = 0.007230753629648483 - Loss: 0.2813383936882019, aux loss1: 0.795920193195343, 
		 aux loss2: 0.42791369557380676, total loss: 0.691279947757721
27th Epoch, 27230th Step, learning rate = 0.007230235285733445 - Loss: 0.3549558222293854, aux loss1: 1.0095618963241577, 
		 aux loss2: 0.5542719960212708, total loss: 0.8795331716537476
27th Epoch, 27235th Step, learning rate = 0.007229716937689409 - Loss: 0.33458706736564636, aux loss1: 0.844697117805481, 
		 aux loss2: 0.47661668062210083, total loss: 0.7786428928375244
27th Epoch, 27240th Step, learning rate = 0.007229198585516015 - Loss: 0.49793684482574463, aux loss1: 1.036331057548523, 
		 aux loss2: 0.6587997674942017, total loss: 1.072356104850769
27th Epoch, 27245th Step, learning rate = 0.007228680229212901 - Loss: 0.3644550144672394, aux loss1: 0.9035377502441406, 
		 aux loss2: 0.5159125328063965, total loss: 0.8418813943862915
27th Epoch, 27250th Step, learning rate = 0.007228161868779704 - Loss: 0.40491974353790283, aux loss1: 1.0301010608673096, 
		 aux loss2: 0.5779047608375549, total loss: 0.9451119303703308
27th Epoch, 27255th Step, learning rate = 0.007227643504216063 - Loss: 0.28767129778862, aux loss1: 0.678490936756134, 
		 aux loss2: 0.371526300907135, total loss: 0.6398290991783142
27th Epoch, 27260th Step, learning rate = 0.007227125135521615 - Loss: 0.27033531665802, aux loss1: 0.7133939266204834, 
		 aux loss2: 0.3916809558868408, total loss: 0.6410259008407593
27th Epoch, 27265th Step, learning rate = 0.007226606762695998 - Loss: 0.30752798914909363, aux loss1: 0.8676457405090332, 
		 aux loss2: 0.46274444460868835, total loss: 0.7529195547103882
27th Epoch, 27270th Step, learning rate = 0.007226088385738852 - Loss: 0.4310523271560669, aux loss1: 0.9953431487083435, 
		 aux loss2: 0.5900529623031616, total loss: 0.9656764268875122
27th Epoch, 27275th Step, learning rate = 0.007225570004649813 - Loss: 0.3145582973957062, aux loss1: 0.8070278763771057, 
		 aux loss2: 0.4213472306728363, total loss: 0.7252055406570435
27th Epoch, 27280th Step, learning rate = 0.007225051619428517 - Loss: 0.476808100938797, aux loss1: 1.0158497095108032, 
		 aux loss2: 0.6301381587982178, total loss: 1.0336183309555054
27th Epoch, 27285th Step, learning rate = 0.007224533230074604 - Loss: 0.2900168299674988, aux loss1: 0.7530814409255981, 
		 aux loss2: 0.3613913059234619, total loss: 0.660497784614563
27th Epoch, 27290th Step, learning rate = 0.007224014836587712 - Loss: 0.30150604248046875, aux loss1: 0.713886022567749, 
		 aux loss2: 0.38940203189849854, total loss: 0.6714326739311218
27th Epoch, 27295th Step, learning rate = 0.007223496438967477 - Loss: 0.3585355877876282, aux loss1: 0.8974751830101013, 
		 aux loss2: 0.481118381023407, total loss: 0.8202255368232727
27th Epoch, 27300th Step, learning rate = 0.0072229780372135375 - Loss: 0.3339264988899231, aux loss1: 0.8676252365112305, 
		 aux loss2: 0.4922509491443634, total loss: 0.7911144495010376
<27300th step>
*************************** Test ***************************
time:3m 18s, 27300th Step, Loss: 0.5256817936897278, Mean IoU = 43.386%
************************************************************
27th Epoch, 27305th Step, learning rate = 0.00722245963132553 - Loss: 0.4198252260684967, aux loss1: 0.9428457617759705, 
		 aux loss2: 0.5739469528198242, total loss: 0.9322577714920044
27th Epoch, 27310th Step, learning rate = 0.007221941221303091 - Loss: 0.34846559166908264, aux loss1: 0.9171067476272583, 
		 aux loss2: 0.5087382793426514, total loss: 0.8270929455757141
27th Epoch, 27315th Step, learning rate = 0.00722142280714586 - Loss: 0.35143738985061646, aux loss1: 1.0254367589950562, 
		 aux loss2: 0.5137046575546265, total loss: 0.8645503520965576
27th Epoch, 27320th Step, learning rate = 0.007220904388853473 - Loss: 0.31192177534103394, aux loss1: 0.7176949977874756, 
		 aux loss2: 0.4116820991039276, total loss: 0.6919031143188477
27th Epoch, 27325th Step, learning rate = 0.0072203859664255665 - Loss: 0.3287965953350067, aux loss1: 0.7850330471992493, 
		 aux loss2: 0.43771031498908997, total loss: 0.7393906116485596
27th Epoch, 27330th Step, learning rate = 0.00721986753986178 - Loss: 0.40771618485450745, aux loss1: 1.0573536157608032, 
		 aux loss2: 0.6080656051635742, total loss: 0.9681485295295715
27th Epoch, 27335th Step, learning rate = 0.0072193491091617455 - Loss: 0.3383027911186218, aux loss1: 0.9309285879135132, 
		 aux loss2: 0.5357424020767212, total loss: 0.8318783044815063
27th Epoch, 27340th Step, learning rate = 0.007218830674325106 - Loss: 0.39769354462623596, aux loss1: 0.9718742966651917, 
		 aux loss2: 0.5863690972328186, total loss: 0.923803448677063
27th Epoch, 27345th Step, learning rate = 0.007218312235351496 - Loss: 0.2495238333940506, aux loss1: 0.6916959881782532, 
		 aux loss2: 0.3647300899028778, total loss: 0.602924644947052
27th Epoch, 27350th Step, learning rate = 0.00721779379224055 - Loss: 0.3236459791660309, aux loss1: 0.8103154897689819, 
		 aux loss2: 0.47056150436401367, total loss: 0.7549652457237244
27th Epoch, 27355th Step, learning rate = 0.00721727534499191 - Loss: 0.4835844933986664, aux loss1: 0.992979884147644, 
		 aux loss2: 0.6416293978691101, total loss: 1.038130283355713
27th Epoch, 27360th Step, learning rate = 0.007216756893605207 - Loss: 0.2713959813117981, aux loss1: 0.7860044240951538, 
		 aux loss2: 0.3910874128341675, total loss: 0.6636322736740112
27th Epoch, 27365th Step, learning rate = 0.007216238438080079 - Loss: 0.2628387212753296, aux loss1: 0.7049815654754639, 
		 aux loss2: 0.3717513084411621, total loss: 0.6230337023735046
27th Epoch, 27370th Step, learning rate = 0.007215719978416167 - Loss: 0.33130893111228943, aux loss1: 0.8505644202232361, 
		 aux loss2: 0.49563154578208923, total loss: 0.784730851650238
27th Epoch, 27375th Step, learning rate = 0.007215201514613102 - Loss: 0.3026142120361328, aux loss1: 0.7791720628738403, 
		 aux loss2: 0.4020277261734009, total loss: 0.6971769332885742
27th Epoch, 27380th Step, learning rate = 0.007214683046670524 - Loss: 0.2567813992500305, aux loss1: 0.9338014125823975, 
		 aux loss2: 0.4225892126560211, total loss: 0.7059575319290161
27th Epoch, 27385th Step, learning rate = 0.007214164574588069 - Loss: 0.3232690691947937, aux loss1: 1.0297956466674805, 
		 aux loss2: 0.5163731575012207, total loss: 0.8387570381164551
27th Epoch, 27390th Step, learning rate = 0.00721364609836537 - Loss: 0.29904526472091675, aux loss1: 0.7501099705696106, 
		 aux loss2: 0.39265379309654236, total loss: 0.6811397671699524
27th Epoch, 27395th Step, learning rate = 0.007213127618002068 - Loss: 0.31656593084335327, aux loss1: 0.8818646669387817, 
		 aux loss2: 0.48073846101760864, total loss: 0.7734207510948181
27th Epoch, 27400th Step, learning rate = 0.007212609133497797 - Loss: 0.2581900954246521, aux loss1: 0.7401770353317261, 
		 aux loss2: 0.3732203245162964, total loss: 0.6295313239097595
<27400th step>
*************************** Test ***************************
time:3m 15s, 27400th Step, Loss: 0.5300659537315369, Mean IoU = 45.589%
************************************************************
27th Epoch, 27405th Step, learning rate = 0.007212090644852192 - Loss: 0.32408884167671204, aux loss1: 0.7668057084083557, 
		 aux loss2: 0.4446994364261627, total loss: 0.7320103645324707
27th Epoch, 27410th Step, learning rate = 0.007211572152064891 - Loss: 0.32974332571029663, aux loss1: 0.7612895369529724, 
		 aux loss2: 0.4604981541633606, total loss: 0.742329478263855
27th Epoch, 27415th Step, learning rate = 0.00721105365513553 - Loss: 0.27329322695732117, aux loss1: 0.7707284092903137, 
		 aux loss2: 0.38444027304649353, total loss: 0.6582878828048706
27th Epoch, 27420th Step, learning rate = 0.007210535154063743 - Loss: 0.324920117855072, aux loss1: 0.9373736381530762, 
		 aux loss2: 0.4794355034828186, total loss: 0.7979063987731934
27th Epoch, 27425th Step, learning rate = 0.007210016648849169 - Loss: 0.32733744382858276, aux loss1: 0.779900074005127, 
		 aux loss2: 0.43751946091651917, total loss: 0.7363152503967285
27th Epoch, 27430th Step, learning rate = 0.007209498139491442 - Loss: 0.3114820122718811, aux loss1: 0.8616811037063599, 
		 aux loss2: 0.46561211347579956, total loss: 0.7562311887741089
27th Epoch, 27435th Step, learning rate = 0.007208979625990197 - Loss: 0.3192424774169922, aux loss1: 0.8766257762908936, 
		 aux loss2: 0.45736294984817505, total loss: 0.7651754021644592
27th Epoch, 27440th Step, learning rate = 0.007208461108345073 - Loss: 0.3535093069076538, aux loss1: 0.8237494826316833, 
		 aux loss2: 0.4720889925956726, total loss: 0.7894697785377502
27th Epoch, 27445th Step, learning rate = 0.0072079425865557 - Loss: 0.3329116106033325, aux loss1: 0.9365304708480835, 
		 aux loss2: 0.4845377206802368, total loss: 0.8076858520507812
27th Epoch, 27450th Step, learning rate = 0.007207424060621719 - Loss: 0.3064984381198883, aux loss1: 0.7900532484054565, 
		 aux loss2: 0.450423002243042, total loss: 0.7236836552619934
27th Epoch, 27455th Step, learning rate = 0.007206905530542765 - Loss: 0.38497722148895264, aux loss1: 1.039687156677246, 
		 aux loss2: 0.5919841527938843, total loss: 0.933677077293396
27th Epoch, 27460th Step, learning rate = 0.007206386996318468 - Loss: 0.24945545196533203, aux loss1: 0.7349978685379028, 
		 aux loss2: 0.36748772859573364, total loss: 0.6169499158859253
27th Epoch, 27465th Step, learning rate = 0.0072058684579484715 - Loss: 0.3649369478225708, aux loss1: 0.8925285339355469, 
		 aux loss2: 0.48089250922203064, total loss: 0.8250525593757629
27th Epoch, 27470th Step, learning rate = 0.007205349915432404 - Loss: 0.5608266592025757, aux loss1: 1.423730492591858, 
		 aux loss2: 0.8965373635292053, total loss: 1.3465607166290283
27th Epoch, 27475th Step, learning rate = 0.007204831368769905 - Loss: 0.283195823431015, aux loss1: 0.6565729379653931, 
		 aux loss2: 0.37720218300819397, total loss: 0.6310485601425171
27th Epoch, 27480th Step, learning rate = 0.00720431281796061 - Loss: 0.2770521342754364, aux loss1: 0.7835383415222168, 
		 aux loss2: 0.4090142250061035, total loss: 0.6757193207740784
27th Epoch, 27485th Step, learning rate = 0.007203794263004151 - Loss: 0.2939043343067169, aux loss1: 0.7907915115356445, 
		 aux loss2: 0.426359623670578, total loss: 0.7016856670379639
27th Epoch, 27490th Step, learning rate = 0.007203275703900164 - Loss: 0.3680219054222107, aux loss1: 0.8502594828605652, 
		 aux loss2: 0.5250057578086853, total loss: 0.8331021070480347
27th Epoch, 27495th Step, learning rate = 0.007202757140648287 - Loss: 0.37684956192970276, aux loss1: 0.9625698924064636, 
		 aux loss2: 0.5249005556106567, total loss: 0.8755807876586914
27th Epoch, 27500th Step, learning rate = 0.007202238573248151 - Loss: 0.32299238443374634, aux loss1: 0.792629063129425, 
		 aux loss2: 0.4558674991130829, total loss: 0.7431281208992004
<27500th step>
*************************** Test ***************************
time:3m 19s, 27500th Step, Loss: 0.5325106978416443, Mean IoU = 44.837%
************************************************************
27th Epoch, 27505th Step, learning rate = 0.007201720001699393 - Loss: 0.3751903176307678, aux loss1: 0.8582996129989624, 
		 aux loss2: 0.5302304029464722, total loss: 0.8447723388671875
27th Epoch, 27510th Step, learning rate = 0.00720120142600165 - Loss: 0.3159298002719879, aux loss1: 0.8694944381713867, 
		 aux loss2: 0.47865623235702515, total loss: 0.7682406902313232
27th Epoch, 27515th Step, learning rate = 0.007200682846154552 - Loss: 0.24168552458286285, aux loss1: 0.7204686403274536, 
		 aux loss2: 0.3309517502784729, total loss: 0.5902068614959717
28th Epoch, 27520th Step, learning rate = 0.007200164262157737 - Loss: 0.28238198161125183, aux loss1: 0.727506160736084, 
		 aux loss2: 0.41173768043518066, total loss: 0.6653289198875427
28th Epoch, 27525th Step, learning rate = 0.0071996456740108395 - Loss: 0.3714912533760071, aux loss1: 0.9620314240455627, 
		 aux loss2: 0.5530814528465271, total loss: 0.8813332915306091
28th Epoch, 27530th Step, learning rate = 0.007199127081713492 - Loss: 0.35866692662239075, aux loss1: 1.0182578563690186, 
		 aux loss2: 0.5404553413391113, total loss: 0.8803263902664185
28th Epoch, 27535th Step, learning rate = 0.0071986084852653336 - Loss: 0.3335846960544586, aux loss1: 0.8570411205291748, 
		 aux loss2: 0.4451235234737396, total loss: 0.7687464952468872
28th Epoch, 27540th Step, learning rate = 0.007198089884665994 - Loss: 0.35282501578330994, aux loss1: 0.83034348487854, 
		 aux loss2: 0.4903615415096283, total loss: 0.7980726957321167
28th Epoch, 27545th Step, learning rate = 0.007197571279915109 - Loss: 0.2779640555381775, aux loss1: 0.6885514855384827, 
		 aux loss2: 0.38800665736198425, total loss: 0.6397321820259094
28th Epoch, 27550th Step, learning rate = 0.007197052671012315 - Loss: 0.2726583480834961, aux loss1: 0.8802676200866699, 
		 aux loss2: 0.414165735244751, total loss: 0.7024049162864685
28th Epoch, 27555th Step, learning rate = 0.007196534057957245 - Loss: 0.3694086968898773, aux loss1: 0.8080851435661316, 
		 aux loss2: 0.492017537355423, total loss: 0.808641254901886
28th Epoch, 27560th Step, learning rate = 0.0071960154407495315 - Loss: 0.40394067764282227, aux loss1: 0.9644904732704163, 
		 aux loss2: 0.5734859704971313, total loss: 0.9226822257041931
28th Epoch, 27565th Step, learning rate = 0.007195496819388813 - Loss: 0.23299875855445862, aux loss1: 0.5931981801986694, 
		 aux loss2: 0.3089958131313324, total loss: 0.5345565676689148
28th Epoch, 27570th Step, learning rate = 0.007194978193874719 - Loss: 0.35102859139442444, aux loss1: 0.8526067733764648, 
		 aux loss2: 0.5179230570793152, total loss: 0.8139798641204834
28th Epoch, 27575th Step, learning rate = 0.0071944595642068855 - Loss: 0.27021080255508423, aux loss1: 0.7486695647239685, 
		 aux loss2: 0.38072285056114197, total loss: 0.6471008062362671
28th Epoch, 27580th Step, learning rate = 0.007193940930384948 - Loss: 0.3508424758911133, aux loss1: 0.990833580493927, 
		 aux loss2: 0.5581185221672058, total loss: 0.8713399767875671
28th Epoch, 27585th Step, learning rate = 0.007193422292408537 - Loss: 0.2717801630496979, aux loss1: 0.70823073387146, 
		 aux loss2: 0.3678159713745117, total loss: 0.631375789642334
28th Epoch, 27590th Step, learning rate = 0.007192903650277291 - Loss: 0.35713469982147217, aux loss1: 0.9153743982315063, 
		 aux loss2: 0.5360574126243591, total loss: 0.8461699485778809
28th Epoch, 27595th Step, learning rate = 0.007192385003990839 - Loss: 0.26367148756980896, aux loss1: 0.703952968120575, 
		 aux loss2: 0.3573666512966156, total loss: 0.6178040504455566
28th Epoch, 27600th Step, learning rate = 0.007191866353548819 - Loss: 0.34205496311187744, aux loss1: 0.9855213165283203, 
		 aux loss2: 0.5752553343772888, total loss: 0.8678135275840759
<27600th step>
*************************** Test ***************************
time:3m 17s, 27600th Step, Loss: 0.5397205352783203, Mean IoU = 45.638%
************************************************************
28th Epoch, 27605th Step, learning rate = 0.007191347698950862 - Loss: 0.30647245049476624, aux loss1: 0.796225905418396, 
		 aux loss2: 0.4645695388317108, total loss: 0.7311680316925049
28th Epoch, 27610th Step, learning rate = 0.007190829040196602 - Loss: 0.2688625454902649, aux loss1: 0.7373080253601074, 
		 aux loss2: 0.3724347651004791, total loss: 0.6390289068222046
28th Epoch, 27615th Step, learning rate = 0.007190310377285673 - Loss: 0.2954225242137909, aux loss1: 0.8180639743804932, 
		 aux loss2: 0.44521471858024597, total loss: 0.7189276218414307
28th Epoch, 27620th Step, learning rate = 0.007189791710217711 - Loss: 0.3240731358528137, aux loss1: 0.7746362686157227, 
		 aux loss2: 0.45703762769699097, total loss: 0.7392790913581848
28th Epoch, 27625th Step, learning rate = 0.007189273038992345 - Loss: 0.3937513828277588, aux loss1: 1.033851981163025, 
		 aux loss2: 0.5719811320304871, total loss: 0.93269944190979
28th Epoch, 27630th Step, learning rate = 0.007188754363609211 - Loss: 0.3808276951313019, aux loss1: 0.77217036485672, 
		 aux loss2: 0.4725998342037201, total loss: 0.8015187382698059
28th Epoch, 27635th Step, learning rate = 0.007188235684067942 - Loss: 0.2885836064815521, aux loss1: 0.7619779109954834, 
		 aux loss2: 0.3885333836078644, total loss: 0.6725903749465942
28th Epoch, 27640th Step, learning rate = 0.0071877170003681705 - Loss: 0.2915106415748596, aux loss1: 0.7810624241828918, 
		 aux loss2: 0.4166342318058014, total loss: 0.6924830675125122
28th Epoch, 27645th Step, learning rate = 0.007187198312509531 - Loss: 0.27148470282554626, aux loss1: 0.8058772683143616, 
		 aux loss2: 0.4125128388404846, total loss: 0.6782530546188354
28th Epoch, 27650th Step, learning rate = 0.007186679620491655 - Loss: 0.24579539895057678, aux loss1: 0.667775571346283, 
		 aux loss2: 0.3561815023422241, total loss: 0.5886006951332092
28th Epoch, 27655th Step, learning rate = 0.007186160924314178 - Loss: 0.37398645281791687, aux loss1: 0.7972524166107178, 
		 aux loss2: 0.4899301826953888, total loss: 0.8091342449188232
28th Epoch, 27660th Step, learning rate = 0.007185642223976732 - Loss: 0.28474462032318115, aux loss1: 0.7820982933044434, 
		 aux loss2: 0.41023728251457214, total loss: 0.6834690570831299
28th Epoch, 27665th Step, learning rate = 0.0071851235194789476 - Loss: 0.49490946531295776, aux loss1: 1.0249056816101074, 
		 aux loss2: 0.6185392141342163, total loss: 1.0497968196868896
28th Epoch, 27670th Step, learning rate = 0.007184604810820461 - Loss: 0.20251458883285522, aux loss1: 0.5799722075462341, 
		 aux loss2: 0.29149699211120605, total loss: 0.49310505390167236
28th Epoch, 27675th Step, learning rate = 0.0071840860980009035 - Loss: 0.3099639117717743, aux loss1: 0.8261545896530151, 
		 aux loss2: 0.4496925473213196, total loss: 0.737687349319458
28th Epoch, 27680th Step, learning rate = 0.007183567381019908 - Loss: 0.2881515324115753, aux loss1: 0.8307725787162781, 
		 aux loss2: 0.4115844964981079, total loss: 0.7020171284675598
28th Epoch, 27685th Step, learning rate = 0.007183048659877109 - Loss: 0.3432042598724365, aux loss1: 0.908577024936676, 
		 aux loss2: 0.4744977653026581, total loss: 0.805576503276825
28th Epoch, 27690th Step, learning rate = 0.007182529934572136 - Loss: 0.36992037296295166, aux loss1: 0.9599534869194031, 
		 aux loss2: 0.5391157865524292, total loss: 0.8735527396202087
28th Epoch, 27695th Step, learning rate = 0.007182011205104623 - Loss: 0.26768264174461365, aux loss1: 0.7116784453392029, 
		 aux loss2: 0.38174518942832947, total loss: 0.6338842511177063
28th Epoch, 27700th Step, learning rate = 0.007181492471474204 - Loss: 0.2554725110530853, aux loss1: 0.6854130625724792, 
		 aux loss2: 0.35842040181159973, total loss: 0.604464590549469
<27700th step>
*************************** Test ***************************
time:3m 19s, 27700th Step, Loss: 0.518438458442688, Mean IoU = 44.660%
************************************************************
28th Epoch, 27705th Step, learning rate = 0.007180973733680509 - Loss: 0.31092187762260437, aux loss1: 0.9451249241828918, 
		 aux loss2: 0.48180559277534485, total loss: 0.7871816158294678
28th Epoch, 27710th Step, learning rate = 0.007180454991723171 - Loss: 0.3450322449207306, aux loss1: 1.26621413230896, 
		 aux loss2: 0.6597744822502136, total loss: 0.9888062477111816
28th Epoch, 27715th Step, learning rate = 0.007179936245601825 - Loss: 0.285540372133255, aux loss1: 0.8433223366737366, 
		 aux loss2: 0.4457504451274872, total loss: 0.7168372869491577
28th Epoch, 27720th Step, learning rate = 0.007179417495316101 - Loss: 0.28200486302375793, aux loss1: 0.8139035701751709, 
		 aux loss2: 0.42374908924102783, total loss: 0.6956756114959717
28th Epoch, 27725th Step, learning rate = 0.007178898740865629 - Loss: 0.3375663757324219, aux loss1: 0.840229868888855, 
		 aux loss2: 0.48194506764411926, total loss: 0.7824134230613708
28th Epoch, 27730th Step, learning rate = 0.007178379982250047 - Loss: 0.3483773469924927, aux loss1: 0.8663253784179688, 
		 aux loss2: 0.4640800952911377, total loss: 0.7939069867134094
28th Epoch, 27735th Step, learning rate = 0.007177861219468982 - Loss: 0.3483127951622009, aux loss1: 0.9479650259017944, 
		 aux loss2: 0.5396210551261902, total loss: 0.8485507965087891
28th Epoch, 27740th Step, learning rate = 0.007177342452522067 - Loss: 0.3239845037460327, aux loss1: 0.7776164412498474, 
		 aux loss2: 0.4207373559474945, total loss: 0.7255644202232361
28th Epoch, 27745th Step, learning rate = 0.007176823681408937 - Loss: 0.5559440851211548, aux loss1: 1.191348910331726, 
		 aux loss2: 0.7607986330986023, total loss: 1.2176682949066162
28th Epoch, 27750th Step, learning rate = 0.007176304906129221 - Loss: 0.26180166006088257, aux loss1: 0.7027633786201477, 
		 aux loss2: 0.3890819847583771, total loss: 0.6282634735107422
28th Epoch, 27755th Step, learning rate = 0.007175786126682551 - Loss: 0.3145290017127991, aux loss1: 0.9377245903015137, 
		 aux loss2: 0.5044735074043274, total loss: 0.7976357936859131
28th Epoch, 27760th Step, learning rate = 0.00717526734306856 - Loss: 0.25963154435157776, aux loss1: 0.6635003685951233, 
		 aux loss2: 0.3613680899143219, total loss: 0.6032288670539856
28th Epoch, 27765th Step, learning rate = 0.007174748555286877 - Loss: 0.3224748969078064, aux loss1: 0.9731951951980591, 
		 aux loss2: 0.5038037300109863, total loss: 0.8159549832344055
28th Epoch, 27770th Step, learning rate = 0.007174229763337139 - Loss: 0.30016136169433594, aux loss1: 0.8085361123085022, 
		 aux loss2: 0.42945781350135803, total loss: 0.7145053744316101
28th Epoch, 27775th Step, learning rate = 0.007173710967218972 - Loss: 0.29784801602363586, aux loss1: 0.7797852158546448, 
		 aux loss2: 0.419662207365036, total loss: 0.6996484994888306
28th Epoch, 27780th Step, learning rate = 0.007173192166932012 - Loss: 0.38241443037986755, aux loss1: 1.0541446208953857, 
		 aux loss2: 0.5871514081954956, total loss: 0.9335184097290039
28th Epoch, 27785th Step, learning rate = 0.007172673362475888 - Loss: 0.49105504155158997, aux loss1: 1.2343463897705078, 
		 aux loss2: 0.7804713249206543, total loss: 1.1735475063323975
28th Epoch, 27790th Step, learning rate = 0.0071721545538502305 - Loss: 0.3472789227962494, aux loss1: 0.8893319964408875, 
		 aux loss2: 0.47851449251174927, total loss: 0.8054842948913574
28th Epoch, 27795th Step, learning rate = 0.007171635741054674 - Loss: 0.42233720421791077, aux loss1: 0.8784762620925903, 
		 aux loss2: 0.5674888491630554, total loss: 0.9128755927085876
28th Epoch, 27800th Step, learning rate = 0.007171116924088847 - Loss: 0.42612534761428833, aux loss1: 0.9975203275680542, 
		 aux loss2: 0.615138828754425, total loss: 0.9714370369911194
<27800th step>
*************************** Test ***************************
time:3m 16s, 27800th Step, Loss: 0.553027331829071, Mean IoU = 43.646%
************************************************************
28th Epoch, 27805th Step, learning rate = 0.007170598102952383 - Loss: 0.3551194667816162, aux loss1: 0.9851752519607544, 
		 aux loss2: 0.5066339373588562, total loss: 0.8533256649971008
28th Epoch, 27810th Step, learning rate = 0.00717007927764491 - Loss: 0.32027921080589294, aux loss1: 0.880798876285553, 
		 aux loss2: 0.4515230655670166, total loss: 0.7651281356811523
28th Epoch, 27815th Step, learning rate = 0.007169560448166063 - Loss: 0.34662580490112305, aux loss1: 0.8878033757209778, 
		 aux loss2: 0.4660041630268097, total loss: 0.7993685007095337
28th Epoch, 27820th Step, learning rate = 0.007169041614515469 - Loss: 0.31277787685394287, aux loss1: 0.8204461336135864, 
		 aux loss2: 0.439841091632843, total loss: 0.7348482012748718
28th Epoch, 27825th Step, learning rate = 0.007168522776692763 - Loss: 0.27547571063041687, aux loss1: 0.7372704744338989, 
		 aux loss2: 0.3845904469490051, total loss: 0.6504930257797241
28th Epoch, 27830th Step, learning rate = 0.007168003934697572 - Loss: 0.36427199840545654, aux loss1: 0.917399525642395, 
		 aux loss2: 0.5196283459663391, total loss: 0.8473432064056396
28th Epoch, 27835th Step, learning rate = 0.00716748508852953 - Loss: 0.3182138502597809, aux loss1: 0.7912091016769409, 
		 aux loss2: 0.4282493591308594, total loss: 0.7268763184547424
28th Epoch, 27840th Step, learning rate = 0.007166966238188268 - Loss: 0.29543301463127136, aux loss1: 0.7417811751365662, 
		 aux loss2: 0.40544629096984863, total loss: 0.6801458597183228
28th Epoch, 27845th Step, learning rate = 0.0071664473836734145 - Loss: 0.29620361328125, aux loss1: 0.7324823141098022, 
		 aux loss2: 0.4021306037902832, total loss: 0.676800549030304
28th Epoch, 27850th Step, learning rate = 0.0071659285249846 - Loss: 0.27015867829322815, aux loss1: 0.6897889971733093, 
		 aux loss2: 0.3499770164489746, total loss: 0.6170861721038818
28th Epoch, 27855th Step, learning rate = 0.007165409662121459 - Loss: 0.4496268332004547, aux loss1: 1.1485583782196045, 
		 aux loss2: 0.6760666966438293, total loss: 1.0646209716796875
28th Epoch, 27860th Step, learning rate = 0.007164890795083617 - Loss: 0.3688545823097229, aux loss1: 0.9243001937866211, 
		 aux loss2: 0.5455192923545837, total loss: 0.8643523454666138
28th Epoch, 27865th Step, learning rate = 0.0071643719238707075 - Loss: 0.3520527780056, aux loss1: 0.9264724254608154, 
		 aux loss2: 0.5060319900512695, total loss: 0.8324072957038879
28th Epoch, 27870th Step, learning rate = 0.007163853048482362 - Loss: 0.32655465602874756, aux loss1: 0.8348335027694702, 
		 aux loss2: 0.4563772976398468, total loss: 0.7595556378364563
28th Epoch, 27875th Step, learning rate = 0.007163334168918205 - Loss: 0.2880069613456726, aux loss1: 0.7935927510261536, 
		 aux loss2: 0.43992921710014343, total loss: 0.7020564675331116
28th Epoch, 27880th Step, learning rate = 0.007162815285177874 - Loss: 0.27816036343574524, aux loss1: 0.7391535639762878, 
		 aux loss2: 0.3834335505962372, total loss: 0.6532798409461975
28th Epoch, 27885th Step, learning rate = 0.007162296397260997 - Loss: 0.39330756664276123, aux loss1: 1.0360355377197266, 
		 aux loss2: 0.5895870923995972, total loss: 0.939953088760376
29th Epoch, 27890th Step, learning rate = 0.0071617775051672 - Loss: 0.2956394553184509, aux loss1: 0.8125529885292053, 
		 aux loss2: 0.42540034651756287, total loss: 0.7095655202865601
29th Epoch, 27895th Step, learning rate = 0.007161258608896119 - Loss: 0.26010969281196594, aux loss1: 0.8136047720909119, 
		 aux loss2: 0.37905481457710266, total loss: 0.6558130979537964
29th Epoch, 27900th Step, learning rate = 0.007160739708447379 - Loss: 0.3712281584739685, aux loss1: 0.9312299489974976, 
		 aux loss2: 0.524154782295227, total loss: 0.8602590560913086
<27900th step>
*************************** Test ***************************
time:3m 15s, 27900th Step, Loss: 0.5329504013061523, Mean IoU = 45.696%
************************************************************
29th Epoch, 27905th Step, learning rate = 0.007160220803820614 - Loss: 0.29239895939826965, aux loss1: 0.7879554033279419, 
		 aux loss2: 0.40386033058166504, total loss: 0.6903297305107117
29th Epoch, 27910th Step, learning rate = 0.007159701895015453 - Loss: 0.36399391293525696, aux loss1: 0.8420380353927612, 
		 aux loss2: 0.5235567688941956, total loss: 0.826028048992157
29th Epoch, 27915th Step, learning rate = 0.007159182982031525 - Loss: 0.32561731338500977, aux loss1: 0.897926926612854, 
		 aux loss2: 0.4711269736289978, total loss: 0.783446192741394
29th Epoch, 27920th Step, learning rate = 0.00715866406486846 - Loss: 0.4123801290988922, aux loss1: 0.9807289242744446, 
		 aux loss2: 0.582970917224884, total loss: 0.9397872090339661
29th Epoch, 27925th Step, learning rate = 0.0071581451435258885 - Loss: 0.3460916578769684, aux loss1: 1.055477499961853, 
		 aux loss2: 0.5270784497261047, total loss: 0.8735663294792175
29th Epoch, 27930th Step, learning rate = 0.007157626218003438 - Loss: 0.3140382766723633, aux loss1: 0.7534293532371521, 
		 aux loss2: 0.45257988572120667, total loss: 0.7210990190505981
29th Epoch, 27935th Step, learning rate = 0.007157107288300739 - Loss: 0.3333028256893158, aux loss1: 0.8371232151985168, 
		 aux loss2: 0.4681870937347412, total loss: 0.7717146873474121
29th Epoch, 27940th Step, learning rate = 0.0071565883544174235 - Loss: 0.33134397864341736, aux loss1: 0.8433842062950134, 
		 aux loss2: 0.4806377589702606, total loss: 0.7766144275665283
29th Epoch, 27945th Step, learning rate = 0.007156069416353118 - Loss: 0.39688640832901, aux loss1: 0.9715694189071655, 
		 aux loss2: 0.5771772265434265, total loss: 0.9192281365394592
29th Epoch, 27950th Step, learning rate = 0.007155550474107454 - Loss: 0.26719561219215393, aux loss1: 0.9734191298484802, 
		 aux loss2: 0.5367815494537354, total loss: 0.773934006690979
29th Epoch, 27955th Step, learning rate = 0.0071550315276800594 - Loss: 0.27400797605514526, aux loss1: 0.841853141784668, 
		 aux loss2: 0.41186919808387756, total loss: 0.6913115978240967
29th Epoch, 27960th Step, learning rate = 0.007154512577070563 - Loss: 0.33435702323913574, aux loss1: 0.8158595561981201, 
		 aux loss2: 0.4582260549068451, total loss: 0.7624053359031677
29th Epoch, 27965th Step, learning rate = 0.0071539936222785976 - Loss: 0.3862830698490143, aux loss1: 0.8602085113525391, 
		 aux loss2: 0.49578264355659485, total loss: 0.8426586985588074
29th Epoch, 27970th Step, learning rate = 0.007153474663303789 - Loss: 0.2879462242126465, aux loss1: 0.8531389236450195, 
		 aux loss2: 0.4125450551509857, total loss: 0.7089059352874756
29th Epoch, 27975th Step, learning rate = 0.007152955700145766 - Loss: 0.3601376414299011, aux loss1: 0.8419114947319031, 
		 aux loss2: 0.4773360788822174, total loss: 0.8036454916000366
29th Epoch, 27980th Step, learning rate = 0.007152436732804159 - Loss: 0.27723613381385803, aux loss1: 0.7966055870056152, 
		 aux loss2: 0.4064143896102905, total loss: 0.6787835955619812
29th Epoch, 27985th Step, learning rate = 0.007151917761278598 - Loss: 0.3162578344345093, aux loss1: 0.8280491828918457, 
		 aux loss2: 0.4503202736377716, total loss: 0.7448006868362427
29th Epoch, 27990th Step, learning rate = 0.007151398785568709 - Loss: 0.34434789419174194, aux loss1: 0.8515235185623169, 
		 aux loss2: 0.4849245548248291, total loss: 0.7937748432159424
29th Epoch, 27995th Step, learning rate = 0.007150879805674125 - Loss: 0.3862922787666321, aux loss1: 1.0712732076644897, 
		 aux loss2: 0.5731388330459595, total loss: 0.9369298219680786
29th Epoch, 28000th Step, learning rate = 0.007150360821594469 - Loss: 0.37458646297454834, aux loss1: 1.0899856090545654, 
		 aux loss2: 0.5565497279167175, total loss: 0.9242020845413208
<28000th step>
*************************** Test ***************************
time:3m 18s, 28000th Step, Loss: 0.5607193112373352, Mean IoU = 44.489%
************************************************************
29th Epoch, 28005th Step, learning rate = 0.0071498418333293765 - Loss: 0.3815068304538727, aux loss1: 1.0430114269256592, 
		 aux loss2: 0.5883406400680542, total loss: 0.9297465085983276
29th Epoch, 28010th Step, learning rate = 0.0071493228408784715 - Loss: 0.2909311354160309, aux loss1: 0.7579942345619202, 
		 aux loss2: 0.37849849462509155, total loss: 0.6697287559509277
29th Epoch, 28015th Step, learning rate = 0.007148803844241383 - Loss: 0.3095541000366211, aux loss1: 0.8550052046775818, 
		 aux loss2: 0.4699738621711731, total loss: 0.7540451884269714
29th Epoch, 28020th Step, learning rate = 0.007148284843417743 - Loss: 0.37084731459617615, aux loss1: 0.8761715292930603, 
		 aux loss2: 0.5304704904556274, total loss: 0.8458870053291321
29th Epoch, 28025th Step, learning rate = 0.007147765838407174 - Loss: 0.3428926169872284, aux loss1: 0.8818802833557129, 
		 aux loss2: 0.4893145263195038, total loss: 0.8031824827194214
29th Epoch, 28030th Step, learning rate = 0.007147246829209309 - Loss: 0.3187631070613861, aux loss1: 0.7583280205726624, 
		 aux loss2: 0.43762877583503723, total loss: 0.7213130593299866
29th Epoch, 28035th Step, learning rate = 0.007146727815823778 - Loss: 0.292029470205307, aux loss1: 0.8685441017150879, 
		 aux loss2: 0.43870463967323303, total loss: 0.7280746102333069
29th Epoch, 28040th Step, learning rate = 0.007146208798250203 - Loss: 0.31256261467933655, aux loss1: 0.839747965335846, 
		 aux loss2: 0.45972129702568054, total loss: 0.7483755350112915
29th Epoch, 28045th Step, learning rate = 0.007145689776488218 - Loss: 0.35862278938293457, aux loss1: 0.9506073594093323, 
		 aux loss2: 0.5164504647254944, total loss: 0.8503851890563965
29th Epoch, 28050th Step, learning rate = 0.007145170750537448 - Loss: 0.33090922236442566, aux loss1: 0.7464668154716492, 
		 aux loss2: 0.44064152240753174, total loss: 0.7311058640480042
29th Epoch, 28055th Step, learning rate = 0.007144651720397522 - Loss: 0.3238523304462433, aux loss1: 0.9903869032859802, 
		 aux loss2: 0.5140982866287231, total loss: 0.8266077041625977
29th Epoch, 28060th Step, learning rate = 0.007144132686068068 - Loss: 0.2806157171726227, aux loss1: 0.7852592468261719, 
		 aux loss2: 0.4047134518623352, total loss: 0.6780788898468018
29th Epoch, 28065th Step, learning rate = 0.007143613647548714 - Loss: 0.27776283025741577, aux loss1: 0.7048710584640503, 
		 aux loss2: 0.39664551615715027, total loss: 0.647882342338562
29th Epoch, 28070th Step, learning rate = 0.007143094604839088 - Loss: 0.31732138991355896, aux loss1: 0.7338138222694397, 
		 aux loss2: 0.4188826382160187, total loss: 0.7050186395645142
29th Epoch, 28075th Step, learning rate = 0.007142575557938818 - Loss: 0.3023028075695038, aux loss1: 0.7265242338180542, 
		 aux loss2: 0.39871010184288025, total loss: 0.6797441244125366
29th Epoch, 28080th Step, learning rate = 0.007142056506847532 - Loss: 0.3026902675628662, aux loss1: 0.800187885761261, 
		 aux loss2: 0.42043232917785645, total loss: 0.7109196186065674
29th Epoch, 28085th Step, learning rate = 0.007141537451564857 - Loss: 0.3126014769077301, aux loss1: 0.6926660537719727, 
		 aux loss2: 0.409134179353714, total loss: 0.684054970741272
29th Epoch, 28090th Step, learning rate = 0.007141018392090422 - Loss: 0.34818410873413086, aux loss1: 0.981524646282196, 
		 aux loss2: 0.5374111533164978, total loss: 0.8576059937477112
29th Epoch, 28095th Step, learning rate = 0.007140499328423852 - Loss: 0.32991960644721985, aux loss1: 0.9206867814064026, 
		 aux loss2: 0.4967103600502014, total loss: 0.8048098087310791
29th Epoch, 28100th Step, learning rate = 0.007139980260564777 - Loss: 0.4713696539402008, aux loss1: 1.111501693725586, 
		 aux loss2: 0.6497468948364258, total loss: 1.0647189617156982
<28100th step>
*************************** Test ***************************
time:3m 17s, 28100th Step, Loss: 0.5452659130096436, Mean IoU = 44.815%
************************************************************
29th Epoch, 28105th Step, learning rate = 0.007139461188512823 - Loss: 0.33821406960487366, aux loss1: 0.8019723296165466, 
		 aux loss2: 0.4533519744873047, total loss: 0.7601466178894043
29th Epoch, 28110th Step, learning rate = 0.007138942112267619 - Loss: 0.24969884753227234, aux loss1: 0.6716277003288269, 
		 aux loss2: 0.349514901638031, total loss: 0.5909931063652039
29th Epoch, 28115th Step, learning rate = 0.00713842303182879 - Loss: 0.40165209770202637, aux loss1: 0.9839372634887695, 
		 aux loss2: 0.5856080055236816, total loss: 0.9310764670372009
29th Epoch, 28120th Step, learning rate = 0.007137903947195966 - Loss: 0.34148719906806946, aux loss1: 0.896973192691803, 
		 aux loss2: 0.484130859375, total loss: 0.8042314648628235
29th Epoch, 28125th Step, learning rate = 0.007137384858368772 - Loss: 0.3455963432788849, aux loss1: 0.9098947048187256, 
		 aux loss2: 0.5028281807899475, total loss: 0.8196960091590881
29th Epoch, 28130th Step, learning rate = 0.007136865765346837 - Loss: 0.3085874021053314, aux loss1: 0.8256999850273132, 
		 aux loss2: 0.4437553584575653, total loss: 0.7337995767593384
29th Epoch, 28135th Step, learning rate = 0.007136346668129786 - Loss: 0.35412734746932983, aux loss1: 0.9440797567367554, 
		 aux loss2: 0.5097768902778625, total loss: 0.8412620425224304
29th Epoch, 28140th Step, learning rate = 0.007135827566717248 - Loss: 0.26876282691955566, aux loss1: 0.7771389484405518, 
		 aux loss2: 0.3874257206916809, total loss: 0.6568747758865356
29th Epoch, 28145th Step, learning rate = 0.007135308461108851 - Loss: 0.30631962418556213, aux loss1: 0.7243994474411011, 
		 aux loss2: 0.3980981111526489, total loss: 0.6828786730766296
29th Epoch, 28150th Step, learning rate = 0.0071347893513042165 - Loss: 0.3649801015853882, aux loss1: 0.8581851124763489, 
		 aux loss2: 0.5297648310661316, total loss: 0.8343416452407837
29th Epoch, 28155th Step, learning rate = 0.007134270237302977 - Loss: 0.32065579295158386, aux loss1: 0.8536940217018127, 
		 aux loss2: 0.4583997130393982, total loss: 0.7601238489151001
29th Epoch, 28160th Step, learning rate = 0.007133751119104756 - Loss: 0.27227988839149475, aux loss1: 0.8385885953903198, 
		 aux loss2: 0.41057518124580383, total loss: 0.6880866289138794
29th Epoch, 28165th Step, learning rate = 0.007133231996709183 - Loss: 0.3752491772174835, aux loss1: 0.8190111517906189, 
		 aux loss2: 0.4804709851741791, total loss: 0.8131409287452698
29th Epoch, 28170th Step, learning rate = 0.0071327128701158815 - Loss: 0.27172112464904785, aux loss1: 0.7746949195861816, 
		 aux loss2: 0.3799850046634674, total loss: 0.6561235785484314
29th Epoch, 28175th Step, learning rate = 0.00713219373932448 - Loss: 0.279398649930954, aux loss1: 0.8607940673828125, 
		 aux loss2: 0.42331379652023315, total loss: 0.7069624066352844
29th Epoch, 28180th Step, learning rate = 0.007131674604334605 - Loss: 0.34539157152175903, aux loss1: 0.9386897683143616, 
		 aux loss2: 0.49453338980674744, total loss: 0.8248119354248047
29th Epoch, 28185th Step, learning rate = 0.007131155465145883 - Loss: 0.2977903187274933, aux loss1: 0.7353217601776123, 
		 aux loss2: 0.4069216549396515, total loss: 0.6811555027961731
29th Epoch, 28190th Step, learning rate = 0.007130636321757941 - Loss: 0.27240729331970215, aux loss1: 0.9029262065887451, 
		 aux loss2: 0.44685620069503784, total loss: 0.722027599811554
29th Epoch, 28195th Step, learning rate = 0.007130117174170402 - Loss: 0.2641175091266632, aux loss1: 0.6464391946792603, 
		 aux loss2: 0.34907296299934387, total loss: 0.5976784825325012
29th Epoch, 28200th Step, learning rate = 0.007129598022382896 - Loss: 0.27876362204551697, aux loss1: 0.7867955565452576, 
		 aux loss2: 0.4120296537876129, total loss: 0.6796141266822815
<28200th step>
*************************** Test ***************************
time:3m 20s, 28200th Step, Loss: 0.5141018629074097, Mean IoU = 45.791%
************************************************************
29th Epoch, 28205th Step, learning rate = 0.0071290788663950465 - Loss: 0.44836506247520447, aux loss1: 1.026977777481079, 
		 aux loss2: 0.6400756239891052, total loss: 1.012488603591919
29th Epoch, 28210th Step, learning rate = 0.007128559706206482 - Loss: 0.39113539457321167, aux loss1: 0.9832664132118225, 
		 aux loss2: 0.5298314094543457, total loss: 0.898047924041748
29th Epoch, 28215th Step, learning rate = 0.00712804054181683 - Loss: 0.479248970746994, aux loss1: 1.2350032329559326, 
		 aux loss2: 0.7305607199668884, total loss: 1.1419742107391357
29th Epoch, 28220th Step, learning rate = 0.00712752137322571 - Loss: 0.29428398609161377, aux loss1: 0.7678965926170349, 
		 aux loss2: 0.3971562683582306, total loss: 0.6835154891014099
29th Epoch, 28225th Step, learning rate = 0.007127002200432754 - Loss: 0.37209710478782654, aux loss1: 0.9776270985603333, 
		 aux loss2: 0.5485891103744507, total loss: 0.8848208785057068
29th Epoch, 28230th Step, learning rate = 0.007126483023437586 - Loss: 0.4482235014438629, aux loss1: 0.932462215423584, 
		 aux loss2: 0.578199565410614, total loss: 0.9592419862747192
29th Epoch, 28235th Step, learning rate = 0.007125963842239831 - Loss: 0.33465513586997986, aux loss1: 0.8095546960830688, 
		 aux loss2: 0.46669715642929077, total loss: 0.7642004489898682
29th Epoch, 28240th Step, learning rate = 0.007125444656839116 - Loss: 0.3405821919441223, aux loss1: 0.8517476916313171, 
		 aux loss2: 0.4764079749584198, total loss: 0.7866697311401367
29th Epoch, 28245th Step, learning rate = 0.007124925467235067 - Loss: 0.468095988035202, aux loss1: 1.040105938911438, 
		 aux loss2: 0.6651855707168579, total loss: 1.0462019443511963
29th Epoch, 28250th Step, learning rate = 0.0071244062734273075 - Loss: 0.3472164571285248, aux loss1: 0.815318763256073, 
		 aux loss2: 0.459711492061615, total loss: 0.7756966948509216
29th Epoch, 28255th Step, learning rate = 0.007123887075415466 - Loss: 0.30969902873039246, aux loss1: 0.8627516031265259, 
		 aux loss2: 0.44974038004875183, total loss: 0.7484206557273865
29th Epoch, 28260th Step, learning rate = 0.007123367873199164 - Loss: 0.2851811647415161, aux loss1: 0.7567875981330872, 
		 aux loss2: 0.37890860438346863, total loss: 0.663780927658081
30th Epoch, 28265th Step, learning rate = 0.007122848666778031 - Loss: 0.26356226205825806, aux loss1: 0.737183153629303, 
		 aux loss2: 0.3713007867336273, total loss: 0.6332375407218933
30th Epoch, 28270th Step, learning rate = 0.007122329456151691 - Loss: 0.3160732388496399, aux loss1: 0.8297429084777832, 
		 aux loss2: 0.46570655703544617, total loss: 0.7512787580490112
30th Epoch, 28275th Step, learning rate = 0.007121810241319769 - Loss: 0.3183801770210266, aux loss1: 0.7724926471710205, 
		 aux loss2: 0.4416975677013397, total loss: 0.7268069982528687
30th Epoch, 28280th Step, learning rate = 0.007121291022281891 - Loss: 0.3429547846317291, aux loss1: 0.9634954929351807, 
		 aux loss2: 0.5303328037261963, total loss: 0.8441365361213684
30th Epoch, 28285th Step, learning rate = 0.007120771799037681 - Loss: 0.3221014738082886, aux loss1: 0.8398107290267944, 
		 aux loss2: 0.4603407382965088, total loss: 0.7581809759140015
30th Epoch, 28290th Step, learning rate = 0.007120252571586764 - Loss: 0.2316693812608719, aux loss1: 0.6453566551208496, 
		 aux loss2: 0.3374703526496887, total loss: 0.560264527797699
30th Epoch, 28295th Step, learning rate = 0.007119733339928767 - Loss: 0.2731044590473175, aux loss1: 0.7373337149620056, 
		 aux loss2: 0.37440183758735657, total loss: 0.6440653204917908
30th Epoch, 28300th Step, learning rate = 0.007119214104063313 - Loss: 0.32642215490341187, aux loss1: 0.8822989463806152, 
		 aux loss2: 0.48178744316101074, total loss: 0.7838268280029297
<28300th step>
*************************** Test ***************************
time:3m 17s, 28300th Step, Loss: 0.531882643699646, Mean IoU = 44.700%
************************************************************
30th Epoch, 28305th Step, learning rate = 0.007118694863990026 - Loss: 0.3222089409828186, aux loss1: 0.7958211898803711, 
		 aux loss2: 0.44552356004714966, total loss: 0.7391647100448608
30th Epoch, 28310th Step, learning rate = 0.007118175619708535 - Loss: 0.39362749457359314, aux loss1: 1.1015619039535522, 
		 aux loss2: 0.6141307950019836, total loss: 0.9697483777999878
30th Epoch, 28315th Step, learning rate = 0.007117656371218461 - Loss: 0.2892439365386963, aux loss1: 0.8535287380218506, 
		 aux loss2: 0.42083969712257385, total loss: 0.713638424873352
30th Epoch, 28320th Step, learning rate = 0.007117137118519431 - Loss: 0.30627092719078064, aux loss1: 0.7719653248786926, 
		 aux loss2: 0.4385647475719452, total loss: 0.7132863998413086
30th Epoch, 28325th Step, learning rate = 0.0071166178616110685 - Loss: 0.30479177832603455, aux loss1: 0.930984616279602, 
		 aux loss2: 0.45401158928871155, total loss: 0.7656917572021484
30th Epoch, 28330th Step, learning rate = 0.007116098600492999 - Loss: 0.26482221484184265, aux loss1: 0.6931204795837402, 
		 aux loss2: 0.3493649363517761, total loss: 0.6125043630599976
30th Epoch, 28335th Step, learning rate = 0.007115579335164844 - Loss: 0.3356466591358185, aux loss1: 0.8012232184410095, 
		 aux loss2: 0.46540939807891846, total loss: 0.7621774077415466
30th Epoch, 28340th Step, learning rate = 0.007115060065626234 - Loss: 0.3061404824256897, aux loss1: 0.8308677673339844, 
		 aux loss2: 0.43842336535453796, total loss: 0.7307702302932739
30th Epoch, 28345th Step, learning rate = 0.007114540791876788 - Loss: 0.42070192098617554, aux loss1: 0.8939893245697021, 
		 aux loss2: 0.5508162379264832, total loss: 0.9092252254486084
30th Epoch, 28350th Step, learning rate = 0.007114021513916131 - Loss: 0.36820489168167114, aux loss1: 0.9296806454658508, 
		 aux loss2: 0.5449866056442261, total loss: 0.8651037216186523
30th Epoch, 28355th Step, learning rate = 0.007113502231743891 - Loss: 0.32003098726272583, aux loss1: 0.7413051724433899, 
		 aux loss2: 0.43781304359436035, total loss: 0.7175477743148804
30th Epoch, 28360th Step, learning rate = 0.0071129829453596876 - Loss: 0.292842835187912, aux loss1: 0.7970547676086426, 
		 aux loss2: 0.4186301827430725, total loss: 0.6994113922119141
30th Epoch, 28365th Step, learning rate = 0.0071124636547631485 - Loss: 0.2552986443042755, aux loss1: 0.7685580849647522, 
		 aux loss2: 0.38805022835731506, total loss: 0.6410861611366272
30th Epoch, 28370th Step, learning rate = 0.007111944359953897 - Loss: 0.32623037695884705, aux loss1: 0.8994516134262085, 
		 aux loss2: 0.49134138226509094, total loss: 0.7926024198532104
30th Epoch, 28375th Step, learning rate = 0.007111425060931553 - Loss: 0.30389365553855896, aux loss1: 0.8678250908851624, 
		 aux loss2: 0.4844050109386444, total loss: 0.7580031752586365
30th Epoch, 28380th Step, learning rate = 0.007110905757695748 - Loss: 0.3381223678588867, aux loss1: 0.8918061852455139, 
		 aux loss2: 0.4792627990245819, total loss: 0.7973693609237671
30th Epoch, 28385th Step, learning rate = 0.007110386450246101 - Loss: 0.26983335614204407, aux loss1: 0.7213793396949768, 
		 aux loss2: 0.39095258712768555, total loss: 0.6426281929016113
30th Epoch, 28390th Step, learning rate = 0.007109867138582236 - Loss: 0.3111456632614136, aux loss1: 0.8036529421806335, 
		 aux loss2: 0.44246187806129456, total loss: 0.7292263507843018
30th Epoch, 28395th Step, learning rate = 0.007109347822703778 - Loss: 0.37111732363700867, aux loss1: 0.8429397344589233, 
		 aux loss2: 0.4910566210746765, total loss: 0.8204218745231628
30th Epoch, 28400th Step, learning rate = 0.007108828502610349 - Loss: 0.2883017361164093, aux loss1: 0.9092113971710205, 
		 aux loss2: 0.4388354420661926, total loss: 0.7365993857383728
<28400th step>
*************************** Test ***************************
time:3m 16s, 28400th Step, Loss: 0.5450834035873413, Mean IoU = 44.809%
************************************************************
30th Epoch, 28405th Step, learning rate = 0.007108309178301575 - Loss: 0.2860187888145447, aux loss1: 0.8662328720092773, 
		 aux loss2: 0.4255019724369049, total loss: 0.7160894870758057
30th Epoch, 28410th Step, learning rate = 0.00710778984977708 - Loss: 0.23817290365695953, aux loss1: 0.7145130634307861, 
		 aux loss2: 0.35507717728614807, total loss: 0.5945577025413513
30th Epoch, 28415th Step, learning rate = 0.0071072705170364845 - Loss: 0.3169209659099579, aux loss1: 0.7882022261619568, 
		 aux loss2: 0.4423879086971283, total loss: 0.7303367853164673
30th Epoch, 28420th Step, learning rate = 0.007106751180079414 - Loss: 0.2817544639110565, aux loss1: 0.805855929851532, 
		 aux loss2: 0.4238073527812958, total loss: 0.6930341720581055
30th Epoch, 28425th Step, learning rate = 0.007106231838905491 - Loss: 0.27325037121772766, aux loss1: 0.8084958791732788, 
		 aux loss2: 0.4111436605453491, total loss: 0.6802566051483154
30th Epoch, 28430th Step, learning rate = 0.007105712493514339 - Loss: 0.31656619906425476, aux loss1: 0.8125014901161194, 
		 aux loss2: 0.42925384640693665, total loss: 0.732018232345581
30th Epoch, 28435th Step, learning rate = 0.007105193143905583 - Loss: 0.33076369762420654, aux loss1: 0.797640860080719, 
		 aux loss2: 0.46368011832237244, total loss: 0.7555280327796936
30th Epoch, 28440th Step, learning rate = 0.007104673790078842 - Loss: 0.4359043836593628, aux loss1: 1.0482087135314941, 
		 aux loss2: 0.6190957427024841, total loss: 0.9980053305625916
30th Epoch, 28445th Step, learning rate = 0.007104154432033744 - Loss: 0.4118099510669708, aux loss1: 0.9434878826141357, 
		 aux loss2: 0.5488827228546143, total loss: 0.9144093990325928
30th Epoch, 28450th Step, learning rate = 0.007103635069769912 - Loss: 0.3172180652618408, aux loss1: 0.7316533327102661, 
		 aux loss2: 0.43945419788360596, total loss: 0.712495744228363
30th Epoch, 28455th Step, learning rate = 0.0071031157032869635 - Loss: 0.364408016204834, aux loss1: 1.1199074983596802, 
		 aux loss2: 0.5876272916793823, total loss: 0.935431182384491
30th Epoch, 28460th Step, learning rate = 0.007102596332584525 - Loss: 0.34067466855049133, aux loss1: 0.8146893978118896, 
		 aux loss2: 0.43858057260513306, total loss: 0.7605137825012207
30th Epoch, 28465th Step, learning rate = 0.007102076957662221 - Loss: 0.22653676569461823, aux loss1: 0.7352377772331238, 
		 aux loss2: 0.34386172890663147, total loss: 0.5846527814865112
30th Epoch, 28470th Step, learning rate = 0.007101557578519673 - Loss: 0.37812739610671997, aux loss1: 1.0115158557891846, 
		 aux loss2: 0.5871529579162598, total loss: 0.9164433479309082
30th Epoch, 28475th Step, learning rate = 0.007101038195156502 - Loss: 0.32494935393333435, aux loss1: 0.8119030594825745, 
		 aux loss2: 0.4585775136947632, total loss: 0.7519513368606567
30th Epoch, 28480th Step, learning rate = 0.007100518807572333 - Loss: 0.34259033203125, aux loss1: 0.9481047987937927, 
		 aux loss2: 0.527152955532074, total loss: 0.8378829956054688
30th Epoch, 28485th Step, learning rate = 0.007099999415766786 - Loss: 0.44673314690589905, aux loss1: 1.0853271484375, 
		 aux loss2: 0.6447277665138245, total loss: 1.0302224159240723
30th Epoch, 28490th Step, learning rate = 0.007099480019739487 - Loss: 0.33283206820487976, aux loss1: 0.835315465927124, 
		 aux loss2: 0.46352702379226685, total loss: 0.7688375115394592
30th Epoch, 28495th Step, learning rate = 0.007098960619490056 - Loss: 0.3811969757080078, aux loss1: 0.9855477213859558, 
		 aux loss2: 0.5295050144195557, total loss: 0.8886632919311523
30th Epoch, 28500th Step, learning rate = 0.007098441215018117 - Loss: 0.3422574996948242, aux loss1: 0.9837846755981445, 
		 aux loss2: 0.5165283679962158, total loss: 0.844004213809967
<28500th step>
*************************** Test ***************************
time:3m 16s, 28500th Step, Loss: 0.5314806699752808, Mean IoU = 44.953%
************************************************************
30th Epoch, 28505th Step, learning rate = 0.007097921806323291 - Loss: 0.2647952735424042, aux loss1: 0.7406362891197205, 
		 aux loss2: 0.39512574672698975, total loss: 0.6450364589691162
30th Epoch, 28510th Step, learning rate = 0.007097402393405201 - Loss: 0.2951754033565521, aux loss1: 0.836755633354187, 
		 aux loss2: 0.44499942660331726, total loss: 0.7242018580436707
30th Epoch, 28515th Step, learning rate = 0.007096882976263469 - Loss: 0.33538132905960083, aux loss1: 0.8634662628173828, 
		 aux loss2: 0.48346200585365295, total loss: 0.7878060340881348
30th Epoch, 28520th Step, learning rate = 0.007096363554897718 - Loss: 0.32354307174682617, aux loss1: 0.797645092010498, 
		 aux loss2: 0.44108718633651733, total loss: 0.7392714619636536
30th Epoch, 28525th Step, learning rate = 0.007095844129307569 - Loss: 0.3249496519565582, aux loss1: 0.8360834121704102, 
		 aux loss2: 0.4527120590209961, total loss: 0.7568594813346863
30th Epoch, 28530th Step, learning rate = 0.007095324699492644 - Loss: 0.3471786677837372, aux loss1: 0.8430523872375488, 
		 aux loss2: 0.4689238965511322, total loss: 0.787663996219635
30th Epoch, 28535th Step, learning rate = 0.007094805265452566 - Loss: 0.3293243646621704, aux loss1: 0.9325735569000244, 
		 aux loss2: 0.5099690556526184, total loss: 0.8130840063095093
30th Epoch, 28540th Step, learning rate = 0.007094285827186955 - Loss: 0.27296707034111023, aux loss1: 0.700143039226532, 
		 aux loss2: 0.3716374933719635, total loss: 0.6316649913787842
30th Epoch, 28545th Step, learning rate = 0.007093766384695436 - Loss: 0.34126806259155273, aux loss1: 0.7738786935806274, 
		 aux loss2: 0.44093871116638184, total loss: 0.7498071789741516
30th Epoch, 28550th Step, learning rate = 0.007093246937977629 - Loss: 0.3283178210258484, aux loss1: 0.741806149482727, 
		 aux loss2: 0.4264269769191742, total loss: 0.7214304804801941
30th Epoch, 28555th Step, learning rate = 0.0070927274870331534 - Loss: 0.33344778418540955, aux loss1: 0.8403846025466919, 
		 aux loss2: 0.47002410888671875, total loss: 0.7735728025436401
30th Epoch, 28560th Step, learning rate = 0.007092208031861636 - Loss: 0.30046215653419495, aux loss1: 0.7178800106048584, 
		 aux loss2: 0.4216688573360443, total loss: 0.6844937205314636
30th Epoch, 28565th Step, learning rate = 0.007091688572462693 - Loss: 0.2945616841316223, aux loss1: 0.8791384696960449, 
		 aux loss2: 0.46367326378822327, total loss: 0.743772566318512
30th Epoch, 28570th Step, learning rate = 0.007091169108835949 - Loss: 0.3783703148365021, aux loss1: 0.9044659733772278, 
		 aux loss2: 0.533067524433136, total loss: 0.8629371523857117
30th Epoch, 28575th Step, learning rate = 0.007090649640981029 - Loss: 0.3571065068244934, aux loss1: 0.8512880206108093, 
		 aux loss2: 0.478783518075943, total loss: 0.8040063381195068
30th Epoch, 28580th Step, learning rate = 0.007090130168897546 - Loss: 0.2472234070301056, aux loss1: 0.8010004162788391, 
		 aux loss2: 0.40118274092674255, total loss: 0.6479966640472412
30th Epoch, 28585th Step, learning rate = 0.007089610692585127 - Loss: 0.44648611545562744, aux loss1: 1.0384702682495117, 
		 aux loss2: 0.6287326812744141, total loss: 1.0095202922821045
30th Epoch, 28590th Step, learning rate = 0.007089091212043393 - Loss: 0.3380759358406067, aux loss1: 0.8402134776115417, 
		 aux loss2: 0.45530450344085693, total loss: 0.7722617983818054
30th Epoch, 28595th Step, learning rate = 0.0070885717272719615 - Loss: 0.2868666350841522, aux loss1: 0.7874876856803894, 
		 aux loss2: 0.43467164039611816, total loss: 0.6969816088676453
30th Epoch, 28600th Step, learning rate = 0.007088052238270458 - Loss: 0.28604456782341003, aux loss1: 0.8121065497398376, 
		 aux loss2: 0.40718764066696167, total loss: 0.6925516128540039
<28600th step>
*************************** Test ***************************
time:3m 18s, 28600th Step, Loss: 0.5615643262863159, Mean IoU = 44.310%
************************************************************
30th Epoch, 28605th Step, learning rate = 0.007087532745038503 - Loss: 0.45785507559776306, aux loss1: 1.0184047222137451, 
		 aux loss2: 0.6324472427368164, total loss: 1.0163553953170776
30th Epoch, 28610th Step, learning rate = 0.007087013247575714 - Loss: 0.242240771651268, aux loss1: 0.750917375087738, 
		 aux loss2: 0.33422228693962097, total loss: 0.6012049317359924
30th Epoch, 28615th Step, learning rate = 0.007086493745881716 - Loss: 0.32996654510498047, aux loss1: 0.8930875062942505, 
		 aux loss2: 0.4719288945198059, total loss: 0.7866643667221069
30th Epoch, 28620th Step, learning rate = 0.007085974239956128 - Loss: 0.44804757833480835, aux loss1: 1.0500423908233643, 
		 aux loss2: 0.6479151248931885, total loss: 1.022226333618164
30th Epoch, 28625th Step, learning rate = 0.00708545472979857 - Loss: 0.31801363825798035, aux loss1: 0.7886708974838257, 
		 aux loss2: 0.4568256139755249, total loss: 0.7373451590538025
30th Epoch, 28630th Step, learning rate = 0.007084935215408666 - Loss: 0.26643112301826477, aux loss1: 0.8077552318572998, 
		 aux loss2: 0.40207788348197937, total loss: 0.6695888638496399
31th Epoch, 28635th Step, learning rate = 0.007084415696786033 - Loss: 0.2960508465766907, aux loss1: 0.7020511031150818, 
		 aux loss2: 0.4248916208744049, total loss: 0.6766228675842285
31th Epoch, 28640th Step, learning rate = 0.007083896173930293 - Loss: 0.2826022803783417, aux loss1: 0.8069375157356262, 
		 aux loss2: 0.40435412526130676, total loss: 0.6864252090454102
31th Epoch, 28645th Step, learning rate = 0.007083376646841067 - Loss: 0.2949725091457367, aux loss1: 0.8260483741760254, 
		 aux loss2: 0.44829487800598145, total loss: 0.7221049666404724
31th Epoch, 28650th Step, learning rate = 0.007082857115517977 - Loss: 0.316634863615036, aux loss1: 0.860621988773346, 
		 aux loss2: 0.4622683823108673, total loss: 0.7597288489341736
31th Epoch, 28655th Step, learning rate = 0.00708233757996064 - Loss: 0.2835148572921753, aux loss1: 0.9048956036567688, 
		 aux loss2: 0.48845699429512024, total loss: 0.7503663301467896
31th Epoch, 28660th Step, learning rate = 0.0070818180401686776 - Loss: 0.24723011255264282, aux loss1: 0.7717698216438293, 
		 aux loss2: 0.40263795852661133, total loss: 0.6398162841796875
31th Epoch, 28665th Step, learning rate = 0.007081298496141709 - Loss: 0.29713502526283264, aux loss1: 0.8403183817863464, 
		 aux loss2: 0.4443657696247101, total loss: 0.7269768714904785
31th Epoch, 28670th Step, learning rate = 0.007080778947879359 - Loss: 0.377021461725235, aux loss1: 0.9793829321861267, 
		 aux loss2: 0.6012483835220337, total loss: 0.9113357067108154
31th Epoch, 28675th Step, learning rate = 0.007080259395381244 - Loss: 0.34255942702293396, aux loss1: 0.9379640817642212, 
		 aux loss2: 0.5134556889533997, total loss: 0.8293309807777405
31th Epoch, 28680th Step, learning rate = 0.007079739838646982 - Loss: 0.30039235949516296, aux loss1: 0.8626800775527954, 
		 aux loss2: 0.4456656277179718, total loss: 0.7374626398086548
31th Epoch, 28685th Step, learning rate = 0.0070792202776761995 - Loss: 0.28292420506477356, aux loss1: 0.706169068813324, 
		 aux loss2: 0.37645334005355835, total loss: 0.645356297492981
31th Epoch, 28690th Step, learning rate = 0.007078700712468511 - Loss: 0.28954723477363586, aux loss1: 0.7999652624130249, 
		 aux loss2: 0.4084208309650421, total loss: 0.6929051876068115
31th Epoch, 28695th Step, learning rate = 0.007078181143023538 - Loss: 0.26034751534461975, aux loss1: 0.7707053422927856, 
		 aux loss2: 0.39652323722839355, total loss: 0.6501684188842773
31th Epoch, 28700th Step, learning rate = 0.0070776615693409015 - Loss: 0.2817079424858093, aux loss1: 0.8012440204620361, 
		 aux loss2: 0.38585469126701355, total loss: 0.6764230132102966
<28700th step>
*************************** Test ***************************
time:3m 17s, 28700th Step, Loss: 0.5108934640884399, Mean IoU = 46.079%
************************************************************
31th Epoch, 28705th Step, learning rate = 0.00707714199142022 - Loss: 0.33698371052742004, aux loss1: 0.9491829872131348, 
		 aux loss2: 0.526885449886322, total loss: 0.8324928283691406
31th Epoch, 28710th Step, learning rate = 0.007076622409261112 - Loss: 0.33989864587783813, aux loss1: 0.7855709195137024, 
		 aux loss2: 0.470175176858902, total loss: 0.7636399865150452
31th Epoch, 28715th Step, learning rate = 0.007076102822863201 - Loss: 0.24932792782783508, aux loss1: 0.6833235025405884, 
		 aux loss2: 0.35421106219291687, total loss: 0.5960094332695007
31th Epoch, 28720th Step, learning rate = 0.007075583232226103 - Loss: 0.32896581292152405, aux loss1: 0.8838399648666382, 
		 aux loss2: 0.5058713555335999, total loss: 0.7964663505554199
31th Epoch, 28725th Step, learning rate = 0.007075063637349439 - Loss: 0.4271867871284485, aux loss1: 1.0400773286819458, 
		 aux loss2: 0.5869054794311523, total loss: 0.9739722013473511
31th Epoch, 28730th Step, learning rate = 0.007074544038232829 - Loss: 0.3548419773578644, aux loss1: 1.0705645084381104, 
		 aux loss2: 0.6042095422744751, total loss: 0.917695164680481
31th Epoch, 28735th Step, learning rate = 0.00707402443487589 - Loss: 0.28063541650772095, aux loss1: 0.6779963970184326, 
		 aux loss2: 0.3854004442691803, total loss: 0.6381945610046387
31th Epoch, 28740th Step, learning rate = 0.007073504827278245 - Loss: 0.3346872925758362, aux loss1: 0.9840173125267029, 
		 aux loss2: 0.5522785186767578, total loss: 0.8508038520812988
31th Epoch, 28745th Step, learning rate = 0.0070729852154395095 - Loss: 0.3158477544784546, aux loss1: 0.786457359790802, 
		 aux loss2: 0.4395906925201416, total loss: 0.7276212573051453
31th Epoch, 28750th Step, learning rate = 0.0070724655993593035 - Loss: 0.28547701239585876, aux loss1: 0.7218732833862305, 
		 aux loss2: 0.3975178599357605, total loss: 0.6610461473464966
31th Epoch, 28755th Step, learning rate = 0.00707194597903725 - Loss: 0.27091753482818604, aux loss1: 0.64372718334198, 
		 aux loss2: 0.364950954914093, total loss: 0.6100161075592041
31th Epoch, 28760th Step, learning rate = 0.007071426354472963 - Loss: 0.34119316935539246, aux loss1: 0.902239978313446, 
		 aux loss2: 0.5624523162841797, total loss: 0.836846113204956
31th Epoch, 28765th Step, learning rate = 0.007070906725666063 - Loss: 0.33359989523887634, aux loss1: 0.7903321385383606, 
		 aux loss2: 0.4549783766269684, total loss: 0.7526909112930298
31th Epoch, 28770th Step, learning rate = 0.007070387092616172 - Loss: 0.45716750621795654, aux loss1: 1.0098893642425537, 
		 aux loss2: 0.6442617774009705, total loss: 1.0178390741348267
31th Epoch, 28775th Step, learning rate = 0.007069867455322904 - Loss: 0.2739127576351166, aux loss1: 0.7459650635719299, 
		 aux loss2: 0.4033092260360718, total loss: 0.659026026725769
31th Epoch, 28780th Step, learning rate = 0.00706934781378588 - Loss: 0.29824355244636536, aux loss1: 0.7741000652313232, 
		 aux loss2: 0.4178708493709564, total loss: 0.6976219415664673
31th Epoch, 28785th Step, learning rate = 0.0070688281680047205 - Loss: 0.27341029047966003, aux loss1: 0.7670716047286987, 
		 aux loss2: 0.39491376280784607, total loss: 0.6614973545074463
31th Epoch, 28790th Step, learning rate = 0.0070683085179790404 - Loss: 0.4172475039958954, aux loss1: 0.9196535348892212, 
		 aux loss2: 0.5663818717002869, total loss: 0.9196963310241699
31th Epoch, 28795th Step, learning rate = 0.0070677888637084635 - Loss: 0.35817959904670715, aux loss1: 0.8787199258804321, 
		 aux loss2: 0.48936834931373596, total loss: 0.8175429105758667
31th Epoch, 28800th Step, learning rate = 0.0070672692051926035 - Loss: 0.33645346760749817, aux loss1: 0.7765628695487976, 
		 aux loss2: 0.44908833503723145, total loss: 0.7490577101707458
<28800th step>
*************************** Test ***************************
time:3m 20s, 28800th Step, Loss: 0.5654749274253845, Mean IoU = 45.358%
************************************************************
31th Epoch, 28805th Step, learning rate = 0.007066749542431082 - Loss: 0.247319296002388, aux loss1: 0.6277084946632385, 
		 aux loss2: 0.3378825783729553, total loss: 0.5707849264144897
31th Epoch, 28810th Step, learning rate = 0.007066229875423514 - Loss: 0.32691439986228943, aux loss1: 0.814253568649292, 
		 aux loss2: 0.4838520288467407, total loss: 0.7647312879562378
31th Epoch, 28815th Step, learning rate = 0.007065710204169521 - Loss: 0.27709266543388367, aux loss1: 0.7540789842605591, 
		 aux loss2: 0.38600459694862366, total loss: 0.6577182412147522
31th Epoch, 28820th Step, learning rate = 0.00706519052866872 - Loss: 0.2718242108821869, aux loss1: 0.7667132616043091, 
		 aux loss2: 0.39812931418418884, total loss: 0.6610899567604065
31th Epoch, 28825th Step, learning rate = 0.00706467084892073 - Loss: 0.36437082290649414, aux loss1: 1.0097602605819702, 
		 aux loss2: 0.5799902677536011, total loss: 0.8992950320243835
31th Epoch, 28830th Step, learning rate = 0.0070641511649251676 - Loss: 0.25523024797439575, aux loss1: 0.759635329246521, 
		 aux loss2: 0.39862072467803955, total loss: 0.6425691843032837
31th Epoch, 28835th Step, learning rate = 0.007063631476681652 - Loss: 0.521011471748352, aux loss1: 1.0830234289169312, 
		 aux loss2: 0.6927899718284607, total loss: 1.1230344772338867
31th Epoch, 28840th Step, learning rate = 0.007063111784189803 - Loss: 0.31867536902427673, aux loss1: 0.8136706948280334, 
		 aux loss2: 0.4400079846382141, total loss: 0.7387797832489014
31th Epoch, 28845th Step, learning rate = 0.007062592087449233 - Loss: 0.3655772805213928, aux loss1: 0.8662233352661133, 
		 aux loss2: 0.49677905440330505, total loss: 0.8241559267044067
31th Epoch, 28850th Step, learning rate = 0.007062072386459566 - Loss: 0.2615176737308502, aux loss1: 0.7570500373840332, 
		 aux loss2: 0.38065099716186523, total loss: 0.6408931016921997
31th Epoch, 28855th Step, learning rate = 0.007061552681220418 - Loss: 0.317870169878006, aux loss1: 0.9070481061935425, 
		 aux loss2: 0.4867912828922272, total loss: 0.7847011685371399
31th Epoch, 28860th Step, learning rate = 0.007061032971731404 - Loss: 0.3107790946960449, aux loss1: 0.9128597974777222, 
		 aux loss2: 0.47576507925987244, total loss: 0.7749431133270264
31th Epoch, 28865th Step, learning rate = 0.007060513257992144 - Loss: 0.263086199760437, aux loss1: 0.7752162218093872, 
		 aux loss2: 0.39293205738067627, total loss: 0.6528239250183105
31th Epoch, 28870th Step, learning rate = 0.007059993540002256 - Loss: 0.25184911489486694, aux loss1: 0.6672499179840088, 
		 aux loss2: 0.3469083607196808, total loss: 0.5907874703407288
31th Epoch, 28875th Step, learning rate = 0.007059473817761356 - Loss: 0.2566201388835907, aux loss1: 0.6922110915184021, 
		 aux loss2: 0.36088383197784424, total loss: 0.6086369752883911
31th Epoch, 28880th Step, learning rate = 0.0070589540912690645 - Loss: 0.3232106864452362, aux loss1: 0.9918984174728394, 
		 aux loss2: 0.525330126285553, total loss: 0.8309122920036316
31th Epoch, 28885th Step, learning rate = 0.007058434360524994 - Loss: 0.3381424844264984, aux loss1: 0.9571906924247742, 
		 aux loss2: 0.5183865427970886, total loss: 0.8326542973518372
31th Epoch, 28890th Step, learning rate = 0.007057914625528766 - Loss: 0.32025524973869324, aux loss1: 0.7611241936683655, 
		 aux loss2: 0.4208742678165436, total loss: 0.7169421911239624
31th Epoch, 28895th Step, learning rate = 0.007057394886279997 - Loss: 0.3743988573551178, aux loss1: 0.9835061430931091, 
		 aux loss2: 0.5425270795822144, total loss: 0.8864615559577942
31th Epoch, 28900th Step, learning rate = 0.007056875142778303 - Loss: 0.4023490250110626, aux loss1: 0.917748749256134, 
		 aux loss2: 0.5250715017318726, total loss: 0.8877022862434387
<28900th step>
*************************** Test ***************************
time:3m 18s, 28900th Step, Loss: 0.6008540391921997, Mean IoU = 43.117%
************************************************************
31th Epoch, 28905th Step, learning rate = 0.007056355395023302 - Loss: 0.27854621410369873, aux loss1: 0.757712721824646, 
		 aux loss2: 0.4115324318408966, total loss: 0.6704729795455933
31th Epoch, 28910th Step, learning rate = 0.007055835643014612 - Loss: 0.2859351336956024, aux loss1: 0.8040922284126282, 
		 aux loss2: 0.41311129927635193, total loss: 0.6924073100090027
31th Epoch, 28915th Step, learning rate = 0.007055315886751846 - Loss: 0.3829135596752167, aux loss1: 0.9531896710395813, 
		 aux loss2: 0.5412063002586365, total loss: 0.8853529691696167
31th Epoch, 28920th Step, learning rate = 0.007054796126234626 - Loss: 0.3761969804763794, aux loss1: 0.8570029735565186, 
		 aux loss2: 0.5191999673843384, total loss: 0.8409779071807861
31th Epoch, 28925th Step, learning rate = 0.007054276361462567 - Loss: 0.346219003200531, aux loss1: 0.8983016014099121, 
		 aux loss2: 0.4969596266746521, total loss: 0.8144933581352234
31th Epoch, 28930th Step, learning rate = 0.007053756592435285 - Loss: 0.35339465737342834, aux loss1: 0.9467365741729736, 
		 aux loss2: 0.5449720621109009, total loss: 0.8554044961929321
31th Epoch, 28935th Step, learning rate = 0.007053236819152398 - Loss: 0.3405718207359314, aux loss1: 0.9515613317489624, 
		 aux loss2: 0.49143311381340027, total loss: 0.8226134777069092
31th Epoch, 28940th Step, learning rate = 0.007052717041613521 - Loss: 0.2917422950267792, aux loss1: 0.8892173767089844, 
		 aux loss2: 0.4405458867549896, total loss: 0.7347259521484375
31th Epoch, 28945th Step, learning rate = 0.007052197259818272 - Loss: 0.21807995438575745, aux loss1: 0.8190258145332336, 
		 aux loss2: 0.3670932352542877, total loss: 0.6106250286102295
31th Epoch, 28950th Step, learning rate = 0.007051677473766269 - Loss: 0.4737789034843445, aux loss1: 1.0843939781188965, 
		 aux loss2: 0.6158041954040527, total loss: 1.0454187393188477
31th Epoch, 28955th Step, learning rate = 0.007051157683457126 - Loss: 0.29419806599617004, aux loss1: 0.8413330912590027, 
		 aux loss2: 0.44006362557411194, total loss: 0.7226234674453735
31th Epoch, 28960th Step, learning rate = 0.007050637888890459 - Loss: 0.4034925401210785, aux loss1: 0.9707709550857544, 
		 aux loss2: 0.5931277871131897, total loss: 0.9319749474525452
31th Epoch, 28965th Step, learning rate = 0.007050118090065888 - Loss: 0.28559237718582153, aux loss1: 0.694442093372345, 
		 aux loss2: 0.37350258231163025, total loss: 0.6433260440826416
31th Epoch, 28970th Step, learning rate = 0.007049598286983023 - Loss: 0.3812599182128906, aux loss1: 0.8535135984420776, 
		 aux loss2: 0.5404568314552307, total loss: 0.853496789932251
31th Epoch, 28975th Step, learning rate = 0.007049078479641487 - Loss: 0.3506229817867279, aux loss1: 1.0450042486190796, 
		 aux loss2: 0.5891602039337158, total loss: 0.8997883200645447
31th Epoch, 28980th Step, learning rate = 0.007048558668040893 - Loss: 0.2222689837217331, aux loss1: 0.6338202357292175, 
		 aux loss2: 0.3094562590122223, total loss: 0.5361975431442261
31th Epoch, 28985th Step, learning rate = 0.007048038852180857 - Loss: 0.25348299741744995, aux loss1: 0.7083700895309448, 
		 aux loss2: 0.37203648686408997, total loss: 0.6148086190223694
31th Epoch, 28990th Step, learning rate = 0.0070475190320609974 - Loss: 0.3517303764820099, aux loss1: 1.0041674375534058, 
		 aux loss2: 0.5328184962272644, total loss: 0.8661080598831177
31th Epoch, 28995th Step, learning rate = 0.007046999207680925 - Loss: 0.3519516587257385, aux loss1: 0.993903398513794, 
		 aux loss2: 0.5334194302558899, total loss: 0.8634904623031616
31th Epoch, 29000th Step, learning rate = 0.007046479379040261 - Loss: 0.2807832658290863, aux loss1: 0.7879270315170288, 
		 aux loss2: 0.40999850630760193, total loss: 0.6811608076095581
<29000th step>
*************************** Test ***************************
time:3m 14s, 29000th Step, Loss: 0.5390461087226868, Mean IoU = 46.066%
************************************************************
32th Epoch, 29005th Step, learning rate = 0.00704595954613862 - Loss: 0.27303335070610046, aux loss1: 0.7524392604827881, 
		 aux loss2: 0.4099734127521515, total loss: 0.6627545356750488
32th Epoch, 29010th Step, learning rate = 0.007045439708975615 - Loss: 0.250491738319397, aux loss1: 0.8386735916137695, 
		 aux loss2: 0.3966875672340393, total loss: 0.6607688069343567
32th Epoch, 29015th Step, learning rate = 0.007044919867550863 - Loss: 0.26114389300346375, aux loss1: 0.790092408657074, 
		 aux loss2: 0.38520774245262146, total loss: 0.6522547006607056
32th Epoch, 29020th Step, learning rate = 0.007044400021863982 - Loss: 0.309887170791626, aux loss1: 0.831530749797821, 
		 aux loss2: 0.45234519243240356, total loss: 0.7402845025062561
32th Epoch, 29025th Step, learning rate = 0.007043880171914585 - Loss: 0.3348214626312256, aux loss1: 0.8600369691848755, 
		 aux loss2: 0.5149614810943604, total loss: 0.7988171577453613
32th Epoch, 29030th Step, learning rate = 0.00704336031770229 - Loss: 0.31949496269226074, aux loss1: 0.9135299921035767, 
		 aux loss2: 0.4797208607196808, total loss: 0.7854422926902771
32th Epoch, 29035th Step, learning rate = 0.00704284045922671 - Loss: 0.30763494968414307, aux loss1: 0.8950022459030151, 
		 aux loss2: 0.47246986627578735, total loss: 0.7651236057281494
32th Epoch, 29040th Step, learning rate = 0.00704232059648746 - Loss: 0.2728050649166107, aux loss1: 0.6396550536155701, 
		 aux loss2: 0.3609194755554199, total loss: 0.6090694069862366
32th Epoch, 29045th Step, learning rate = 0.007041800729484158 - Loss: 0.23791874945163727, aux loss1: 0.7011308670043945, 
		 aux loss2: 0.32755473256111145, total loss: 0.579279899597168
32th Epoch, 29050th Step, learning rate = 0.007041280858216417 - Loss: 0.3274726867675781, aux loss1: 0.8763420581817627, 
		 aux loss2: 0.5053831934928894, total loss: 0.7925285696983337
32th Epoch, 29055th Step, learning rate = 0.007040760982683853 - Loss: 0.25168636441230774, aux loss1: 0.7438220381736755, 
		 aux loss2: 0.34673696756362915, total loss: 0.613527774810791
32th Epoch, 29060th Step, learning rate = 0.007040241102886082 - Loss: 0.3278300166130066, aux loss1: 0.8662608861923218, 
		 aux loss2: 0.4793635904788971, total loss: 0.7794537544250488
32th Epoch, 29065th Step, learning rate = 0.0070397212188227165 - Loss: 0.2980862557888031, aux loss1: 0.7541318535804749, 
		 aux loss2: 0.42656636238098145, total loss: 0.6949523687362671
32th Epoch, 29070th Step, learning rate = 0.007039201330493373 - Loss: 0.32422441244125366, aux loss1: 0.8944289684295654, 
		 aux loss2: 0.4889979064464569, total loss: 0.7881523370742798
32th Epoch, 29075th Step, learning rate = 0.007038681437897669 - Loss: 0.24462486803531647, aux loss1: 0.8661812543869019, 
		 aux loss2: 0.39815837144851685, total loss: 0.6637426018714905
32th Epoch, 29080th Step, learning rate = 0.007038161541035215 - Loss: 0.25539231300354004, aux loss1: 0.8451513648033142, 
		 aux loss2: 0.47028982639312744, total loss: 0.6970536708831787
32th Epoch, 29085th Step, learning rate = 0.0070376416399056275 - Loss: 0.3100557327270508, aux loss1: 0.9397176504135132, 
		 aux loss2: 0.5097220540046692, total loss: 0.7958598732948303
32th Epoch, 29090th Step, learning rate = 0.007037121734508523 - Loss: 0.3743819296360016, aux loss1: 0.9310858845710754, 
		 aux loss2: 0.5154996514320374, total loss: 0.8599076271057129
32th Epoch, 29095th Step, learning rate = 0.007036601824843511 - Loss: 0.31370168924331665, aux loss1: 0.8077929615974426, 
		 aux loss2: 0.43763086199760437, total loss: 0.7310919165611267
32th Epoch, 29100th Step, learning rate = 0.007036081910910212 - Loss: 0.31806302070617676, aux loss1: 0.8349162936210632, 
		 aux loss2: 0.45967528223991394, total loss: 0.7524080872535706
<29100th step>
*************************** Test ***************************
time:3m 18s, 29100th Step, Loss: 0.5433244705200195, Mean IoU = 45.263%
************************************************************
32th Epoch, 29105th Step, learning rate = 0.007035561992708238 - Loss: 0.26867032051086426, aux loss1: 0.7679447531700134, 
		 aux loss2: 0.38495972752571106, total loss: 0.6530376672744751
32th Epoch, 29110th Step, learning rate = 0.007035042070237203 - Loss: 0.32113489508628845, aux loss1: 0.8243721723556519, 
		 aux loss2: 0.45408254861831665, total loss: 0.7500796318054199
32th Epoch, 29115th Step, learning rate = 0.007034522143496723 - Loss: 0.3222293257713318, aux loss1: 0.8815467357635498, 
		 aux loss2: 0.4955884516239166, total loss: 0.7849287390708923
32th Epoch, 29120th Step, learning rate = 0.00703400221248641 - Loss: 0.21435973048210144, aux loss1: 0.675689160823822, 
		 aux loss2: 0.33178991079330444, total loss: 0.5497824549674988
32th Epoch, 29125th Step, learning rate = 0.00703348227720588 - Loss: 0.412823349237442, aux loss1: 0.9454544186592102, 
		 aux loss2: 0.5706941485404968, total loss: 0.9247373342514038
32th Epoch, 29130th Step, learning rate = 0.007032962337654748 - Loss: 0.2807983458042145, aux loss1: 0.7960189580917358, 
		 aux loss2: 0.4149949848651886, total loss: 0.6856020092964172
32th Epoch, 29135th Step, learning rate = 0.007032442393832624 - Loss: 0.289249449968338, aux loss1: 0.8670713901519775, 
		 aux loss2: 0.44205546379089355, total loss: 0.7261930704116821
32th Epoch, 29140th Step, learning rate = 0.0070319224457391265 - Loss: 0.32756686210632324, aux loss1: 0.9776690602302551, 
		 aux loss2: 0.5587955117225647, total loss: 0.8443858027458191
32th Epoch, 29145th Step, learning rate = 0.007031402493373869 - Loss: 0.3771267533302307, aux loss1: 0.9787206649780273, 
		 aux loss2: 0.5505623817443848, total loss: 0.8909679651260376
32th Epoch, 29150th Step, learning rate = 0.00703088253673646 - Loss: 0.2595631182193756, aux loss1: 0.6606318950653076, 
		 aux loss2: 0.3581324815750122, total loss: 0.6010056734085083
32th Epoch, 29155th Step, learning rate = 0.007030362575826521 - Loss: 0.25627073645591736, aux loss1: 0.7408996224403381, 
		 aux loss2: 0.34841376543045044, total loss: 0.6179061532020569
32th Epoch, 29160th Step, learning rate = 0.007029842610643662 - Loss: 0.35298383235931396, aux loss1: 0.866453230381012, 
		 aux loss2: 0.5039653778076172, total loss: 0.814505934715271
32th Epoch, 29165th Step, learning rate = 0.0070293226411874965 - Loss: 0.28363731503486633, aux loss1: 0.924210250377655, 
		 aux loss2: 0.44171902537345886, total loss: 0.7375879883766174
32th Epoch, 29170th Step, learning rate = 0.007028802667457638 - Loss: 0.2647131085395813, aux loss1: 0.7732488512992859, 
		 aux loss2: 0.39788445830345154, total loss: 0.655841588973999
32th Epoch, 29175th Step, learning rate = 0.007028282689453702 - Loss: 0.4437408149242401, aux loss1: 1.0293885469436646, 
		 aux loss2: 0.6336007714271545, total loss: 1.005997657775879
32th Epoch, 29180th Step, learning rate = 0.0070277627071753 - Loss: 0.27387842535972595, aux loss1: 0.6745918989181519, 
		 aux loss2: 0.3739626407623291, total loss: 0.6258410811424255
32th Epoch, 29185th Step, learning rate = 0.007027242720622048 - Loss: 0.28578129410743713, aux loss1: 0.8009521961212158, 
		 aux loss2: 0.4245879650115967, total loss: 0.6959021687507629
32th Epoch, 29190th Step, learning rate = 0.007026722729793556 - Loss: 0.3146277666091919, aux loss1: 0.8142730593681335, 
		 aux loss2: 0.440617173910141, total loss: 0.7351565957069397
32th Epoch, 29195th Step, learning rate = 0.00702620273468944 - Loss: 0.33935829997062683, aux loss1: 0.8950029015541077, 
		 aux loss2: 0.5201188325881958, total loss: 0.8159067630767822
32th Epoch, 29200th Step, learning rate = 0.007025682735309311 - Loss: 0.36427879333496094, aux loss1: 1.0686421394348145, 
		 aux loss2: 0.6007148027420044, total loss: 0.925157368183136
<29200th step>
*************************** Test ***************************
time:3m 18s, 29200th Step, Loss: 0.5243066549301147, Mean IoU = 46.805%
************************************************************
32th Epoch, 29205th Step, learning rate = 0.007025162731652784 - Loss: 0.4944835603237152, aux loss1: 0.9438372254371643, 
		 aux loss2: 0.5815877914428711, total loss: 1.0102698802947998
32th Epoch, 29210th Step, learning rate = 0.007024642723719471 - Loss: 0.29639261960983276, aux loss1: 0.842154860496521, 
		 aux loss2: 0.40996846556663513, total loss: 0.7130265235900879
32th Epoch, 29215th Step, learning rate = 0.007024122711508987 - Loss: 0.3617185652256012, aux loss1: 0.9186144471168518, 
		 aux loss2: 0.5259376764297485, total loss: 0.8476779460906982
32th Epoch, 29220th Step, learning rate = 0.00702360269502094 - Loss: 0.31407707929611206, aux loss1: 0.8978525996208191, 
		 aux loss2: 0.46720173954963684, total loss: 0.7703136205673218
32th Epoch, 29225th Step, learning rate = 0.00702308267425495 - Loss: 0.3419608473777771, aux loss1: 1.0739833116531372, 
		 aux loss2: 0.5277186632156372, total loss: 0.8752433061599731
32th Epoch, 29230th Step, learning rate = 0.007022562649210626 - Loss: 0.30805671215057373, aux loss1: 0.8159137964248657, 
		 aux loss2: 0.43481019139289856, total loss: 0.7267549633979797
32th Epoch, 29235th Step, learning rate = 0.00702204261988758 - Loss: 0.30397382378578186, aux loss1: 0.7687828540802002, 
		 aux loss2: 0.41680750250816345, total loss: 0.7013317346572876
32th Epoch, 29240th Step, learning rate = 0.007021522586285427 - Loss: 0.24470937252044678, aux loss1: 0.7890699505805969, 
		 aux loss2: 0.37985849380493164, total loss: 0.6333737373352051
32th Epoch, 29245th Step, learning rate = 0.0070210025484037765 - Loss: 0.2941789925098419, aux loss1: 0.7912187576293945, 
		 aux loss2: 0.4101349115371704, total loss: 0.6955986022949219
32th Epoch, 29250th Step, learning rate = 0.007020482506242244 - Loss: 0.3130926489830017, aux loss1: 0.8655810356140137, 
		 aux loss2: 0.47899776697158813, total loss: 0.764366090297699
32th Epoch, 29255th Step, learning rate = 0.007019962459800442 - Loss: 0.34518635272979736, aux loss1: 0.9405608773231506, 
		 aux loss2: 0.5004860758781433, total loss: 0.8275490403175354
32th Epoch, 29260th Step, learning rate = 0.0070194424090779806 - Loss: 0.277998149394989, aux loss1: 0.8041992783546448, 
		 aux loss2: 0.42825818061828613, total loss: 0.6905612349510193
32th Epoch, 29265th Step, learning rate = 0.007018922354074474 - Loss: 0.4499378204345703, aux loss1: 1.0983818769454956, 
		 aux loss2: 0.6567469239234924, total loss: 1.0421512126922607
32th Epoch, 29270th Step, learning rate = 0.007018402294789534 - Loss: 0.36978796124458313, aux loss1: 0.865627110004425, 
		 aux loss2: 0.4960998594760895, total loss: 0.8279160261154175
32th Epoch, 29275th Step, learning rate = 0.007017882231222772 - Loss: 0.2732110619544983, aux loss1: 0.7503734230995178, 
		 aux loss2: 0.3677012324333191, total loss: 0.6454035639762878
32th Epoch, 29280th Step, learning rate = 0.007017362163373802 - Loss: 0.2668871581554413, aux loss1: 0.8436784744262695, 
		 aux loss2: 0.4345954954624176, total loss: 0.6938288807868958
32th Epoch, 29285th Step, learning rate = 0.007016842091242236 - Loss: 0.3533531427383423, aux loss1: 0.8839532136917114, 
		 aux loss2: 0.4712730646133423, total loss: 0.8070483207702637
32th Epoch, 29290th Step, learning rate = 0.007016322014827684 - Loss: 0.275529682636261, aux loss1: 0.7567944526672363, 
		 aux loss2: 0.39621421694755554, total loss: 0.6610537171363831
32th Epoch, 29295th Step, learning rate = 0.00701580193412976 - Loss: 0.2898787260055542, aux loss1: 0.8413559198379517, 
		 aux loss2: 0.4263207018375397, total loss: 0.7128137946128845
32th Epoch, 29300th Step, learning rate = 0.007015281849148074 - Loss: 0.3094865083694458, aux loss1: 0.8292317986488342, 
		 aux loss2: 0.4485733211040497, total loss: 0.7376853823661804
<29300th step>
*************************** Test ***************************
time:3m 19s, 29300th Step, Loss: 0.5264374017715454, Mean IoU = 45.812%
************************************************************
32th Epoch, 29305th Step, learning rate = 0.00701476175988224 - Loss: 0.28427907824516296, aux loss1: 0.8295261859893799, 
		 aux loss2: 0.4252151846885681, total loss: 0.7032230496406555
32th Epoch, 29310th Step, learning rate = 0.007014241666331869 - Loss: 0.278708815574646, aux loss1: 0.8574422597885132, 
		 aux loss2: 0.43513616919517517, total loss: 0.7099959850311279
32th Epoch, 29315th Step, learning rate = 0.0070137215684965715 - Loss: 0.45735833048820496, aux loss1: 0.9350997805595398, 
		 aux loss2: 0.5749094486236572, total loss: 0.9678520560264587
32th Epoch, 29320th Step, learning rate = 0.007013201466375961 - Loss: 0.273856520652771, aux loss1: 0.7954880595207214, 
		 aux loss2: 0.3964710235595703, total loss: 0.6710913777351379
32th Epoch, 29325th Step, learning rate = 0.0070126813599696485 - Loss: 0.3198901414871216, aux loss1: 0.7994451522827148, 
		 aux loss2: 0.4456416666507721, total loss: 0.7379803657531738
32th Epoch, 29330th Step, learning rate = 0.007012161249277242 - Loss: 0.28622907400131226, aux loss1: 0.862594723701477, 
		 aux loss2: 0.4689139723777771, total loss: 0.7325730323791504
32th Epoch, 29335th Step, learning rate = 0.00701164113429836 - Loss: 0.3630569875240326, aux loss1: 0.8989405632019043, 
		 aux loss2: 0.5525690913200378, total loss: 0.8537667989730835
32th Epoch, 29340th Step, learning rate = 0.007011121015032609 - Loss: 0.24795658886432648, aux loss1: 0.6456896066665649, 
		 aux loss2: 0.3444300591945648, total loss: 0.5794354677200317
32th Epoch, 29345th Step, learning rate = 0.007010600891479599 - Loss: 0.330885112285614, aux loss1: 0.815399706363678, 
		 aux loss2: 0.4809015095233917, total loss: 0.7678656578063965
32th Epoch, 29350th Step, learning rate = 0.0070100807636389465 - Loss: 0.3061527907848358, aux loss1: 0.8083881735801697, 
		 aux loss2: 0.46186405420303345, total loss: 0.7334148287773132
32th Epoch, 29355th Step, learning rate = 0.007009560631510258 - Loss: 0.27129870653152466, aux loss1: 0.7829815149307251, 
		 aux loss2: 0.40271511673927307, total loss: 0.6672792434692383
32th Epoch, 29360th Step, learning rate = 0.007009040495093146 - Loss: 0.4058483839035034, aux loss1: 0.9516806602478027, 
		 aux loss2: 0.5591138005256653, total loss: 0.9149981141090393
32th Epoch, 29365th Step, learning rate = 0.007008520354387223 - Loss: 0.3303232491016388, aux loss1: 0.8579827547073364, 
		 aux loss2: 0.4547986090183258, total loss: 0.7696375846862793
32th Epoch, 29370th Step, learning rate = 0.007008000209392098 - Loss: 0.32652905583381653, aux loss1: 0.8746406435966492, 
		 aux loss2: 0.4646218717098236, total loss: 0.7747700214385986
33th Epoch, 29375th Step, learning rate = 0.007007480060107383 - Loss: 0.29583320021629333, aux loss1: 0.8115730285644531, 
		 aux loss2: 0.44447970390319824, total loss: 0.7170969843864441
33th Epoch, 29380th Step, learning rate = 0.007006959906532689 - Loss: 0.39023804664611816, aux loss1: 0.9501741528511047, 
		 aux loss2: 0.5517381429672241, total loss: 0.8959856033325195
33th Epoch, 29385th Step, learning rate = 0.007006439748667627 - Loss: 0.29417532682418823, aux loss1: 0.8161953687667847, 
		 aux loss2: 0.44916269183158875, total loss: 0.718699038028717
33th Epoch, 29390th Step, learning rate = 0.0070059195865118055 - Loss: 0.5663991570472717, aux loss1: 1.1042271852493286, 
		 aux loss2: 0.7564470767974854, total loss: 1.2002460956573486
33th Epoch, 29395th Step, learning rate = 0.007005399420064838 - Loss: 0.38183706998825073, aux loss1: 1.0268518924713135, 
		 aux loss2: 0.5532243847846985, total loss: 0.9111824035644531
33th Epoch, 29400th Step, learning rate = 0.00700487924932633 - Loss: 0.27837055921554565, aux loss1: 0.7860963344573975, 
		 aux loss2: 0.4052458703517914, total loss: 0.6762978434562683
<29400th step>
*************************** Test ***************************
time:3m 18s, 29400th Step, Loss: 0.5345369577407837, Mean IoU = 45.124%
************************************************************
33th Epoch, 29405th Step, learning rate = 0.007004359074295899 - Loss: 0.3173527419567108, aux loss1: 0.9116296172142029, 
		 aux loss2: 0.5177280902862549, total loss: 0.7979328632354736
33th Epoch, 29410th Step, learning rate = 0.007003838894973152 - Loss: 0.33109089732170105, aux loss1: 0.7825819253921509, 
		 aux loss2: 0.4591812193393707, total loss: 0.749538004398346
33th Epoch, 29415th Step, learning rate = 0.007003318711357699 - Loss: 0.29405155777931213, aux loss1: 0.6933871507644653, 
		 aux loss2: 0.40590640902519226, total loss: 0.6644302606582642
33th Epoch, 29420th Step, learning rate = 0.0070027985234491505 - Loss: 0.3188436031341553, aux loss1: 0.8028342127799988, 
		 aux loss2: 0.4506736695766449, total loss: 0.7399633526802063
33th Epoch, 29425th Step, learning rate = 0.007002278331247117 - Loss: 0.31482383608818054, aux loss1: 0.8178571462631226, 
		 aux loss2: 0.4557771682739258, total loss: 0.7424919009208679
33th Epoch, 29430th Step, learning rate = 0.00700175813475121 - Loss: 0.2688137888908386, aux loss1: 0.8884745240211487, 
		 aux loss2: 0.43520447611808777, total loss: 0.7094379663467407
33th Epoch, 29435th Step, learning rate = 0.007001237933961037 - Loss: 0.3560590147972107, aux loss1: 1.0002148151397705, 
		 aux loss2: 0.5235646963119507, total loss: 0.8655493259429932
33th Epoch, 29440th Step, learning rate = 0.0070007177288762094 - Loss: 0.29044288396835327, aux loss1: 0.8116726875305176, 
		 aux loss2: 0.4344180226325989, total loss: 0.707711935043335
33th Epoch, 29445th Step, learning rate = 0.007000197519496336 - Loss: 0.2740534543991089, aux loss1: 0.8294270038604736, 
		 aux loss2: 0.4189463257789612, total loss: 0.6904600858688354
33th Epoch, 29450th Step, learning rate = 0.006999677305821031 - Loss: 0.34013381600379944, aux loss1: 0.8373755812644958, 
		 aux loss2: 0.4615683853626251, total loss: 0.7759738564491272
33th Epoch, 29455th Step, learning rate = 0.006999157087849896 - Loss: 0.21978707611560822, aux loss1: 0.6337799429893494, 
		 aux loss2: 0.2993592619895935, total loss: 0.5296647548675537
33th Epoch, 29460th Step, learning rate = 0.006998636865582549 - Loss: 0.2844843864440918, aux loss1: 0.8128848671913147, 
		 aux loss2: 0.4103998839855194, total loss: 0.6925098299980164
33th Epoch, 29465th Step, learning rate = 0.006998116639018597 - Loss: 0.3373609185218811, aux loss1: 0.8144800662994385, 
		 aux loss2: 0.4511406421661377, total loss: 0.7621612548828125
33th Epoch, 29470th Step, learning rate = 0.0069975964081576475 - Loss: 0.3293498754501343, aux loss1: 0.8441541194915771, 
		 aux loss2: 0.5022066235542297, total loss: 0.7834787964820862
33th Epoch, 29475th Step, learning rate = 0.006997076172999312 - Loss: 0.22170543670654297, aux loss1: 0.724349319934845, 
		 aux loss2: 0.32257866859436035, total loss: 0.5680417418479919
33th Epoch, 29480th Step, learning rate = 0.006996555933543199 - Loss: 0.34032654762268066, aux loss1: 1.001034140586853, 
		 aux loss2: 0.5390458703041077, total loss: 0.8562551736831665
33th Epoch, 29485th Step, learning rate = 0.006996035689788919 - Loss: 0.33049237728118896, aux loss1: 0.94305020570755, 
		 aux loss2: 0.4954643249511719, total loss: 0.811593234539032
33th Epoch, 29490th Step, learning rate = 0.006995515441736081 - Loss: 0.3195558786392212, aux loss1: 0.8882890343666077, 
		 aux loss2: 0.49419525265693665, total loss: 0.7837207317352295
33th Epoch, 29495th Step, learning rate = 0.006994995189384293 - Loss: 0.3098229467868805, aux loss1: 0.8219066858291626, 
		 aux loss2: 0.45225340127944946, total loss: 0.7372962832450867
33th Epoch, 29500th Step, learning rate = 0.0069944749327331655 - Loss: 0.26947513222694397, aux loss1: 0.7384109497070312, 
		 aux loss2: 0.4002304971218109, total loss: 0.6510906219482422
<29500th step>
*************************** Test ***************************
time:3m 17s, 29500th Step, Loss: 0.5788720846176147, Mean IoU = 43.992%
************************************************************
33th Epoch, 29505th Step, learning rate = 0.006993954671782309 - Loss: 0.38167980313301086, aux loss1: 0.9632357358932495, 
		 aux loss2: 0.5756537914276123, total loss: 0.9009120464324951
33th Epoch, 29510th Step, learning rate = 0.006993434406531328 - Loss: 0.2898789048194885, aux loss1: 0.8005907535552979, 
		 aux loss2: 0.3981497287750244, total loss: 0.6893160343170166
33th Epoch, 29515th Step, learning rate = 0.006992914136979837 - Loss: 0.37025368213653564, aux loss1: 1.1643260717391968, 
		 aux loss2: 0.6266924142837524, total loss: 0.9702284336090088
33th Epoch, 29520th Step, learning rate = 0.006992393863127443 - Loss: 0.25434184074401855, aux loss1: 0.8399720191955566, 
		 aux loss2: 0.4117821156978607, total loss: 0.6710463166236877
33th Epoch, 29525th Step, learning rate = 0.006991873584973752 - Loss: 0.29824140667915344, aux loss1: 0.7923775315284729, 
		 aux loss2: 0.43047940731048584, total loss: 0.7081464529037476
33th Epoch, 29530th Step, learning rate = 0.006991353302518376 - Loss: 0.2589748799800873, aux loss1: 0.7269676327705383, 
		 aux loss2: 0.37481510639190674, total loss: 0.6269912123680115
33th Epoch, 29535th Step, learning rate = 0.006990833015760922 - Loss: 0.23607219755649567, aux loss1: 0.6913037896156311, 
		 aux loss2: 0.35073184967041016, total loss: 0.5837560892105103
33th Epoch, 29540th Step, learning rate = 0.006990312724701001 - Loss: 0.2861863076686859, aux loss1: 0.8701754808425903, 
		 aux loss2: 0.4474678933620453, total loss: 0.7262260913848877
33th Epoch, 29545th Step, learning rate = 0.006989792429338219 - Loss: 0.2811368405818939, aux loss1: 0.7104806303977966, 
		 aux loss2: 0.38227221369743347, total loss: 0.6471899747848511
33th Epoch, 29550th Step, learning rate = 0.006989272129672187 - Loss: 0.29785752296447754, aux loss1: 0.7548778057098389, 
		 aux loss2: 0.38629427552223206, total loss: 0.6788385510444641
33th Epoch, 29555th Step, learning rate = 0.006988751825702512 - Loss: 0.3107193410396576, aux loss1: 0.9627557992935181, 
		 aux loss2: 0.5190730094909668, total loss: 0.8071752786636353
33th Epoch, 29560th Step, learning rate = 0.006988231517428801 - Loss: 0.29536595940589905, aux loss1: 0.7396655082702637, 
		 aux loss2: 0.417217880487442, total loss: 0.6841527819633484
33th Epoch, 29565th Step, learning rate = 0.006987711204850665 - Loss: 0.3814816474914551, aux loss1: 0.8855172991752625, 
		 aux loss2: 0.49124956130981445, total loss: 0.8436366319656372
33th Epoch, 29570th Step, learning rate = 0.0069871908879677105 - Loss: 0.2448035180568695, aux loss1: 0.7008683085441589, 
		 aux loss2: 0.35186779499053955, total loss: 0.595811128616333
33th Epoch, 29575th Step, learning rate = 0.006986670566779547 - Loss: 0.25607842206954956, aux loss1: 0.7005687952041626, 
		 aux loss2: 0.3632546067237854, total loss: 0.6115509271621704
33th Epoch, 29580th Step, learning rate = 0.00698615024128578 - Loss: 0.4147370159626007, aux loss1: 1.1622422933578491, 
		 aux loss2: 0.624118983745575, total loss: 1.0130573511123657
33th Epoch, 29585th Step, learning rate = 0.006985629911486022 - Loss: 0.2971544861793518, aux loss1: 0.8161169290542603, 
		 aux loss2: 0.43142223358154297, total loss: 0.714558482170105
33th Epoch, 29590th Step, learning rate = 0.006985109577379878 - Loss: 0.31493356823921204, aux loss1: 0.8116768002510071, 
		 aux loss2: 0.4481956958770752, total loss: 0.7377148866653442
33th Epoch, 29595th Step, learning rate = 0.006984589238966955 - Loss: 0.3150887191295624, aux loss1: 0.9027259945869446, 
		 aux loss2: 0.48177698254585266, total loss: 0.7786173224449158
33th Epoch, 29600th Step, learning rate = 0.006984068896246864 - Loss: 0.3722657263278961, aux loss1: 0.8771547079086304, 
		 aux loss2: 0.49856361746788025, total loss: 0.8348376154899597
<29600th step>
*************************** Test ***************************
time:3m 13s, 29600th Step, Loss: 0.5473052859306335, Mean IoU = 45.093%
************************************************************
33th Epoch, 29605th Step, learning rate = 0.006983548549219208 - Loss: 0.3543959856033325, aux loss1: 1.0464229583740234, 
		 aux loss2: 0.5658020377159119, total loss: 0.8946437239646912
33th Epoch, 29610th Step, learning rate = 0.006983028197883601 - Loss: 0.3132875859737396, aux loss1: 0.7867982387542725, 
		 aux loss2: 0.42299818992614746, total loss: 0.7185263633728027
33th Epoch, 29615th Step, learning rate = 0.006982507842239646 - Loss: 0.26429736614227295, aux loss1: 0.7375202775001526, 
		 aux loss2: 0.38736817240715027, total loss: 0.6405007243156433
33th Epoch, 29620th Step, learning rate = 0.006981987482286952 - Loss: 0.5200903415679932, aux loss1: 1.0684726238250732, 
		 aux loss2: 0.7416316270828247, total loss: 1.137284755706787
33th Epoch, 29625th Step, learning rate = 0.006981467118025125 - Loss: 0.3255760073661804, aux loss1: 0.9107373952865601, 
		 aux loss2: 0.4891592264175415, total loss: 0.7944608926773071
33th Epoch, 29630th Step, learning rate = 0.006980946749453777 - Loss: 0.3498850464820862, aux loss1: 0.9400779008865356, 
		 aux loss2: 0.5101013779640198, total loss: 0.8359489440917969
33th Epoch, 29635th Step, learning rate = 0.00698042637657251 - Loss: 0.3508916199207306, aux loss1: 0.9977921843528748, 
		 aux loss2: 0.5698534250259399, total loss: 0.8781706690788269
33th Epoch, 29640th Step, learning rate = 0.006979905999380935 - Loss: 0.29039517045021057, aux loss1: 0.7760804295539856, 
		 aux loss2: 0.4176812767982483, total loss: 0.6902918219566345
33th Epoch, 29645th Step, learning rate = 0.006979385617878656 - Loss: 0.2746983766555786, aux loss1: 0.7399417757987976, 
		 aux loss2: 0.4026101231575012, total loss: 0.6577249765396118
33th Epoch, 29650th Step, learning rate = 0.006978865232065283 - Loss: 0.3423231244087219, aux loss1: 0.8950926065444946, 
		 aux loss2: 0.5256606340408325, total loss: 0.8211151957511902
33th Epoch, 29655th Step, learning rate = 0.006978344841940422 - Loss: 0.25613078474998474, aux loss1: 0.6946411728858948, 
		 aux loss2: 0.3857486844062805, total loss: 0.6188226342201233
33th Epoch, 29660th Step, learning rate = 0.0069778244475036805 - Loss: 0.31165948510169983, aux loss1: 0.8479927778244019, 
		 aux loss2: 0.4511878192424774, total loss: 0.7465324401855469
33th Epoch, 29665th Step, learning rate = 0.006977304048754664 - Loss: 0.24540027976036072, aux loss1: 0.8083319067955017, 
		 aux loss2: 0.3834099769592285, total loss: 0.6412638425827026
33th Epoch, 29670th Step, learning rate = 0.006976783645692981 - Loss: 0.387013703584671, aux loss1: 1.027086853981018, 
		 aux loss2: 0.5873776078224182, total loss: 0.9300907850265503
33th Epoch, 29675th Step, learning rate = 0.0069762632383182374 - Loss: 0.290388286113739, aux loss1: 0.7849873304367065, 
		 aux loss2: 0.41973739862442017, total loss: 0.693779468536377
33th Epoch, 29680th Step, learning rate = 0.006975742826630041 - Loss: 0.34473729133605957, aux loss1: 0.8212546706199646, 
		 aux loss2: 0.4705701172351837, total loss: 0.7793417572975159
33th Epoch, 29685th Step, learning rate = 0.006975222410627998 - Loss: 0.3440978229045868, aux loss1: 0.8752920031547546, 
		 aux loss2: 0.5129048824310303, total loss: 0.8118473291397095
33th Epoch, 29690th Step, learning rate = 0.0069747019903117135 - Loss: 0.26918697357177734, aux loss1: 0.7811340093612671, 
		 aux loss2: 0.4070640504360199, total loss: 0.6663528084754944
33th Epoch, 29695th Step, learning rate = 0.006974181565680797 - Loss: 0.4314248561859131, aux loss1: 1.2410770654678345, 
		 aux loss2: 0.6788696646690369, total loss: 1.0752959251403809
33th Epoch, 29700th Step, learning rate = 0.006973661136734854 - Loss: 0.29884105920791626, aux loss1: 0.8437674045562744, 
		 aux loss2: 0.4103851020336151, total loss: 0.7161253690719604
<29700th step>
*************************** Test ***************************
time:3m 15s, 29700th Step, Loss: 0.5448914766311646, Mean IoU = 46.788%
************************************************************
33th Epoch, 29705th Step, learning rate = 0.006973140703473489 - Loss: 0.3706705868244171, aux loss1: 0.9548235535621643, 
		 aux loss2: 0.5586617588996887, total loss: 0.8805823922157288
33th Epoch, 29710th Step, learning rate = 0.00697262026589631 - Loss: 0.28652650117874146, aux loss1: 0.7888419032096863, 
		 aux loss2: 0.4366481304168701, total loss: 0.697838306427002
33th Epoch, 29715th Step, learning rate = 0.006972099824002922 - Loss: 0.2953760027885437, aux loss1: 0.8047338128089905, 
		 aux loss2: 0.4169250726699829, total loss: 0.7035661935806274
33th Epoch, 29720th Step, learning rate = 0.006971579377792933 - Loss: 0.3576889932155609, aux loss1: 0.934104323387146, 
		 aux loss2: 0.5496903657913208, total loss: 0.8577964305877686
33th Epoch, 29725th Step, learning rate = 0.0069710589272659485 - Loss: 0.271034300327301, aux loss1: 0.859382688999176, 
		 aux loss2: 0.41948944330215454, total loss: 0.6966449022293091
33th Epoch, 29730th Step, learning rate = 0.006970538472421573 - Loss: 0.30503344535827637, aux loss1: 0.908939778804779, 
		 aux loss2: 0.4420210123062134, total loss: 0.7545238137245178
33th Epoch, 29735th Step, learning rate = 0.006970018013259416 - Loss: 0.31705737113952637, aux loss1: 0.8383901119232178, 
		 aux loss2: 0.4353230595588684, total loss: 0.7427036762237549
33th Epoch, 29740th Step, learning rate = 0.006969497549779081 - Loss: 0.2739582359790802, aux loss1: 0.7149951457977295, 
		 aux loss2: 0.378078818321228, total loss: 0.6396883130073547
34th Epoch, 29745th Step, learning rate = 0.006968977081980172 - Loss: 0.24119924008846283, aux loss1: 0.7210907936096191, 
		 aux loss2: 0.35745948553085327, total loss: 0.60051029920578
34th Epoch, 29750th Step, learning rate = 0.006968456609862298 - Loss: 0.2813431918621063, aux loss1: 0.7810686230659485, 
		 aux loss2: 0.4205372929573059, total loss: 0.6838787198066711
34th Epoch, 29755th Step, learning rate = 0.006967936133425065 - Loss: 0.3002968728542328, aux loss1: 0.9448764324188232, 
		 aux loss2: 0.5118728876113892, total loss: 0.788508951663971
34th Epoch, 29760th Step, learning rate = 0.006967415652668075 - Loss: 0.3483726680278778, aux loss1: 0.9654466509819031, 
		 aux loss2: 0.550086259841919, total loss: 0.8580411672592163
34th Epoch, 29765th Step, learning rate = 0.006966895167590938 - Loss: 0.4496082365512848, aux loss1: 1.121554970741272, 
		 aux loss2: 0.645935595035553, total loss: 1.044448971748352
34th Epoch, 29770th Step, learning rate = 0.006966374678193257 - Loss: 0.24836598336696625, aux loss1: 0.6961663961410522, 
		 aux loss2: 0.35527026653289795, total loss: 0.5993239879608154
34th Epoch, 29775th Step, learning rate = 0.0069658541844746374 - Loss: 0.2705850601196289, aux loss1: 0.831021785736084, 
		 aux loss2: 0.4167151153087616, total loss: 0.6865776777267456
34th Epoch, 29780th Step, learning rate = 0.006965333686434686 - Loss: 0.21721404790878296, aux loss1: 0.6868637800216675, 
		 aux loss2: 0.3224969506263733, total loss: 0.5522719621658325
34th Epoch, 29785th Step, learning rate = 0.006964813184073007 - Loss: 0.25963732600212097, aux loss1: 0.6748847365379333, 
		 aux loss2: 0.3610934615135193, total loss: 0.6065401434898376
34th Epoch, 29790th Step, learning rate = 0.006964292677389204 - Loss: 0.3381296694278717, aux loss1: 0.8948360681533813, 
		 aux loss2: 0.5314493775367737, total loss: 0.8191602230072021
34th Epoch, 29795th Step, learning rate = 0.006963772166382887 - Loss: 0.25758612155914307, aux loss1: 0.6778413653373718, 
		 aux loss2: 0.35474276542663574, total loss: 0.6028356552124023
34th Epoch, 29800th Step, learning rate = 0.006963251651053657 - Loss: 0.3361649513244629, aux loss1: 0.8519430160522461, 
		 aux loss2: 0.4839561879634857, total loss: 0.7853303551673889
<29800th step>
*************************** Test ***************************
time:3m 18s, 29800th Step, Loss: 0.5427602529525757, Mean IoU = 46.001%
************************************************************
34th Epoch, 29805th Step, learning rate = 0.006962731131401119 - Loss: 0.2979965806007385, aux loss1: 0.8125991821289062, 
		 aux loss2: 0.42399275302886963, total loss: 0.7113734483718872
34th Epoch, 29810th Step, learning rate = 0.006962210607424881 - Loss: 0.2819868326187134, aux loss1: 0.7531766295433044, 
		 aux loss2: 0.4026864171028137, total loss: 0.6690143942832947
34th Epoch, 29815th Step, learning rate = 0.006961690079124544 - Loss: 0.2796071171760559, aux loss1: 0.736066997051239, 
		 aux loss2: 0.3797477185726166, total loss: 0.6523263454437256
34th Epoch, 29820th Step, learning rate = 0.006961169546499717 - Loss: 0.37859395146369934, aux loss1: 0.8904892802238464, 
		 aux loss2: 0.5493122339248657, total loss: 0.8654656410217285
34th Epoch, 29825th Step, learning rate = 0.006960649009550003 - Loss: 0.26677918434143066, aux loss1: 0.9303407073020935, 
		 aux loss2: 0.49178215861320496, total loss: 0.7425942420959473
34th Epoch, 29830th Step, learning rate = 0.006960128468275003 - Loss: 0.2599078118801117, aux loss1: 0.7339826822280884, 
		 aux loss2: 0.369834303855896, total loss: 0.628036379814148
34th Epoch, 29835th Step, learning rate = 0.006959607922674328 - Loss: 0.29915687441825867, aux loss1: 0.8353193402290344, 
		 aux loss2: 0.4497961103916168, total loss: 0.7296711802482605
34th Epoch, 29840th Step, learning rate = 0.0069590873727475785 - Loss: 0.31925636529922485, aux loss1: 0.8406574130058289, 
		 aux loss2: 0.48749956488609314, total loss: 0.7664533853530884
34th Epoch, 29845th Step, learning rate = 0.006958566818494361 - Loss: 0.3361281156539917, aux loss1: 0.8047581911087036, 
		 aux loss2: 0.45813485980033875, total loss: 0.7608095407485962
34th Epoch, 29850th Step, learning rate = 0.006958046259914278 - Loss: 0.31475067138671875, aux loss1: 0.8353044986724854, 
		 aux loss2: 0.45987433195114136, total loss: 0.7492917776107788
34th Epoch, 29855th Step, learning rate = 0.006957525697006936 - Loss: 0.3230498731136322, aux loss1: 0.8099459409713745, 
		 aux loss2: 0.46442410349845886, total loss: 0.7518032789230347
34th Epoch, 29860th Step, learning rate = 0.006957005129771936 - Loss: 0.3563852310180664, aux loss1: 0.8750154376029968, 
		 aux loss2: 0.4854118824005127, total loss: 0.813054621219635
34th Epoch, 29865th Step, learning rate = 0.006956484558208887 - Loss: 0.25573939085006714, aux loss1: 0.7194386720657349, 
		 aux loss2: 0.3653571605682373, total loss: 0.6177138686180115
34th Epoch, 29870th Step, learning rate = 0.006955963982317388 - Loss: 0.24763008952140808, aux loss1: 0.7791993618011475, 
		 aux loss2: 0.37865906953811646, total loss: 0.6328535079956055
34th Epoch, 29875th Step, learning rate = 0.006955443402097047 - Loss: 0.3114705979824066, aux loss1: 0.8703547716140747, 
		 aux loss2: 0.44965898990631104, total loss: 0.7524405717849731
34th Epoch, 29880th Step, learning rate = 0.006954922817547467 - Loss: 0.23307877779006958, aux loss1: 0.6835381984710693, 
		 aux loss2: 0.33900922536849976, total loss: 0.5737439393997192
34th Epoch, 29885th Step, learning rate = 0.0069544022286682486 - Loss: 0.359367311000824, aux loss1: 0.9028109908103943, 
		 aux loss2: 0.5322301983833313, total loss: 0.8431026935577393
34th Epoch, 29890th Step, learning rate = 0.006953881635459002 - Loss: 0.3648388385772705, aux loss1: 0.9918361306190491, 
		 aux loss2: 0.5523486137390137, total loss: 0.8833291530609131
34th Epoch, 29895th Step, learning rate = 0.006953361037919325 - Loss: 0.3051892817020416, aux loss1: 0.8460007905960083, 
		 aux loss2: 0.43793922662734985, total loss: 0.7341651916503906
34th Epoch, 29900th Step, learning rate = 0.006952840436048825 - Loss: 0.341385155916214, aux loss1: 0.7757253646850586, 
		 aux loss2: 0.4632490575313568, total loss: 0.7594023942947388
<29900th step>
*************************** Test ***************************
time:3m 14s, 29900th Step, Loss: 0.5328022241592407, Mean IoU = 45.999%
************************************************************
34th Epoch, 29905th Step, learning rate = 0.0069523198298471044 - Loss: 0.3576890528202057, aux loss1: 1.0797300338745117, 
		 aux loss2: 0.6259799599647522, total loss: 0.9320000410079956
34th Epoch, 29910th Step, learning rate = 0.006951799219313767 - Loss: 0.2764761745929718, aux loss1: 0.8253080248832703, 
		 aux loss2: 0.38996565341949463, total loss: 0.6800548434257507
34th Epoch, 29915th Step, learning rate = 0.006951278604448417 - Loss: 0.333258718252182, aux loss1: 0.8407759666442871, 
		 aux loss2: 0.5001742839813232, total loss: 0.7855612635612488
34th Epoch, 29920th Step, learning rate = 0.006950757985250656 - Loss: 0.30303603410720825, aux loss1: 0.8713157176971436, 
		 aux loss2: 0.4469551742076874, total loss: 0.7432128190994263
34th Epoch, 29925th Step, learning rate = 0.0069502373617200885 - Loss: 0.573501706123352, aux loss1: 1.3519659042358398, 
		 aux loss2: 0.8955366015434265, total loss: 1.3373061418533325
34th Epoch, 29930th Step, learning rate = 0.0069497167338563185 - Loss: 0.27981188893318176, aux loss1: 0.7740874290466309, 
		 aux loss2: 0.3954469859600067, total loss: 0.6702169179916382
34th Epoch, 29935th Step, learning rate = 0.006949196101658949 - Loss: 0.29118475317955017, aux loss1: 0.8274369239807129, 
		 aux loss2: 0.4351212978363037, total loss: 0.7134643793106079
34th Epoch, 29940th Step, learning rate = 0.006948675465127581 - Loss: 0.32485997676849365, aux loss1: 0.7792800664901733, 
		 aux loss2: 0.45115137100219727, total loss: 0.7391045689582825
34th Epoch, 29945th Step, learning rate = 0.006948154824261821 - Loss: 0.26171329617500305, aux loss1: 0.7158823013305664, 
		 aux loss2: 0.3732948303222656, total loss: 0.6257959008216858
34th Epoch, 29950th Step, learning rate = 0.0069476341790612696 - Loss: 0.2757616341114044, aux loss1: 0.8087153434753418, 
		 aux loss2: 0.416045606136322, total loss: 0.6847944855690002
34th Epoch, 29955th Step, learning rate = 0.00694711352952553 - Loss: 0.3438532054424286, aux loss1: 0.7798476815223694, 
		 aux loss2: 0.4545978307723999, total loss: 0.7596466541290283
34th Epoch, 29960th Step, learning rate = 0.006946592875654206 - Loss: 0.4181707799434662, aux loss1: 0.9873650670051575, 
		 aux loss2: 0.6041864156723022, total loss: 0.9560549259185791
34th Epoch, 29965th Step, learning rate = 0.0069460722174469 - Loss: 0.2682449221611023, aux loss1: 0.7517315149307251, 
		 aux loss2: 0.3943338096141815, total loss: 0.6514979600906372
34th Epoch, 29970th Step, learning rate = 0.006945551554903216 - Loss: 0.4076346755027771, aux loss1: 0.9685673117637634, 
		 aux loss2: 0.5665754675865173, total loss: 0.9248350858688354
34th Epoch, 29975th Step, learning rate = 0.006945030888022756 - Loss: 0.23573781549930573, aux loss1: 0.7613933682441711, 
		 aux loss2: 0.37295451760292053, total loss: 0.6133376359939575
34th Epoch, 29980th Step, learning rate = 0.006944510216805119 - Loss: 0.31014639139175415, aux loss1: 0.8347211480140686, 
		 aux loss2: 0.45681294798851013, total loss: 0.7432879209518433
34th Epoch, 29985th Step, learning rate = 0.006943989541249912 - Loss: 0.31441357731819153, aux loss1: 0.9174008369445801, 
		 aux loss2: 0.4694643020629883, total loss: 0.7774195671081543
34th Epoch, 29990th Step, learning rate = 0.006943468861356737 - Loss: 0.4112943112850189, aux loss1: 1.1382970809936523, 
		 aux loss2: 0.627667248249054, total loss: 1.0038503408432007
34th Epoch, 29995th Step, learning rate = 0.006942948177125195 - Loss: 0.31719353795051575, aux loss1: 0.9616736769676208, 
		 aux loss2: 0.5339432954788208, total loss: 0.8192729949951172
34th Epoch, 30000th Step, learning rate = 0.0069424274885548885 - Loss: 0.2837889790534973, aux loss1: 0.862949013710022, 
		 aux loss2: 0.4621346592903137, total loss: 0.7275275588035583
<30000th step>
*************************** Test ***************************
time:3m 14s, 30000th Step, Loss: 0.5154374837875366, Mean IoU = 46.340%
************************************************************
34th Epoch, 30005th Step, learning rate = 0.006941906795645422 - Loss: 0.22366943955421448, aux loss1: 0.7126737236976624, 
		 aux loss2: 0.33690550923347473, total loss: 0.5722337961196899
34th Epoch, 30010th Step, learning rate = 0.006941386098396394 - Loss: 0.34311991930007935, aux loss1: 0.9662177562713623, 
		 aux loss2: 0.5336589813232422, total loss: 0.8464488387107849
34th Epoch, 30015th Step, learning rate = 0.006940865396807409 - Loss: 0.3325856626033783, aux loss1: 0.829098105430603, 
		 aux loss2: 0.4668916165828705, total loss: 0.7680717706680298
34th Epoch, 30020th Step, learning rate = 0.0069403446908780685 - Loss: 0.26459625363349915, aux loss1: 0.7182479500770569, 
		 aux loss2: 0.36257123947143555, total loss: 0.6250991821289062
34th Epoch, 30025th Step, learning rate = 0.0069398239806079745 - Loss: 0.32883042097091675, aux loss1: 0.9228000640869141, 
		 aux loss2: 0.49055948853492737, total loss: 0.8018942475318909
34th Epoch, 30030th Step, learning rate = 0.006939303265996731 - Loss: 0.2785387337207794, aux loss1: 0.7309065461158752, 
		 aux loss2: 0.38927552103996277, total loss: 0.653520941734314
34th Epoch, 30035th Step, learning rate = 0.0069387825470439346 - Loss: 0.25945568084716797, aux loss1: 0.7060254812240601, 
		 aux loss2: 0.36459779739379883, total loss: 0.6171025037765503
34th Epoch, 30040th Step, learning rate = 0.0069382618237491915 - Loss: 0.2824673056602478, aux loss1: 0.7082482576370239, 
		 aux loss2: 0.3903452455997467, total loss: 0.6510798931121826
34th Epoch, 30045th Step, learning rate = 0.006937741096112103 - Loss: 0.31286710500717163, aux loss1: 0.809209942817688, 
		 aux loss2: 0.4586307406425476, total loss: 0.739082396030426
34th Epoch, 30050th Step, learning rate = 0.0069372203641322695 - Loss: 0.2933707535266876, aux loss1: 0.8861700892448425, 
		 aux loss2: 0.42527103424072266, total loss: 0.7293302416801453
34th Epoch, 30055th Step, learning rate = 0.006936699627809293 - Loss: 0.3108347952365875, aux loss1: 0.8961314558982849, 
		 aux loss2: 0.48221662640571594, total loss: 0.7725608944892883
34th Epoch, 30060th Step, learning rate = 0.006936178887142775 - Loss: 0.25013408064842224, aux loss1: 0.6265376806259155, 
		 aux loss2: 0.33071401715278625, total loss: 0.5703809857368469
34th Epoch, 30065th Step, learning rate = 0.006935658142132316 - Loss: 0.2605478763580322, aux loss1: 0.7887164354324341, 
		 aux loss2: 0.37311774492263794, total loss: 0.6464099287986755
34th Epoch, 30070th Step, learning rate = 0.006935137392777521 - Loss: 0.3449406325817108, aux loss1: 0.8947080373764038, 
		 aux loss2: 0.49468904733657837, total loss: 0.8112286329269409
34th Epoch, 30075th Step, learning rate = 0.006934616639077986 - Loss: 0.2745246887207031, aux loss1: 0.7413138747215271, 
		 aux loss2: 0.3735275864601135, total loss: 0.6463298797607422
34th Epoch, 30080th Step, learning rate = 0.006934095881033317 - Loss: 0.272682785987854, aux loss1: 0.77970290184021, 
		 aux loss2: 0.378944993019104, total loss: 0.6581716537475586
34th Epoch, 30085th Step, learning rate = 0.006933575118643112 - Loss: 0.33172962069511414, aux loss1: 0.7873610258102417, 
		 aux loss2: 0.42916983366012573, total loss: 0.7396059036254883
34th Epoch, 30090th Step, learning rate = 0.006933054351906973 - Loss: 0.3061619997024536, aux loss1: 0.7493523359298706, 
		 aux loss2: 0.43863385915756226, total loss: 0.7064212560653687
34th Epoch, 30095th Step, learning rate = 0.006932533580824502 - Loss: 0.2689782679080963, aux loss1: 0.7363400459289551, 
		 aux loss2: 0.40233489871025085, total loss: 0.6508142352104187
34th Epoch, 30100th Step, learning rate = 0.006932012805395298 - Loss: 0.40562936663627625, aux loss1: 0.8868544697761536, 
		 aux loss2: 0.5615870356559753, total loss: 0.8963205218315125
<30100th step>
*************************** Test ***************************
time:3m 14s, 30100th Step, Loss: 0.5640419721603394, Mean IoU = 43.092%
************************************************************
34th Epoch, 30105th Step, learning rate = 0.006931492025618964 - Loss: 0.2956664264202118, aux loss1: 0.7758923172950745, 
		 aux loss2: 0.4311971366405487, total loss: 0.7009130120277405
34th Epoch, 30110th Step, learning rate = 0.006930971241495098 - Loss: 0.39777278900146484, aux loss1: 1.067037582397461, 
		 aux loss2: 0.612946093082428, total loss: 0.9630625247955322
34th Epoch, 30115th Step, learning rate = 0.006930450453023305 - Loss: 0.45097848773002625, aux loss1: 1.220760703086853, 
		 aux loss2: 0.7035654783248901, total loss: 1.0986329317092896
35th Epoch, 30120th Step, learning rate = 0.00692992966020318 - Loss: 0.3074053227901459, aux loss1: 0.8406212329864502, 
		 aux loss2: 0.45398712158203125, total loss: 0.7411865592002869
35th Epoch, 30125th Step, learning rate = 0.0069294088630343295 - Loss: 0.2309226095676422, aux loss1: 0.6975710988044739, 
		 aux loss2: 0.3527449369430542, total loss: 0.581291913986206
35th Epoch, 30130th Step, learning rate = 0.00692888806151635 - Loss: 0.37916100025177, aux loss1: 0.9327508807182312, 
		 aux loss2: 0.5039153099060059, total loss: 0.8605524301528931
35th Epoch, 30135th Step, learning rate = 0.0069283672556488445 - Loss: 0.2954707145690918, aux loss1: 0.9866681694984436, 
		 aux loss2: 0.46027395129203796, total loss: 0.7755807638168335
35th Epoch, 30140th Step, learning rate = 0.006927846445431412 - Loss: 0.2533993721008301, aux loss1: 0.7166897654533386, 
		 aux loss2: 0.3602253794670105, total loss: 0.6124964952468872
35th Epoch, 30145th Step, learning rate = 0.006927325630863651 - Loss: 0.2503082752227783, aux loss1: 0.7650417685508728, 
		 aux loss2: 0.3709927201271057, total loss: 0.6282179355621338
35th Epoch, 30150th Step, learning rate = 0.0069268048119451656 - Loss: 0.42377522587776184, aux loss1: 1.0230257511138916, 
		 aux loss2: 0.6843277215957642, total loss: 1.0044140815734863
35th Epoch, 30155th Step, learning rate = 0.006926283988675554 - Loss: 0.25155290961265564, aux loss1: 0.7423512935638428, 
		 aux loss2: 0.3558903932571411, total loss: 0.6166144609451294
35th Epoch, 30160th Step, learning rate = 0.006925763161054416 - Loss: 0.2767394781112671, aux loss1: 0.8707692623138428, 
		 aux loss2: 0.4438971281051636, total loss: 0.7155291438102722
35th Epoch, 30165th Step, learning rate = 0.0069252423290813514 - Loss: 0.30762794613838196, aux loss1: 0.916671872138977, 
		 aux loss2: 0.48999258875846863, total loss: 0.7786266207695007
35th Epoch, 30170th Step, learning rate = 0.006924721492755962 - Loss: 0.4133097529411316, aux loss1: 1.0012685060501099, 
		 aux loss2: 0.5941920876502991, total loss: 0.9513671398162842
35th Epoch, 30175th Step, learning rate = 0.006924200652077844 - Loss: 0.26229172945022583, aux loss1: 0.7900031805038452, 
		 aux loss2: 0.37618502974510193, total loss: 0.6497666835784912
35th Epoch, 30180th Step, learning rate = 0.006923679807046603 - Loss: 0.42987579107284546, aux loss1: 1.1314239501953125, 
		 aux loss2: 0.7043116688728333, total loss: 1.0510276556015015
35th Epoch, 30185th Step, learning rate = 0.006923158957661834 - Loss: 0.29448094964027405, aux loss1: 0.9387603998184204, 
		 aux loss2: 0.4409404695034027, total loss: 0.7524852752685547
35th Epoch, 30190th Step, learning rate = 0.006922638103923137 - Loss: 0.26972976326942444, aux loss1: 0.7478653788566589, 
		 aux loss2: 0.3723525106906891, total loss: 0.6430304050445557
35th Epoch, 30195th Step, learning rate = 0.006922117245830114 - Loss: 0.3365376889705658, aux loss1: 0.8755892515182495, 
		 aux loss2: 0.4897787570953369, total loss: 0.7951259613037109
35th Epoch, 30200th Step, learning rate = 0.0069215963833823635 - Loss: 0.30589765310287476, aux loss1: 0.8188920617103577, 
		 aux loss2: 0.431041955947876, total loss: 0.7239820957183838
<30200th step>
*************************** Test ***************************
time:3m 14s, 30200th Step, Loss: 0.5519412755966187, Mean IoU = 46.069%
************************************************************
35th Epoch, 30205th Step, learning rate = 0.006921075516579484 - Loss: 0.3019673526287079, aux loss1: 0.7807316184043884, 
		 aux loss2: 0.4360002875328064, total loss: 0.7105869054794312
35th Epoch, 30210th Step, learning rate = 0.006920554645421077 - Loss: 0.35515883564949036, aux loss1: 1.0193456411361694, 
		 aux loss2: 0.5655497312545776, total loss: 0.8871824741363525
35th Epoch, 30215th Step, learning rate = 0.006920033769906738 - Loss: 0.2815852165222168, aux loss1: 0.7060937881469727, 
		 aux loss2: 0.3895730674266815, total loss: 0.6492425799369812
35th Epoch, 30220th Step, learning rate = 0.00691951289003607 - Loss: 0.31801754236221313, aux loss1: 0.8679942488670349, 
		 aux loss2: 0.48993927240371704, total loss: 0.7743915915489197
35th Epoch, 30225th Step, learning rate = 0.006918992005808673 - Loss: 0.34464848041534424, aux loss1: 0.8498756885528564, 
		 aux loss2: 0.49956080317497253, total loss: 0.7994354963302612
35th Epoch, 30230th Step, learning rate = 0.0069184711172241425 - Loss: 0.2694191038608551, aux loss1: 0.7768123149871826, 
		 aux loss2: 0.40003475546836853, total loss: 0.6624767184257507
35th Epoch, 30235th Step, learning rate = 0.006917950224282078 - Loss: 0.3177875876426697, aux loss1: 0.9231408834457397, 
		 aux loss2: 0.4899879992008209, total loss: 0.7907251119613647
35th Epoch, 30240th Step, learning rate = 0.006917429326982081 - Loss: 0.3007778227329254, aux loss1: 0.8895367383956909, 
		 aux loss2: 0.4631798267364502, total loss: 0.7529107928276062
35th Epoch, 30245th Step, learning rate = 0.006916908425323748 - Loss: 0.32501766085624695, aux loss1: 0.9276573657989502, 
		 aux loss2: 0.46835649013519287, total loss: 0.7906574606895447
35th Epoch, 30250th Step, learning rate = 0.00691638751930668 - Loss: 0.3154292106628418, aux loss1: 0.951301634311676, 
		 aux loss2: 0.4697889983654022, total loss: 0.7887353301048279
35th Epoch, 30255th Step, learning rate = 0.006915866608930473 - Loss: 0.30559104681015015, aux loss1: 0.8346860408782959, 
		 aux loss2: 0.4705492854118347, total loss: 0.7442166209220886
35th Epoch, 30260th Step, learning rate = 0.006915345694194729 - Loss: 0.3090333342552185, aux loss1: 0.9965710043907166, 
		 aux loss2: 0.5138946771621704, total loss: 0.8135625720024109
35th Epoch, 30265th Step, learning rate = 0.006914824775099046 - Loss: 0.2983925938606262, aux loss1: 0.8973045349121094, 
		 aux loss2: 0.45371362566947937, total loss: 0.7490694522857666
35th Epoch, 30270th Step, learning rate = 0.006914303851643019 - Loss: 0.27360978722572327, aux loss1: 0.8293177485466003, 
		 aux loss2: 0.4271848201751709, total loss: 0.6932790875434875
35th Epoch, 30275th Step, learning rate = 0.006913782923826249 - Loss: 0.4169001281261444, aux loss1: 1.0556843280792236, 
		 aux loss2: 0.6190024614334106, total loss: 0.9812064170837402
35th Epoch, 30280th Step, learning rate = 0.006913261991648337 - Loss: 0.35810622572898865, aux loss1: 1.0891560316085815, 
		 aux loss2: 0.6226382851600647, total loss: 0.9339084029197693
35th Epoch, 30285th Step, learning rate = 0.006912741055108877 - Loss: 0.4219945967197418, aux loss1: 0.9969881176948547, 
		 aux loss2: 0.6249971985816956, total loss: 0.9710898995399475
35th Epoch, 30290th Step, learning rate = 0.006912220114207468 - Loss: 0.2799895703792572, aux loss1: 0.7213366031646729, 
		 aux loss2: 0.37873244285583496, total loss: 0.6478835344314575
35th Epoch, 30295th Step, learning rate = 0.006911699168943712 - Loss: 0.2808164954185486, aux loss1: 0.7509512901306152, 
		 aux loss2: 0.38958674669265747, total loss: 0.6619366407394409
35th Epoch, 30300th Step, learning rate = 0.006911178219317201 - Loss: 0.29052168130874634, aux loss1: 0.7491832971572876, 
		 aux loss2: 0.4102801978588104, total loss: 0.6793887615203857
<30300th step>
*************************** Test ***************************
time:3m 19s, 30300th Step, Loss: 0.5285874009132385, Mean IoU = 44.724%
************************************************************
35th Epoch, 30305th Step, learning rate = 0.006910657265327539 - Loss: 0.27402403950691223, aux loss1: 0.8008289933204651, 
		 aux loss2: 0.4108172357082367, total loss: 0.6785996556282043
35th Epoch, 30310th Step, learning rate = 0.006910136306974319 - Loss: 0.319964200258255, aux loss1: 0.8894439339637756, 
		 aux loss2: 0.47287577390670776, total loss: 0.7759476900100708
35th Epoch, 30315th Step, learning rate = 0.0069096153442571445 - Loss: 0.23782745003700256, aux loss1: 0.6676135659217834, 
		 aux loss2: 0.34948888421058655, total loss: 0.5779070854187012
35th Epoch, 30320th Step, learning rate = 0.006909094377175609 - Loss: 0.3240889012813568, aux loss1: 0.8331502079963684, 
		 aux loss2: 0.45054781436920166, total loss: 0.754253089427948
35th Epoch, 30325th Step, learning rate = 0.006908573405729311 - Loss: 0.2646372616291046, aux loss1: 0.7633638978004456, 
		 aux loss2: 0.3974636197090149, total loss: 0.6526318788528442
35th Epoch, 30330th Step, learning rate = 0.006908052429917848 - Loss: 0.3130975663661957, aux loss1: 0.8572053909301758, 
		 aux loss2: 0.4642001688480377, total loss: 0.7559393048286438
35th Epoch, 30335th Step, learning rate = 0.006907531449740821 - Loss: 0.41743865609169006, aux loss1: 1.065155029296875, 
		 aux loss2: 0.6541999578475952, total loss: 0.9986652135848999
35th Epoch, 30340th Step, learning rate = 0.006907010465197822 - Loss: 0.2941614091396332, aux loss1: 0.7166062593460083, 
		 aux loss2: 0.40628474950790405, total loss: 0.6716572046279907
35th Epoch, 30345th Step, learning rate = 0.006906489476288452 - Loss: 0.29894500970840454, aux loss1: 0.7766528725624084, 
		 aux loss2: 0.4188607335090637, total loss: 0.699485182762146
35th Epoch, 30350th Step, learning rate = 0.006905968483012309 - Loss: 0.2971724271774292, aux loss1: 0.8589950799942017, 
		 aux loss2: 0.45948949456214905, total loss: 0.7386667728424072
35th Epoch, 30355th Step, learning rate = 0.0069054474853689875 - Loss: 0.2874557375907898, aux loss1: 0.8100059032440186, 
		 aux loss2: 0.43686458468437195, total loss: 0.7052033543586731
35th Epoch, 30360th Step, learning rate = 0.006904926483358088 - Loss: 0.2492688149213791, aux loss1: 0.708213746547699, 
		 aux loss2: 0.35062849521636963, total loss: 0.6019843816757202
35th Epoch, 30365th Step, learning rate = 0.006904405476979207 - Loss: 0.3089120388031006, aux loss1: 0.8073328137397766, 
		 aux loss2: 0.4433976709842682, total loss: 0.7284709215164185
35th Epoch, 30370th Step, learning rate = 0.0069038844662319375 - Loss: 0.346032053232193, aux loss1: 0.8146466016769409, 
		 aux loss2: 0.48872968554496765, total loss: 0.7859178781509399
35th Epoch, 30375th Step, learning rate = 0.0069033634511158825 - Loss: 0.3540925085544586, aux loss1: 0.9613127112388611, 
		 aux loss2: 0.535932719707489, total loss: 0.8568594455718994
35th Epoch, 30380th Step, learning rate = 0.006902842431630636 - Loss: 0.2275657206773758, aux loss1: 0.7197908759117126, 
		 aux loss2: 0.35039085149765015, total loss: 0.5836593508720398
35th Epoch, 30385th Step, learning rate = 0.006902321407775794 - Loss: 0.33196187019348145, aux loss1: 0.8474121689796448, 
		 aux loss2: 0.4879240393638611, total loss: 0.7813552021980286
35th Epoch, 30390th Step, learning rate = 0.006901800379550958 - Loss: 0.38061732053756714, aux loss1: 1.1713778972625732, 
		 aux loss2: 0.6458618640899658, total loss: 0.9903753995895386
35th Epoch, 30395th Step, learning rate = 0.006901279346955717 - Loss: 0.2948116660118103, aux loss1: 0.7923785448074341, 
		 aux loss2: 0.4392770826816559, total loss: 0.7082360982894897
35th Epoch, 30400th Step, learning rate = 0.006900758309989675 - Loss: 0.2962379455566406, aux loss1: 0.8299598693847656, 
		 aux loss2: 0.43542152643203735, total loss: 0.7193945646286011
<30400th step>
*************************** Test ***************************
time:3m 18s, 30400th Step, Loss: 0.5521823167800903, Mean IoU = 44.931%
************************************************************
35th Epoch, 30405th Step, learning rate = 0.006900237268652426 - Loss: 0.2615956962108612, aux loss1: 0.7186521291732788, 
		 aux loss2: 0.3643408417701721, total loss: 0.6229276657104492
35th Epoch, 30410th Step, learning rate = 0.006899716222943565 - Loss: 0.300899475812912, aux loss1: 0.7841732501983643, 
		 aux loss2: 0.4244336187839508, total loss: 0.705924928188324
35th Epoch, 30415th Step, learning rate = 0.0068991951728626915 - Loss: 0.2856906056404114, aux loss1: 0.7934989333152771, 
		 aux loss2: 0.41296669840812683, total loss: 0.6889269948005676
35th Epoch, 30420th Step, learning rate = 0.006898674118409399 - Loss: 0.34162992238998413, aux loss1: 0.851926326751709, 
		 aux loss2: 0.4877376854419708, total loss: 0.7923029065132141
35th Epoch, 30425th Step, learning rate = 0.006898153059583284 - Loss: 0.3949397802352905, aux loss1: 0.9813711047172546, 
		 aux loss2: 0.5225156545639038, total loss: 0.8983573317527771
35th Epoch, 30430th Step, learning rate = 0.006897631996383947 - Loss: 0.31672000885009766, aux loss1: 0.7073367238044739, 
		 aux loss2: 0.39585599303245544, total loss: 0.6872634291648865
35th Epoch, 30435th Step, learning rate = 0.006897110928810979 - Loss: 0.34008699655532837, aux loss1: 1.0247156620025635, 
		 aux loss2: 0.5408092737197876, total loss: 0.8638254404067993
35th Epoch, 30440th Step, learning rate = 0.00689658985686398 - Loss: 0.2837710976600647, aux loss1: 0.7590461373329163, 
		 aux loss2: 0.40262675285339355, total loss: 0.6725356578826904
35th Epoch, 30445th Step, learning rate = 0.006896068780542544 - Loss: 0.37733370065689087, aux loss1: 0.9058992862701416, 
		 aux loss2: 0.5390652418136597, total loss: 0.864729642868042
35th Epoch, 30450th Step, learning rate = 0.006895547699846266 - Loss: 0.3084055185317993, aux loss1: 0.8648700714111328, 
		 aux loss2: 0.4717661142349243, total loss: 0.7565730214118958
35th Epoch, 30455th Step, learning rate = 0.006895026614774744 - Loss: 0.3711082339286804, aux loss1: 0.9418313503265381, 
		 aux loss2: 0.5323070883750916, total loss: 0.8665804862976074
35th Epoch, 30460th Step, learning rate = 0.006894505525327574 - Loss: 0.3031523525714874, aux loss1: 0.9160372614860535, 
		 aux loss2: 0.4576486051082611, total loss: 0.7610229849815369
35th Epoch, 30465th Step, learning rate = 0.006893984431504351 - Loss: 0.2824493646621704, aux loss1: 0.7616393566131592, 
		 aux loss2: 0.4013124108314514, total loss: 0.6714661121368408
35th Epoch, 30470th Step, learning rate = 0.00689346333330467 - Loss: 0.32363465428352356, aux loss1: 0.8123806118965149, 
		 aux loss2: 0.47152718901634216, total loss: 0.7559597492218018
35th Epoch, 30475th Step, learning rate = 0.0068929422307281284 - Loss: 0.33944135904312134, aux loss1: 0.8841617107391357, 
		 aux loss2: 0.5007448792457581, total loss: 0.8049878478050232
35th Epoch, 30480th Step, learning rate = 0.00689242112377432 - Loss: 0.4059767723083496, aux loss1: 1.0089638233184814, 
		 aux loss2: 0.6356774568557739, total loss: 0.9629369974136353
35th Epoch, 30485th Step, learning rate = 0.006891900012442841 - Loss: 0.25404682755470276, aux loss1: 0.6688882112503052, 
		 aux loss2: 0.3601986765861511, total loss: 0.5987927913665771
36th Epoch, 30490th Step, learning rate = 0.006891378896733288 - Loss: 0.3146202266216278, aux loss1: 0.8640585541725159, 
		 aux loss2: 0.4738265872001648, total loss: 0.7633684873580933
36th Epoch, 30495th Step, learning rate = 0.006890857776645253 - Loss: 0.25963908433914185, aux loss1: 0.7990832924842834, 
		 aux loss2: 0.39904147386550903, total loss: 0.658980667591095
36th Epoch, 30500th Step, learning rate = 0.006890336652178336 - Loss: 0.26996031403541565, aux loss1: 0.7756799459457397, 
		 aux loss2: 0.39329594373703003, total loss: 0.6599826812744141
<30500th step>
*************************** Test ***************************
time:3m 17s, 30500th Step, Loss: 0.5443907380104065, Mean IoU = 45.818%
************************************************************
36th Epoch, 30505th Step, learning rate = 0.006889815523332129 - Loss: 0.28428077697753906, aux loss1: 0.8642667531967163, 
		 aux loss2: 0.4429604411125183, total loss: 0.7207449674606323
36th Epoch, 30510th Step, learning rate = 0.0068892943901062275 - Loss: 0.29980504512786865, aux loss1: 0.8898635506629944, 
		 aux loss2: 0.4359017014503479, total loss: 0.7411248087882996
36th Epoch, 30515th Step, learning rate = 0.006888773252500228 - Loss: 0.2884284257888794, aux loss1: 0.9166622757911682, 
		 aux loss2: 0.44949445128440857, total loss: 0.7432248592376709
36th Epoch, 30520th Step, learning rate = 0.006888252110513723 - Loss: 0.27761659026145935, aux loss1: 0.78114914894104, 
		 aux loss2: 0.3957671821117401, total loss: 0.6702682375907898
36th Epoch, 30525th Step, learning rate = 0.0068877309641463096 - Loss: 0.3360670208930969, aux loss1: 0.8374638557434082, 
		 aux loss2: 0.46704238653182983, total loss: 0.7741231918334961
36th Epoch, 30530th Step, learning rate = 0.006887209813397584 - Loss: 0.24410705268383026, aux loss1: 0.8147339820861816, 
		 aux loss2: 0.3986300528049469, total loss: 0.6479792594909668
36th Epoch, 30535th Step, learning rate = 0.006886688658267136 - Loss: 0.2427293360233307, aux loss1: 0.7888192534446716, 
		 aux loss2: 0.3870377838611603, total loss: 0.6341902613639832
36th Epoch, 30540th Step, learning rate = 0.006886167498754564 - Loss: 0.31847333908081055, aux loss1: 0.8217675089836121, 
		 aux loss2: 0.4606892764568329, total loss: 0.7492793798446655
36th Epoch, 30545th Step, learning rate = 0.0068856463348594635 - Loss: 0.3059738576412201, aux loss1: 1.0436465740203857, 
		 aux loss2: 0.5129233002662659, total loss: 0.8242371678352356
36th Epoch, 30550th Step, learning rate = 0.0068851251665814255 - Loss: 0.31249359250068665, aux loss1: 0.8664116859436035, 
		 aux loss2: 0.5133118629455566, total loss: 0.7777419090270996
36th Epoch, 30555th Step, learning rate = 0.006884603993920047 - Loss: 0.2445526123046875, aux loss1: 0.7182005047798157, 
		 aux loss2: 0.3576480746269226, total loss: 0.6030720472335815
36th Epoch, 30560th Step, learning rate = 0.006884082816874923 - Loss: 0.28496742248535156, aux loss1: 0.7333263158798218, 
		 aux loss2: 0.39547199010849, total loss: 0.663154125213623
36th Epoch, 30565th Step, learning rate = 0.0068835616354456465 - Loss: 0.23088553547859192, aux loss1: 0.7092586159706116, 
		 aux loss2: 0.34143900871276855, total loss: 0.5802386999130249
36th Epoch, 30570th Step, learning rate = 0.0068830404496318135 - Loss: 0.28072836995124817, aux loss1: 0.7808429598808289, 
		 aux loss2: 0.4099421203136444, total loss: 0.6789581179618835
36th Epoch, 30575th Step, learning rate = 0.006882519259433014 - Loss: 0.24949386715888977, aux loss1: 0.7428615689277649, 
		 aux loss2: 0.37101632356643677, total loss: 0.6207588911056519
36th Epoch, 30580th Step, learning rate = 0.006881998064848847 - Loss: 0.2845461666584015, aux loss1: 0.796445906162262, 
		 aux loss2: 0.4505139887332916, total loss: 0.7036855220794678
36th Epoch, 30585th Step, learning rate = 0.006881476865878905 - Loss: 0.30705681443214417, aux loss1: 1.0243414640426636, 
		 aux loss2: 0.5039470195770264, total loss: 0.8159380555152893
36th Epoch, 30590th Step, learning rate = 0.006880955662522781 - Loss: 0.2593577802181244, aux loss1: 0.7007066011428833, 
		 aux loss2: 0.4136737585067749, total loss: 0.6350392699241638
36th Epoch, 30595th Step, learning rate = 0.006880434454780069 - Loss: 0.3730037808418274, aux loss1: 0.9749325513839722, 
		 aux loss2: 0.5519434809684753, total loss: 0.886260986328125
36th Epoch, 30600th Step, learning rate = 0.006879913242650364 - Loss: 0.33859166502952576, aux loss1: 0.8483227491378784, 
		 aux loss2: 0.46664848923683167, total loss: 0.7797479033470154
<30600th step>
*************************** Test ***************************
time:3m 17s, 30600th Step, Loss: 0.5334292650222778, Mean IoU = 46.615%
************************************************************
36th Epoch, 30605th Step, learning rate = 0.006879392026133258 - Loss: 0.3375016748905182, aux loss1: 0.8775309324264526, 
		 aux loss2: 0.4978489875793457, total loss: 0.7999005317687988
36th Epoch, 30610th Step, learning rate = 0.006878870805228346 - Loss: 0.2903837263584137, aux loss1: 0.7359554767608643, 
		 aux loss2: 0.3982183635234833, total loss: 0.6704577207565308
36th Epoch, 30615th Step, learning rate = 0.006878349579935223 - Loss: 0.42173823714256287, aux loss1: 1.0910776853561401, 
		 aux loss2: 0.6353292465209961, total loss: 1.0031932592391968
36th Epoch, 30620th Step, learning rate = 0.00687782835025348 - Loss: 0.36871445178985596, aux loss1: 0.9793887138366699, 
		 aux loss2: 0.5901852250099182, total loss: 0.8986051678657532
36th Epoch, 30625th Step, learning rate = 0.006877307116182713 - Loss: 0.25587186217308044, aux loss1: 0.8197749853134155, 
		 aux loss2: 0.4141557514667511, total loss: 0.6674666404724121
36th Epoch, 30630th Step, learning rate = 0.006876785877722513 - Loss: 0.27231094241142273, aux loss1: 0.7535126209259033, 
		 aux loss2: 0.3723098933696747, total loss: 0.6472886800765991
36th Epoch, 30635th Step, learning rate = 0.006876264634872473 - Loss: 0.258329838514328, aux loss1: 0.7981002330780029, 
		 aux loss2: 0.410771906375885, total loss: 0.6620687246322632
36th Epoch, 30640th Step, learning rate = 0.00687574338763219 - Loss: 0.38729143142700195, aux loss1: 1.2166770696640015, 
		 aux loss2: 0.6939042210578918, total loss: 1.0298562049865723
36th Epoch, 30645th Step, learning rate = 0.006875222136001255 - Loss: 0.3927307724952698, aux loss1: 1.0587525367736816, 
		 aux loss2: 0.593380331993103, total loss: 0.9477086663246155
36th Epoch, 30650th Step, learning rate = 0.006874700879979259 - Loss: 0.2471127063035965, aux loss1: 0.7313909530639648, 
		 aux loss2: 0.36826562881469727, total loss: 0.6138362288475037
36th Epoch, 30655th Step, learning rate = 0.006874179619565799 - Loss: 0.33684608340263367, aux loss1: 0.7607435584068298, 
		 aux loss2: 0.45197030901908875, total loss: 0.7458572387695312
36th Epoch, 30660th Step, learning rate = 0.0068736583547604636 - Loss: 0.3977717459201813, aux loss1: 0.9643074870109558, 
		 aux loss2: 0.5575280785560608, total loss: 0.9100752472877502
36th Epoch, 30665th Step, learning rate = 0.006873137085562851 - Loss: 0.30882325768470764, aux loss1: 0.8262742161750793, 
		 aux loss2: 0.4603882431983948, total loss: 0.7408608198165894
36th Epoch, 30670th Step, learning rate = 0.006872615811972551 - Loss: 0.2848064601421356, aux loss1: 0.9239999055862427, 
		 aux loss2: 0.4839934706687927, total loss: 0.7556038498878479
36th Epoch, 30675th Step, learning rate = 0.006872094533989154 - Loss: 0.2519812285900116, aux loss1: 0.6620892882347107, 
		 aux loss2: 0.3538186550140381, total loss: 0.592135488986969
36th Epoch, 30680th Step, learning rate = 0.0068715732516122585 - Loss: 0.3189205825328827, aux loss1: 0.9747347831726074, 
		 aux loss2: 0.5132779479026794, total loss: 0.8166521787643433
36th Epoch, 30685th Step, learning rate = 0.006871051964841453 - Loss: 0.3385680615901947, aux loss1: 0.885020911693573, 
		 aux loss2: 0.4860325753688812, total loss: 0.7984874248504639
36th Epoch, 30690th Step, learning rate = 0.00687053067367633 - Loss: 0.2556041479110718, aux loss1: 0.7030127048492432, 
		 aux loss2: 0.37246525287628174, total loss: 0.6154940724372864
36th Epoch, 30695th Step, learning rate = 0.006870009378116484 - Loss: 0.2870602607727051, aux loss1: 0.6683013439178467, 
		 aux loss2: 0.3998013436794281, total loss: 0.6474711894989014
36th Epoch, 30700th Step, learning rate = 0.006869488078161507 - Loss: 0.2631666362285614, aux loss1: 0.7644804120063782, 
		 aux loss2: 0.4060671031475067, total loss: 0.6549376249313354
<30700th step>
*************************** Test ***************************
time:3m 18s, 30700th Step, Loss: 0.5229877233505249, Mean IoU = 46.329%
************************************************************
36th Epoch, 30705th Step, learning rate = 0.00686896677381099 - Loss: 0.3177236318588257, aux loss1: 0.9102556109428406, 
		 aux loss2: 0.4594167470932007, total loss: 0.7745670080184937
36th Epoch, 30710th Step, learning rate = 0.006868445465064527 - Loss: 0.2295597791671753, aux loss1: 0.69080650806427, 
		 aux loss2: 0.3341687023639679, total loss: 0.5704692006111145
36th Epoch, 30715th Step, learning rate = 0.006867924151921709 - Loss: 0.32124441862106323, aux loss1: 0.7667458057403564, 
		 aux loss2: 0.4437918961048126, total loss: 0.7287849187850952
36th Epoch, 30720th Step, learning rate = 0.0068674028343821275 - Loss: 0.4016130268573761, aux loss1: 1.0153677463531494, 
		 aux loss2: 0.6047056317329407, total loss: 0.9481056332588196
36th Epoch, 30725th Step, learning rate = 0.006866881512445376 - Loss: 0.3547903895378113, aux loss1: 0.884324848651886, 
		 aux loss2: 0.5143032073974609, total loss: 0.825809121131897
36th Epoch, 30730th Step, learning rate = 0.006866360186111045 - Loss: 0.2551804184913635, aux loss1: 0.7342466115951538, 
		 aux loss2: 0.3756210505962372, total loss: 0.6257027983665466
36th Epoch, 30735th Step, learning rate = 0.006865838855378729 - Loss: 0.27647271752357483, aux loss1: 0.7883602380752563, 
		 aux loss2: 0.38764429092407227, total loss: 0.668038547039032
36th Epoch, 30740th Step, learning rate = 0.0068653175202480175 - Loss: 0.23085162043571472, aux loss1: 0.6657185554504395, 
		 aux loss2: 0.3173585534095764, total loss: 0.5575106143951416
36th Epoch, 30745th Step, learning rate = 0.006864796180718503 - Loss: 0.2231213003396988, aux loss1: 0.6551028490066528, 
		 aux loss2: 0.3281288146972656, total loss: 0.5509036779403687
36th Epoch, 30750th Step, learning rate = 0.006864274836789779 - Loss: 0.3326786756515503, aux loss1: 0.8127171993255615, 
		 aux loss2: 0.47354939579963684, total loss: 0.7659136056900024
36th Epoch, 30755th Step, learning rate = 0.006863753488461433 - Loss: 0.3663760721683502, aux loss1: 1.029639482498169, 
		 aux loss2: 0.561649739742279, total loss: 0.8999278545379639
36th Epoch, 30760th Step, learning rate = 0.00686323213573306 - Loss: 0.4194026589393616, aux loss1: 1.0868645906448364, 
		 aux loss2: 0.6773753762245178, total loss: 1.0164122581481934
36th Epoch, 30765th Step, learning rate = 0.006862710778604251 - Loss: 0.28823021054267883, aux loss1: 0.8465266823768616, 
		 aux loss2: 0.4347352683544159, total loss: 0.7160823345184326
36th Epoch, 30770th Step, learning rate = 0.006862189417074596 - Loss: 0.3021351993083954, aux loss1: 0.7243989109992981, 
		 aux loss2: 0.41679906845092773, total loss: 0.6861745119094849
36th Epoch, 30775th Step, learning rate = 0.006861668051143686 - Loss: 0.3002738058567047, aux loss1: 0.8551334738731384, 
		 aux loss2: 0.48556533455848694, total loss: 0.751039981842041
36th Epoch, 30780th Step, learning rate = 0.006861146680811115 - Loss: 0.2909322679042816, aux loss1: 0.90430748462677, 
		 aux loss2: 0.5005208253860474, total loss: 0.7624328136444092
36th Epoch, 30785th Step, learning rate = 0.006860625306076471 - Loss: 0.3258275091648102, aux loss1: 0.9743961691856384, 
		 aux loss2: 0.48483386635780334, total loss: 0.812079906463623
36th Epoch, 30790th Step, learning rate = 0.006860103926939348 - Loss: 0.24222615361213684, aux loss1: 0.6714071035385132, 
		 aux loss2: 0.3380317687988281, total loss: 0.5788609981536865
36th Epoch, 30795th Step, learning rate = 0.006859582543399336 - Loss: 0.23927587270736694, aux loss1: 0.7811704277992249, 
		 aux loss2: 0.36947473883628845, total loss: 0.6214169263839722
36th Epoch, 30800th Step, learning rate = 0.006859061155456024 - Loss: 0.26014140248298645, aux loss1: 0.7644863128662109, 
		 aux loss2: 0.4095206558704376, total loss: 0.6532955765724182
<30800th step>
*************************** Test ***************************
time:3m 16s, 30800th Step, Loss: 0.5571025609970093, Mean IoU = 46.294%
************************************************************
36th Epoch, 30805th Step, learning rate = 0.006858539763109008 - Loss: 0.3368397057056427, aux loss1: 0.9443118572235107, 
		 aux loss2: 0.5129797458648682, total loss: 0.8253251910209656
36th Epoch, 30810th Step, learning rate = 0.0068580183663578724 - Loss: 0.28970643877983093, aux loss1: 0.7911602258682251, 
		 aux loss2: 0.43057405948638916, total loss: 0.6992841958999634
36th Epoch, 30815th Step, learning rate = 0.006857496965202213 - Loss: 0.2602647840976715, aux loss1: 0.6711154580116272, 
		 aux loss2: 0.36322110891342163, total loss: 0.6068878769874573
36th Epoch, 30820th Step, learning rate = 0.006856975559641617 - Loss: 0.37509897351264954, aux loss1: 0.8514668941497803, 
		 aux loss2: 0.5206026434898376, total loss: 0.8387801051139832
36th Epoch, 30825th Step, learning rate = 0.006856454149675677 - Loss: 0.36667007207870483, aux loss1: 0.8715883493423462, 
		 aux loss2: 0.5151826739311218, total loss: 0.8342196941375732
36th Epoch, 30830th Step, learning rate = 0.006855932735303982 - Loss: 0.31232333183288574, aux loss1: 0.8014874458312988, 
		 aux loss2: 0.44515660405158997, total loss: 0.7308322191238403
36th Epoch, 30835th Step, learning rate = 0.006855411316526125 - Loss: 0.2748587429523468, aux loss1: 0.8014420866966248, 
		 aux loss2: 0.40282076597213745, total loss: 0.676419734954834
36th Epoch, 30840th Step, learning rate = 0.0068548898933416934 - Loss: 0.3360455334186554, aux loss1: 0.9119083881378174, 
		 aux loss2: 0.5210816860198975, total loss: 0.818050742149353
36th Epoch, 30845th Step, learning rate = 0.006854368465750282 - Loss: 0.24943378567695618, aux loss1: 0.7686895132064819, 
		 aux loss2: 0.3607273995876312, total loss: 0.6243316531181335
36th Epoch, 30850th Step, learning rate = 0.006853847033751476 - Loss: 0.3811075687408447, aux loss1: 0.959348201751709, 
		 aux loss2: 0.5118416547775269, total loss: 0.8736487030982971
36th Epoch, 30855th Step, learning rate = 0.006853325597344866 - Loss: 0.306685209274292, aux loss1: 0.8504037261009216, 
		 aux loss2: 0.4588403105735779, total loss: 0.7453424334526062
37th Epoch, 30860th Step, learning rate = 0.006852804156530047 - Loss: 0.31805869936943054, aux loss1: 1.093669056892395, 
		 aux loss2: 0.551313042640686, total loss: 0.86668461561203
37th Epoch, 30865th Step, learning rate = 0.006852282711306603 - Loss: 0.3720315992832184, aux loss1: 1.1801435947418213, 
		 aux loss2: 0.6642183065414429, total loss: 0.9917620420455933
37th Epoch, 30870th Step, learning rate = 0.006851761261674127 - Loss: 0.35127633810043335, aux loss1: 0.8135049939155579, 
		 aux loss2: 0.48469287157058716, total loss: 0.789205014705658
37th Epoch, 30875th Step, learning rate = 0.006851239807632211 - Loss: 0.3636254072189331, aux loss1: 0.9529346823692322, 
		 aux loss2: 0.5662125945091248, total loss: 0.8759908676147461
37th Epoch, 30880th Step, learning rate = 0.006850718349180441 - Loss: 0.25463274121284485, aux loss1: 0.7337029576301575, 
		 aux loss2: 0.3841266334056854, total loss: 0.6283943057060242
37th Epoch, 30885th Step, learning rate = 0.006850196886318409 - Loss: 0.27767661213874817, aux loss1: 0.7610578536987305, 
		 aux loss2: 0.38916295766830444, total loss: 0.6616591215133667
37th Epoch, 30890th Step, learning rate = 0.006849675419045702 - Loss: 0.25130948424339294, aux loss1: 0.8577438592910767, 
		 aux loss2: 0.4119349420070648, total loss: 0.6734066605567932
37th Epoch, 30895th Step, learning rate = 0.006849153947361912 - Loss: 0.290879487991333, aux loss1: 0.777743399143219, 
		 aux loss2: 0.4380985200405121, total loss: 0.6994419097900391
37th Epoch, 30900th Step, learning rate = 0.006848632471266629 - Loss: 0.2646215856075287, aux loss1: 0.843048095703125, 
		 aux loss2: 0.40556806325912476, total loss: 0.6797632575035095
<30900th step>
*************************** Test ***************************
time:3m 16s, 30900th Step, Loss: 0.5516481399536133, Mean IoU = 44.599%
************************************************************
37th Epoch, 30905th Step, learning rate = 0.006848110990759442 - Loss: 0.24947085976600647, aux loss1: 0.7819710373878479, 
		 aux loss2: 0.373371958732605, total loss: 0.6334109902381897
37th Epoch, 30910th Step, learning rate = 0.006847589505839936 - Loss: 0.3356655240058899, aux loss1: 0.978760838508606, 
		 aux loss2: 0.5848081707954407, total loss: 0.8632170557975769
37th Epoch, 30915th Step, learning rate = 0.006847068016507708 - Loss: 0.19836343824863434, aux loss1: 0.6923723816871643, 
		 aux loss2: 0.3318136930465698, total loss: 0.5388006567955017
37th Epoch, 30920th Step, learning rate = 0.0068465465227623415 - Loss: 0.326448917388916, aux loss1: 0.817876935005188, 
		 aux loss2: 0.4651818871498108, total loss: 0.7578848004341125
37th Epoch, 30925th Step, learning rate = 0.006846025024603427 - Loss: 0.3029688596725464, aux loss1: 0.9038577675819397, 
		 aux loss2: 0.437011182308197, total loss: 0.7489306926727295
37th Epoch, 30930th Step, learning rate = 0.006845503522030556 - Loss: 0.29924407601356506, aux loss1: 0.9914411306381226, 
		 aux loss2: 0.47427818179130554, total loss: 0.7863877415657043
37th Epoch, 30935th Step, learning rate = 0.006844982015043314 - Loss: 0.21599286794662476, aux loss1: 0.6864129304885864, 
		 aux loss2: 0.3134291172027588, total loss: 0.5472884178161621
37th Epoch, 30940th Step, learning rate = 0.006844460503641291 - Loss: 0.2825665771961212, aux loss1: 0.7925801873207092, 
		 aux loss2: 0.4349273443222046, total loss: 0.6943115592002869
37th Epoch, 30945th Step, learning rate = 0.0068439389878240785 - Loss: 0.2732580006122589, aux loss1: 0.7879432439804077, 
		 aux loss2: 0.40755900740623474, total loss: 0.6726645827293396
37th Epoch, 30950th Step, learning rate = 0.006843417467591261 - Loss: 0.3024325966835022, aux loss1: 0.9347282648086548, 
		 aux loss2: 0.4983617067337036, total loss: 0.7821957468986511
37th Epoch, 30955th Step, learning rate = 0.00684289594294243 - Loss: 0.2492043823003769, aux loss1: 0.7735711932182312, 
		 aux loss2: 0.38823238015174866, total loss: 0.6365686655044556
37th Epoch, 30960th Step, learning rate = 0.006842374413877174 - Loss: 0.3065875470638275, aux loss1: 0.8889878988265991, 
		 aux loss2: 0.46059152483940125, total loss: 0.7575205564498901
37th Epoch, 30965th Step, learning rate = 0.00684185288039508 - Loss: 0.2848188281059265, aux loss1: 0.7756990790367126, 
		 aux loss2: 0.4158719480037689, total loss: 0.6838773488998413
37th Epoch, 30970th Step, learning rate = 0.006841331342495738 - Loss: 0.304230272769928, aux loss1: 0.8618224263191223, 
		 aux loss2: 0.4512583017349243, total loss: 0.7432803511619568
37th Epoch, 30975th Step, learning rate = 0.006840809800178736 - Loss: 0.33529046177864075, aux loss1: 0.8465411067008972, 
		 aux loss2: 0.5025345087051392, total loss: 0.7902666330337524
37th Epoch, 30980th Step, learning rate = 0.006840288253443662 - Loss: 0.32010117173194885, aux loss1: 0.8042692542076111, 
		 aux loss2: 0.4697153568267822, total loss: 0.7492680549621582
37th Epoch, 30985th Step, learning rate = 0.006839766702290105 - Loss: 0.21118131279945374, aux loss1: 0.7356850504875183, 
		 aux loss2: 0.33889198303222656, total loss: 0.5674436688423157
37th Epoch, 30990th Step, learning rate = 0.006839245146717653 - Loss: 0.22495263814926147, aux loss1: 0.7517603635787964, 
		 aux loss2: 0.32587167620658875, total loss: 0.5808294415473938
37th Epoch, 30995th Step, learning rate = 0.006838723586725893 - Loss: 0.2143455147743225, aux loss1: 0.6778713464736938, 
		 aux loss2: 0.33269497752189636, total loss: 0.5507848858833313
37th Epoch, 31000th Step, learning rate = 0.006838202022314416 - Loss: 0.29171043634414673, aux loss1: 0.7967931628227234, 
		 aux loss2: 0.42160525918006897, total loss: 0.6993904709815979
<31000th step>
*************************** Test ***************************
time:3m 19s, 31000th Step, Loss: 0.5306182503700256, Mean IoU = 46.533%
************************************************************
37th Epoch, 31005th Step, learning rate = 0.0068376804534828065 - Loss: 0.2906716763973236, aux loss1: 0.7887973189353943, 
		 aux loss2: 0.4099279046058655, total loss: 0.6912820339202881
37th Epoch, 31010th Step, learning rate = 0.006837158880230654 - Loss: 0.30154967308044434, aux loss1: 0.8790289163589478, 
		 aux loss2: 0.48336243629455566, total loss: 0.7586033344268799
37th Epoch, 31015th Step, learning rate = 0.006836637302557547 - Loss: 0.2842687964439392, aux loss1: 0.8344063758850098, 
		 aux loss2: 0.4337513744831085, total loss: 0.7080912590026855
37th Epoch, 31020th Step, learning rate = 0.00683611572046307 - Loss: 0.35165947675704956, aux loss1: 0.9323168396949768, 
		 aux loss2: 0.5822308659553528, total loss: 0.8642469048500061
37th Epoch, 31025th Step, learning rate = 0.006835594133946815 - Loss: 0.36711499094963074, aux loss1: 0.9060709476470947, 
		 aux loss2: 0.5504732131958008, total loss: 0.859125554561615
37th Epoch, 31030th Step, learning rate = 0.006835072543008369 - Loss: 0.30727821588516235, aux loss1: 0.8504368662834167, 
		 aux loss2: 0.4862101972103119, total loss: 0.7568933963775635
37th Epoch, 31035th Step, learning rate = 0.006834550947647316 - Loss: 0.3628162443637848, aux loss1: 0.9453160166740417, 
		 aux loss2: 0.5399059653282166, total loss: 0.8623734712600708
37th Epoch, 31040th Step, learning rate = 0.006834029347863246 - Loss: 0.4452158808708191, aux loss1: 1.1333231925964355, 
		 aux loss2: 0.6838356256484985, total loss: 1.0587471723556519
37th Epoch, 31045th Step, learning rate = 0.006833507743655748 - Loss: 0.34503352642059326, aux loss1: 0.9736128449440002, 
		 aux loss2: 0.5288597941398621, total loss: 0.8486613035202026
37th Epoch, 31050th Step, learning rate = 0.006832986135024406 - Loss: 0.2836753726005554, aux loss1: 0.8521285653114319, 
		 aux loss2: 0.4219155013561249, total loss: 0.7080801129341125
37th Epoch, 31055th Step, learning rate = 0.00683246452196881 - Loss: 0.3013243079185486, aux loss1: 0.8670201897621155, 
		 aux loss2: 0.4671163558959961, total loss: 0.7482768893241882
37th Epoch, 31060th Step, learning rate = 0.006831942904488545 - Loss: 0.3450142443180084, aux loss1: 0.7857313752174377, 
		 aux loss2: 0.4607711434364319, total loss: 0.7650421261787415
37th Epoch, 31065th Step, learning rate = 0.006831421282583199 - Loss: 0.24201275408267975, aux loss1: 0.7588236927986145, 
		 aux loss2: 0.3707738518714905, total loss: 0.6179693937301636
37th Epoch, 31070th Step, learning rate = 0.006830899656252359 - Loss: 0.2540791928768158, aux loss1: 0.7129606604576111, 
		 aux loss2: 0.36629849672317505, total loss: 0.614486813545227
37th Epoch, 31075th Step, learning rate = 0.006830378025495612 - Loss: 0.3894538879394531, aux loss1: 0.9009827375411987, 
		 aux loss2: 0.5656828880310059, total loss: 0.8860219120979309
37th Epoch, 31080th Step, learning rate = 0.006829856390312546 - Loss: 0.36339449882507324, aux loss1: 0.8506244421005249, 
		 aux loss2: 0.5206145644187927, total loss: 0.8268276453018188
37th Epoch, 31085th Step, learning rate = 0.006829334750702746 - Loss: 0.2614731192588806, aux loss1: 0.7692704200744629, 
		 aux loss2: 0.38383176922798157, total loss: 0.6457870006561279
37th Epoch, 31090th Step, learning rate = 0.006828813106665797 - Loss: 0.21476514637470245, aux loss1: 0.6632839441299438, 
		 aux loss2: 0.32038015127182007, total loss: 0.5419024229049683
37th Epoch, 31095th Step, learning rate = 0.006828291458201292 - Loss: 0.3413540720939636, aux loss1: 0.8488290309906006, 
		 aux loss2: 0.4781177341938019, total loss: 0.7872499227523804
37th Epoch, 31100th Step, learning rate = 0.006827769805308812 - Loss: 0.34912505745887756, aux loss1: 0.8437480926513672, 
		 aux loss2: 0.4887459874153137, total loss: 0.7977479100227356
<31100th step>
*************************** Test ***************************
time:3m 18s, 31100th Step, Loss: 0.5568735003471375, Mean IoU = 45.901%
************************************************************
37th Epoch, 31105th Step, learning rate = 0.006827248147987944 - Loss: 0.3504785895347595, aux loss1: 0.8822252154350281, 
		 aux loss2: 0.5147531032562256, total loss: 0.8210474252700806
37th Epoch, 31110th Step, learning rate = 0.006826726486238278 - Loss: 0.3904927968978882, aux loss1: 1.0540827512741089, 
		 aux loss2: 0.6060408353805542, total loss: 0.9491339325904846
37th Epoch, 31115th Step, learning rate = 0.006826204820059398 - Loss: 0.26945066452026367, aux loss1: 0.7045326232910156, 
		 aux loss2: 0.3775865435600281, total loss: 0.6318451166152954
37th Epoch, 31120th Step, learning rate = 0.006825683149450888 - Loss: 0.26856571435928345, aux loss1: 0.692571222782135, 
		 aux loss2: 0.38137349486351013, total loss: 0.6288864612579346
37th Epoch, 31125th Step, learning rate = 0.006825161474412339 - Loss: 0.31186819076538086, aux loss1: 0.8257315158843994, 
		 aux loss2: 0.4562125504016876, total loss: 0.7420727014541626
37th Epoch, 31130th Step, learning rate = 0.006824639794943334 - Loss: 0.2609052360057831, aux loss1: 0.7023937702178955, 
		 aux loss2: 0.35344505310058594, total loss: 0.6130014061927795
37th Epoch, 31135th Step, learning rate = 0.006824118111043458 - Loss: 0.2915259301662445, aux loss1: 0.8915636539459229, 
		 aux loss2: 0.4673648476600647, total loss: 0.7459409236907959
37th Epoch, 31140th Step, learning rate = 0.0068235964227123 - Loss: 0.3498021364212036, aux loss1: 0.9166498780250549, 
		 aux loss2: 0.4974183142185211, total loss: 0.823764443397522
37th Epoch, 31145th Step, learning rate = 0.006823074729949445 - Loss: 0.28703320026397705, aux loss1: 0.8302503824234009, 
		 aux loss2: 0.4123033881187439, total loss: 0.7010296583175659
37th Epoch, 31150th Step, learning rate = 0.006822553032754478 - Loss: 0.3591245412826538, aux loss1: 0.8961238861083984, 
		 aux loss2: 0.5169856548309326, total loss: 0.8347560167312622
37th Epoch, 31155th Step, learning rate = 0.006822031331126986 - Loss: 0.351346880197525, aux loss1: 0.91413813829422, 
		 aux loss2: 0.4967060685157776, total loss: 0.8242707252502441
37th Epoch, 31160th Step, learning rate = 0.006821509625066552 - Loss: 0.2910533547401428, aux loss1: 0.7748839855194092, 
		 aux loss2: 0.427876353263855, total loss: 0.6946691274642944
37th Epoch, 31165th Step, learning rate = 0.006820987914572766 - Loss: 0.28338804841041565, aux loss1: 0.8024095892906189, 
		 aux loss2: 0.41721639037132263, total loss: 0.6909974813461304
37th Epoch, 31170th Step, learning rate = 0.00682046619964521 - Loss: 0.3830614686012268, aux loss1: 1.0928705930709839, 
		 aux loss2: 0.6348375082015991, total loss: 0.9648576974868774
37th Epoch, 31175th Step, learning rate = 0.00681994448028347 - Loss: 0.3148196339607239, aux loss1: 0.8619966506958008, 
		 aux loss2: 0.4417595863342285, total loss: 0.7501224279403687
37th Epoch, 31180th Step, learning rate = 0.006819422756487134 - Loss: 0.25052183866500854, aux loss1: 0.6954746842384338, 
		 aux loss2: 0.3469618856906891, total loss: 0.5979490280151367
37th Epoch, 31185th Step, learning rate = 0.006818901028255784 - Loss: 0.26364415884017944, aux loss1: 0.698894202709198, 
		 aux loss2: 0.3955134153366089, total loss: 0.6315178275108337
37th Epoch, 31190th Step, learning rate = 0.006818379295589007 - Loss: 0.25662416219711304, aux loss1: 0.7900186777114868, 
		 aux loss2: 0.41512107849121094, total loss: 0.6596782207489014
37th Epoch, 31195th Step, learning rate = 0.006817857558486387 - Loss: 0.2736331522464752, aux loss1: 0.717188835144043, 
		 aux loss2: 0.37743327021598816, total loss: 0.6397631168365479
37th Epoch, 31200th Step, learning rate = 0.00681733581694751 - Loss: 0.2869712710380554, aux loss1: 0.8016406893730164, 
		 aux loss2: 0.45103979110717773, total loss: 0.7078794240951538
<31200th step>
*************************** Test ***************************
time:3m 18s, 31200th Step, Loss: 0.5372976064682007, Mean IoU = 46.903%
************************************************************
37th Epoch, 31205th Step, learning rate = 0.006816814070971963 - Loss: 0.30229735374450684, aux loss1: 0.8848957419395447, 
		 aux loss2: 0.47856831550598145, total loss: 0.7591934204101562
37th Epoch, 31210th Step, learning rate = 0.006816292320559327 - Loss: 0.3200514316558838, aux loss1: 0.792987585067749, 
		 aux loss2: 0.4486958682537079, total loss: 0.7374260425567627
37th Epoch, 31215th Step, learning rate = 0.006815770565709188 - Loss: 0.3481442630290985, aux loss1: 0.8444427847862244, 
		 aux loss2: 0.4815950095653534, total loss: 0.7941151857376099
37th Epoch, 31220th Step, learning rate = 0.006815248806421135 - Loss: 0.3409401476383209, aux loss1: 0.9435248970985413, 
		 aux loss2: 0.5304163694381714, total loss: 0.8361641764640808
37th Epoch, 31225th Step, learning rate = 0.0068147270426947475 - Loss: 0.3804575800895691, aux loss1: 0.9656199812889099, 
		 aux loss2: 0.5655552744865417, total loss: 0.8963657021522522
38th Epoch, 31230th Step, learning rate = 0.006814205274529611 - Loss: 0.3711940348148346, aux loss1: 1.0495617389678955, 
		 aux loss2: 0.6178470849990845, total loss: 0.9332014322280884
38th Epoch, 31235th Step, learning rate = 0.006813683501925313 - Loss: 0.3416379690170288, aux loss1: 0.833242654800415, 
		 aux loss2: 0.483174592256546, total loss: 0.7848806381225586
38th Epoch, 31240th Step, learning rate = 0.006813161724881435 - Loss: 0.3163548707962036, aux loss1: 0.841682493686676, 
		 aux loss2: 0.4796845316886902, total loss: 0.7607334852218628
38th Epoch, 31245th Step, learning rate = 0.006812639943397562 - Loss: 0.25011780858039856, aux loss1: 0.7168666124343872, 
		 aux loss2: 0.36930015683174133, total loss: 0.6128978729248047
38th Epoch, 31250th Step, learning rate = 0.006812118157473281 - Loss: 0.26062095165252686, aux loss1: 0.7560499906539917, 
		 aux loss2: 0.37736597657203674, total loss: 0.6383823156356812
38th Epoch, 31255th Step, learning rate = 0.006811596367108172 - Loss: 0.3448377847671509, aux loss1: 0.8571526408195496, 
		 aux loss2: 0.4981430172920227, total loss: 0.8012407422065735
38th Epoch, 31260th Step, learning rate = 0.006811074572301822 - Loss: 0.32110849022865295, aux loss1: 0.9506141543388367, 
		 aux loss2: 0.5245031118392944, total loss: 0.8160939812660217
38th Epoch, 31265th Step, learning rate = 0.0068105527730538155 - Loss: 0.3082796335220337, aux loss1: 1.003810167312622, 
		 aux loss2: 0.5184375643730164, total loss: 0.8167977333068848
38th Epoch, 31270th Step, learning rate = 0.006810030969363734 - Loss: 0.2491377741098404, aux loss1: 0.778822124004364, 
		 aux loss2: 0.3954174518585205, total loss: 0.64095139503479
38th Epoch, 31275th Step, learning rate = 0.006809509161231165 - Loss: 0.2649560272693634, aux loss1: 0.8084481358528137, 
		 aux loss2: 0.39303550124168396, total loss: 0.6647046804428101
38th Epoch, 31280th Step, learning rate = 0.00680898734865569 - Loss: 0.2406136691570282, aux loss1: 0.7293656468391418, 
		 aux loss2: 0.3683711290359497, total loss: 0.6067718267440796
38th Epoch, 31285th Step, learning rate = 0.006808465531636893 - Loss: 0.26851287484169006, aux loss1: 0.8108875155448914, 
		 aux loss2: 0.4272446036338806, total loss: 0.6826769709587097
38th Epoch, 31290th Step, learning rate = 0.006807943710174359 - Loss: 0.30699530243873596, aux loss1: 0.8631210923194885, 
		 aux loss2: 0.45287010073661804, total loss: 0.7470797300338745
38th Epoch, 31295th Step, learning rate = 0.00680742188426767 - Loss: 0.3593747317790985, aux loss1: 0.9863595366477966, 
		 aux loss2: 0.5783297419548035, total loss: 0.8866145014762878
38th Epoch, 31300th Step, learning rate = 0.006806900053916411 - Loss: 0.3005164563655853, aux loss1: 0.8079113960266113, 
		 aux loss2: 0.4422578811645508, total loss: 0.7197930812835693
<31300th step>
*************************** Test ***************************
time:3m 18s, 31300th Step, Loss: 0.5440526008605957, Mean IoU = 46.454%
************************************************************
38th Epoch, 31305th Step, learning rate = 0.006806378219120165 - Loss: 0.313171923160553, aux loss1: 0.8609893321990967, 
		 aux loss2: 0.448928564786911, total loss: 0.7510401606559753
38th Epoch, 31310th Step, learning rate = 0.006805856379878516 - Loss: 0.25418269634246826, aux loss1: 0.8053749203681946, 
		 aux loss2: 0.4137817919254303, total loss: 0.6613079309463501
38th Epoch, 31315th Step, learning rate = 0.006805334536191046 - Loss: 0.2881118357181549, aux loss1: 0.7904741764068604, 
		 aux loss2: 0.43820348381996155, total loss: 0.7005355358123779
38th Epoch, 31320th Step, learning rate = 0.006804812688057341 - Loss: 0.3348534107208252, aux loss1: 0.7593615055084229, 
		 aux loss2: 0.4718702733516693, total loss: 0.7514100074768066
38th Epoch, 31325th Step, learning rate = 0.006804290835476979 - Loss: 0.3611527383327484, aux loss1: 0.9126733541488647, 
		 aux loss2: 0.5421991944313049, total loss: 0.8518344163894653
38th Epoch, 31330th Step, learning rate = 0.0068037689784495505 - Loss: 0.20914655923843384, aux loss1: 0.5812544226646423, 
		 aux loss2: 0.31150469183921814, total loss: 0.5081247687339783
38th Epoch, 31335th Step, learning rate = 0.006803247116974633 - Loss: 0.23694761097431183, aux loss1: 0.71519935131073, 
		 aux loss2: 0.36431774497032166, total loss: 0.5972344875335693
38th Epoch, 31340th Step, learning rate = 0.006802725251051811 - Loss: 0.4208686649799347, aux loss1: 0.9239107370376587, 
		 aux loss2: 0.5583192706108093, total loss: 0.9213696122169495
38th Epoch, 31345th Step, learning rate = 0.006802203380680669 - Loss: 0.2991081774234772, aux loss1: 0.7719178199768066, 
		 aux loss2: 0.41989389061927795, total loss: 0.6986410617828369
38th Epoch, 31350th Step, learning rate = 0.0068016815058607885 - Loss: 0.3116048276424408, aux loss1: 0.8523051142692566, 
		 aux loss2: 0.4412366449832916, total loss: 0.7437910437583923
38th Epoch, 31355th Step, learning rate = 0.006801159626591752 - Loss: 0.2406337559223175, aux loss1: 0.6732968091964722, 
		 aux loss2: 0.3524288237094879, total loss: 0.5835943222045898
38th Epoch, 31360th Step, learning rate = 0.006800637742873143 - Loss: 0.34431320428848267, aux loss1: 0.8129911422729492, 
		 aux loss2: 0.49856075644493103, total loss: 0.7876349091529846
38th Epoch, 31365th Step, learning rate = 0.006800115854704544 - Loss: 0.22577281296253204, aux loss1: 0.7607062458992004, 
		 aux loss2: 0.3741782605648041, total loss: 0.603655993938446
38th Epoch, 31370th Step, learning rate = 0.006799593962085536 - Loss: 0.33387741446495056, aux loss1: 0.8810604214668274, 
		 aux loss2: 0.5028550624847412, total loss: 0.7993375658988953
38th Epoch, 31375th Step, learning rate = 0.006799072065015705 - Loss: 0.2879857122898102, aux loss1: 0.8190320134162903, 
		 aux loss2: 0.4217991232872009, total loss: 0.7024149894714355
38th Epoch, 31380th Step, learning rate = 0.00679855016349463 - Loss: 0.3580043911933899, aux loss1: 0.9223107099533081, 
		 aux loss2: 0.5381858348846436, total loss: 0.8499719500541687
38th Epoch, 31385th Step, learning rate = 0.0067980282575218955 - Loss: 0.3101215362548828, aux loss1: 0.8959791660308838, 
		 aux loss2: 0.4563474655151367, total loss: 0.7614542841911316
38th Epoch, 31390th Step, learning rate = 0.006797506347097083 - Loss: 0.45391979813575745, aux loss1: 1.0646437406539917, 
		 aux loss2: 0.6549136638641357, total loss: 1.0352784395217896
38th Epoch, 31395th Step, learning rate = 0.006796984432219774 - Loss: 0.2740354835987091, aux loss1: 0.8395578861236572, 
		 aux loss2: 0.42408066987991333, total loss: 0.6955351233482361
38th Epoch, 31400th Step, learning rate = 0.006796462512889552 - Loss: 0.2523971498012543, aux loss1: 0.7848016023635864, 
		 aux loss2: 0.36644446849823, total loss: 0.6344154477119446
<31400th step>
*************************** Test ***************************
time:3m 17s, 31400th Step, Loss: 0.5830845832824707, Mean IoU = 44.538%
************************************************************
38th Epoch, 31405th Step, learning rate = 0.006795940589105998 - Loss: 0.3117319941520691, aux loss1: 0.8293297290802002, 
		 aux loss2: 0.45554792881011963, total loss: 0.7427500486373901
38th Epoch, 31410th Step, learning rate = 0.006795418660868694 - Loss: 0.3127497136592865, aux loss1: 0.8542966842651367, 
		 aux loss2: 0.47316861152648926, total loss: 0.7583062052726746
38th Epoch, 31415th Step, learning rate = 0.006794896728177223 - Loss: 0.30906054377555847, aux loss1: 0.7727640271186829, 
		 aux loss2: 0.4457436501979828, total loss: 0.7191872000694275
38th Epoch, 31420th Step, learning rate = 0.006794374791031166 - Loss: 0.24761170148849487, aux loss1: 0.7093687057495117, 
		 aux loss2: 0.34717124700546265, total loss: 0.5992908477783203
38th Epoch, 31425th Step, learning rate = 0.006793852849430105 - Loss: 0.28780725598335266, aux loss1: 0.8661183714866638, 
		 aux loss2: 0.4503816068172455, total loss: 0.727795422077179
38th Epoch, 31430th Step, learning rate = 0.006793330903373621 - Loss: 0.28043198585510254, aux loss1: 0.6826786398887634, 
		 aux loss2: 0.3749529719352722, total loss: 0.6352167725563049
38th Epoch, 31435th Step, learning rate = 0.006792808952861297 - Loss: 0.3427289128303528, aux loss1: 1.0901321172714233, 
		 aux loss2: 0.6310255527496338, total loss: 0.9221788048744202
38th Epoch, 31440th Step, learning rate = 0.006792286997892713 - Loss: 0.331266850233078, aux loss1: 1.0986653566360474, 
		 aux loss2: 0.569989025592804, total loss: 0.888862133026123
38th Epoch, 31445th Step, learning rate = 0.006791765038467451 - Loss: 0.30688533186912537, aux loss1: 0.8226073980331421, 
		 aux loss2: 0.46567612886428833, total loss: 0.7399380207061768
38th Epoch, 31450th Step, learning rate = 0.006791243074585091 - Loss: 0.3884245753288269, aux loss1: 0.952195942401886, 
		 aux loss2: 0.5569478869438171, total loss: 0.8968625068664551
38th Epoch, 31455th Step, learning rate = 0.006790721106245219 - Loss: 0.2808897793292999, aux loss1: 0.7521963119506836, 
		 aux loss2: 0.408907413482666, total loss: 0.6701116561889648
38th Epoch, 31460th Step, learning rate = 0.006790199133447411 - Loss: 0.30431362986564636, aux loss1: 1.0398606061935425, 
		 aux loss2: 0.5263035297393799, total loss: 0.8267932534217834
38th Epoch, 31465th Step, learning rate = 0.006789677156191251 - Loss: 0.27991577982902527, aux loss1: 0.8323058485984802, 
		 aux loss2: 0.4229143261909485, total loss: 0.6987732648849487
38th Epoch, 31470th Step, learning rate = 0.00678915517447632 - Loss: 0.3196588456630707, aux loss1: 0.9776223301887512, 
		 aux loss2: 0.5269705057144165, total loss: 0.8237337470054626
38th Epoch, 31475th Step, learning rate = 0.006788633188302196 - Loss: 0.2562096118927002, aux loss1: 0.8485958576202393, 
		 aux loss2: 0.42054423689842224, total loss: 0.6790060997009277
38th Epoch, 31480th Step, learning rate = 0.006788111197668465 - Loss: 0.28111982345581055, aux loss1: 0.7601844668388367, 
		 aux loss2: 0.40166613459587097, total loss: 0.6698416471481323
38th Epoch, 31485th Step, learning rate = 0.0067875892025747045 - Loss: 0.29084694385528564, aux loss1: 0.7834210395812988, 
		 aux loss2: 0.4522889256477356, total loss: 0.7067888379096985
38th Epoch, 31490th Step, learning rate = 0.006787067203020495 - Loss: 0.33835867047309875, aux loss1: 0.9605988264083862, 
		 aux loss2: 0.5371881723403931, total loss: 0.8414136171340942
38th Epoch, 31495th Step, learning rate = 0.006786545199005417 - Loss: 0.2983770966529846, aux loss1: 0.8846773505210876, 
		 aux loss2: 0.4564943015575409, total loss: 0.7463780641555786
38th Epoch, 31500th Step, learning rate = 0.006786023190529055 - Loss: 0.22008557617664337, aux loss1: 0.6753897070884705, 
		 aux loss2: 0.3231925964355469, total loss: 0.5519795417785645
<31500th step>
*************************** Test ***************************
time:3m 19s, 31500th Step, Loss: 0.5327603816986084, Mean IoU = 46.035%
************************************************************
38th Epoch, 31505th Step, learning rate = 0.006785501177590984 - Loss: 0.2990425229072571, aux loss1: 0.8383650779724121, 
		 aux loss2: 0.43548083305358887, total loss: 0.724744439125061
38th Epoch, 31510th Step, learning rate = 0.006784979160190789 - Loss: 0.3450112044811249, aux loss1: 0.996058464050293, 
		 aux loss2: 0.519935667514801, total loss: 0.8518030047416687
38th Epoch, 31515th Step, learning rate = 0.0067844571383280485 - Loss: 0.33869442343711853, aux loss1: 0.8732472658157349, 
		 aux loss2: 0.5273388624191284, total loss: 0.8116041421890259
38th Epoch, 31520th Step, learning rate = 0.006783935112002341 - Loss: 0.27632763981819153, aux loss1: 0.9907788038253784, 
		 aux loss2: 0.4429846704006195, total loss: 0.7507551908493042
38th Epoch, 31525th Step, learning rate = 0.006783413081213251 - Loss: 0.3545941710472107, aux loss1: 0.8733190298080444, 
		 aux loss2: 0.4829975366592407, total loss: 0.8097889423370361
38th Epoch, 31530th Step, learning rate = 0.006782891045960355 - Loss: 0.2597581744194031, aux loss1: 0.7906205058097839, 
		 aux loss2: 0.38796061277389526, total loss: 0.6521285772323608
38th Epoch, 31535th Step, learning rate = 0.006782369006243235 - Loss: 0.39601126313209534, aux loss1: 0.9148540496826172, 
		 aux loss2: 0.5650405883789062, total loss: 0.8964837193489075
38th Epoch, 31540th Step, learning rate = 0.006781846962061471 - Loss: 0.2663251757621765, aux loss1: 0.8081209659576416, 
		 aux loss2: 0.4130162000656128, total loss: 0.6739679574966431
38th Epoch, 31545th Step, learning rate = 0.0067813249134146426 - Loss: 0.34265658259391785, aux loss1: 0.8559730648994446, 
		 aux loss2: 0.48399293422698975, total loss: 0.793045699596405
38th Epoch, 31550th Step, learning rate = 0.006780802860302328 - Loss: 0.25486990809440613, aux loss1: 0.7029635906219482, 
		 aux loss2: 0.34151551127433777, total loss: 0.6023651957511902
38th Epoch, 31555th Step, learning rate = 0.00678028080272411 - Loss: 0.25604909658432007, aux loss1: 0.7264174222946167, 
		 aux loss2: 0.38794204592704773, total loss: 0.6291511654853821
38th Epoch, 31560th Step, learning rate = 0.006779758740679567 - Loss: 0.273040235042572, aux loss1: 0.7650354504585266, 
		 aux loss2: 0.4229859411716461, total loss: 0.6717453002929688
38th Epoch, 31565th Step, learning rate = 0.006779236674168278 - Loss: 0.3412487804889679, aux loss1: 0.9246421456336975, 
		 aux loss2: 0.5501735806465149, total loss: 0.8387109041213989
38th Epoch, 31570th Step, learning rate = 0.006778714603189823 - Loss: 0.30341216921806335, aux loss1: 0.9589329361915588, 
		 aux loss2: 0.4895087778568268, total loss: 0.7868955731391907
38th Epoch, 31575th Step, learning rate = 0.006778192527743781 - Loss: 0.3790903091430664, aux loss1: 1.0124716758728027, 
		 aux loss2: 0.5649963021278381, total loss: 0.9088303446769714
38th Epoch, 31580th Step, learning rate = 0.006777670447829732 - Loss: 0.3344700336456299, aux loss1: 0.9263768196105957, 
		 aux loss2: 0.516771137714386, total loss: 0.8190915584564209
38th Epoch, 31585th Step, learning rate = 0.006777148363447256 - Loss: 0.3068963885307312, aux loss1: 0.7046133875846863, 
		 aux loss2: 0.3902081847190857, total loss: 0.6743636727333069
38th Epoch, 31590th Step, learning rate = 0.006776626274595932 - Loss: 0.2935621738433838, aux loss1: 0.8715436458587646, 
		 aux loss2: 0.4255838692188263, total loss: 0.7252588272094727
38th Epoch, 31595th Step, learning rate = 0.006776104181275339 - Loss: 0.33911994099617004, aux loss1: 1.0458126068115234, 
		 aux loss2: 0.5557578206062317, total loss: 0.8751668930053711
39th Epoch, 31600th Step, learning rate = 0.006775582083485054 - Loss: 0.309475839138031, aux loss1: 0.8845033645629883, 
		 aux loss2: 0.48426294326782227, total loss: 0.7685320377349854
<31600th step>
*************************** Test ***************************
time:3m 17s, 31600th Step, Loss: 0.504584789276123, Mean IoU = 45.292%
************************************************************
39th Epoch, 31605th Step, learning rate = 0.0067750599812246605 - Loss: 0.2701473832130432, aux loss1: 0.7609890699386597, 
		 aux loss2: 0.4102465510368347, total loss: 0.6625427007675171
39th Epoch, 31610th Step, learning rate = 0.006774537874493733 - Loss: 0.266901433467865, aux loss1: 0.8283159136772156, 
		 aux loss2: 0.4313616454601288, total loss: 0.6879408955574036
39th Epoch, 31615th Step, learning rate = 0.006774015763291855 - Loss: 0.28109973669052124, aux loss1: 0.7507243752479553, 
		 aux loss2: 0.406710684299469, total loss: 0.6690013408660889
39th Epoch, 31620th Step, learning rate = 0.0067734936476186 - Loss: 0.2960945963859558, aux loss1: 0.8372884392738342, 
		 aux loss2: 0.4212268590927124, total loss: 0.7157719135284424
39th Epoch, 31625th Step, learning rate = 0.00677297152747355 - Loss: 0.41682347655296326, aux loss1: 1.1617603302001953, 
		 aux loss2: 0.6772620677947998, total loss: 1.0362564325332642
39th Epoch, 31630th Step, learning rate = 0.006772449402856282 - Loss: 0.24627827107906342, aux loss1: 0.7359375953674316, 
		 aux loss2: 0.38801494240760803, total loss: 0.6222655177116394
39th Epoch, 31635th Step, learning rate = 0.006771927273766378 - Loss: 0.24924804270267487, aux loss1: 0.6957294940948486, 
		 aux loss2: 0.3573503792285919, total loss: 0.600907027721405
39th Epoch, 31640th Step, learning rate = 0.0067714051402034126 - Loss: 0.3019786477088928, aux loss1: 0.7744065523147583, 
		 aux loss2: 0.444474995136261, total loss: 0.7120906114578247
39th Epoch, 31645th Step, learning rate = 0.006770883002166966 - Loss: 0.3120974600315094, aux loss1: 0.8017011880874634, 
		 aux loss2: 0.4818670153617859, total loss: 0.7453546524047852
39th Epoch, 31650th Step, learning rate = 0.006770360859656618 - Loss: 0.2866871953010559, aux loss1: 0.827932596206665, 
		 aux loss2: 0.43270692229270935, total loss: 0.7081497311592102
39th Epoch, 31655th Step, learning rate = 0.006769838712671944 - Loss: 0.29545915126800537, aux loss1: 0.9289470911026001, 
		 aux loss2: 0.5139894485473633, total loss: 0.7797390818595886
39th Epoch, 31660th Step, learning rate = 0.006769316561212523 - Loss: 0.2593603730201721, aux loss1: 0.874100387096405, 
		 aux loss2: 0.4216790795326233, total loss: 0.6902620792388916
39th Epoch, 31665th Step, learning rate = 0.006768794405277935 - Loss: 0.2868497669696808, aux loss1: 0.8196009993553162, 
		 aux loss2: 0.4601880609989166, total loss: 0.7168053388595581
39th Epoch, 31670th Step, learning rate = 0.006768272244867755 - Loss: 0.24455296993255615, aux loss1: 0.733858585357666, 
		 aux loss2: 0.3832681477069855, total loss: 0.6180177927017212
39th Epoch, 31675th Step, learning rate = 0.006767750079981564 - Loss: 0.27644941210746765, aux loss1: 0.738955020904541, 
		 aux loss2: 0.4051998257637024, total loss: 0.6602158546447754
39th Epoch, 31680th Step, learning rate = 0.0067672279106189386 - Loss: 0.2036679983139038, aux loss1: 0.6823601126670837, 
		 aux loss2: 0.3026096820831299, total loss: 0.5294198989868164
39th Epoch, 31685th Step, learning rate = 0.006766705736779454 - Loss: 0.2740898132324219, aux loss1: 0.7248072624206543, 
		 aux loss2: 0.4098621606826782, total loss: 0.6554768681526184
39th Epoch, 31690th Step, learning rate = 0.006766183558462693 - Loss: 0.23023001849651337, aux loss1: 0.7645314335823059, 
		 aux loss2: 0.37425607442855835, total loss: 0.6092919111251831
39th Epoch, 31695th Step, learning rate = 0.006765661375668232 - Loss: 0.2787182033061981, aux loss1: 0.9422560930252075, 
		 aux loss2: 0.41223666071891785, total loss: 0.7262897491455078
39th Epoch, 31700th Step, learning rate = 0.006765139188395644 - Loss: 0.3100101053714752, aux loss1: 0.8983649611473083, 
		 aux loss2: 0.49933552742004395, total loss: 0.7792538404464722
<31700th step>
*************************** Test ***************************
time:3m 19s, 31700th Step, Loss: 0.5314803719520569, Mean IoU = 45.925%
************************************************************
39th Epoch, 31705th Step, learning rate = 0.006764616996644513 - Loss: 0.26053449511528015, aux loss1: 0.7556594014167786, 
		 aux loss2: 0.38926294445991516, total loss: 0.6429375410079956
39th Epoch, 31710th Step, learning rate = 0.006764094800414411 - Loss: 0.2698247730731964, aux loss1: 0.8724862933158875, 
		 aux loss2: 0.49632567167282104, total loss: 0.7301009297370911
39th Epoch, 31715th Step, learning rate = 0.006763572599704918 - Loss: 0.2862486243247986, aux loss1: 0.8448973298072815, 
		 aux loss2: 0.46240103244781494, total loss: 0.7246782183647156
39th Epoch, 31720th Step, learning rate = 0.006763050394515613 - Loss: 0.2732154428958893, aux loss1: 0.7548362016677856, 
		 aux loss2: 0.3903407156467438, total loss: 0.6558026075363159
39th Epoch, 31725th Step, learning rate = 0.006762528184846069 - Loss: 0.2505987286567688, aux loss1: 0.7821462750434875, 
		 aux loss2: 0.3965930640697479, total loss: 0.6438798308372498
39th Epoch, 31730th Step, learning rate = 0.006762005970695867 - Loss: 0.3301243484020233, aux loss1: 0.7530527710914612, 
		 aux loss2: 0.4502068758010864, total loss: 0.7361229062080383
39th Epoch, 31735th Step, learning rate = 0.006761483752064583 - Loss: 0.30108293890953064, aux loss1: 0.702087938785553, 
		 aux loss2: 0.39658787846565247, total loss: 0.6703444719314575
39th Epoch, 31740th Step, learning rate = 0.006760961528951792 - Loss: 0.31197914481163025, aux loss1: 0.9027912020683289, 
		 aux loss2: 0.4818195700645447, total loss: 0.775544285774231
39th Epoch, 31745th Step, learning rate = 0.006760439301357073 - Loss: 0.3050490915775299, aux loss1: 0.9641016721725464, 
		 aux loss2: 0.5190774202346802, total loss: 0.8019106388092041
39th Epoch, 31750th Step, learning rate = 0.0067599170692800034 - Loss: 0.33981072902679443, aux loss1: 0.9678693413734436, 
		 aux loss2: 0.5070633292198181, total loss: 0.8329968452453613
39th Epoch, 31755th Step, learning rate = 0.006759394832720156 - Loss: 0.3603762090206146, aux loss1: 0.9844631552696228, 
		 aux loss2: 0.5474095940589905, total loss: 0.8746790289878845
39th Epoch, 31760th Step, learning rate = 0.0067588725916771135 - Loss: 0.35704267024993896, aux loss1: 0.8585186004638672, 
		 aux loss2: 0.5377854108810425, total loss: 0.829712450504303
39th Epoch, 31765th Step, learning rate = 0.006758350346150447 - Loss: 0.2597835958003998, aux loss1: 0.7672921419143677, 
		 aux loss2: 0.38514167070388794, total loss: 0.6440279483795166
39th Epoch, 31770th Step, learning rate = 0.006757828096139736 - Loss: 0.2835482060909271, aux loss1: 0.7916092872619629, 
		 aux loss2: 0.4203936457633972, total loss: 0.6891884803771973
39th Epoch, 31775th Step, learning rate = 0.006757305841644558 - Loss: 0.29357391595840454, aux loss1: 0.855493426322937, 
		 aux loss2: 0.4683036804199219, total loss: 0.7375434041023254
39th Epoch, 31780th Step, learning rate = 0.006756783582664485 - Loss: 0.42331141233444214, aux loss1: 1.197587251663208, 
		 aux loss2: 0.7516995072364807, total loss: 1.0832674503326416
39th Epoch, 31785th Step, learning rate = 0.006756261319199097 - Loss: 0.3167749345302582, aux loss1: 0.8314427137374878, 
		 aux loss2: 0.4732820391654968, total loss: 0.7555205821990967
39th Epoch, 31790th Step, learning rate = 0.006755739051247971 - Loss: 0.3743721544742584, aux loss1: 0.9940175414085388, 
		 aux loss2: 0.6006844639778137, total loss: 0.9128512144088745
39th Epoch, 31795th Step, learning rate = 0.00675521677881068 - Loss: 0.3143395185470581, aux loss1: 0.900185763835907, 
		 aux loss2: 0.5141340494155884, total loss: 0.7900488972663879
39th Epoch, 31800th Step, learning rate = 0.0067546945018868015 - Loss: 0.3083367943763733, aux loss1: 0.8629058003425598, 
		 aux loss2: 0.4700220227241516, total loss: 0.7552173137664795
<31800th step>
*************************** Test ***************************
time:3m 14s, 31800th Step, Loss: 0.5454091429710388, Mean IoU = 45.966%
************************************************************
39th Epoch, 31805th Step, learning rate = 0.006754172220475911 - Loss: 0.3685537874698639, aux loss1: 0.9938592910766602, 
		 aux loss2: 0.5777047276496887, total loss: 0.8977934718132019
39th Epoch, 31810th Step, learning rate = 0.006753649934577583 - Loss: 0.31930291652679443, aux loss1: 1.0223687887191772, 
		 aux loss2: 0.5171591639518738, total loss: 0.8328772783279419
39th Epoch, 31815th Step, learning rate = 0.006753127644191399 - Loss: 0.3085612654685974, aux loss1: 0.9511781930923462, 
		 aux loss2: 0.532282292842865, total loss: 0.8068276643753052
39th Epoch, 31820th Step, learning rate = 0.0067526053493169305 - Loss: 0.27692610025405884, aux loss1: 0.7629452347755432, 
		 aux loss2: 0.3902418315410614, total loss: 0.6619064211845398
39th Epoch, 31825th Step, learning rate = 0.006752083049953751 - Loss: 0.2543624937534332, aux loss1: 0.7220491170883179, 
		 aux loss2: 0.34604278206825256, total loss: 0.609394371509552
39th Epoch, 31830th Step, learning rate = 0.006751560746101441 - Loss: 0.31837156414985657, aux loss1: 0.9649806022644043, 
		 aux loss2: 0.5771573781967163, total loss: 0.8387287259101868
39th Epoch, 31835th Step, learning rate = 0.006751038437759573 - Loss: 0.34163349866867065, aux loss1: 0.8756915330886841, 
		 aux loss2: 0.5169128179550171, total loss: 0.8111060857772827
39th Epoch, 31840th Step, learning rate = 0.006750516124927725 - Loss: 0.2544403076171875, aux loss1: 0.8297057151794434, 
		 aux loss2: 0.41931793093681335, total loss: 0.6710792183876038
39th Epoch, 31845th Step, learning rate = 0.0067499938076054705 - Loss: 0.2290189415216446, aux loss1: 0.6955000162124634, 
		 aux loss2: 0.34180739521980286, total loss: 0.5743919014930725
39th Epoch, 31850th Step, learning rate = 0.006749471485792384 - Loss: 0.28211119771003723, aux loss1: 0.8524537086486816, 
		 aux loss2: 0.4408584237098694, total loss: 0.714190661907196
39th Epoch, 31855th Step, learning rate = 0.006748949159488041 - Loss: 0.2509453594684601, aux loss1: 0.7380442023277283, 
		 aux loss2: 0.37764060497283936, total loss: 0.6234148740768433
39th Epoch, 31860th Step, learning rate = 0.006748426828692018 - Loss: 0.4857812523841858, aux loss1: 1.093485951423645, 
		 aux loss2: 0.7132193446159363, total loss: 1.0991147756576538
39th Epoch, 31865th Step, learning rate = 0.006747904493403889 - Loss: 0.3296518325805664, aux loss1: 0.8896806240081787, 
		 aux loss2: 0.48751935362815857, total loss: 0.7915638089179993
39th Epoch, 31870th Step, learning rate = 0.00674738215362323 - Loss: 0.3221682906150818, aux loss1: 0.8500428199768066, 
		 aux loss2: 0.48207220435142517, total loss: 0.7700100541114807
39th Epoch, 31875th Step, learning rate = 0.006746859809349617 - Loss: 0.2954491972923279, aux loss1: 0.8149634003639221, 
		 aux loss2: 0.4453384578227997, total loss: 0.7180736064910889
39th Epoch, 31880th Step, learning rate = 0.00674633746058262 - Loss: 0.3117762506008148, aux loss1: 0.8720561265945435, 
		 aux loss2: 0.4794372618198395, total loss: 0.7651680111885071
39th Epoch, 31885th Step, learning rate = 0.00674581510732182 - Loss: 0.2620888650417328, aux loss1: 0.7260645031929016, 
		 aux loss2: 0.3652786612510681, total loss: 0.6260197162628174
39th Epoch, 31890th Step, learning rate = 0.006745292749566788 - Loss: 0.2988360524177551, aux loss1: 0.7405945658683777, 
		 aux loss2: 0.4399663209915161, total loss: 0.6970009803771973
39th Epoch, 31895th Step, learning rate = 0.006744770387317098 - Loss: 0.3900456130504608, aux loss1: 1.0020735263824463, 
		 aux loss2: 0.5690154433250427, total loss: 0.9182738661766052
39th Epoch, 31900th Step, learning rate = 0.006744248020572328 - Loss: 0.27752119302749634, aux loss1: 0.7094267010688782, 
		 aux loss2: 0.3856924772262573, total loss: 0.644626259803772
<31900th step>
*************************** Test ***************************
time:3m 17s, 31900th Step, Loss: 0.5591772794723511, Mean IoU = 43.975%
************************************************************
39th Epoch, 31905th Step, learning rate = 0.00674372564933205 - Loss: 0.28924092650413513, aux loss1: 0.7456885576248169, 
		 aux loss2: 0.4061241149902344, total loss: 0.6753971576690674
39th Epoch, 31910th Step, learning rate = 0.006743203273595837 - Loss: 0.19152140617370605, aux loss1: 0.6370205879211426, 
		 aux loss2: 0.27415260672569275, total loss: 0.49228864908218384
39th Epoch, 31915th Step, learning rate = 0.006742680893363268 - Loss: 0.20310081541538239, aux loss1: 0.6349137425422668, 
		 aux loss2: 0.29630452394485474, total loss: 0.5120967626571655
39th Epoch, 31920th Step, learning rate = 0.006742158508633912 - Loss: 0.2908007800579071, aux loss1: 0.853033721446991, 
		 aux loss2: 0.46300622820854187, total loss: 0.7319133877754211
39th Epoch, 31925th Step, learning rate = 0.006741636119407345 - Loss: 0.28498637676239014, aux loss1: 0.7793050408363342, 
		 aux loss2: 0.4098980128765106, total loss: 0.6827371120452881
39th Epoch, 31930th Step, learning rate = 0.006741113725683145 - Loss: 0.4381391406059265, aux loss1: 1.0100703239440918, 
		 aux loss2: 0.6248219013214111, total loss: 0.9910890460014343
39th Epoch, 31935th Step, learning rate = 0.006740591327460878 - Loss: 0.309527724981308, aux loss1: 0.9555667638778687, 
		 aux loss2: 0.5208731889724731, total loss: 0.8045470118522644
39th Epoch, 31940th Step, learning rate = 0.006740068924740126 - Loss: 0.28406664729118347, aux loss1: 0.787053644657135, 
		 aux loss2: 0.45814716815948486, total loss: 0.7034416198730469
39th Epoch, 31945th Step, learning rate = 0.006739546517520457 - Loss: 0.37027522921562195, aux loss1: 1.0099201202392578, 
		 aux loss2: 0.5660830140113831, total loss: 0.899684488773346
39th Epoch, 31950th Step, learning rate = 0.006739024105801448 - Loss: 0.32330429553985596, aux loss1: 0.8903405070304871, 
		 aux loss2: 0.4805484414100647, total loss: 0.7826257944107056
39th Epoch, 31955th Step, learning rate = 0.006738501689582673 - Loss: 0.3275052607059479, aux loss1: 0.8936440944671631, 
		 aux loss2: 0.5024826526641846, total loss: 0.7965915203094482
39th Epoch, 31960th Step, learning rate = 0.006737979268863703 - Loss: 0.22031565010547638, aux loss1: 0.9219648838043213, 
		 aux loss2: 0.390581876039505, total loss: 0.6531379222869873
39th Epoch, 31965th Step, learning rate = 0.006737456843644113 - Loss: 0.37980175018310547, aux loss1: 0.9341331720352173, 
		 aux loss2: 0.5466645359992981, total loss: 0.8787075281143188
39th Epoch, 31970th Step, learning rate = 0.006736934413923478 - Loss: 0.2827529311180115, aux loss1: 0.8318458199501038, 
		 aux loss2: 0.44047409296035767, total loss: 0.7084963321685791
40th Epoch, 31975th Step, learning rate = 0.006736411979701369 - Loss: 0.31830352544784546, aux loss1: 0.9328987002372742, 
		 aux loss2: 0.5003429055213928, total loss: 0.7983102798461914
40th Epoch, 31980th Step, learning rate = 0.006735889540977359 - Loss: 0.31435495615005493, aux loss1: 0.9099393486976624, 
		 aux loss2: 0.4661797285079956, total loss: 0.7738086581230164
40th Epoch, 31985th Step, learning rate = 0.006735367097751024 - Loss: 0.264360636472702, aux loss1: 0.6945548057556152, 
		 aux loss2: 0.38028913736343384, total loss: 0.6248427629470825
40th Epoch, 31990th Step, learning rate = 0.006734844650021934 - Loss: 0.24624982476234436, aux loss1: 0.6962333917617798, 
		 aux loss2: 0.36943599581718445, total loss: 0.6028942465782166
40th Epoch, 31995th Step, learning rate = 0.006734322197789665 - Loss: 0.3118162453174591, aux loss1: 0.7815238237380981, 
		 aux loss2: 0.4793825149536133, total loss: 0.7380264401435852
40th Epoch, 32000th Step, learning rate = 0.006733799741053789 - Loss: 0.3070923984050751, aux loss1: 0.7631597518920898, 
		 aux loss2: 0.4617474675178528, total loss: 0.7207393050193787
<32000th step>
*************************** Test ***************************
time:3m 15s, 32000th Step, Loss: 0.5300561189651489, Mean IoU = 45.704%
************************************************************
40th Epoch, 32005th Step, learning rate = 0.006733277279813876 - Loss: 0.23369255661964417, aux loss1: 0.7261852622032166, 
		 aux loss2: 0.3784375786781311, total loss: 0.6029232144355774
40th Epoch, 32010th Step, learning rate = 0.006732754814069504 - Loss: 0.2671585977077484, aux loss1: 0.8223814368247986, 
		 aux loss2: 0.4204420745372772, total loss: 0.6820498704910278
40th Epoch, 32015th Step, learning rate = 0.0067322323438202426 - Loss: 0.276319295167923, aux loss1: 0.7151500582695007, 
		 aux loss2: 0.3904508054256439, total loss: 0.6470446586608887
40th Epoch, 32020th Step, learning rate = 0.006731709869065664 - Loss: 0.366487592458725, aux loss1: 0.9810597896575928, 
		 aux loss2: 0.5561400651931763, total loss: 0.8832616209983826
40th Epoch, 32025th Step, learning rate = 0.006731187389805343 - Loss: 0.2616082429885864, aux loss1: 0.8040712475776672, 
		 aux loss2: 0.4341002404689789, total loss: 0.6764696836471558
40th Epoch, 32030th Step, learning rate = 0.006730664906038851 - Loss: 0.30643904209136963, aux loss1: 0.8314641118049622, 
		 aux loss2: 0.466412752866745, total loss: 0.7424433827400208
40th Epoch, 32035th Step, learning rate = 0.006730142417765759 - Loss: 0.26402589678764343, aux loss1: 0.8009004592895508, 
		 aux loss2: 0.4005451202392578, total loss: 0.6645141243934631
40th Epoch, 32040th Step, learning rate = 0.006729619924985643 - Loss: 0.285672128200531, aux loss1: 0.7885423302650452, 
		 aux loss2: 0.4271447956562042, total loss: 0.6930927634239197
40th Epoch, 32045th Step, learning rate = 0.006729097427698072 - Loss: 0.21861697733402252, aux loss1: 0.6430054903030396, 
		 aux loss2: 0.32600918412208557, total loss: 0.5419223308563232
40th Epoch, 32050th Step, learning rate = 0.006728574925902619 - Loss: 0.26148977875709534, aux loss1: 0.6879702210426331, 
		 aux loss2: 0.3810008764266968, total loss: 0.6202812194824219
40th Epoch, 32055th Step, learning rate = 0.006728052419598858 - Loss: 0.27174240350723267, aux loss1: 0.8018914461135864, 
		 aux loss2: 0.4282582700252533, total loss: 0.6836131811141968
40th Epoch, 32060th Step, learning rate = 0.006727529908786356 - Loss: 0.2918119728565216, aux loss1: 0.7373783588409424, 
		 aux loss2: 0.425181120634079, total loss: 0.6830979585647583
40th Epoch, 32065th Step, learning rate = 0.006727007393464692 - Loss: 0.29367169737815857, aux loss1: 0.8367969393730164, 
		 aux loss2: 0.4761545956134796, total loss: 0.7351726293563843
40th Epoch, 32070th Step, learning rate = 0.006726484873633434 - Loss: 0.2822089195251465, aux loss1: 0.7582132816314697, 
		 aux loss2: 0.4186362028121948, total loss: 0.6771273612976074
40th Epoch, 32075th Step, learning rate = 0.006725962349292154 - Loss: 0.24881160259246826, aux loss1: 0.8479165434837341, 
		 aux loss2: 0.39210450649261475, total loss: 0.6600283980369568
40th Epoch, 32080th Step, learning rate = 0.0067254398204404245 - Loss: 0.23254534602165222, aux loss1: 0.6652382612228394, 
		 aux loss2: 0.329959511756897, total loss: 0.5641006231307983
40th Epoch, 32085th Step, learning rate = 0.006724917287077817 - Loss: 0.26178503036499023, aux loss1: 0.7503306269645691, 
		 aux loss2: 0.3860865831375122, total loss: 0.6413188576698303
40th Epoch, 32090th Step, learning rate = 0.006724394749203902 - Loss: 0.30442702770233154, aux loss1: 0.7729096412658691, 
		 aux loss2: 0.4532438814640045, total loss: 0.717597484588623
40th Epoch, 32095th Step, learning rate = 0.006723872206818252 - Loss: 0.3574765622615814, aux loss1: 0.8227210640907288, 
		 aux loss2: 0.5327684879302979, total loss: 0.8174002766609192
40th Epoch, 32100th Step, learning rate = 0.0067233496599204395 - Loss: 0.33954691886901855, aux loss1: 0.8939783573150635, 
		 aux loss2: 0.47598955035209656, total loss: 0.7981362342834473
<32100th step>
*************************** Test ***************************
time:3m 17s, 32100th Step, Loss: 0.6382982134819031, Mean IoU = 43.491%
************************************************************
40th Epoch, 32105th Step, learning rate = 0.006722827108510033 - Loss: 0.2887992858886719, aux loss1: 0.7284290790557861, 
		 aux loss2: 0.39725229144096375, total loss: 0.6662289500236511
40th Epoch, 32110th Step, learning rate = 0.006722304552586608 - Loss: 0.2666958272457123, aux loss1: 0.7688225507736206, 
		 aux loss2: 0.4176357388496399, total loss: 0.6643968820571899
40th Epoch, 32115th Step, learning rate = 0.00672178199214973 - Loss: 0.23846270143985748, aux loss1: 0.6315637826919556, 
		 aux loss2: 0.3418341875076294, total loss: 0.5646655559539795
40th Epoch, 32120th Step, learning rate = 0.006721259427198976 - Loss: 0.3191525936126709, aux loss1: 0.851432740688324, 
		 aux loss2: 0.48202651739120483, total loss: 0.7673930525779724
40th Epoch, 32125th Step, learning rate = 0.006720736857733913 - Loss: 0.3788900673389435, aux loss1: 0.9731632471084595, 
		 aux loss2: 0.5374137759208679, total loss: 0.8858045935630798
40th Epoch, 32130th Step, learning rate = 0.006720214283754114 - Loss: 0.3541480004787445, aux loss1: 0.9822799563407898, 
		 aux loss2: 0.5632613897323608, total loss: 0.8741365075111389
40th Epoch, 32135th Step, learning rate = 0.006719691705259151 - Loss: 0.3226027488708496, aux loss1: 0.8534972071647644, 
		 aux loss2: 0.48740723729133606, total loss: 0.7736148238182068
40th Epoch, 32140th Step, learning rate = 0.006719169122248592 - Loss: 0.2720876932144165, aux loss1: 0.8202345967292786, 
		 aux loss2: 0.44664067029953003, total loss: 0.6968143582344055
40th Epoch, 32145th Step, learning rate = 0.006718646534722008 - Loss: 0.3819599151611328, aux loss1: 1.1567692756652832, 
		 aux loss2: 0.6493937969207764, total loss: 0.9887481927871704
40th Epoch, 32150th Step, learning rate = 0.006718123942678972 - Loss: 0.19884568452835083, aux loss1: 0.6119655966758728, 
		 aux loss2: 0.3016669750213623, total loss: 0.50310218334198
40th Epoch, 32155th Step, learning rate = 0.006717601346119054 - Loss: 0.3206159472465515, aux loss1: 0.8524090051651001, 
		 aux loss2: 0.46510738134384155, total loss: 0.7623816132545471
40th Epoch, 32160th Step, learning rate = 0.006717078745041821 - Loss: 0.24887706339359283, aux loss1: 0.8758031725883484, 
		 aux loss2: 0.42030611634254456, total loss: 0.6797404885292053
40th Epoch, 32165th Step, learning rate = 0.006716556139446848 - Loss: 0.2741234600543976, aux loss1: 0.797731339931488, 
		 aux loss2: 0.4134901762008667, total loss: 0.6788389682769775
40th Epoch, 32170th Step, learning rate = 0.0067160335293337025 - Loss: 0.3049432039260864, aux loss1: 0.9344768524169922, 
		 aux loss2: 0.45029670000076294, total loss: 0.7654049396514893
40th Epoch, 32175th Step, learning rate = 0.006715510914701957 - Loss: 0.24749962985515594, aux loss1: 0.7171638607978821, 
		 aux loss2: 0.36477044224739075, total loss: 0.6085569858551025
40th Epoch, 32180th Step, learning rate = 0.006714988295551181 - Loss: 0.23503616452217102, aux loss1: 0.6840652227401733, 
		 aux loss2: 0.33512845635414124, total loss: 0.5743071436882019
40th Epoch, 32185th Step, learning rate = 0.006714465671880942 - Loss: 0.2637487053871155, aux loss1: 0.7581389546394348, 
		 aux loss2: 0.3839702308177948, total loss: 0.6447784900665283
40th Epoch, 32190th Step, learning rate = 0.006713943043690815 - Loss: 0.29230034351348877, aux loss1: 1.0378848314285278, 
		 aux loss2: 0.4906386435031891, total loss: 0.7999212741851807
40th Epoch, 32195th Step, learning rate = 0.006713420410980365 - Loss: 0.3273014724254608, aux loss1: 0.9840616583824158, 
		 aux loss2: 0.5338754057884216, total loss: 0.8360701203346252
40th Epoch, 32200th Step, learning rate = 0.0067128977737491635 - Loss: 0.35645896196365356, aux loss1: 0.9118502140045166, 
		 aux loss2: 0.531894862651825, total loss: 0.8427720069885254
<32200th step>
*************************** Test ***************************
time:3m 19s, 32200th Step, Loss: 0.5843245983123779, Mean IoU = 44.624%
************************************************************
40th Epoch, 32205th Step, learning rate = 0.006712375131996783 - Loss: 0.2654753625392914, aux loss1: 0.7181518077850342, 
		 aux loss2: 0.38614970445632935, total loss: 0.6353808045387268
40th Epoch, 32210th Step, learning rate = 0.00671185248572279 - Loss: 0.2897771894931793, aux loss1: 0.8120298385620117, 
		 aux loss2: 0.44447392225265503, total loss: 0.7111757397651672
40th Epoch, 32215th Step, learning rate = 0.006711329834926756 - Loss: 0.2657557725906372, aux loss1: 0.8155248761177063, 
		 aux loss2: 0.4296337962150574, total loss: 0.6822667717933655
40th Epoch, 32220th Step, learning rate = 0.00671080717960825 - Loss: 0.24664247035980225, aux loss1: 0.8453454971313477, 
		 aux loss2: 0.3930748701095581, total loss: 0.6574761271476746
40th Epoch, 32225th Step, learning rate = 0.00671028451976684 - Loss: 0.22409233450889587, aux loss1: 0.7607629299163818, 
		 aux loss2: 0.3868037760257721, total loss: 0.6070427298545837
40th Epoch, 32230th Step, learning rate = 0.006709761855402098 - Loss: 0.31061023473739624, aux loss1: 0.8516135215759277, 
		 aux loss2: 0.4931078255176544, total loss: 0.7633374333381653
40th Epoch, 32235th Step, learning rate = 0.006709239186513592 - Loss: 0.3398474454879761, aux loss1: 0.9262591004371643, 
		 aux loss2: 0.5438518524169922, total loss: 0.8352659344673157
40th Epoch, 32240th Step, learning rate = 0.00670871651310089 - Loss: 0.2918960452079773, aux loss1: 0.9733923077583313, 
		 aux loss2: 0.5106861591339111, total loss: 0.7881882190704346
40th Epoch, 32245th Step, learning rate = 0.006708193835163565 - Loss: 0.30777624249458313, aux loss1: 0.8410065770149231, 
		 aux loss2: 0.4726657271385193, total loss: 0.7491445541381836
40th Epoch, 32250th Step, learning rate = 0.0067076711527011825 - Loss: 0.2828105092048645, aux loss1: 0.8198614120483398, 
		 aux loss2: 0.42283087968826294, total loss: 0.6979013085365295
40th Epoch, 32255th Step, learning rate = 0.006707148465713312 - Loss: 0.2287963628768921, aux loss1: 0.7044433951377869, 
		 aux loss2: 0.337006151676178, total loss: 0.5749318599700928
40th Epoch, 32260th Step, learning rate = 0.006706625774199525 - Loss: 0.3912491500377655, aux loss1: 0.9681656360626221, 
		 aux loss2: 0.5873277187347412, total loss: 0.9166299700737
40th Epoch, 32265th Step, learning rate = 0.0067061030781593875 - Loss: 0.28344884514808655, aux loss1: 0.8970197439193726, 
		 aux loss2: 0.48197489976882935, total loss: 0.7453447580337524
40th Epoch, 32270th Step, learning rate = 0.0067055803775924695 - Loss: 0.2985757291316986, aux loss1: 0.7266998887062073, 
		 aux loss2: 0.4175782799720764, total loss: 0.6836169958114624
40th Epoch, 32275th Step, learning rate = 0.00670505767249834 - Loss: 0.30739837884902954, aux loss1: 0.8669756054878235, 
		 aux loss2: 0.4665907621383667, total loss: 0.7541273832321167
40th Epoch, 32280th Step, learning rate = 0.0067045349628765665 - Loss: 0.37018856406211853, aux loss1: 1.015468955039978, 
		 aux loss2: 0.5965878963470459, total loss: 0.9134644269943237
40th Epoch, 32285th Step, learning rate = 0.0067040122487267186 - Loss: 0.3437623381614685, aux loss1: 0.8390280604362488, 
		 aux loss2: 0.5175287127494812, total loss: 0.8024822473526001
40th Epoch, 32290th Step, learning rate = 0.006703489530048365 - Loss: 0.2482791244983673, aux loss1: 0.6693922877311707, 
		 aux loss2: 0.35410797595977783, total loss: 0.5907399654388428
40th Epoch, 32295th Step, learning rate = 0.006702966806841072 - Loss: 0.3625962436199188, aux loss1: 0.9382470846176147, 
		 aux loss2: 0.5426307916641235, total loss: 0.861122727394104
40th Epoch, 32300th Step, learning rate = 0.0067024440791044115 - Loss: 0.2411319464445114, aux loss1: 0.6624100804328918, 
		 aux loss2: 0.34931060671806335, total loss: 0.57957923412323
<32300th step>
*************************** Test ***************************
time:3m 17s, 32300th Step, Loss: 0.5533258318901062, Mean IoU = 45.767%
************************************************************
40th Epoch, 32305th Step, learning rate = 0.006701921346837948 - Loss: 0.3032692074775696, aux loss1: 0.8073262572288513, 
		 aux loss2: 0.45618388056755066, total loss: 0.7279406189918518
40th Epoch, 32310th Step, learning rate = 0.006701398610041253 - Loss: 0.2902238070964813, aux loss1: 0.9616729021072388, 
		 aux loss2: 0.4942295551300049, total loss: 0.7764174938201904
40th Epoch, 32315th Step, learning rate = 0.006700875868713893 - Loss: 0.2953020930290222, aux loss1: 0.852275013923645, 
		 aux loss2: 0.4656302034854889, total loss: 0.737236738204956
40th Epoch, 32320th Step, learning rate = 0.006700353122855435 - Loss: 0.2896299958229065, aux loss1: 0.8199732899665833, 
		 aux loss2: 0.45721670985221863, total loss: 0.7185087203979492
40th Epoch, 32325th Step, learning rate = 0.006699830372465449 - Loss: 0.3675078749656677, aux loss1: 0.8540580868721008, 
		 aux loss2: 0.5449608564376831, total loss: 0.8417096138000488
40th Epoch, 32330th Step, learning rate = 0.0066993076175435005 - Loss: 0.2897629737854004, aux loss1: 0.7109795808792114, 
		 aux loss2: 0.3921975791454315, total loss: 0.6599359512329102
40th Epoch, 32335th Step, learning rate = 0.00669878485808916 - Loss: 0.28320494294166565, aux loss1: 0.7516016960144043, 
		 aux loss2: 0.3896850645542145, total loss: 0.6645594835281372
40th Epoch, 32340th Step, learning rate = 0.006698262094101993 - Loss: 0.31345584988594055, aux loss1: 0.9007463455200195, 
		 aux loss2: 0.48079806566238403, total loss: 0.7759990096092224
41th Epoch, 32345th Step, learning rate = 0.006697739325581569 - Loss: 0.24815116822719574, aux loss1: 0.7493966817855835, 
		 aux loss2: 0.3991904854774475, total loss: 0.632646381855011
41th Epoch, 32350th Step, learning rate = 0.006697216552527453 - Loss: 0.2769727110862732, aux loss1: 0.7571244239807129, 
		 aux loss2: 0.39721381664276123, total loss: 0.6629955768585205
41th Epoch, 32355th Step, learning rate = 0.0066966937749392145 - Loss: 0.25101497769355774, aux loss1: 0.818413496017456, 
		 aux loss2: 0.4103262722492218, total loss: 0.6606695652008057
41th Epoch, 32360th Step, learning rate = 0.006696170992816421 - Loss: 0.27097415924072266, aux loss1: 0.9394547939300537, 
		 aux loss2: 0.46843844652175903, total loss: 0.7401859760284424
41th Epoch, 32365th Step, learning rate = 0.006695648206158636 - Loss: 0.23323337733745575, aux loss1: 0.7169938087463379, 
		 aux loss2: 0.37584373354911804, total loss: 0.5986690521240234
41th Epoch, 32370th Step, learning rate = 0.006695125414965434 - Loss: 0.3341979682445526, aux loss1: 1.0710307359695435, 
		 aux loss2: 0.6047354340553284, total loss: 0.8974013924598694
41th Epoch, 32375th Step, learning rate = 0.006694602619236377 - Loss: 0.47645795345306396, aux loss1: 1.1897132396697998, 
		 aux loss2: 0.7196996212005615, total loss: 1.1212518215179443
41th Epoch, 32380th Step, learning rate = 0.00669407981897103 - Loss: 0.30465346574783325, aux loss1: 0.9402990341186523, 
		 aux loss2: 0.5098316669464111, total loss: 0.7906758785247803
41th Epoch, 32385th Step, learning rate = 0.006693557014168967 - Loss: 0.2063376009464264, aux loss1: 0.6579338312149048, 
		 aux loss2: 0.2973327338695526, total loss: 0.5226508378982544
41th Epoch, 32390th Step, learning rate = 0.006693034204829749 - Loss: 0.4795324504375458, aux loss1: 1.1067639589309692, 
		 aux loss2: 0.743135929107666, total loss: 1.1088160276412964
41th Epoch, 32395th Step, learning rate = 0.0066925113909529444 - Loss: 0.38415583968162537, aux loss1: 0.9735567569732666, 
		 aux loss2: 0.6109954118728638, total loss: 0.9206210970878601
41th Epoch, 32400th Step, learning rate = 0.006691988572538122 - Loss: 0.23492567241191864, aux loss1: 0.7058172821998596, 
		 aux loss2: 0.37072837352752686, total loss: 0.5949622392654419
<32400th step>
*************************** Test ***************************
time:3m 20s, 32400th Step, Loss: 0.5594152808189392, Mean IoU = 46.228%
************************************************************
41th Epoch, 32405th Step, learning rate = 0.006691465749584845 - Loss: 0.27368393540382385, aux loss1: 0.7405807375907898, 
		 aux loss2: 0.4279301166534424, total loss: 0.6670302152633667
41th Epoch, 32410th Step, learning rate = 0.0066909429220926835 - Loss: 0.2919727861881256, aux loss1: 0.839778482913971, 
		 aux loss2: 0.44698184728622437, total loss: 0.7226990461349487
41th Epoch, 32415th Step, learning rate = 0.006690420090061202 - Loss: 0.28089195489883423, aux loss1: 0.6953210830688477, 
		 aux loss2: 0.38162916898727417, total loss: 0.6421399712562561
41th Epoch, 32420th Step, learning rate = 0.006689897253489965 - Loss: 0.2339443415403366, aux loss1: 0.6840901970863342, 
		 aux loss2: 0.34417369961738586, total loss: 0.576840877532959
41th Epoch, 32425th Step, learning rate = 0.006689374412378544 - Loss: 0.22250333428382874, aux loss1: 0.7088315486907959, 
		 aux loss2: 0.33851611614227295, total loss: 0.5705592632293701
41th Epoch, 32430th Step, learning rate = 0.006688851566726501 - Loss: 0.34814172983169556, aux loss1: 1.0523879528045654, 
		 aux loss2: 0.5204933881759644, total loss: 0.8720554709434509
41th Epoch, 32435th Step, learning rate = 0.006688328716533402 - Loss: 0.3449985682964325, aux loss1: 1.0215880870819092, 
		 aux loss2: 0.5504580736160278, total loss: 0.8716582655906677
41th Epoch, 32440th Step, learning rate = 0.006687805861798818 - Loss: 0.297982394695282, aux loss1: 0.762785792350769, 
		 aux loss2: 0.4152032732963562, total loss: 0.6928994655609131
41th Epoch, 32445th Step, learning rate = 0.006687283002522311 - Loss: 0.24654901027679443, aux loss1: 0.7232627868652344, 
		 aux loss2: 0.3718199133872986, total loss: 0.6122558116912842
41th Epoch, 32450th Step, learning rate = 0.006686760138703446 - Loss: 0.3158673644065857, aux loss1: 0.8351213335990906, 
		 aux loss2: 0.4894849359989166, total loss: 0.762197732925415
41th Epoch, 32455th Step, learning rate = 0.006686237270341793 - Loss: 0.304619699716568, aux loss1: 0.7721449732780457, 
		 aux loss2: 0.4496443271636963, total loss: 0.7161209583282471
41th Epoch, 32460th Step, learning rate = 0.006685714397436913 - Loss: 0.30803176760673523, aux loss1: 1.0172957181930542, 
		 aux loss2: 0.4678837060928345, total loss: 0.800373911857605
41th Epoch, 32465th Step, learning rate = 0.006685191519988375 - Loss: 0.34791100025177, aux loss1: 0.9955654740333557, 
		 aux loss2: 0.579032301902771, total loss: 0.8781936168670654
41th Epoch, 32470th Step, learning rate = 0.006684668637995744 - Loss: 0.2595633566379547, aux loss1: 0.7917174696922302, 
		 aux loss2: 0.4044475853443146, total loss: 0.6588576436042786
41th Epoch, 32475th Step, learning rate = 0.0066841457514585844 - Loss: 0.24026256799697876, aux loss1: 0.7492961287498474, 
		 aux loss2: 0.38132810592651367, total loss: 0.6175826787948608
41th Epoch, 32480th Step, learning rate = 0.006683622860376464 - Loss: 0.395142138004303, aux loss1: 0.9965857267379761, 
		 aux loss2: 0.5981166958808899, total loss: 0.9333645701408386
41th Epoch, 32485th Step, learning rate = 0.006683099964748946 - Loss: 0.2407502830028534, aux loss1: 0.8807699680328369, 
		 aux loss2: 0.4092499017715454, total loss: 0.668681263923645
41th Epoch, 32490th Step, learning rate = 0.006682577064575596 - Loss: 0.3014103174209595, aux loss1: 0.8121194839477539, 
		 aux loss2: 0.4632489085197449, total loss: 0.7303457260131836
41th Epoch, 32495th Step, learning rate = 0.0066820541598559815 - Loss: 0.3376900851726532, aux loss1: 0.9339346885681152, 
		 aux loss2: 0.5162392258644104, total loss: 0.8243662118911743
41th Epoch, 32500th Step, learning rate = 0.006681531250589665 - Loss: 0.2648153007030487, aux loss1: 0.7699452042579651, 
		 aux loss2: 0.40096133947372437, total loss: 0.6561834216117859
<32500th step>
*************************** Test ***************************
time:3m 18s, 32500th Step, Loss: 0.5424949526786804, Mean IoU = 45.123%
************************************************************
41th Epoch, 32505th Step, learning rate = 0.006681008336776212 - Loss: 0.22904722392559052, aux loss1: 0.712840735912323, 
		 aux loss2: 0.3603465259075165, total loss: 0.5870380997657776
41th Epoch, 32510th Step, learning rate = 0.006680485418415189 - Loss: 0.2864590287208557, aux loss1: 0.8166974782943726, 
		 aux loss2: 0.41592130064964294, total loss: 0.6978368163108826
41th Epoch, 32515th Step, learning rate = 0.006679962495506159 - Loss: 0.24348944425582886, aux loss1: 0.6679560542106628, 
		 aux loss2: 0.32487794756889343, total loss: 0.5738274455070496
41th Epoch, 32520th Step, learning rate = 0.0066794395680486885 - Loss: 0.25725817680358887, aux loss1: 0.7143805027008057, 
		 aux loss2: 0.3777252435684204, total loss: 0.6226624250411987
41th Epoch, 32525th Step, learning rate = 0.006678916636042341 - Loss: 0.3011775016784668, aux loss1: 0.8024162650108337, 
		 aux loss2: 0.43600279092788696, total loss: 0.7163035273551941
41th Epoch, 32530th Step, learning rate = 0.006678393699486683 - Loss: 0.2430003434419632, aux loss1: 0.6770161986351013, 
		 aux loss2: 0.35486844182014465, total loss: 0.5880525708198547
41th Epoch, 32535th Step, learning rate = 0.006677870758381277 - Loss: 0.334612101316452, aux loss1: 0.8893893957138062, 
		 aux loss2: 0.5108612179756165, total loss: 0.8057734370231628
41th Epoch, 32540th Step, learning rate = 0.006677347812725689 - Loss: 0.31939613819122314, aux loss1: 0.9359172582626343, 
		 aux loss2: 0.5005820393562317, total loss: 0.8004041314125061
41th Epoch, 32545th Step, learning rate = 0.006676824862519482 - Loss: 0.31103646755218506, aux loss1: 0.9214370250701904, 
		 aux loss2: 0.4675792455673218, total loss: 0.774499237537384
41th Epoch, 32550th Step, learning rate = 0.006676301907762222 - Loss: 0.2721530795097351, aux loss1: 0.7612252235412598, 
		 aux loss2: 0.39039114117622375, total loss: 0.6566771268844604
41th Epoch, 32555th Step, learning rate = 0.006675778948453471 - Loss: 0.25903433561325073, aux loss1: 0.7916650176048279, 
		 aux loss2: 0.41316208243370056, total loss: 0.6617987155914307
41th Epoch, 32560th Step, learning rate = 0.006675255984592796 - Loss: 0.31294283270835876, aux loss1: 0.9291954040527344, 
		 aux loss2: 0.528213381767273, total loss: 0.8029868602752686
41th Epoch, 32565th Step, learning rate = 0.006674733016179761 - Loss: 0.3606480658054352, aux loss1: 0.8847949504852295, 
		 aux loss2: 0.5044702887535095, total loss: 0.8278747200965881
41th Epoch, 32570th Step, learning rate = 0.006674210043213927 - Loss: 0.20573140680789948, aux loss1: 0.6462280750274658, 
		 aux loss2: 0.30653253197669983, total loss: 0.5222128629684448
41th Epoch, 32575th Step, learning rate = 0.006673687065694861 - Loss: 0.3106997311115265, aux loss1: 0.8621634244918823, 
		 aux loss2: 0.4756738245487213, total loss: 0.75961834192276
41th Epoch, 32580th Step, learning rate = 0.006673164083622127 - Loss: 0.2815627455711365, aux loss1: 0.8343544602394104, 
		 aux loss2: 0.44639959931373596, total loss: 0.7104288935661316
41th Epoch, 32585th Step, learning rate = 0.006672641096995287 - Loss: 0.3065505623817444, aux loss1: 0.8258064985275269, 
		 aux loss2: 0.44755232334136963, total loss: 0.7333134412765503
41th Epoch, 32590th Step, learning rate = 0.006672118105813904 - Loss: 0.25492990016937256, aux loss1: 0.8149577379226685, 
		 aux loss2: 0.41123345494270325, total loss: 0.6639106273651123
41th Epoch, 32595th Step, learning rate = 0.006671595110077544 - Loss: 0.24605537950992584, aux loss1: 0.855467677116394, 
		 aux loss2: 0.39262956380844116, total loss: 0.6597474813461304
41th Epoch, 32600th Step, learning rate = 0.006671072109785768 - Loss: 0.2321997582912445, aux loss1: 0.7701156139373779, 
		 aux loss2: 0.38767072558403015, total loss: 0.6183027625083923
<32600th step>
*************************** Test ***************************
time:3m 17s, 32600th Step, Loss: 0.5527611970901489, Mean IoU = 46.656%
************************************************************
41th Epoch, 32605th Step, learning rate = 0.006670549104938144 - Loss: 0.2766142189502716, aux loss1: 0.8373271226882935, 
		 aux loss2: 0.44449105858802795, total loss: 0.7056087851524353
41th Epoch, 32610th Step, learning rate = 0.006670026095534231 - Loss: 0.2771230936050415, aux loss1: 0.7386646270751953, 
		 aux loss2: 0.4344351291656494, total loss: 0.6724965572357178
41th Epoch, 32615th Step, learning rate = 0.006669503081573593 - Loss: 0.2263907492160797, aux loss1: 0.6501131653785706, 
		 aux loss2: 0.3280280828475952, total loss: 0.552635908126831
41th Epoch, 32620th Step, learning rate = 0.006668980063055796 - Loss: 0.28812775015830994, aux loss1: 0.8290029168128967, 
		 aux loss2: 0.4217120409011841, total loss: 0.7055134773254395
41th Epoch, 32625th Step, learning rate = 0.0066684570399804 - Loss: 0.22876131534576416, aux loss1: 0.769935131072998, 
		 aux loss2: 0.3605842888355255, total loss: 0.6039755940437317
41th Epoch, 32630th Step, learning rate = 0.006667934012346969 - Loss: 0.3003474175930023, aux loss1: 0.815338671207428, 
		 aux loss2: 0.44205012917518616, total loss: 0.7217690944671631
41th Epoch, 32635th Step, learning rate = 0.006667410980155068 - Loss: 0.27411916851997375, aux loss1: 0.7848542332649231, 
		 aux loss2: 0.4017813205718994, total loss: 0.6702879667282104
41th Epoch, 32640th Step, learning rate = 0.006666887943404257 - Loss: 0.2869755029678345, aux loss1: 0.7644336819648743, 
		 aux loss2: 0.42981454730033875, total loss: 0.6882314682006836
41th Epoch, 32645th Step, learning rate = 0.006666364902094101 - Loss: 0.3262045979499817, aux loss1: 0.9805619120597839, 
		 aux loss2: 0.5520389080047607, total loss: 0.8411887884140015
41th Epoch, 32650th Step, learning rate = 0.0066658418562241615 - Loss: 0.2391914576292038, aux loss1: 0.7374776601791382, 
		 aux loss2: 0.3706359565258026, total loss: 0.6086891293525696
41th Epoch, 32655th Step, learning rate = 0.006665318805794001 - Loss: 0.27307581901550293, aux loss1: 0.6726592779159546, 
		 aux loss2: 0.37705549597740173, total loss: 0.6256958246231079
41th Epoch, 32660th Step, learning rate = 0.006664795750803185 - Loss: 0.28277766704559326, aux loss1: 1.0098036527633667, 
		 aux loss2: 0.48691824078559875, total loss: 0.7804860472679138
41th Epoch, 32665th Step, learning rate = 0.006664272691251273 - Loss: 0.3732770085334778, aux loss1: 1.0536932945251465, 
		 aux loss2: 0.5887447595596313, total loss: 0.9248828887939453
41th Epoch, 32670th Step, learning rate = 0.006663749627137826 - Loss: 0.28742605447769165, aux loss1: 0.8251791000366211, 
		 aux loss2: 0.4287547767162323, total loss: 0.7064817547798157
41th Epoch, 32675th Step, learning rate = 0.00666322655846241 - Loss: 0.283695250749588, aux loss1: 0.8185961842536926, 
		 aux loss2: 0.46342188119888306, total loss: 0.7146428823471069
41th Epoch, 32680th Step, learning rate = 0.006662703485224587 - Loss: 0.33342504501342773, aux loss1: 0.9656785726547241, 
		 aux loss2: 0.548177182674408, total loss: 0.842399537563324
41th Epoch, 32685th Step, learning rate = 0.006662180407423918 - Loss: 0.25201216340065, aux loss1: 0.7699577212333679, 
		 aux loss2: 0.3943064212799072, total loss: 0.6407220959663391
41th Epoch, 32690th Step, learning rate = 0.006661657325059966 - Loss: 0.25496989488601685, aux loss1: 0.8524263501167297, 
		 aux loss2: 0.4168587327003479, total loss: 0.6774413585662842
41th Epoch, 32695th Step, learning rate = 0.006661134238132291 - Loss: 0.3452860116958618, aux loss1: 0.9196327924728394, 
		 aux loss2: 0.5128652453422546, total loss: 0.8263219594955444
41th Epoch, 32700th Step, learning rate = 0.006660611146640455 - Loss: 0.331405907869339, aux loss1: 0.8173431754112244, 
		 aux loss2: 0.4434422254562378, total loss: 0.7539857625961304
<32700th step>
*************************** Test ***************************
time:3m 19s, 32700th Step, Loss: 0.5349757671356201, Mean IoU = 44.323%
************************************************************
41th Epoch, 32705th Step, learning rate = 0.006660088050584024 - Loss: 0.37080004811286926, aux loss1: 0.9738407135009766, 
		 aux loss2: 0.5234981179237366, total loss: 0.8723515272140503
41th Epoch, 32710th Step, learning rate = 0.006659564949962555 - Loss: 0.37238195538520813, aux loss1: 1.0236821174621582, 
		 aux loss2: 0.5735208988189697, total loss: 0.9088950157165527
42th Epoch, 32715th Step, learning rate = 0.006659041844775613 - Loss: 0.28524380922317505, aux loss1: 0.769014298915863, 
		 aux loss2: 0.4215531647205353, total loss: 0.6845693588256836
42th Epoch, 32720th Step, learning rate = 0.006658518735022758 - Loss: 0.2545910179615021, aux loss1: 0.7003176212310791, 
		 aux loss2: 0.3638876676559448, total loss: 0.6102414131164551
42th Epoch, 32725th Step, learning rate = 0.006657995620703551 - Loss: 0.35623401403427124, aux loss1: 0.7785739898681641, 
		 aux loss2: 0.4576151669025421, total loss: 0.7728523015975952
42th Epoch, 32730th Step, learning rate = 0.0066574725018175565 - Loss: 0.258881151676178, aux loss1: 0.8147874474525452, 
		 aux loss2: 0.4118380546569824, total loss: 0.6680526733398438
42th Epoch, 32735th Step, learning rate = 0.0066569493783643335 - Loss: 0.236805722117424, aux loss1: 0.6742231249809265, 
		 aux loss2: 0.34919294714927673, total loss: 0.5787498354911804
42th Epoch, 32740th Step, learning rate = 0.006656426250343442 - Loss: 0.3041577637195587, aux loss1: 0.8212222456932068, 
		 aux loss2: 0.4159747362136841, total loss: 0.7169143557548523
42th Epoch, 32745th Step, learning rate = 0.006655903117754447 - Loss: 0.24609039723873138, aux loss1: 0.7355313301086426, 
		 aux loss2: 0.3745601177215576, total loss: 0.6165738105773926
42th Epoch, 32750th Step, learning rate = 0.006655379980596906 - Loss: 0.23623952269554138, aux loss1: 0.7085776925086975, 
		 aux loss2: 0.36511218547821045, total loss: 0.5948576927185059
42th Epoch, 32755th Step, learning rate = 0.0066548568388703835 - Loss: 0.36500638723373413, aux loss1: 1.0531424283981323, 
		 aux loss2: 0.5879200100898743, total loss: 0.9161170721054077
42th Epoch, 32760th Step, learning rate = 0.006654333692574438 - Loss: 0.32271814346313477, aux loss1: 0.8652762174606323, 
		 aux loss2: 0.49614906311035156, total loss: 0.780760645866394
42th Epoch, 32765th Step, learning rate = 0.0066538105417086315 - Loss: 0.2775426208972931, aux loss1: 0.7933619618415833, 
		 aux loss2: 0.40716707706451416, total loss: 0.6784180402755737
42th Epoch, 32770th Step, learning rate = 0.0066532873862725226 - Loss: 0.3853329122066498, aux loss1: 0.9135468006134033, 
		 aux loss2: 0.5569712519645691, total loss: 0.8821855187416077
42th Epoch, 32775th Step, learning rate = 0.0066527642262656774 - Loss: 0.2718675136566162, aux loss1: 0.8775239586830139, 
		 aux loss2: 0.4382511377334595, total loss: 0.7104251980781555
42th Epoch, 32780th Step, learning rate = 0.0066522410616876495 - Loss: 0.26515838503837585, aux loss1: 0.7453800439834595, 
		 aux loss2: 0.3978482484817505, total loss: 0.6479116678237915
42th Epoch, 32785th Step, learning rate = 0.006651717892538006 - Loss: 0.3615341782569885, aux loss1: 1.0142868757247925, 
		 aux loss2: 0.610334575176239, total loss: 0.9099540710449219
42th Epoch, 32790th Step, learning rate = 0.006651194718816303 - Loss: 0.2638462483882904, aux loss1: 0.8100059628486633, 
		 aux loss2: 0.4442916810512543, total loss: 0.6845647096633911
42th Epoch, 32795th Step, learning rate = 0.006650671540522104 - Loss: 0.3089276850223541, aux loss1: 0.9280378818511963, 
		 aux loss2: 0.5123776197433472, total loss: 0.7922900915145874
42th Epoch, 32800th Step, learning rate = 0.006650148357654968 - Loss: 0.3492065966129303, aux loss1: 1.02901029586792, 
		 aux loss2: 0.5507838726043701, total loss: 0.8782232403755188
<32800th step>
*************************** Test ***************************
time:3m 17s, 32800th Step, Loss: 0.5247641801834106, Mean IoU = 45.862%
************************************************************
42th Epoch, 32805th Step, learning rate = 0.006649625170214454 - Loss: 0.2800506055355072, aux loss1: 0.9875524044036865, 
		 aux loss2: 0.46699443459510803, total loss: 0.7631141543388367
42th Epoch, 32810th Step, learning rate = 0.0066491019782001235 - Loss: 0.22045999765396118, aux loss1: 0.7234836220741272, 
		 aux loss2: 0.33518972992897034, total loss: 0.5715810060501099
42th Epoch, 32815th Step, learning rate = 0.006648578781611538 - Loss: 0.2764858603477478, aux loss1: 0.788682222366333, 
		 aux loss2: 0.43065598607063293, total loss: 0.6853529214859009
42th Epoch, 32820th Step, learning rate = 0.0066480555804482545 - Loss: 0.2580670714378357, aux loss1: 0.7649958729743958, 
		 aux loss2: 0.40801411867141724, total loss: 0.6507714986801147
42th Epoch, 32825th Step, learning rate = 0.006647532374709836 - Loss: 0.25655868649482727, aux loss1: 0.7357289791107178, 
		 aux loss2: 0.39237990975379944, total loss: 0.6342293620109558
42th Epoch, 32830th Step, learning rate = 0.00664700916439584 - Loss: 0.2565965950489044, aux loss1: 0.7870919108390808, 
		 aux loss2: 0.4023824632167816, total loss: 0.6536771655082703
42th Epoch, 32835th Step, learning rate = 0.006646485949505827 - Loss: 0.2561418116092682, aux loss1: 0.6659145355224609, 
		 aux loss2: 0.3768555819988251, total loss: 0.606658399105072
42th Epoch, 32840th Step, learning rate = 0.006645962730039358 - Loss: 0.26953431963920593, aux loss1: 0.7723172307014465, 
		 aux loss2: 0.41959524154663086, total loss: 0.6690676212310791
42th Epoch, 32845th Step, learning rate = 0.006645439505995991 - Loss: 0.3355015516281128, aux loss1: 0.8871762752532959, 
		 aux loss2: 0.506458044052124, total loss: 0.8042376041412354
42th Epoch, 32850th Step, learning rate = 0.006644916277375286 - Loss: 0.31621918082237244, aux loss1: 0.9017517566680908, 
		 aux loss2: 0.5054478645324707, total loss: 0.7889238595962524
42th Epoch, 32855th Step, learning rate = 0.006644393044176803 - Loss: 0.24167154729366302, aux loss1: 0.6683703064918518, 
		 aux loss2: 0.33480730652809143, total loss: 0.5761055946350098
42th Epoch, 32860th Step, learning rate = 0.006643869806400101 - Loss: 0.30077308416366577, aux loss1: 0.7864983081817627, 
		 aux loss2: 0.43518924713134766, total loss: 0.7107983231544495
42th Epoch, 32865th Step, learning rate = 0.0066433465640447385 - Loss: 0.24797175824642181, aux loss1: 0.740595817565918, 
		 aux loss2: 0.3696604073047638, total loss: 0.6180146932601929
42th Epoch, 32870th Step, learning rate = 0.006642823317110277 - Loss: 0.3412802815437317, aux loss1: 0.7384546995162964, 
		 aux loss2: 0.44986578822135925, total loss: 0.7427629828453064
42th Epoch, 32875th Step, learning rate = 0.006642300065596274 - Loss: 0.2250860333442688, aux loss1: 0.7100972533226013, 
		 aux loss2: 0.35244596004486084, total loss: 0.5790936350822449
42th Epoch, 32880th Step, learning rate = 0.0066417768095022875 - Loss: 0.30673572421073914, aux loss1: 0.988402247428894, 
		 aux loss2: 0.5170150399208069, total loss: 0.8100624084472656
42th Epoch, 32885th Step, learning rate = 0.0066412535488278805 - Loss: 0.31209129095077515, aux loss1: 0.7697494029998779, 
		 aux loss2: 0.4500337243080139, total loss: 0.723029613494873
42th Epoch, 32890th Step, learning rate = 0.006640730283572607 - Loss: 0.2974768280982971, aux loss1: 0.8894658088684082, 
		 aux loss2: 0.4616042971611023, total loss: 0.7489582896232605
42th Epoch, 32895th Step, learning rate = 0.0066402070137360275 - Loss: 0.22547347843647003, aux loss1: 0.6254072189331055, 
		 aux loss2: 0.32313644886016846, total loss: 0.5423502326011658
42th Epoch, 32900th Step, learning rate = 0.006639683739317704 - Loss: 0.2965177297592163, aux loss1: 0.8434808254241943, 
		 aux loss2: 0.47762811183929443, total loss: 0.7406132221221924
<32900th step>
*************************** Test ***************************
time:3m 20s, 32900th Step, Loss: 0.5366464853286743, Mean IoU = 45.504%
************************************************************
42th Epoch, 32905th Step, learning rate = 0.006639160460317189 - Loss: 0.4539554715156555, aux loss1: 1.151451826095581, 
		 aux loss2: 0.7026511430740356, total loss: 1.080451488494873
42th Epoch, 32910th Step, learning rate = 0.006638637176734047 - Loss: 0.43983227014541626, aux loss1: 1.0084190368652344, 
		 aux loss2: 0.6402365565299988, total loss: 0.9984526038169861
42th Epoch, 32915th Step, learning rate = 0.006638113888567832 - Loss: 0.29149720072746277, aux loss1: 0.8554957509040833, 
		 aux loss2: 0.44350993633270264, total loss: 0.7255499362945557
42th Epoch, 32920th Step, learning rate = 0.006637590595818106 - Loss: 0.26033326983451843, aux loss1: 0.7779261469841003, 
		 aux loss2: 0.41581404209136963, total loss: 0.6600367426872253
42th Epoch, 32925th Step, learning rate = 0.006637067298484426 - Loss: 0.2539488673210144, aux loss1: 0.7079193592071533, 
		 aux loss2: 0.3487144112586975, total loss: 0.6058104634284973
42th Epoch, 32930th Step, learning rate = 0.00663654399656635 - Loss: 0.3733071982860565, aux loss1: 1.0354454517364502, 
		 aux loss2: 0.5415918231010437, total loss: 0.9005776047706604
42th Epoch, 32935th Step, learning rate = 0.0066360206900634355 - Loss: 0.339454710483551, aux loss1: 0.9419470429420471, 
		 aux loss2: 0.5409725308418274, total loss: 0.8384278416633606
42th Epoch, 32940th Step, learning rate = 0.006635497378975242 - Loss: 0.30701854825019836, aux loss1: 0.8674077391624451, 
		 aux loss2: 0.48677903413772583, total loss: 0.7619525194168091
42th Epoch, 32945th Step, learning rate = 0.006634974063301327 - Loss: 0.24108467996120453, aux loss1: 0.7568158507347107, 
		 aux loss2: 0.3738566040992737, total loss: 0.6176720857620239
42th Epoch, 32950th Step, learning rate = 0.006634450743041247 - Loss: 0.3313154876232147, aux loss1: 0.7631804943084717, 
		 aux loss2: 0.4428713917732239, total loss: 0.7374182343482971
42th Epoch, 32955th Step, learning rate = 0.006633927418194563 - Loss: 0.332658052444458, aux loss1: 1.0613545179367065, 
		 aux loss2: 0.6092262864112854, total loss: 0.8947548866271973
42th Epoch, 32960th Step, learning rate = 0.006633404088760829 - Loss: 0.3002840578556061, aux loss1: 0.9406675100326538, 
		 aux loss2: 0.4574194550514221, total loss: 0.7654521465301514
42th Epoch, 32965th Step, learning rate = 0.006632880754739607 - Loss: 0.29940682649612427, aux loss1: 0.86983722448349, 
		 aux loss2: 0.4893805682659149, total loss: 0.7561103105545044
42th Epoch, 32970th Step, learning rate = 0.0066323574161304515 - Loss: 0.31639793515205383, aux loss1: 0.8209110498428345, 
		 aux loss2: 0.49164819717407227, total loss: 0.7593305110931396
42th Epoch, 32975th Step, learning rate = 0.006631834072932919 - Loss: 0.29369136691093445, aux loss1: 0.7583721876144409, 
		 aux loss2: 0.4172925651073456, total loss: 0.6881200671195984
42th Epoch, 32980th Step, learning rate = 0.00663131072514657 - Loss: 0.3476984202861786, aux loss1: 1.0154601335525513, 
		 aux loss2: 0.5474165678024292, total loss: 0.8713030815124512
42th Epoch, 32985th Step, learning rate = 0.00663078737277096 - Loss: 0.3062624931335449, aux loss1: 0.893683910369873, 
		 aux loss2: 0.5355280637741089, total loss: 0.7885788679122925
42th Epoch, 32990th Step, learning rate = 0.006630264015805646 - Loss: 0.26130300760269165, aux loss1: 0.7500185370445251, 
		 aux loss2: 0.41111820936203003, total loss: 0.6507558822631836
42th Epoch, 32995th Step, learning rate = 0.006629740654250188 - Loss: 0.2633010447025299, aux loss1: 0.7007936835289001, 
		 aux loss2: 0.38867947459220886, total loss: 0.6290109753608704
42th Epoch, 33000th Step, learning rate = 0.00662921728810414 - Loss: 0.3395652770996094, aux loss1: 1.0301822423934937, 
		 aux loss2: 0.5269017219543457, total loss: 0.8593806624412537
<33000th step>
*************************** Test ***************************
time:3m 17s, 33000th Step, Loss: 0.5442837476730347, Mean IoU = 46.924%
************************************************************
42th Epoch, 33005th Step, learning rate = 0.006628693917367061 - Loss: 0.24883976578712463, aux loss1: 0.7750944495201111, 
		 aux loss2: 0.3729451894760132, total loss: 0.6305462121963501
42th Epoch, 33010th Step, learning rate = 0.006628170542038507 - Loss: 0.319670170545578, aux loss1: 0.8186814188957214, 
		 aux loss2: 0.45795655250549316, total loss: 0.7484571933746338
42th Epoch, 33015th Step, learning rate = 0.006627647162118035 - Loss: 0.30176565051078796, aux loss1: 0.9603894352912903, 
		 aux loss2: 0.5099142789840698, total loss: 0.7938482165336609
42th Epoch, 33020th Step, learning rate = 0.006627123777605202 - Loss: 0.24932704865932465, aux loss1: 0.8893657922744751, 
		 aux loss2: 0.3780677318572998, total loss: 0.6673639416694641
42th Epoch, 33025th Step, learning rate = 0.006626600388499564 - Loss: 0.37826651334762573, aux loss1: 1.0374464988708496, 
		 aux loss2: 0.627432107925415, total loss: 0.9404733180999756
42th Epoch, 33030th Step, learning rate = 0.0066260769948006774 - Loss: 0.44813457131385803, aux loss1: 1.1628906726837158, 
		 aux loss2: 0.7077457904815674, total loss: 1.0801000595092773
42th Epoch, 33035th Step, learning rate = 0.006625553596508102 - Loss: 0.32681044936180115, aux loss1: 0.8369868397712708, 
		 aux loss2: 0.4845764636993408, total loss: 0.7717370986938477
42th Epoch, 33040th Step, learning rate = 0.006625030193621389 - Loss: 0.2563127279281616, aux loss1: 0.8289098143577576, 
		 aux loss2: 0.41143569350242615, total loss: 0.6695599555969238
42th Epoch, 33045th Step, learning rate = 0.006624506786140099 - Loss: 0.2833823561668396, aux loss1: 0.7610558867454529, 
		 aux loss2: 0.39797714352607727, total loss: 0.6708899736404419
42th Epoch, 33050th Step, learning rate = 0.006623983374063788 - Loss: 0.2686944007873535, aux loss1: 0.811022937297821, 
		 aux loss2: 0.43550437688827515, total loss: 0.6862030029296875
42th Epoch, 33055th Step, learning rate = 0.0066234599573920085 - Loss: 0.3227168917655945, aux loss1: 0.8454000353813171, 
		 aux loss2: 0.5110469460487366, total loss: 0.7807556986808777
42th Epoch, 33060th Step, learning rate = 0.006622936536124321 - Loss: 0.24828915297985077, aux loss1: 0.7520409226417542, 
		 aux loss2: 0.3515126705169678, total loss: 0.6145065426826477
42th Epoch, 33065th Step, learning rate = 0.006622413110260281 - Loss: 0.2680969834327698, aux loss1: 0.8327934741973877, 
		 aux loss2: 0.4140413999557495, total loss: 0.6835516095161438
42th Epoch, 33070th Step, learning rate = 0.0066218896797994396 - Loss: 0.2802925705909729, aux loss1: 0.8629501461982727, 
		 aux loss2: 0.4591439962387085, total loss: 0.7228352427482605
42th Epoch, 33075th Step, learning rate = 0.006621366244741359 - Loss: 0.32444489002227783, aux loss1: 1.0008941888809204, 
		 aux loss2: 0.550814688205719, total loss: 0.8450390696525574
42th Epoch, 33080th Step, learning rate = 0.006620842805085593 - Loss: 0.28781116008758545, aux loss1: 0.9442575573921204, 
		 aux loss2: 0.4542003273963928, total loss: 0.7527685761451721
43th Epoch, 33085th Step, learning rate = 0.006620319360831694 - Loss: 0.2767438590526581, aux loss1: 0.7639027833938599, 
		 aux loss2: 0.4045153558254242, total loss: 0.6677208542823792
43th Epoch, 33090th Step, learning rate = 0.0066197959119792225 - Loss: 0.2817118167877197, aux loss1: 0.8335451483726501, 
		 aux loss2: 0.4453238546848297, total loss: 0.7099049091339111
43th Epoch, 33095th Step, learning rate = 0.006619272458527731 - Loss: 0.32485583424568176, aux loss1: 0.8278050422668457, 
		 aux loss2: 0.4927172064781189, total loss: 0.7702842354774475
43th Epoch, 33100th Step, learning rate = 0.006618749000476776 - Loss: 0.21550120413303375, aux loss1: 0.6248689293861389, 
		 aux loss2: 0.3016105592250824, total loss: 0.5236061215400696
<33100th step>
*************************** Test ***************************
time:3m 15s, 33100th Step, Loss: 0.6048258543014526, Mean IoU = 46.066%
************************************************************
43th Epoch, 33105th Step, learning rate = 0.006618225537825914 - Loss: 0.3148415982723236, aux loss1: 0.8606213331222534, 
		 aux loss2: 0.5192149877548218, total loss: 0.7807139754295349
43th Epoch, 33110th Step, learning rate = 0.006617702070574697 - Loss: 0.2667236924171448, aux loss1: 0.7657269835472107, 
		 aux loss2: 0.4036664068698883, total loss: 0.6579083204269409
43th Epoch, 33115th Step, learning rate = 0.006617178598722684 - Loss: 0.31420233845710754, aux loss1: 0.8951200842857361, 
		 aux loss2: 0.5057199597358704, total loss: 0.7850263714790344
43th Epoch, 33120th Step, learning rate = 0.006616655122269428 - Loss: 0.24358482658863068, aux loss1: 0.7610295414924622, 
		 aux loss2: 0.40928298234939575, total loss: 0.6356068849563599
43th Epoch, 33125th Step, learning rate = 0.006616131641214486 - Loss: 0.26899027824401855, aux loss1: 0.8562098741531372, 
		 aux loss2: 0.45409828424453735, total loss: 0.7074925899505615
43th Epoch, 33130th Step, learning rate = 0.006615608155557409 - Loss: 0.312395304441452, aux loss1: 0.8600534796714783, 
		 aux loss2: 0.4896545112133026, total loss: 0.7662731409072876
43th Epoch, 33135th Step, learning rate = 0.006615084665297757 - Loss: 0.28979745507240295, aux loss1: 0.8820219039916992, 
		 aux loss2: 0.46494874358177185, total loss: 0.740383505821228
43th Epoch, 33140th Step, learning rate = 0.00661456117043508 - Loss: 0.26903584599494934, aux loss1: 0.7273661494255066, 
		 aux loss2: 0.38792359828948975, total loss: 0.6424151062965393
43th Epoch, 33145th Step, learning rate = 0.006614037670968936 - Loss: 0.26083657145500183, aux loss1: 0.7764268517494202, 
		 aux loss2: 0.38552913069725037, total loss: 0.647976279258728
43th Epoch, 33150th Step, learning rate = 0.006613514166898881 - Loss: 0.23027579486370087, aux loss1: 0.7059676647186279, 
		 aux loss2: 0.3573925495147705, total loss: 0.5850231051445007
43th Epoch, 33155th Step, learning rate = 0.006612990658224464 - Loss: 0.35950836539268494, aux loss1: 1.0011745691299438, 
		 aux loss2: 0.574537992477417, total loss: 0.8896759152412415
43th Epoch, 33160th Step, learning rate = 0.0066124671449452445 - Loss: 0.2631106376647949, aux loss1: 0.7243145108222961, 
		 aux loss2: 0.4055667519569397, total loss: 0.6426317095756531
43th Epoch, 33165th Step, learning rate = 0.006611943627060773 - Loss: 0.33141955733299255, aux loss1: 0.8228036165237427, 
		 aux loss2: 0.48162537813186646, total loss: 0.7709107995033264
43th Epoch, 33170th Step, learning rate = 0.006611420104570609 - Loss: 0.3886660933494568, aux loss1: 0.9737287163734436, 
		 aux loss2: 0.5582290887832642, total loss: 0.904076337814331
43th Epoch, 33175th Step, learning rate = 0.006610896577474303 - Loss: 0.4246595799922943, aux loss1: 1.1195346117019653, 
		 aux loss2: 0.6315096020698547, total loss: 1.013123869895935
43th Epoch, 33180th Step, learning rate = 0.006610373045771409 - Loss: 0.2565988004207611, aux loss1: 0.8042554259300232, 
		 aux loss2: 0.415348619222641, total loss: 0.6640149354934692
43th Epoch, 33185th Step, learning rate = 0.006609849509461483 - Loss: 0.2242359071969986, aux loss1: 0.6625370979309082, 
		 aux loss2: 0.31405845284461975, total loss: 0.5486204624176025
43th Epoch, 33190th Step, learning rate = 0.006609325968544078 - Loss: 0.2720758318901062, aux loss1: 0.6692367196083069, 
		 aux loss2: 0.3844892978668213, total loss: 0.6266425848007202
43th Epoch, 33195th Step, learning rate = 0.006608802423018748 - Loss: 0.3322623670101166, aux loss1: 0.9493287205696106, 
		 aux loss2: 0.5385721921920776, total loss: 0.8324899077415466
43th Epoch, 33200th Step, learning rate = 0.006608278872885048 - Loss: 0.288570374250412, aux loss1: 0.8810058832168579, 
		 aux loss2: 0.5163663625717163, total loss: 0.7594187259674072
<33200th step>
*************************** Test ***************************
time:3m 18s, 33200th Step, Loss: 0.5323843359947205, Mean IoU = 47.370%
************************************************************
43th Epoch, 33205th Step, learning rate = 0.006607755318142529 - Loss: 0.22296006977558136, aux loss1: 0.6524394154548645, 
		 aux loss2: 0.3292907774448395, total loss: 0.5504082441329956
43th Epoch, 33210th Step, learning rate = 0.0066072317587907445 - Loss: 0.2483050674200058, aux loss1: 0.7578651309013367, 
		 aux loss2: 0.392072468996048, total loss: 0.6324936151504517
43th Epoch, 33215th Step, learning rate = 0.006606708194829254 - Loss: 0.2635194659233093, aux loss1: 0.8768464922904968, 
		 aux loss2: 0.44240909814834595, total loss: 0.7035370469093323
43th Epoch, 33220th Step, learning rate = 0.006606184626257604 - Loss: 0.3090304136276245, aux loss1: 0.8279283046722412, 
		 aux loss2: 0.47382766008377075, total loss: 0.746940016746521
43th Epoch, 33225th Step, learning rate = 0.006605661053075351 - Loss: 0.24350710213184357, aux loss1: 0.8805807828903198, 
		 aux loss2: 0.41984277963638306, total loss: 0.6756184697151184
43th Epoch, 33230th Step, learning rate = 0.00660513747528205 - Loss: 0.22801682353019714, aux loss1: 0.6542572975158691, 
		 aux loss2: 0.3296118974685669, total loss: 0.5561387538909912
43th Epoch, 33235th Step, learning rate = 0.006604613892877252 - Loss: 0.330426961183548, aux loss1: 0.8047152161598206, 
		 aux loss2: 0.47451499104499817, total loss: 0.7616475224494934
43th Epoch, 33240th Step, learning rate = 0.006604090305860509 - Loss: 0.24810919165611267, aux loss1: 0.7393732666969299, 
		 aux loss2: 0.36121273040771484, total loss: 0.6144062876701355
43th Epoch, 33245th Step, learning rate = 0.006603566714231377 - Loss: 0.31833794713020325, aux loss1: 0.8235698342323303, 
		 aux loss2: 0.46876174211502075, total loss: 0.7529135942459106
43th Epoch, 33250th Step, learning rate = 0.006603043117989407 - Loss: 0.2881161570549011, aux loss1: 0.7812559604644775, 
		 aux loss2: 0.4279923439025879, total loss: 0.6936898827552795
43th Epoch, 33255th Step, learning rate = 0.006602519517134153 - Loss: 0.2501039505004883, aux loss1: 0.7407025694847107, 
		 aux loss2: 0.40174031257629395, total loss: 0.6330108642578125
43th Epoch, 33260th Step, learning rate = 0.006601995911665167 - Loss: 0.22617347538471222, aux loss1: 0.6650986075401306, 
		 aux loss2: 0.3172791004180908, total loss: 0.552614688873291
43th Epoch, 33265th Step, learning rate = 0.006601472301582001 - Loss: 0.26383036375045776, aux loss1: 0.7493342161178589, 
		 aux loss2: 0.3810417950153351, total loss: 0.6410473585128784
43th Epoch, 33270th Step, learning rate = 0.0066009486868842115 - Loss: 0.2948634922504425, aux loss1: 0.8556153774261475, 
		 aux loss2: 0.45038288831710815, total loss: 0.7317012548446655
43th Epoch, 33275th Step, learning rate = 0.006600425067571347 - Loss: 0.25100886821746826, aux loss1: 0.770071268081665, 
		 aux loss2: 0.381954550743103, total loss: 0.6348121166229248
43th Epoch, 33280th Step, learning rate = 0.006599901443642963 - Loss: 0.25011003017425537, aux loss1: 0.7195224761962891, 
		 aux loss2: 0.38413476943969727, total loss: 0.619620680809021
43th Epoch, 33285th Step, learning rate = 0.006599377815098609 - Loss: 0.24590589106082916, aux loss1: 0.7500865459442139, 
		 aux loss2: 0.3784474730491638, total loss: 0.6223108768463135
43th Epoch, 33290th Step, learning rate = 0.00659885418193784 - Loss: 0.2682289779186249, aux loss1: 0.7659375667572021, 
		 aux loss2: 0.39118653535842896, total loss: 0.6544848680496216
43th Epoch, 33295th Step, learning rate = 0.006598330544160206 - Loss: 0.277645468711853, aux loss1: 0.7840332388877869, 
		 aux loss2: 0.40439340472221375, total loss: 0.674612820148468
43th Epoch, 33300th Step, learning rate = 0.006597806901765261 - Loss: 0.33548644185066223, aux loss1: 1.0716257095336914, 
		 aux loss2: 0.5309292078018188, total loss: 0.8693459033966064
<33300th step>
*************************** Test ***************************
time:3m 18s, 33300th Step, Loss: 0.5692387819290161, Mean IoU = 46.333%
************************************************************
43th Epoch, 33305th Step, learning rate = 0.0065972832547525565 - Loss: 0.29095929861068726, aux loss1: 0.7219620943069458, 
		 aux loss2: 0.41357922554016113, total loss: 0.6729795932769775
43th Epoch, 33310th Step, learning rate = 0.0065967596031216436 - Loss: 0.2763538360595703, aux loss1: 1.0365066528320312, 
		 aux loss2: 0.5378737449645996, total loss: 0.8024553656578064
43th Epoch, 33315th Step, learning rate = 0.006596235946872075 - Loss: 0.21606430411338806, aux loss1: 0.7301759719848633, 
		 aux loss2: 0.3623737692832947, total loss: 0.5800666213035583
43th Epoch, 33320th Step, learning rate = 0.0065957122860034025 - Loss: 0.28259965777397156, aux loss1: 0.7957590818405151, 
		 aux loss2: 0.43528106808662415, total loss: 0.6954398155212402
43th Epoch, 33325th Step, learning rate = 0.00659518862051518 - Loss: 0.2685888111591339, aux loss1: 0.7095752358436584, 
		 aux loss2: 0.3813948631286621, total loss: 0.6340193748474121
43th Epoch, 33330th Step, learning rate = 0.0065946649504069555 - Loss: 0.32268890738487244, aux loss1: 0.8175349235534668, 
		 aux loss2: 0.48430684208869934, total loss: 0.7616721391677856
43th Epoch, 33335th Step, learning rate = 0.006594141275678282 - Loss: 0.28339147567749023, aux loss1: 0.7835826277732849, 
		 aux loss2: 0.41256269812583923, total loss: 0.6834913492202759
43th Epoch, 33340th Step, learning rate = 0.0065936175963287125 - Loss: 0.3133968710899353, aux loss1: 0.8447254300117493, 
		 aux loss2: 0.4649920165538788, total loss: 0.7528113722801208
43th Epoch, 33345th Step, learning rate = 0.006593093912357796 - Loss: 0.3003006875514984, aux loss1: 0.8767277002334595, 
		 aux loss2: 0.5222284197807312, total loss: 0.7722103595733643
43th Epoch, 33350th Step, learning rate = 0.006592570223765085 - Loss: 0.22509115934371948, aux loss1: 0.661045253276825, 
		 aux loss2: 0.334919273853302, total loss: 0.5573724508285522
43th Epoch, 33355th Step, learning rate = 0.006592046530550132 - Loss: 0.22942417860031128, aux loss1: 0.6799373626708984, 
		 aux loss2: 0.3508414924144745, total loss: 0.5737420320510864
43th Epoch, 33360th Step, learning rate = 0.0065915228327124865 - Loss: 0.38913193345069885, aux loss1: 1.0398335456848145, 
		 aux loss2: 0.5737490653991699, total loss: 0.9305816292762756
43th Epoch, 33365th Step, learning rate = 0.0065909991302517 - Loss: 0.26815617084503174, aux loss1: 0.8979085683822632, 
		 aux loss2: 0.4018467664718628, total loss: 0.6982674598693848
43th Epoch, 33370th Step, learning rate = 0.006590475423167325 - Loss: 0.21449215710163116, aux loss1: 0.7089466452598572, 
		 aux loss2: 0.3383876383304596, total loss: 0.5625312328338623
43th Epoch, 33375th Step, learning rate = 0.006589951711458909 - Loss: 0.38452646136283875, aux loss1: 1.0606629848480225, 
		 aux loss2: 0.6055755615234375, total loss: 0.9449556469917297
43th Epoch, 33380th Step, learning rate = 0.006589427995126005 - Loss: 0.2699255049228668, aux loss1: 0.7672848105430603, 
		 aux loss2: 0.38683781027793884, total loss: 0.6548461318016052
43th Epoch, 33385th Step, learning rate = 0.006588904274168166 - Loss: 0.2609805762767792, aux loss1: 0.7363303303718567, 
		 aux loss2: 0.36570116877555847, total loss: 0.6281601190567017
43th Epoch, 33390th Step, learning rate = 0.006588380548584937 - Loss: 0.28771451115608215, aux loss1: 0.7726315855979919, 
		 aux loss2: 0.41705846786499023, total loss: 0.6863273978233337
43th Epoch, 33395th Step, learning rate = 0.0065878568183758745 - Loss: 0.30305200815200806, aux loss1: 0.8425863981246948, 
		 aux loss2: 0.4404783248901367, total loss: 0.732019305229187
43th Epoch, 33400th Step, learning rate = 0.006587333083540527 - Loss: 0.28697288036346436, aux loss1: 0.8216203451156616, 
		 aux loss2: 0.4376015067100525, total loss: 0.7084996104240417
<33400th step>
*************************** Test ***************************
time:3m 18s, 33400th Step, Loss: 0.5496572256088257, Mean IoU = 46.716%
************************************************************
43th Epoch, 33405th Step, learning rate = 0.006586809344078443 - Loss: 0.2694697678089142, aux loss1: 0.7661765217781067, 
		 aux loss2: 0.3916573226451874, total loss: 0.6559856534004211
43th Epoch, 33410th Step, learning rate = 0.006586285599989175 - Loss: 0.4005317687988281, aux loss1: 0.8837899565696716, 
		 aux loss2: 0.5784235000610352, total loss: 0.8970381021499634
43th Epoch, 33415th Step, learning rate = 0.006585761851272273 - Loss: 0.23817230761051178, aux loss1: 0.7702458500862122, 
		 aux loss2: 0.380693256855011, total loss: 0.621523380279541
43th Epoch, 33420th Step, learning rate = 0.006585238097927285 - Loss: 0.22727753221988678, aux loss1: 0.711402177810669, 
		 aux loss2: 0.3589317202568054, total loss: 0.5842708945274353
43th Epoch, 33425th Step, learning rate = 0.006584714339953766 - Loss: 0.2785719931125641, aux loss1: 0.7692749500274658, 
		 aux loss2: 0.41611579060554504, total loss: 0.6758008003234863
43th Epoch, 33430th Step, learning rate = 0.00658419057735126 - Loss: 0.30579227209091187, aux loss1: 0.7869886755943298, 
		 aux loss2: 0.43002986907958984, total loss: 0.7139008641242981
43th Epoch, 33435th Step, learning rate = 0.006583666810119321 - Loss: 0.30859848856925964, aux loss1: 0.9310603141784668, 
		 aux loss2: 0.4705618619918823, total loss: 0.776141345500946
43th Epoch, 33440th Step, learning rate = 0.006583143038257498 - Loss: 0.32758817076683044, aux loss1: 0.8645614981651306, 
		 aux loss2: 0.4931076169013977, total loss: 0.7841996550559998
43th Epoch, 33445th Step, learning rate = 0.00658261926176534 - Loss: 0.3059336245059967, aux loss1: 0.8926025032997131, 
		 aux loss2: 0.5159392356872559, total loss: 0.7800900936126709
43th Epoch, 33450th Step, learning rate = 0.006582095480642398 - Loss: 0.21594032645225525, aux loss1: 0.6905936598777771, 
		 aux loss2: 0.3260650932788849, total loss: 0.5535444617271423
44th Epoch, 33455th Step, learning rate = 0.0065815716948882195 - Loss: 0.2886859178543091, aux loss1: 0.9150322675704956, 
		 aux loss2: 0.46311917901039124, total loss: 0.7484432458877563
44th Epoch, 33460th Step, learning rate = 0.006581047904502356 - Loss: 0.2406492382287979, aux loss1: 0.7189217805862427, 
		 aux loss2: 0.3636170029640198, total loss: 0.6017725467681885
44th Epoch, 33465th Step, learning rate = 0.006580524109484357 - Loss: 0.2674812972545624, aux loss1: 0.66835618019104, 
		 aux loss2: 0.3892139792442322, total loss: 0.6236737370491028
44th Epoch, 33470th Step, learning rate = 0.0065800003098337705 - Loss: 0.28446492552757263, aux loss1: 0.799273669719696, 
		 aux loss2: 0.46018916368484497, total loss: 0.7083227038383484
44th Epoch, 33475th Step, learning rate = 0.006579476505550146 - Loss: 0.2652875781059265, aux loss1: 0.8422921299934387, 
		 aux loss2: 0.4214076101779938, total loss: 0.6865382790565491
44th Epoch, 33480th Step, learning rate = 0.006578952696633034 - Loss: 0.2560023367404938, aux loss1: 0.701453447341919, 
		 aux loss2: 0.38112860918045044, total loss: 0.6188898086547852
44th Epoch, 33485th Step, learning rate = 0.0065784288830819816 - Loss: 0.2686130404472351, aux loss1: 0.89836585521698, 
		 aux loss2: 0.4421367645263672, total loss: 0.714977502822876
44th Epoch, 33490th Step, learning rate = 0.00657790506489654 - Loss: 0.3075243830680847, aux loss1: 0.80562824010849, 
		 aux loss2: 0.4570867121219635, total loss: 0.7320475578308105
44th Epoch, 33495th Step, learning rate = 0.006577381242076257 - Loss: 0.29245755076408386, aux loss1: 0.8519018292427063, 
		 aux loss2: 0.4429946541786194, total loss: 0.7252259850502014
44th Epoch, 33500th Step, learning rate = 0.006576857414620679 - Loss: 0.28405722975730896, aux loss1: 0.7477774024009705, 
		 aux loss2: 0.43476733565330505, total loss: 0.6822973489761353
<33500th step>
*************************** Test ***************************
time:3m 16s, 33500th Step, Loss: 0.5885785222053528, Mean IoU = 45.234%
************************************************************
44th Epoch, 33505th Step, learning rate = 0.00657633358252936 - Loss: 0.31604835391044617, aux loss1: 0.9074097275733948, 
		 aux loss2: 0.5123928189277649, total loss: 0.7932283878326416
44th Epoch, 33510th Step, learning rate = 0.006575809745801845 - Loss: 0.25408580899238586, aux loss1: 0.7716209888458252, 
		 aux loss2: 0.35156118869781494, total loss: 0.626196563243866
44th Epoch, 33515th Step, learning rate = 0.006575285904437682 - Loss: 0.3094380497932434, aux loss1: 0.8754119873046875, 
		 aux loss2: 0.4501548111438751, total loss: 0.7521235942840576
44th Epoch, 33520th Step, learning rate = 0.006574762058436425 - Loss: 0.2380663901567459, aux loss1: 0.8200139403343201, 
		 aux loss2: 0.3875211477279663, total loss: 0.6390790939331055
44th Epoch, 33525th Step, learning rate = 0.006574238207797615 - Loss: 0.24947834014892578, aux loss1: 0.8557034730911255, 
		 aux loss2: 0.4110287129878998, total loss: 0.6706008911132812
44th Epoch, 33530th Step, learning rate = 0.006573714352520805 - Loss: 0.3658333420753479, aux loss1: 1.1985341310501099, 
		 aux loss2: 0.6875090599060059, total loss: 1.0003972053527832
44th Epoch, 33535th Step, learning rate = 0.006573190492605542 - Loss: 0.2871899902820587, aux loss1: 0.7633485198020935, 
		 aux loss2: 0.4197072386741638, total loss: 0.6840775012969971
44th Epoch, 33540th Step, learning rate = 0.0065726666280513735 - Loss: 0.3268318474292755, aux loss1: 0.908842146396637, 
		 aux loss2: 0.5038191080093384, total loss: 0.8010121583938599
44th Epoch, 33545th Step, learning rate = 0.0065721427588578485 - Loss: 0.2917702794075012, aux loss1: 0.8457199335098267, 
		 aux loss2: 0.4707430601119995, total loss: 0.733783483505249
44th Epoch, 33550th Step, learning rate = 0.006571618885024516 - Loss: 0.2802393138408661, aux loss1: 0.8210084438323975, 
		 aux loss2: 0.46511003375053406, total loss: 0.7125858664512634
44th Epoch, 33555th Step, learning rate = 0.006571095006550922 - Loss: 0.29120635986328125, aux loss1: 0.940879225730896, 
		 aux loss2: 0.4483112096786499, total loss: 0.752794623374939
44th Epoch, 33560th Step, learning rate = 0.006570571123436615 - Loss: 0.2661072909832001, aux loss1: 0.7928569912910461, 
		 aux loss2: 0.40575695037841797, total loss: 0.6662672162055969
44th Epoch, 33565th Step, learning rate = 0.006570047235681144 - Loss: 0.3897303342819214, aux loss1: 0.9507195949554443, 
		 aux loss2: 0.5323935151100159, total loss: 0.8879035711288452
44th Epoch, 33570th Step, learning rate = 0.006569523343284053 - Loss: 0.22679151594638824, aux loss1: 0.71866774559021, 
		 aux loss2: 0.346983939409256, total loss: 0.5811854004859924
44th Epoch, 33575th Step, learning rate = 0.006568999446244894 - Loss: 0.34101632237434387, aux loss1: 0.9354087710380554, 
		 aux loss2: 0.5064325928688049, total loss: 0.8242120146751404
44th Epoch, 33580th Step, learning rate = 0.006568475544563213 - Loss: 0.25074249505996704, aux loss1: 0.6954646706581116, 
		 aux loss2: 0.35592973232269287, total loss: 0.601753830909729
44th Epoch, 33585th Step, learning rate = 0.0065679516382385564 - Loss: 0.2348918616771698, aux loss1: 0.6854348182678223, 
		 aux loss2: 0.350378155708313, total loss: 0.5806735754013062
44th Epoch, 33590th Step, learning rate = 0.006567427727270473 - Loss: 0.2715325653553009, aux loss1: 0.7975364327430725, 
		 aux loss2: 0.4301272928714752, total loss: 0.6828444004058838
44th Epoch, 33595th Step, learning rate = 0.006566903811658509 - Loss: 0.3570254147052765, aux loss1: 1.1087137460708618, 
		 aux loss2: 0.6484317779541016, total loss: 0.949012279510498
44th Epoch, 33600th Step, learning rate = 0.006566379891402211 - Loss: 0.256858229637146, aux loss1: 0.7430360317230225, 
		 aux loss2: 0.40123751759529114, total loss: 0.6402640342712402
<33600th step>
*************************** Test ***************************
time:3m 15s, 33600th Step, Loss: 0.5430567264556885, Mean IoU = 47.208%
************************************************************
44th Epoch, 33605th Step, learning rate = 0.006565855966501127 - Loss: 0.3161267340183258, aux loss1: 0.8299241662025452, 
		 aux loss2: 0.4831574559211731, total loss: 0.7583670020103455
44th Epoch, 33610th Step, learning rate = 0.006565332036954806 - Loss: 0.2705491781234741, aux loss1: 0.8977805972099304, 
		 aux loss2: 0.445997029542923, total loss: 0.7182822227478027
44th Epoch, 33615th Step, learning rate = 0.00656480810276279 - Loss: 0.2848722040653229, aux loss1: 0.8925155401229858, 
		 aux loss2: 0.4607125520706177, total loss: 0.7369118928909302
44th Epoch, 33620th Step, learning rate = 0.006564284163924631 - Loss: 0.280659556388855, aux loss1: 0.8158432841300964, 
		 aux loss2: 0.4251101613044739, total loss: 0.6954566240310669
44th Epoch, 33625th Step, learning rate = 0.00656376022043987 - Loss: 0.3716644048690796, aux loss1: 1.180130124092102, 
		 aux loss2: 0.6630287766456604, total loss: 0.9909150004386902
44th Epoch, 33630th Step, learning rate = 0.006563236272308061 - Loss: 0.3283194601535797, aux loss1: 0.8369460701942444, 
		 aux loss2: 0.509172797203064, total loss: 0.7830724120140076
44th Epoch, 33635th Step, learning rate = 0.0065627123195287455 - Loss: 0.2792305648326874, aux loss1: 0.8619038462638855, 
		 aux loss2: 0.42318588495254517, total loss: 0.7070760726928711
44th Epoch, 33640th Step, learning rate = 0.006562188362101469 - Loss: 0.32894250750541687, aux loss1: 0.9544882774353027, 
		 aux loss2: 0.5885701775550842, total loss: 0.8507170677185059
44th Epoch, 33645th Step, learning rate = 0.006561664400025783 - Loss: 0.2805549204349518, aux loss1: 0.7521276473999023, 
		 aux loss2: 0.40501871705055237, total loss: 0.6682007312774658
44th Epoch, 33650th Step, learning rate = 0.006561140433301229 - Loss: 0.29162830114364624, aux loss1: 0.7300219535827637, 
		 aux loss2: 0.4168206751346588, total loss: 0.6773631572723389
44th Epoch, 33655th Step, learning rate = 0.006560616461927356 - Loss: 0.29989248514175415, aux loss1: 0.7820799946784973, 
		 aux loss2: 0.4524410665035248, total loss: 0.7154929637908936
44th Epoch, 33660th Step, learning rate = 0.00656009248590371 - Loss: 0.33871304988861084, aux loss1: 0.9923228621482849, 
		 aux loss2: 0.5227892398834229, total loss: 0.8455255627632141
44th Epoch, 33665th Step, learning rate = 0.0065595685052298345 - Loss: 0.3332414925098419, aux loss1: 0.8883169293403625, 
		 aux loss2: 0.47403669357299805, total loss: 0.789351224899292
44th Epoch, 33670th Step, learning rate = 0.0065590445199052785 - Loss: 0.24353431165218353, aux loss1: 0.7720418572425842, 
		 aux loss2: 0.3870883285999298, total loss: 0.6299822330474854
44th Epoch, 33675th Step, learning rate = 0.006558520529929587 - Loss: 0.2965657413005829, aux loss1: 0.7788028717041016, 
		 aux loss2: 0.43853190541267395, total loss: 0.7056193947792053
44th Epoch, 33680th Step, learning rate = 0.006557996535302305 - Loss: 0.3205956816673279, aux loss1: 0.8707408905029297, 
		 aux loss2: 0.5115329623222351, total loss: 0.7864311933517456
44th Epoch, 33685th Step, learning rate = 0.006557472536022978 - Loss: 0.3450620770454407, aux loss1: 0.8761428594589233, 
		 aux loss2: 0.49279919266700745, total loss: 0.8050246238708496
44th Epoch, 33690th Step, learning rate = 0.006556948532091155 - Loss: 0.31582239270210266, aux loss1: 0.8398443460464478, 
		 aux loss2: 0.4628565311431885, total loss: 0.7529183626174927
44th Epoch, 33695th Step, learning rate = 0.006556424523506375 - Loss: 0.2976740002632141, aux loss1: 0.7364829778671265, 
		 aux loss2: 0.42653873562812805, total loss: 0.6892343759536743
44th Epoch, 33700th Step, learning rate = 0.006555900510268191 - Loss: 0.3400149941444397, aux loss1: 1.0974723100662231, 
		 aux loss2: 0.5831480026245117, total loss: 0.9025158882141113
<33700th step>
*************************** Test ***************************
time:3m 15s, 33700th Step, Loss: 0.5138236284255981, Mean IoU = 46.245%
************************************************************
44th Epoch, 33705th Step, learning rate = 0.006555376492376144 - Loss: 0.27743327617645264, aux loss1: 0.8581792712211609, 
		 aux loss2: 0.4798211455345154, total loss: 0.7268155217170715
44th Epoch, 33710th Step, learning rate = 0.006554852469829779 - Loss: 0.3368731737136841, aux loss1: 0.8490439057350159, 
		 aux loss2: 0.5201172828674316, total loss: 0.799633264541626
44th Epoch, 33715th Step, learning rate = 0.006554328442628645 - Loss: 0.27896422147750854, aux loss1: 0.7623964548110962, 
		 aux loss2: 0.4070604741573334, total loss: 0.6705073714256287
44th Epoch, 33720th Step, learning rate = 0.006553804410772282 - Loss: 0.25968900322914124, aux loss1: 0.7395060658454895, 
		 aux loss2: 0.3763830065727234, total loss: 0.6320940256118774
44th Epoch, 33725th Step, learning rate = 0.006553280374260239 - Loss: 0.2951785922050476, aux loss1: 0.8236681222915649, 
		 aux loss2: 0.4476706087589264, total loss: 0.7213472723960876
44th Epoch, 33730th Step, learning rate = 0.006552756333092061 - Loss: 0.3089357316493988, aux loss1: 0.8274379968643188, 
		 aux loss2: 0.4901995360851288, total loss: 0.7532470226287842
44th Epoch, 33735th Step, learning rate = 0.006552232287267288 - Loss: 0.2908729314804077, aux loss1: 0.9279229640960693, 
		 aux loss2: 0.4884554147720337, total loss: 0.7646320462226868
44th Epoch, 33740th Step, learning rate = 0.0065517082367854695 - Loss: 0.31107303500175476, aux loss1: 0.8291801810264587, 
		 aux loss2: 0.4482210576534271, total loss: 0.7391155362129211
44th Epoch, 33745th Step, learning rate = 0.00655118418164615 - Loss: 0.3521568775177002, aux loss1: 1.0401924848556519, 
		 aux loss2: 0.5482385158538818, total loss: 0.8835099935531616
44th Epoch, 33750th Step, learning rate = 0.006550660121848871 - Loss: 0.284371018409729, aux loss1: 0.8402918577194214, 
		 aux loss2: 0.4265482425689697, total loss: 0.7070779204368591
44th Epoch, 33755th Step, learning rate = 0.006550136057393182 - Loss: 0.29944929480552673, aux loss1: 0.9103600382804871, 
		 aux loss2: 0.5169584155082703, total loss: 0.7793406844139099
44th Epoch, 33760th Step, learning rate = 0.006549611988278623 - Loss: 0.25377142429351807, aux loss1: 0.8142033815383911, 
		 aux loss2: 0.4081571102142334, total loss: 0.6612952947616577
44th Epoch, 33765th Step, learning rate = 0.006549087914504741 - Loss: 0.2858870029449463, aux loss1: 0.8479760885238647, 
		 aux loss2: 0.43647074699401855, total loss: 0.7148681879043579
44th Epoch, 33770th Step, learning rate = 0.006548563836071079 - Loss: 0.26743459701538086, aux loss1: 0.8589125871658325, 
		 aux loss2: 0.39827197790145874, total loss: 0.684417188167572
44th Epoch, 33775th Step, learning rate = 0.006548039752977181 - Loss: 0.27314069867134094, aux loss1: 0.789023220539093, 
		 aux loss2: 0.42956891655921936, total loss: 0.6816751956939697
44th Epoch, 33780th Step, learning rate = 0.006547515665222591 - Loss: 0.32464781403541565, aux loss1: 0.960056722164154, 
		 aux loss2: 0.5174755454063416, total loss: 0.8196550607681274
44th Epoch, 33785th Step, learning rate = 0.006546991572806855 - Loss: 0.28780701756477356, aux loss1: 0.7500607371330261, 
		 aux loss2: 0.4353649616241455, total loss: 0.6869712471961975
44th Epoch, 33790th Step, learning rate = 0.006546467475729515 - Loss: 0.2791103422641754, aux loss1: 0.8640301823616028, 
		 aux loss2: 0.4344502389431, total loss: 0.7120994925498962
44th Epoch, 33795th Step, learning rate = 0.006545943373990115 - Loss: 0.2842349708080292, aux loss1: 0.8603394031524658, 
		 aux loss2: 0.4603853225708008, total loss: 0.7264909744262695
44th Epoch, 33800th Step, learning rate = 0.006545419267588201 - Loss: 0.23539818823337555, aux loss1: 0.6784289479255676, 
		 aux loss2: 0.36810538172721863, total loss: 0.5861690044403076
<33800th step>
*************************** Test ***************************
time:3m 18s, 33800th Step, Loss: 0.5562230348587036, Mean IoU = 44.838%
************************************************************
44th Epoch, 33805th Step, learning rate = 0.006544895156523312 - Loss: 0.2520192861557007, aux loss1: 0.7407407760620117, 
		 aux loss2: 0.37835031747817993, total loss: 0.6255816221237183
44th Epoch, 33810th Step, learning rate = 0.006544371040794998 - Loss: 0.35859590768814087, aux loss1: 1.1145479679107666, 
		 aux loss2: 0.5787976384162903, total loss: 0.9244793653488159
44th Epoch, 33815th Step, learning rate = 0.006543846920402797 - Loss: 0.24336057901382446, aux loss1: 0.7882915139198303, 
		 aux loss2: 0.4196416735649109, total loss: 0.6477047204971313
44th Epoch, 33820th Step, learning rate = 0.006543322795346254 - Loss: 0.27996087074279785, aux loss1: 0.6801817417144775, 
		 aux loss2: 0.408809632062912, total loss: 0.6475392580032349
44th Epoch, 33825th Step, learning rate = 0.0065427986656249135 - Loss: 0.2059660404920578, aux loss1: 0.678762674331665, 
		 aux loss2: 0.32214224338531494, total loss: 0.5384517312049866
45th Epoch, 33830th Step, learning rate = 0.006542274531238318 - Loss: 0.23775877058506012, aux loss1: 0.7748872637748718, 
		 aux loss2: 0.36732473969459534, total loss: 0.6171548962593079
45th Epoch, 33835th Step, learning rate = 0.006541750392186011 - Loss: 0.2596217691898346, aux loss1: 0.6872630715370178, 
		 aux loss2: 0.3731648325920105, total loss: 0.615066647529602
45th Epoch, 33840th Step, learning rate = 0.006541226248467536 - Loss: 0.37492886185646057, aux loss1: 0.9845017194747925, 
		 aux loss2: 0.5775503516197205, total loss: 0.9012995362281799
45th Epoch, 33845th Step, learning rate = 0.006540702100082435 - Loss: 0.30314117670059204, aux loss1: 0.8574001789093018, 
		 aux loss2: 0.46667906641960144, total loss: 0.747032880783081
45th Epoch, 33850th Step, learning rate = 0.0065401779470302505 - Loss: 0.28012368083000183, aux loss1: 0.732835590839386, 
		 aux loss2: 0.40728992223739624, total loss: 0.6628903150558472
45th Epoch, 33855th Step, learning rate = 0.006539653789310528 - Loss: 0.34615975618362427, aux loss1: 0.916343092918396, 
		 aux loss2: 0.5234808325767517, total loss: 0.8304550647735596
45th Epoch, 33860th Step, learning rate = 0.006539129626922807 - Loss: 0.24465787410736084, aux loss1: 0.7159156203269958, 
		 aux loss2: 0.35967233777046204, total loss: 0.6033015251159668
45th Epoch, 33865th Step, learning rate = 0.006538605459866631 - Loss: 0.2730361223220825, aux loss1: 0.7327163815498352, 
		 aux loss2: 0.4109460413455963, total loss: 0.657229483127594
45th Epoch, 33870th Step, learning rate = 0.006538081288141546 - Loss: 0.2559022009372711, aux loss1: 0.7472615838050842, 
		 aux loss2: 0.38113558292388916, total loss: 0.632534921169281
45th Epoch, 33875th Step, learning rate = 0.0065375571117470875 - Loss: 0.3031059205532074, aux loss1: 0.8203164935112, 
		 aux loss2: 0.4594145715236664, total loss: 0.7329667210578918
45th Epoch, 33880th Step, learning rate = 0.006537032930682806 - Loss: 0.25650227069854736, aux loss1: 0.8221613168716431, 
		 aux loss2: 0.41965746879577637, total loss: 0.6710137128829956
45th Epoch, 33885th Step, learning rate = 0.0065365087449482375 - Loss: 0.21735399961471558, aux loss1: 0.67665034532547, 
		 aux loss2: 0.3311748802661896, total loss: 0.5528190732002258
45th Epoch, 33890th Step, learning rate = 0.006535984554542927 - Loss: 0.22854873538017273, aux loss1: 0.7231011390686035, 
		 aux loss2: 0.36908310651779175, total loss: 0.5931123495101929
45th Epoch, 33895th Step, learning rate = 0.0065354603594664175 - Loss: 0.2135581374168396, aux loss1: 0.7506990432739258, 
		 aux loss2: 0.3259813189506531, total loss: 0.5691604018211365
45th Epoch, 33900th Step, learning rate = 0.006534936159718249 - Loss: 0.2494657337665558, aux loss1: 0.6776925325393677, 
		 aux loss2: 0.37219667434692383, total loss: 0.601652204990387
<33900th step>
*************************** Test ***************************
time:3m 15s, 33900th Step, Loss: 0.6105425953865051, Mean IoU = 44.459%
************************************************************
45th Epoch, 33905th Step, learning rate = 0.006534411955297964 - Loss: 0.25460073351860046, aux loss1: 0.8338986039161682, 
		 aux loss2: 0.42041656374931335, total loss: 0.6729369759559631
45th Epoch, 33910th Step, learning rate = 0.006533887746205106 - Loss: 0.25207090377807617, aux loss1: 0.8364731669425964, 
		 aux loss2: 0.40257683396339417, total loss: 0.664043664932251
45th Epoch, 33915th Step, learning rate = 0.006533363532439215 - Loss: 0.33740726113319397, aux loss1: 0.7775520086288452, 
		 aux loss2: 0.492628276348114, total loss: 0.7677241563796997
45th Epoch, 33920th Step, learning rate = 0.006532839313999833 - Loss: 0.377329021692276, aux loss1: 0.9361172318458557, 
		 aux loss2: 0.5768890380859375, total loss: 0.8889198303222656
45th Epoch, 33925th Step, learning rate = 0.006532315090886503 - Loss: 0.39159712195396423, aux loss1: 1.1153992414474487, 
		 aux loss2: 0.6313639879226685, total loss: 0.9787625074386597
45th Epoch, 33930th Step, learning rate = 0.0065317908630987635 - Loss: 0.25767743587493896, aux loss1: 0.6636572480201721, 
		 aux loss2: 0.35287991166114807, total loss: 0.5979266166687012
45th Epoch, 33935th Step, learning rate = 0.0065312666306361605 - Loss: 0.3065556287765503, aux loss1: 0.943706214427948, 
		 aux loss2: 0.520188570022583, total loss: 0.7977429628372192
45th Epoch, 33940th Step, learning rate = 0.0065307423934982305 - Loss: 0.31136173009872437, aux loss1: 0.8746492862701416, 
		 aux loss2: 0.454545259475708, total loss: 0.755574643611908
45th Epoch, 33945th Step, learning rate = 0.006530218151684518 - Loss: 0.2536863684654236, aux loss1: 0.743052065372467, 
		 aux loss2: 0.3913462162017822, total loss: 0.633140504360199
45th Epoch, 33950th Step, learning rate = 0.006529693905194565 - Loss: 0.31979483366012573, aux loss1: 0.9120540022850037, 
		 aux loss2: 0.4710828363895416, total loss: 0.7818442583084106
45th Epoch, 33955th Step, learning rate = 0.006529169654027909 - Loss: 0.4054414927959442, aux loss1: 1.0151870250701904, 
		 aux loss2: 0.6006342172622681, total loss: 0.9502513408660889
45th Epoch, 33960th Step, learning rate = 0.006528645398184093 - Loss: 0.28578728437423706, aux loss1: 0.9699092507362366, 
		 aux loss2: 0.49191948771476746, total loss: 0.7735278606414795
45th Epoch, 33965th Step, learning rate = 0.0065281211376626595 - Loss: 0.2593979835510254, aux loss1: 0.75803142786026, 
		 aux loss2: 0.4005125164985657, total loss: 0.6470124125480652
45th Epoch, 33970th Step, learning rate = 0.006527596872463146 - Loss: 0.37003642320632935, aux loss1: 1.0140879154205322, 
		 aux loss2: 0.6891021728515625, total loss: 0.9499037265777588
45th Epoch, 33975th Step, learning rate = 0.0065270726025850965 - Loss: 0.28622108697891235, aux loss1: 0.8114073872566223, 
		 aux loss2: 0.43439731001853943, total loss: 0.7034022212028503
45th Epoch, 33980th Step, learning rate = 0.00652654832802805 - Loss: 0.2856591045856476, aux loss1: 0.8593160510063171, 
		 aux loss2: 0.43861615657806396, total loss: 0.7189003825187683
45th Epoch, 33985th Step, learning rate = 0.006526024048791546 - Loss: 0.2705088257789612, aux loss1: 0.7584971785545349, 
		 aux loss2: 0.4188619554042816, total loss: 0.6656028032302856
45th Epoch, 33990th Step, learning rate = 0.006525499764875129 - Loss: 0.2678523659706116, aux loss1: 0.7187440991401672, 
		 aux loss2: 0.3786127269268036, total loss: 0.6349207162857056
45th Epoch, 33995th Step, learning rate = 0.006524975476278337 - Loss: 0.25219210982322693, aux loss1: 0.8500368595123291, 
		 aux loss2: 0.4057397246360779, total loss: 0.6694990992546082
45th Epoch, 34000th Step, learning rate = 0.006524451183000707 - Loss: 0.4223603904247284, aux loss1: 1.0332772731781006, 
		 aux loss2: 0.6019498705863953, total loss: 0.9731234908103943
<34000th step>
*************************** Test ***************************
time:3m 16s, 34000th Step, Loss: 0.5398777723312378, Mean IoU = 46.379%
************************************************************
45th Epoch, 34005th Step, learning rate = 0.006523926885041786 - Loss: 0.2804708480834961, aux loss1: 0.8225539922714233, 
		 aux loss2: 0.4268319010734558, total loss: 0.6979697942733765
45th Epoch, 34010th Step, learning rate = 0.006523402582401109 - Loss: 0.26341062784194946, aux loss1: 0.8353185653686523, 
		 aux loss2: 0.4198647141456604, total loss: 0.6819521188735962
45th Epoch, 34015th Step, learning rate = 0.006522878275078218 - Loss: 0.23909656703472137, aux loss1: 0.7941088080406189, 
		 aux loss2: 0.405953586101532, total loss: 0.6397106647491455
45th Epoch, 34020th Step, learning rate = 0.006522353963072653 - Loss: 0.22339493036270142, aux loss1: 0.7309362888336182, 
		 aux loss2: 0.3719339966773987, total loss: 0.5914494395256042
45th Epoch, 34025th Step, learning rate = 0.006521829646383953 - Loss: 0.2581140100955963, aux loss1: 0.7597414255142212, 
		 aux loss2: 0.36904940009117126, total loss: 0.6336562037467957
45th Epoch, 34030th Step, learning rate = 0.00652130532501166 - Loss: 0.28900864720344543, aux loss1: 0.8137077689170837, 
		 aux loss2: 0.4388538599014282, total loss: 0.7086625099182129
45th Epoch, 34035th Step, learning rate = 0.006520780998955311 - Loss: 0.27946737408638, aux loss1: 0.8465898633003235, 
		 aux loss2: 0.4321877360343933, total loss: 0.7063194513320923
45th Epoch, 34040th Step, learning rate = 0.006520256668214447 - Loss: 0.23115727305412292, aux loss1: 0.6711561679840088, 
		 aux loss2: 0.33635398745536804, total loss: 0.5670456886291504
45th Epoch, 34045th Step, learning rate = 0.006519732332788609 - Loss: 0.25811803340911865, aux loss1: 0.8203340172767639, 
		 aux loss2: 0.4117017984390259, total loss: 0.6688989400863647
45th Epoch, 34050th Step, learning rate = 0.006519207992677334 - Loss: 0.3069554269313812, aux loss1: 0.7830575108528137, 
		 aux loss2: 0.4285324215888977, total loss: 0.7132856845855713
45th Epoch, 34055th Step, learning rate = 0.00651868364788016 - Loss: 0.28641802072525024, aux loss1: 0.764325737953186, 
		 aux loss2: 0.44105264544487, total loss: 0.6921367645263672
45th Epoch, 34060th Step, learning rate = 0.006518159298396632 - Loss: 0.30714911222457886, aux loss1: 0.9189879894256592, 
		 aux loss2: 0.4940454959869385, total loss: 0.780463695526123
45th Epoch, 34065th Step, learning rate = 0.006517634944226285 - Loss: 0.2870066463947296, aux loss1: 0.8514400720596313, 
		 aux loss2: 0.47653430700302124, total loss: 0.7330524325370789
45th Epoch, 34070th Step, learning rate = 0.0065171105853686585 - Loss: 0.2759355902671814, aux loss1: 0.8481931090354919, 
		 aux loss2: 0.4675188660621643, total loss: 0.7174010872840881
45th Epoch, 34075th Step, learning rate = 0.006516586221823294 - Loss: 0.3514057993888855, aux loss1: 0.9698711037635803, 
		 aux loss2: 0.5593735575675964, total loss: 0.8661165237426758
45th Epoch, 34080th Step, learning rate = 0.006516061853589728 - Loss: 0.29056474566459656, aux loss1: 0.8588133454322815, 
		 aux loss2: 0.44693171977996826, total loss: 0.7269814610481262
45th Epoch, 34085th Step, learning rate = 0.006515537480667498 - Loss: 0.30766230821609497, aux loss1: 0.8919121623039246, 
		 aux loss2: 0.49627038836479187, total loss: 0.7737441062927246
45th Epoch, 34090th Step, learning rate = 0.006515013103056148 - Loss: 0.31752899289131165, aux loss1: 0.9678595066070557, 
		 aux loss2: 0.5417212843894958, total loss: 0.8245753645896912
45th Epoch, 34095th Step, learning rate = 0.00651448872075521 - Loss: 0.29955145716667175, aux loss1: 0.8394591212272644, 
		 aux loss2: 0.4583756923675537, total loss: 0.7347394824028015
45th Epoch, 34100th Step, learning rate = 0.006513964333764229 - Loss: 0.22960472106933594, aux loss1: 0.6431925296783447, 
		 aux loss2: 0.3375457525253296, total loss: 0.5575807690620422
<34100th step>
*************************** Test ***************************
time:3m 18s, 34100th Step, Loss: 0.5759626626968384, Mean IoU = 46.222%
************************************************************
45th Epoch, 34105th Step, learning rate = 0.006513439942082741 - Loss: 0.22481098771095276, aux loss1: 0.7554923892021179, 
		 aux loss2: 0.3575238883495331, total loss: 0.5944682359695435
45th Epoch, 34110th Step, learning rate = 0.006512915545710281 - Loss: 0.25545772910118103, aux loss1: 1.037702202796936, 
		 aux loss2: 0.4108978807926178, total loss: 0.7311275601387024
45th Epoch, 34115th Step, learning rate = 0.006512391144646392 - Loss: 0.29367703199386597, aux loss1: 0.7947309017181396, 
		 aux loss2: 0.4109867215156555, total loss: 0.696491003036499
45th Epoch, 34120th Step, learning rate = 0.006511866738890612 - Loss: 0.27931156754493713, aux loss1: 0.8259132504463196, 
		 aux loss2: 0.44389036297798157, total loss: 0.7046416997909546
45th Epoch, 34125th Step, learning rate = 0.006511342328442475 - Loss: 0.24824835360050201, aux loss1: 0.7421098947525024, 
		 aux loss2: 0.36929604411125183, total loss: 0.6185997724533081
45th Epoch, 34130th Step, learning rate = 0.006510817913301526 - Loss: 0.2786741554737091, aux loss1: 0.7882115244865417, 
		 aux loss2: 0.4134148359298706, total loss: 0.6805035471916199
45th Epoch, 34135th Step, learning rate = 0.006510293493467296 - Loss: 0.2590368986129761, aux loss1: 0.7341235876083374, 
		 aux loss2: 0.3805396258831024, total loss: 0.6314898133277893
45th Epoch, 34140th Step, learning rate = 0.006509769068939328 - Loss: 0.2638094127178192, aux loss1: 0.7676277160644531, 
		 aux loss2: 0.38207146525382996, total loss: 0.6469263434410095
45th Epoch, 34145th Step, learning rate = 0.006509244639717158 - Loss: 0.2994897663593292, aux loss1: 0.7961248755455017, 
		 aux loss2: 0.4508975148200989, total loss: 0.7186862230300903
45th Epoch, 34150th Step, learning rate = 0.006508720205800321 - Loss: 0.29671812057495117, aux loss1: 0.807087242603302, 
		 aux loss2: 0.4235834777355194, total loss: 0.708277702331543
45th Epoch, 34155th Step, learning rate = 0.006508195767188359 - Loss: 0.290261834859848, aux loss1: 0.808132529258728, 
		 aux loss2: 0.4285189211368561, total loss: 0.7041091918945312
45th Epoch, 34160th Step, learning rate = 0.00650767132388081 - Loss: 0.269775390625, aux loss1: 0.7514932751655579, 
		 aux loss2: 0.40021368861198425, total loss: 0.6553089022636414
45th Epoch, 34165th Step, learning rate = 0.006507146875877204 - Loss: 0.2321416437625885, aux loss1: 0.7772024273872375, 
		 aux loss2: 0.3586081862449646, total loss: 0.6087456345558167
45th Epoch, 34170th Step, learning rate = 0.006506622423177089 - Loss: 0.2890546917915344, aux loss1: 0.7529668211936951, 
		 aux loss2: 0.4391939640045166, total loss: 0.6906223297119141
45th Epoch, 34175th Step, learning rate = 0.006506097965779995 - Loss: 0.3057273030281067, aux loss1: 0.7594650387763977, 
		 aux loss2: 0.4256759285926819, total loss: 0.7038372159004211
45th Epoch, 34180th Step, learning rate = 0.00650557350368546 - Loss: 0.41462814807891846, aux loss1: 0.8065172433853149, 
		 aux loss2: 0.5100101232528687, total loss: 0.8605873584747314
45th Epoch, 34185th Step, learning rate = 0.006505049036893024 - Loss: 0.24726490676403046, aux loss1: 0.8580678701400757, 
		 aux loss2: 0.44007086753845215, total loss: 0.6807136535644531
45th Epoch, 34190th Step, learning rate = 0.006504524565402223 - Loss: 0.3385407626628876, aux loss1: 1.0173685550689697, 
		 aux loss2: 0.5918740034103394, total loss: 0.8805009722709656
45th Epoch, 34195th Step, learning rate = 0.0065040000892125915 - Loss: 0.23212121427059174, aux loss1: 0.6776752471923828, 
		 aux loss2: 0.3416464030742645, total loss: 0.5720823407173157
46th Epoch, 34200th Step, learning rate = 0.00650347560832367 - Loss: 0.24422280490398407, aux loss1: 0.7155240774154663, 
		 aux loss2: 0.37387990951538086, total loss: 0.6084319949150085
<34200th step>
*************************** Test ***************************
time:3m 18s, 34200th Step, Loss: 0.5589069128036499, Mean IoU = 45.480%
************************************************************
46th Epoch, 34205th Step, learning rate = 0.006502951122734994 - Loss: 0.2612980604171753, aux loss1: 0.8378061056137085, 
		 aux loss2: 0.4198751747608185, total loss: 0.6805899739265442
46th Epoch, 34210th Step, learning rate = 0.006502426632446098 - Loss: 0.36111345887184143, aux loss1: 0.9594897031784058, 
		 aux loss2: 0.5504781603813171, total loss: 0.8691515922546387
46th Epoch, 34215th Step, learning rate = 0.006501902137456522 - Loss: 0.2880868911743164, aux loss1: 0.9657366871833801, 
		 aux loss2: 0.45792484283447266, total loss: 0.7609778642654419
46th Epoch, 34220th Step, learning rate = 0.006501377637765801 - Loss: 0.29058870673179626, aux loss1: 0.8887009620666504, 
		 aux loss2: 0.44793906807899475, total loss: 0.7363746166229248
46th Epoch, 34225th Step, learning rate = 0.006500853133373471 - Loss: 0.21253342926502228, aux loss1: 0.7034260034561157, 
		 aux loss2: 0.34220650792121887, total loss: 0.5604438781738281
46th Epoch, 34230th Step, learning rate = 0.006500328624279069 - Loss: 0.25650620460510254, aux loss1: 0.7207907438278198, 
		 aux loss2: 0.3849426209926605, total loss: 0.6267204880714417
46th Epoch, 34235th Step, learning rate = 0.00649980411048213 - Loss: 0.2386159896850586, aux loss1: 0.9303776025772095, 
		 aux loss2: 0.4179949164390564, total loss: 0.684927225112915
46th Epoch, 34240th Step, learning rate = 0.0064992795919821935 - Loss: 0.20740929245948792, aux loss1: 0.6082051992416382, 
		 aux loss2: 0.3051791191101074, total loss: 0.5119425058364868
46th Epoch, 34245th Step, learning rate = 0.006498755068778792 - Loss: 0.22647222876548767, aux loss1: 0.7771939635276794, 
		 aux loss2: 0.36533692479133606, total loss: 0.6057652235031128
46th Epoch, 34250th Step, learning rate = 0.006498230540871463 - Loss: 0.2447710931301117, aux loss1: 0.7506526112556458, 
		 aux loss2: 0.4028806686401367, total loss: 0.6311191320419312
46th Epoch, 34255th Step, learning rate = 0.006497706008259744 - Loss: 0.26318132877349854, aux loss1: 0.9184011816978455, 
		 aux loss2: 0.45909810066223145, total loss: 0.7223408818244934
46th Epoch, 34260th Step, learning rate = 0.006497181470943168 - Loss: 0.2379620373249054, aux loss1: 0.7243639826774597, 
		 aux loss2: 0.37441420555114746, total loss: 0.6050369143486023
46th Epoch, 34265th Step, learning rate = 0.006496656928921271 - Loss: 0.2675341069698334, aux loss1: 0.7065178155899048, 
		 aux loss2: 0.38872230052948, total loss: 0.6349783539772034
46th Epoch, 34270th Step, learning rate = 0.00649613238219359 - Loss: 0.22245477139949799, aux loss1: 0.7206773161888123, 
		 aux loss2: 0.3362792134284973, total loss: 0.5731696486473083
46th Epoch, 34275th Step, learning rate = 0.006495607830759661 - Loss: 0.2998707890510559, aux loss1: 0.8312484622001648, 
		 aux loss2: 0.4688832461833954, total loss: 0.7367986440658569
46th Epoch, 34280th Step, learning rate = 0.006495083274619018 - Loss: 0.26011115312576294, aux loss1: 0.6597822904586792, 
		 aux loss2: 0.35390666127204895, total loss: 0.5996085405349731
46th Epoch, 34285th Step, learning rate = 0.0064945587137711985 - Loss: 0.30266571044921875, aux loss1: 0.8309169411659241, 
		 aux loss2: 0.4707510471343994, total loss: 0.7402412295341492
46th Epoch, 34290th Step, learning rate = 0.006494034148215733 - Loss: 0.24972286820411682, aux loss1: 0.763139009475708, 
		 aux loss2: 0.39120563864707947, total loss: 0.6351468563079834
46th Epoch, 34295th Step, learning rate = 0.006493509577952163 - Loss: 0.28213340044021606, aux loss1: 0.8611416220664978, 
		 aux loss2: 0.4643990397453308, total loss: 0.7262355089187622
46th Epoch, 34300th Step, learning rate = 0.0064929850029800205 - Loss: 0.28127604722976685, aux loss1: 0.7134780883789062, 
		 aux loss2: 0.39937978982925415, total loss: 0.6550713777542114
<34300th step>
*************************** Test ***************************
time:3m 17s, 34300th Step, Loss: 0.5811147689819336, Mean IoU = 45.559%
************************************************************
46th Epoch, 34305th Step, learning rate = 0.006492460423298839 - Loss: 0.23627185821533203, aux loss1: 0.7451964616775513, 
		 aux loss2: 0.3519674837589264, total loss: 0.6006178259849548
46th Epoch, 34310th Step, learning rate = 0.006491935838908157 - Loss: 0.28457510471343994, aux loss1: 0.8783420324325562, 
		 aux loss2: 0.46652087569236755, total loss: 0.7346860766410828
46th Epoch, 34315th Step, learning rate = 0.006491411249807507 - Loss: 0.21651865541934967, aux loss1: 0.7053268551826477, 
		 aux loss2: 0.33238574862480164, total loss: 0.5610710382461548
46th Epoch, 34320th Step, learning rate = 0.006490886655996424 - Loss: 0.2760460674762726, aux loss1: 0.7800091505050659, 
		 aux loss2: 0.4425031840801239, total loss: 0.6870501041412354
46th Epoch, 34325th Step, learning rate = 0.006490362057474445 - Loss: 0.24065931141376495, aux loss1: 0.7387140989303589, 
		 aux loss2: 0.3643285632133484, total loss: 0.6080049872398376
46th Epoch, 34330th Step, learning rate = 0.006489837454241101 - Loss: 0.29669299721717834, aux loss1: 0.8345569372177124, 
		 aux loss2: 0.4557333290576935, total loss: 0.7293534874916077
46th Epoch, 34335th Step, learning rate = 0.006489312846295928 - Loss: 0.2980499267578125, aux loss1: 0.8320196270942688, 
		 aux loss2: 0.460544228553772, total loss: 0.7318735122680664
46th Epoch, 34340th Step, learning rate = 0.0064887882336384616 - Loss: 0.2320430874824524, aux loss1: 0.8583401441574097, 
		 aux loss2: 0.4353537857532501, total loss: 0.6636866331100464
46th Epoch, 34345th Step, learning rate = 0.006488263616268235 - Loss: 0.18760423362255096, aux loss1: 0.5941080451011658, 
		 aux loss2: 0.2775738537311554, total loss: 0.4768661856651306
46th Epoch, 34350th Step, learning rate = 0.006487738994184783 - Loss: 0.27243587374687195, aux loss1: 0.7754564881324768, 
		 aux loss2: 0.4130779504776001, total loss: 0.670304000377655
46th Epoch, 34355th Step, learning rate = 0.006487214367387639 - Loss: 0.21752595901489258, aux loss1: 0.7349682450294495, 
		 aux loss2: 0.366702139377594, total loss: 0.5846973061561584
46th Epoch, 34360th Step, learning rate = 0.006486689735876337 - Loss: 0.2887144684791565, aux loss1: 0.7840703725814819, 
		 aux loss2: 0.426151841878891, total loss: 0.6943963170051575
46th Epoch, 34365th Step, learning rate = 0.006486165099650413 - Loss: 0.195815771818161, aux loss1: 0.6044143438339233, 
		 aux loss2: 0.31042492389678955, total loss: 0.5013100504875183
46th Epoch, 34370th Step, learning rate = 0.006485640458709398 - Loss: 0.2395629733800888, aux loss1: 0.7742613554000854, 
		 aux loss2: 0.38621285557746887, total loss: 0.6263265609741211
46th Epoch, 34375th Step, learning rate = 0.006485115813052828 - Loss: 0.23669712245464325, aux loss1: 0.7398720979690552, 
		 aux loss2: 0.38499733805656433, total loss: 0.6126576662063599
46th Epoch, 34380th Step, learning rate = 0.006484591162680237 - Loss: 0.4616298973560333, aux loss1: 1.4589475393295288, 
		 aux loss2: 0.8931864500045776, total loss: 1.2565886974334717
46th Epoch, 34385th Step, learning rate = 0.006484066507591155 - Loss: 0.28490006923675537, aux loss1: 0.7814176082611084, 
		 aux loss2: 0.4212322235107422, total loss: 0.6878182888031006
46th Epoch, 34390th Step, learning rate = 0.00648354184778512 - Loss: 0.30563288927078247, aux loss1: 0.9667197465896606, 
		 aux loss2: 0.5314902663230896, total loss: 0.8082449436187744
46th Epoch, 34395th Step, learning rate = 0.006483017183261663 - Loss: 0.32076534628868103, aux loss1: 0.9646880626678467, 
		 aux loss2: 0.543535053730011, total loss: 0.8275858163833618
46th Epoch, 34400th Step, learning rate = 0.00648249251402032 - Loss: 0.22898533940315247, aux loss1: 0.6960009336471558, 
		 aux loss2: 0.34969326853752136, total loss: 0.5776629447937012
<34400th step>
*************************** Test ***************************
time:3m 20s, 34400th Step, Loss: 0.5692897439002991, Mean IoU = 46.831%
************************************************************
46th Epoch, 34405th Step, learning rate = 0.00648196784006062 - Loss: 0.2818942666053772, aux loss1: 0.8829922080039978, 
		 aux loss2: 0.44594261050224304, total loss: 0.7251689434051514
46th Epoch, 34410th Step, learning rate = 0.0064814431613821 - Loss: 0.34243044257164, aux loss1: 1.007016897201538, 
		 aux loss2: 0.5855354070663452, total loss: 0.8787497282028198
46th Epoch, 34415th Step, learning rate = 0.006480918477984289 - Loss: 0.2638673782348633, aux loss1: 0.7966448068618774, 
		 aux loss2: 0.4206838011741638, total loss: 0.671134352684021
46th Epoch, 34420th Step, learning rate = 0.006480393789866725 - Loss: 0.3472519814968109, aux loss1: 1.0228253602981567, 
		 aux loss2: 0.5945026874542236, total loss: 0.8919006586074829
46th Epoch, 34425th Step, learning rate = 0.006479869097028939 - Loss: 0.2570636570453644, aux loss1: 0.867617130279541, 
		 aux loss2: 0.4219796359539032, total loss: 0.6861406564712524
46th Epoch, 34430th Step, learning rate = 0.0064793443994704625 - Loss: 0.3855662941932678, aux loss1: 0.9975162148475647, 
		 aux loss2: 0.5690757036209106, total loss: 0.9124513864517212
46th Epoch, 34435th Step, learning rate = 0.00647881969719083 - Loss: 0.3025277554988861, aux loss1: 0.8687998652458191, 
		 aux loss2: 0.49225977063179016, total loss: 0.7600716352462769
46th Epoch, 34440th Step, learning rate = 0.006478294990189573 - Loss: 0.35993102192878723, aux loss1: 0.938033401966095, 
		 aux loss2: 0.5279104709625244, total loss: 0.8525052666664124
46th Epoch, 34445th Step, learning rate = 0.006477770278466224 - Loss: 0.25810906291007996, aux loss1: 0.7215273380279541, 
		 aux loss2: 0.36302047967910767, total loss: 0.6197754740715027
46th Epoch, 34450th Step, learning rate = 0.006477245562020318 - Loss: 0.32168886065483093, aux loss1: 0.9403934478759766, 
		 aux loss2: 0.48108747601509094, total loss: 0.7962418794631958
46th Epoch, 34455th Step, learning rate = 0.0064767208408513825 - Loss: 0.2788146734237671, aux loss1: 0.8471609354019165, 
		 aux loss2: 0.4339621365070343, total loss: 0.7065478563308716
46th Epoch, 34460th Step, learning rate = 0.006476196114958955 - Loss: 0.2970229983329773, aux loss1: 0.7489327788352966, 
		 aux loss2: 0.4153798222541809, total loss: 0.6878547668457031
46th Epoch, 34465th Step, learning rate = 0.006475671384342564 - Loss: 0.2549685537815094, aux loss1: 0.71614670753479, 
		 aux loss2: 0.3785642087459564, total loss: 0.6212382316589355
46th Epoch, 34470th Step, learning rate = 0.006475146649001743 - Loss: 0.26638516783714294, aux loss1: 0.8171742558479309, 
		 aux loss2: 0.4037426710128784, total loss: 0.6730344891548157
46th Epoch, 34475th Step, learning rate = 0.006474621908936024 - Loss: 0.3262835443019867, aux loss1: 0.8345552086830139, 
		 aux loss2: 0.48107215762138367, total loss: 0.7690790295600891
46th Epoch, 34480th Step, learning rate = 0.006474097164144942 - Loss: 0.3690643310546875, aux loss1: 0.9027878046035767, 
		 aux loss2: 0.5183964967727661, total loss: 0.8472592830657959
46th Epoch, 34485th Step, learning rate = 0.006473572414628023 - Loss: 0.277583509683609, aux loss1: 0.7840229272842407, 
		 aux loss2: 0.4183211028575897, total loss: 0.6801187992095947
46th Epoch, 34490th Step, learning rate = 0.006473047660384803 - Loss: 0.26966041326522827, aux loss1: 0.8198055624961853, 
		 aux loss2: 0.41905829310417175, total loss: 0.6832254528999329
46th Epoch, 34495th Step, learning rate = 0.006472522901414812 - Loss: 0.23799529671669006, aux loss1: 0.7547764182090759, 
		 aux loss2: 0.4162171185016632, total loss: 0.630915105342865
46th Epoch, 34500th Step, learning rate = 0.006471998137717582 - Loss: 0.26059314608573914, aux loss1: 0.7049384713172913, 
		 aux loss2: 0.37023240327835083, total loss: 0.6201676726341248
<34500th step>
*************************** Test ***************************
time:3m 16s, 34500th Step, Loss: 0.584696888923645, Mean IoU = 46.342%
************************************************************
46th Epoch, 34505th Step, learning rate = 0.006471473369292645 - Loss: 0.2434442639350891, aux loss1: 0.7240643501281738, 
		 aux loss2: 0.36568012833595276, total loss: 0.6069356203079224
46th Epoch, 34510th Step, learning rate = 0.006470948596139532 - Loss: 0.2690314054489136, aux loss1: 0.813481867313385, 
		 aux loss2: 0.45380300283432007, total loss: 0.6945971250534058
46th Epoch, 34515th Step, learning rate = 0.006470423818257774 - Loss: 0.5289067625999451, aux loss1: 1.088417410850525, 
		 aux loss2: 0.759961724281311, total loss: 1.159416675567627
46th Epoch, 34520th Step, learning rate = 0.006469899035646904 - Loss: 0.36488258838653564, aux loss1: 0.8938783407211304, 
		 aux loss2: 0.5364853143692017, total loss: 0.8476402163505554
46th Epoch, 34525th Step, learning rate = 0.006469374248306451 - Loss: 0.2369212508201599, aux loss1: 0.6340950131416321, 
		 aux loss2: 0.34803882241249084, total loss: 0.5663653016090393
46th Epoch, 34530th Step, learning rate = 0.006468849456235947 - Loss: 0.2895722985267639, aux loss1: 0.7146090865135193, 
		 aux loss2: 0.391247421503067, total loss: 0.6604539752006531
46th Epoch, 34535th Step, learning rate = 0.0064683246594349235 - Loss: 0.24140489101409912, aux loss1: 0.6997926235198975, 
		 aux loss2: 0.3531014919281006, total loss: 0.5925832986831665
46th Epoch, 34540th Step, learning rate = 0.00646779985790291 - Loss: 0.2608814239501953, aux loss1: 0.7397787570953369, 
		 aux loss2: 0.41090312600135803, total loss: 0.6471763253211975
46th Epoch, 34545th Step, learning rate = 0.006467275051639438 - Loss: 0.3012380003929138, aux loss1: 0.743661642074585, 
		 aux loss2: 0.42297327518463135, total loss: 0.6935258507728577
46th Epoch, 34550th Step, learning rate = 0.006466750240644038 - Loss: 0.2761560082435608, aux loss1: 0.7101410627365112, 
		 aux loss2: 0.38699084520339966, total loss: 0.6439946889877319
46th Epoch, 34555th Step, learning rate = 0.006466225424916242 - Loss: 0.32502734661102295, aux loss1: 0.9304306507110596, 
		 aux loss2: 0.5073679685592651, total loss: 0.8071037530899048
46th Epoch, 34560th Step, learning rate = 0.00646570060445558 - Loss: 0.31818699836730957, aux loss1: 0.9982210397720337, 
		 aux loss2: 0.5551823377609253, total loss: 0.8397262692451477
46th Epoch, 34565th Step, learning rate = 0.006465175779261581 - Loss: 0.2893172800540924, aux loss1: 0.8314138650894165, 
		 aux loss2: 0.4498254656791687, total loss: 0.7186716794967651
47th Epoch, 34570th Step, learning rate = 0.006464650949333777 - Loss: 0.3566111922264099, aux loss1: 0.9544070363044739, 
		 aux loss2: 0.603228747844696, total loss: 0.8842248320579529
47th Epoch, 34575th Step, learning rate = 0.006464126114671698 - Loss: 0.27822035551071167, aux loss1: 0.9819507002830505, 
		 aux loss2: 0.5204689502716064, total loss: 0.7809931635856628
47th Epoch, 34580th Step, learning rate = 0.006463601275274872 - Loss: 0.28093329071998596, aux loss1: 0.8976719975471497, 
		 aux loss2: 0.4647435247898102, total loss: 0.7361323237419128
47th Epoch, 34585th Step, learning rate = 0.006463076431142832 - Loss: 0.27998974919319153, aux loss1: 0.8262028098106384, 
		 aux loss2: 0.4456215798854828, total loss: 0.706099271774292
47th Epoch, 34590th Step, learning rate = 0.006462551582275108 - Loss: 0.2741357386112213, aux loss1: 0.8160912990570068, 
		 aux loss2: 0.4176352024078369, total loss: 0.6860172748565674
47th Epoch, 34595th Step, learning rate = 0.006462026728671227 - Loss: 0.2423875778913498, aux loss1: 0.8102201223373413, 
		 aux loss2: 0.4084327816963196, total loss: 0.6488267183303833
47th Epoch, 34600th Step, learning rate = 0.006461501870330721 - Loss: 0.3059104084968567, aux loss1: 0.7456504106521606, 
		 aux loss2: 0.4212017357349396, total loss: 0.6980862021446228
<34600th step>
*************************** Test ***************************
time:3m 18s, 34600th Step, Loss: 0.5474934577941895, Mean IoU = 45.588%
************************************************************
47th Epoch, 34605th Step, learning rate = 0.0064609770072531205 - Loss: 0.2603393495082855, aux loss1: 0.9315927028656006, 
		 aux loss2: 0.5097866654396057, total loss: 0.7437318563461304
47th Epoch, 34610th Step, learning rate = 0.006460452139437954 - Loss: 0.2891797125339508, aux loss1: 0.8385829925537109, 
		 aux loss2: 0.4555783271789551, total loss: 0.7229859828948975
47th Epoch, 34615th Step, learning rate = 0.006459927266884752 - Loss: 0.37127685546875, aux loss1: 1.0297259092330933, 
		 aux loss2: 0.6511116623878479, total loss: 0.9406392574310303
47th Epoch, 34620th Step, learning rate = 0.006459402389593042 - Loss: 0.28559139370918274, aux loss1: 0.7916157245635986, 
		 aux loss2: 0.4359540045261383, total loss: 0.6974577307701111
47th Epoch, 34625th Step, learning rate = 0.006458877507562354 - Loss: 0.2523341178894043, aux loss1: 0.7056906223297119, 
		 aux loss2: 0.3762759566307068, total loss: 0.6145516633987427
47th Epoch, 34630th Step, learning rate = 0.006458352620792219 - Loss: 0.3047441244125366, aux loss1: 0.8952788710594177, 
		 aux loss2: 0.4798074960708618, total loss: 0.7652508020401001
47th Epoch, 34635th Step, learning rate = 0.006457827729282165 - Loss: 0.21751877665519714, aux loss1: 0.7120757102966309, 
		 aux loss2: 0.32521000504493713, total loss: 0.5612255334854126
47th Epoch, 34640th Step, learning rate = 0.006457302833031721 - Loss: 0.2876140773296356, aux loss1: 0.8458471298217773, 
		 aux loss2: 0.472215473651886, total loss: 0.7302544116973877
47th Epoch, 34645th Step, learning rate = 0.0064567779320404165 - Loss: 0.42937564849853516, aux loss1: 1.0068100690841675, 
		 aux loss2: 0.6048468351364136, total loss: 0.9733574390411377
47th Epoch, 34650th Step, learning rate = 0.006456253026307779 - Loss: 0.2943010628223419, aux loss1: 0.9813116192817688, 
		 aux loss2: 0.5242166519165039, total loss: 0.7983812093734741
47th Epoch, 34655th Step, learning rate = 0.0064557281158333394 - Loss: 0.2743821144104004, aux loss1: 0.8754358887672424, 
		 aux loss2: 0.5084635615348816, total loss: 0.7403983473777771
47th Epoch, 34660th Step, learning rate = 0.006455203200616626 - Loss: 0.27531903982162476, aux loss1: 0.8157041668891907, 
		 aux loss2: 0.43474653363227844, total loss: 0.6939289569854736
47th Epoch, 34665th Step, learning rate = 0.006454678280657166 - Loss: 0.2991805076599121, aux loss1: 0.917374849319458, 
		 aux loss2: 0.5048555731773376, total loss: 0.7763352394104004
47th Epoch, 34670th Step, learning rate = 0.0064541533559544905 - Loss: 0.30247196555137634, aux loss1: 0.8012151718139648, 
		 aux loss2: 0.45860761404037476, total loss: 0.726279616355896
47th Epoch, 34675th Step, learning rate = 0.006453628426508126 - Loss: 0.27116280794143677, aux loss1: 0.8881233334541321, 
		 aux loss2: 0.46110543608665466, total loss: 0.7220419645309448
47th Epoch, 34680th Step, learning rate = 0.0064531034923176 - Loss: 0.3126845955848694, aux loss1: 0.841655969619751, 
		 aux loss2: 0.4680282175540924, total loss: 0.7523926496505737
47th Epoch, 34685th Step, learning rate = 0.0064525785533824445 - Loss: 0.23008152842521667, aux loss1: 0.7669614553451538, 
		 aux loss2: 0.35379528999328613, total loss: 0.6016880869865417
47th Epoch, 34690th Step, learning rate = 0.006452053609702184 - Loss: 0.23594486713409424, aux loss1: 0.7839177846908569, 
		 aux loss2: 0.3972194492816925, total loss: 0.6300079822540283
47th Epoch, 34695th Step, learning rate = 0.006451528661276349 - Loss: 0.22568145394325256, aux loss1: 0.6733531355857849, 
		 aux loss2: 0.33377137780189514, total loss: 0.561195969581604
47th Epoch, 34700th Step, learning rate = 0.006451003708104467 - Loss: 0.2788632810115814, aux loss1: 0.8785685896873474, 
		 aux loss2: 0.46743902564048767, total loss: 0.7294094562530518
<34700th step>
*************************** Test ***************************
time:3m 18s, 34700th Step, Loss: 0.5556911826133728, Mean IoU = 45.952%
************************************************************
47th Epoch, 34705th Step, learning rate = 0.006450478750186065 - Loss: 0.36557242274284363, aux loss1: 1.1058493852615356, 
		 aux loss2: 0.6587784290313721, total loss: 0.9608386754989624
47th Epoch, 34710th Step, learning rate = 0.0064499537875206715 - Loss: 0.2474873661994934, aux loss1: 0.7409082651138306, 
		 aux loss2: 0.3802236318588257, total loss: 0.6218492984771729
47th Epoch, 34715th Step, learning rate = 0.006449428820107814 - Loss: 0.255054771900177, aux loss1: 0.7179157137870789, 
		 aux loss2: 0.39061811566352844, total loss: 0.6266767382621765
47th Epoch, 34720th Step, learning rate = 0.0064489038479470205 - Loss: 0.25085657835006714, aux loss1: 0.8263677954673767, 
		 aux loss2: 0.4191715717315674, total loss: 0.6664355397224426
47th Epoch, 34725th Step, learning rate = 0.00644837887103782 - Loss: 0.31911852955818176, aux loss1: 0.8938658833503723, 
		 aux loss2: 0.5461847186088562, total loss: 0.8057522177696228
47th Epoch, 34730th Step, learning rate = 0.0064478538893797364 - Loss: 0.25905683636665344, aux loss1: 0.7672802805900574, 
		 aux loss2: 0.40768566727638245, total loss: 0.6523151993751526
47th Epoch, 34735th Step, learning rate = 0.0064473289029723015 - Loss: 0.27854272723197937, aux loss1: 0.8416587710380554, 
		 aux loss2: 0.44812270998954773, total loss: 0.710289478302002
47th Epoch, 34740th Step, learning rate = 0.00644680391181504 - Loss: 0.1813116818666458, aux loss1: 0.6125826239585876, 
		 aux loss2: 0.29274022579193115, total loss: 0.4821825921535492
47th Epoch, 34745th Step, learning rate = 0.006446278915907479 - Loss: 0.27186039090156555, aux loss1: 0.7851231694221497, 
		 aux loss2: 0.4256512522697449, total loss: 0.6776578426361084
47th Epoch, 34750th Step, learning rate = 0.006445753915249146 - Loss: 0.3190793991088867, aux loss1: 0.926918625831604, 
		 aux loss2: 0.4933581054210663, total loss: 0.7944982051849365
47th Epoch, 34755th Step, learning rate = 0.006445228909839569 - Loss: 0.26591190695762634, aux loss1: 0.73619544506073, 
		 aux loss2: 0.40527963638305664, total loss: 0.6488824486732483
47th Epoch, 34760th Step, learning rate = 0.006444703899678273 - Loss: 0.2552647590637207, aux loss1: 0.8645820617675781, 
		 aux loss2: 0.44488251209259033, total loss: 0.6925923824310303
47th Epoch, 34765th Step, learning rate = 0.0064441788847647875 - Loss: 0.2760460674762726, aux loss1: 0.7378774285316467, 
		 aux loss2: 0.4007883071899414, total loss: 0.6577246189117432
47th Epoch, 34770th Step, learning rate = 0.006443653865098639 - Loss: 0.21322916448116302, aux loss1: 0.650370717048645, 
		 aux loss2: 0.30843716859817505, total loss: 0.5317152738571167
47th Epoch, 34775th Step, learning rate = 0.00644312884067935 - Loss: 0.2477671205997467, aux loss1: 0.8032987117767334, 
		 aux loss2: 0.4042619466781616, total loss: 0.6504615545272827
47th Epoch, 34780th Step, learning rate = 0.006442603811506453 - Loss: 0.3078671991825104, aux loss1: 0.8908514976501465, 
		 aux loss2: 0.5301429629325867, total loss: 0.7871798276901245
47th Epoch, 34785th Step, learning rate = 0.006442078777579471 - Loss: 0.2833327054977417, aux loss1: 0.7679690718650818, 
		 aux loss2: 0.4395756423473358, total loss: 0.6895536780357361
47th Epoch, 34790th Step, learning rate = 0.006441553738897931 - Loss: 0.2815094292163849, aux loss1: 0.9832170605659485, 
		 aux loss2: 0.4510160982608795, total loss: 0.7568809986114502
47th Epoch, 34795th Step, learning rate = 0.006441028695461359 - Loss: 0.3245144486427307, aux loss1: 0.8221011757850647, 
		 aux loss2: 0.46907511353492737, total loss: 0.7587748765945435
47th Epoch, 34800th Step, learning rate = 0.0064405036472692835 - Loss: 0.28592634201049805, aux loss1: 0.8088829517364502, 
		 aux loss2: 0.4628751873970032, total loss: 0.7137413024902344
<34800th step>
*************************** Test ***************************
time:3m 18s, 34800th Step, Loss: 0.575485348701477, Mean IoU = 46.724%
************************************************************
47th Epoch, 34805th Step, learning rate = 0.0064399785943212275 - Loss: 0.19475537538528442, aux loss1: 0.5995165705680847, 
		 aux loss2: 0.28914427757263184, total loss: 0.4902680814266205
47th Epoch, 34810th Step, learning rate = 0.006439453536616719 - Loss: 0.2934790551662445, aux loss1: 0.7705124020576477, 
		 aux loss2: 0.4362497925758362, total loss: 0.6991327404975891
47th Epoch, 34815th Step, learning rate = 0.0064389284741552845 - Loss: 0.31100958585739136, aux loss1: 0.8526934385299683, 
		 aux loss2: 0.4664568603038788, total loss: 0.7534003853797913
47th Epoch, 34820th Step, learning rate = 0.006438403406936447 - Loss: 0.2828613817691803, aux loss1: 0.9723663330078125, 
		 aux loss2: 0.45743533968925476, total loss: 0.7575454115867615
47th Epoch, 34825th Step, learning rate = 0.006437878334959737 - Loss: 0.3101339340209961, aux loss1: 0.9993407130241394, 
		 aux loss2: 0.5520246028900146, total loss: 0.8307459354400635
47th Epoch, 34830th Step, learning rate = 0.006437353258224675 - Loss: 0.29940587282180786, aux loss1: 0.9852344393730164, 
		 aux loss2: 0.5284689664840698, total loss: 0.8063637614250183
47th Epoch, 34835th Step, learning rate = 0.006436828176730789 - Loss: 0.28839948773384094, aux loss1: 0.9594110250473022, 
		 aux loss2: 0.4902229309082031, total loss: 0.7723119258880615
47th Epoch, 34840th Step, learning rate = 0.006436303090477606 - Loss: 0.23541061580181122, aux loss1: 0.7250701785087585, 
		 aux loss2: 0.37214481830596924, total loss: 0.6017895936965942
47th Epoch, 34845th Step, learning rate = 0.006435777999464648 - Loss: 0.2572230398654938, aux loss1: 0.7170010209083557, 
		 aux loss2: 0.3942970931529999, total loss: 0.6300421953201294
47th Epoch, 34850th Step, learning rate = 0.006435252903691445 - Loss: 0.23265323042869568, aux loss1: 0.7546041011810303, 
		 aux loss2: 0.37472766637802124, total loss: 0.6089255213737488
47th Epoch, 34855th Step, learning rate = 0.006434727803157518 - Loss: 0.2908032536506653, aux loss1: 0.8586959838867188, 
		 aux loss2: 0.4681618809700012, total loss: 0.7356768250465393
47th Epoch, 34860th Step, learning rate = 0.006434202697862395 - Loss: 0.28967276215553284, aux loss1: 0.7716339826583862, 
		 aux loss2: 0.43391990661621094, total loss: 0.6947309374809265
47th Epoch, 34865th Step, learning rate = 0.0064336775878056 - Loss: 0.22889767587184906, aux loss1: 0.7494327425956726, 
		 aux loss2: 0.3590458035469055, total loss: 0.5973458290100098
47th Epoch, 34870th Step, learning rate = 0.006433152472986656 - Loss: 0.23700442910194397, aux loss1: 0.8193660974502563, 
		 aux loss2: 0.4252663254737854, total loss: 0.6529207825660706
47th Epoch, 34875th Step, learning rate = 0.006432627353405091 - Loss: 0.2480972707271576, aux loss1: 0.6852108836174011, 
		 aux loss2: 0.3281921148300171, total loss: 0.5849373936653137
47th Epoch, 34880th Step, learning rate = 0.006432102229060429 - Loss: 0.2615768015384674, aux loss1: 0.6994830965995789, 
		 aux loss2: 0.370435893535614, total loss: 0.6195960640907288
47th Epoch, 34885th Step, learning rate = 0.006431577099952193 - Loss: 0.3011443018913269, aux loss1: 0.9103807806968689, 
		 aux loss2: 0.5055531859397888, total loss: 0.7764798402786255
47th Epoch, 34890th Step, learning rate = 0.00643105196607991 - Loss: 0.21910260617733002, aux loss1: 0.6233348846435547, 
		 aux loss2: 0.32222771644592285, total loss: 0.5349941849708557
47th Epoch, 34895th Step, learning rate = 0.006430526827443104 - Loss: 0.2788209915161133, aux loss1: 0.6930104494094849, 
		 aux loss2: 0.38934922218322754, total loss: 0.6424638032913208
47th Epoch, 34900th Step, learning rate = 0.006430001684041297 - Loss: 0.36009281873703003, aux loss1: 0.9501833319664001, 
		 aux loss2: 0.5404419898986816, total loss: 0.8613246083259583
<34900th step>
*************************** Test ***************************
time:3m 19s, 34900th Step, Loss: 0.5527812838554382, Mean IoU = 46.580%
************************************************************
47th Epoch, 34905th Step, learning rate = 0.006429476535874016 - Loss: 0.29740768671035767, aux loss1: 0.9752121567726135, 
		 aux loss2: 0.5165610313415527, total loss: 0.7965956926345825
47th Epoch, 34910th Step, learning rate = 0.006428951382940785 - Loss: 0.2302708476781845, aux loss1: 0.7054175138473511, 
		 aux loss2: 0.3630909323692322, total loss: 0.587132453918457
47th Epoch, 34915th Step, learning rate = 0.006428426225241127 - Loss: 0.3610846698284149, aux loss1: 0.915134608745575, 
		 aux loss2: 0.541089653968811, total loss: 0.8520609140396118
47th Epoch, 34920th Step, learning rate = 0.006427901062774568 - Loss: 0.26743850111961365, aux loss1: 0.7676839828491211, 
		 aux loss2: 0.3955705761909485, total loss: 0.6559719443321228
47th Epoch, 34925th Step, learning rate = 0.00642737589554063 - Loss: 0.25402897596359253, aux loss1: 0.8708966970443726, 
		 aux loss2: 0.40867558121681213, total loss: 0.6787682771682739
47th Epoch, 34930th Step, learning rate = 0.006426850723538838 - Loss: 0.276993066072464, aux loss1: 0.9147704243659973, 
		 aux loss2: 0.4701893925666809, total loss: 0.7394999861717224
47th Epoch, 34935th Step, learning rate = 0.0064263255467687155 - Loss: 0.25734809041023254, aux loss1: 0.7870248556137085, 
		 aux loss2: 0.39613792300224304, total loss: 0.6519107222557068
48th Epoch, 34940th Step, learning rate = 0.0064258003652297845 - Loss: 0.23353704810142517, aux loss1: 0.8416405916213989, 
		 aux loss2: 0.4134613871574402, total loss: 0.6514137983322144
48th Epoch, 34945th Step, learning rate = 0.006425275178921572 - Loss: 0.24108214676380157, aux loss1: 0.8355932831764221, 
		 aux loss2: 0.3882181644439697, total loss: 0.6470474004745483
48th Epoch, 34950th Step, learning rate = 0.0064247499878436 - Loss: 0.29100504517555237, aux loss1: 0.9413509368896484, 
		 aux loss2: 0.5017377734184265, total loss: 0.774105429649353
48th Epoch, 34955th Step, learning rate = 0.006424224791995391 - Loss: 0.26409968733787537, aux loss1: 0.8055143356323242, 
		 aux loss2: 0.4188452661037445, total loss: 0.6732921004295349
48th Epoch, 34960th Step, learning rate = 0.006423699591376469 - Loss: 0.2541194558143616, aux loss1: 0.8057488203048706, 
		 aux loss2: 0.4171241223812103, total loss: 0.6626937985420227
48th Epoch, 34965th Step, learning rate = 0.00642317438598636 - Loss: 0.2684953510761261, aux loss1: 0.8122873902320862, 
		 aux loss2: 0.4331159293651581, total loss: 0.6854279637336731
48th Epoch, 34970th Step, learning rate = 0.0064226491758245805 - Loss: 0.1883605420589447, aux loss1: 0.633417546749115, 
		 aux loss2: 0.302924782037735, total loss: 0.4995557367801666
48th Epoch, 34975th Step, learning rate = 0.006422123960890661 - Loss: 0.28833016753196716, aux loss1: 0.7618353962898254, 
		 aux loss2: 0.4612921178340912, total loss: 0.7013976573944092
48th Epoch, 34980th Step, learning rate = 0.006421598741184119 - Loss: 0.27916061878204346, aux loss1: 0.9743400812149048, 
		 aux loss2: 0.44992515444755554, total loss: 0.7514327168464661
48th Epoch, 34985th Step, learning rate = 0.006421073516704481 - Loss: 0.20666296780109406, aux loss1: 0.6638317704200745, 
		 aux loss2: 0.3550878167152405, total loss: 0.5478476285934448
48th Epoch, 34990th Step, learning rate = 0.006420548287451269 - Loss: 0.3749829828739166, aux loss1: 0.9682124257087708, 
		 aux loss2: 0.5431609153747559, total loss: 0.8827111124992371
48th Epoch, 34995th Step, learning rate = 0.0064200230534240035 - Loss: 0.2589465081691742, aux loss1: 0.7830890417098999, 
		 aux loss2: 0.4040713310241699, total loss: 0.6555017828941345
48th Epoch, 35000th Step, learning rate = 0.00641949781462221 - Loss: 0.23716968297958374, aux loss1: 0.7381589412689209, 
		 aux loss2: 0.3905453681945801, total loss: 0.6148355603218079
<35000th step>
*************************** Test ***************************
time:3m 19s, 35000th Step, Loss: 0.5855215191841125, Mean IoU = 45.480%
************************************************************
48th Epoch, 35005th Step, learning rate = 0.006418972571045408 - Loss: 0.24468377232551575, aux loss1: 0.7470693588256836, 
		 aux loss2: 0.389790803194046, total loss: 0.6247209310531616
48th Epoch, 35010th Step, learning rate = 0.006418447322693123 - Loss: 0.22631151974201202, aux loss1: 0.7439051270484924, 
		 aux loss2: 0.3872945308685303, total loss: 0.6044008731842041
48th Epoch, 35015th Step, learning rate = 0.006417922069564875 - Loss: 0.2559581696987152, aux loss1: 0.7716963887214661, 
		 aux loss2: 0.40725770592689514, total loss: 0.650370180606842
48th Epoch, 35020th Step, learning rate = 0.00641739681166019 - Loss: 0.2739608585834503, aux loss1: 0.7348655462265015, 
		 aux loss2: 0.4000961482524872, total loss: 0.6544589996337891
48th Epoch, 35025th Step, learning rate = 0.006416871548978584 - Loss: 0.29693174362182617, aux loss1: 0.8463472127914429, 
		 aux loss2: 0.46848613023757935, total loss: 0.7382303476333618
48th Epoch, 35030th Step, learning rate = 0.006416346281519585 - Loss: 0.24060572683811188, aux loss1: 0.7495488524436951, 
		 aux loss2: 0.4023471772670746, total loss: 0.6264092326164246
48th Epoch, 35035th Step, learning rate = 0.006415821009282712 - Loss: 0.2975752353668213, aux loss1: 1.0369535684585571, 
		 aux loss2: 0.5739317536354065, total loss: 0.838234007358551
48th Epoch, 35040th Step, learning rate = 0.006415295732267487 - Loss: 0.30196714401245117, aux loss1: 0.8189564347267151, 
		 aux loss2: 0.4691430628299713, total loss: 0.7353113293647766
48th Epoch, 35045th Step, learning rate = 0.006414770450473433 - Loss: 0.2585987448692322, aux loss1: 0.8188173770904541, 
		 aux loss2: 0.4307832717895508, total loss: 0.6765573024749756
48th Epoch, 35050th Step, learning rate = 0.006414245163900071 - Loss: 0.2724780738353729, aux loss1: 0.7539856433868408, 
		 aux loss2: 0.4230951964855194, total loss: 0.6679118871688843
48th Epoch, 35055th Step, learning rate = 0.006413719872546922 - Loss: 0.24577799439430237, aux loss1: 0.8067024350166321, 
		 aux loss2: 0.43508946895599365, total loss: 0.6618245244026184
48th Epoch, 35060th Step, learning rate = 0.006413194576413508 - Loss: 0.23221555352210999, aux loss1: 0.7447109222412109, 
		 aux loss2: 0.3718326687812805, total loss: 0.604361891746521
48th Epoch, 35065th Step, learning rate = 0.006412669275499351 - Loss: 0.16943636536598206, aux loss1: 0.7005838751792908, 
		 aux loss2: 0.2767564356327057, total loss: 0.4903141260147095
48th Epoch, 35070th Step, learning rate = 0.006412143969803972 - Loss: 0.3117714524269104, aux loss1: 0.8574767112731934, 
		 aux loss2: 0.4877386689186096, total loss: 0.7641099691390991
48th Epoch, 35075th Step, learning rate = 0.006411618659326893 - Loss: 0.27030545473098755, aux loss1: 0.78257155418396, 
		 aux loss2: 0.4378180503845215, total loss: 0.6802041530609131
48th Epoch, 35080th Step, learning rate = 0.006411093344067631 - Loss: 0.2062770575284958, aux loss1: 0.7110344171524048, 
		 aux loss2: 0.34261900186538696, total loss: 0.5566349625587463
48th Epoch, 35085th Step, learning rate = 0.006410568024025715 - Loss: 0.19795961678028107, aux loss1: 0.6430674195289612, 
		 aux loss2: 0.2953949570655823, total loss: 0.5090378522872925
48th Epoch, 35090th Step, learning rate = 0.006410042699200658 - Loss: 0.25685855746269226, aux loss1: 0.8908290266990662, 
		 aux loss2: 0.4044428765773773, total loss: 0.685884416103363
48th Epoch, 35095th Step, learning rate = 0.0064095173695919855 - Loss: 0.27165237069129944, aux loss1: 0.8140993118286133, 
		 aux loss2: 0.43561965227127075, total loss: 0.6901300549507141
48th Epoch, 35100th Step, learning rate = 0.006408992035199218 - Loss: 0.3187139630317688, aux loss1: 0.934543251991272, 
		 aux loss2: 0.5652512311935425, total loss: 0.8251774907112122
<35100th step>
*************************** Test ***************************
time:3m 21s, 35100th Step, Loss: 0.5367395281791687, Mean IoU = 46.608%
************************************************************
48th Epoch, 35105th Step, learning rate = 0.006408466696021874 - Loss: 0.32702699303627014, aux loss1: 0.9088592529296875, 
		 aux loss2: 0.5215259194374084, total loss: 0.8082951307296753
48th Epoch, 35110th Step, learning rate = 0.0064079413520594765 - Loss: 0.303786039352417, aux loss1: 0.9388953447341919, 
		 aux loss2: 0.5030360221862793, total loss: 0.7866690754890442
48th Epoch, 35115th Step, learning rate = 0.006407416003311545 - Loss: 0.3777483105659485, aux loss1: 1.1983332633972168, 
		 aux loss2: 0.6655400991439819, total loss: 1.0034643411636353
48th Epoch, 35120th Step, learning rate = 0.006406890649777599 - Loss: 0.2629873752593994, aux loss1: 0.7655977606773376, 
		 aux loss2: 0.40270334482192993, total loss: 0.6537480354309082
48th Epoch, 35125th Step, learning rate = 0.006406365291457159 - Loss: 0.2804870009422302, aux loss1: 1.0119824409484863, 
		 aux loss2: 0.5904749035835266, total loss: 0.8202717304229736
48th Epoch, 35130th Step, learning rate = 0.006405839928349748 - Loss: 0.31554365158081055, aux loss1: 0.7827901244163513, 
		 aux loss2: 0.41898220777511597, total loss: 0.7179735898971558
48th Epoch, 35135th Step, learning rate = 0.006405314560454883 - Loss: 0.36053937673568726, aux loss1: 1.0960623025894165, 
		 aux loss2: 0.5887324810028076, total loss: 0.92485111951828
48th Epoch, 35140th Step, learning rate = 0.006404789187772085 - Loss: 0.25825235247612, aux loss1: 0.8045294284820557, 
		 aux loss2: 0.4140739142894745, total loss: 0.6652407646179199
48th Epoch, 35145th Step, learning rate = 0.006404263810300875 - Loss: 0.25404390692710876, aux loss1: 0.7469469308853149, 
		 aux loss2: 0.39872288703918457, total loss: 0.6376171708106995
48th Epoch, 35150th Step, learning rate = 0.00640373842804077 - Loss: 0.2304185926914215, aux loss1: 0.6796321868896484, 
		 aux loss2: 0.36168041825294495, total loss: 0.5789804458618164
48th Epoch, 35155th Step, learning rate = 0.006403213040991295 - Loss: 0.24480971693992615, aux loss1: 0.7907586097717285, 
		 aux loss2: 0.42233261466026306, total loss: 0.6509703397750854
48th Epoch, 35160th Step, learning rate = 0.006402687649151965 - Loss: 0.2611432373523712, aux loss1: 0.8375555872917175, 
		 aux loss2: 0.4176807105541229, total loss: 0.6794822216033936
48th Epoch, 35165th Step, learning rate = 0.006402162252522301 - Loss: 0.2774221897125244, aux loss1: 0.803244948387146, 
		 aux loss2: 0.43542584776878357, total loss: 0.6925660371780396
48th Epoch, 35170th Step, learning rate = 0.006401636851101823 - Loss: 0.2491995394229889, aux loss1: 0.8690581321716309, 
		 aux loss2: 0.44773581624031067, total loss: 0.6890113353729248
48th Epoch, 35175th Step, learning rate = 0.006401111444890049 - Loss: 0.26997578144073486, aux loss1: 0.9763516187667847, 
		 aux loss2: 0.505482017993927, total loss: 0.7650741338729858
48th Epoch, 35180th Step, learning rate = 0.006400586033886501 - Loss: 0.30430376529693604, aux loss1: 0.9410960674285889, 
		 aux loss2: 0.4799124300479889, total loss: 0.7785975933074951
48th Epoch, 35185th Step, learning rate = 0.0064000606180906975 - Loss: 0.27447929978370667, aux loss1: 0.805622935295105, 
		 aux loss2: 0.4335755407810211, total loss: 0.68959641456604
48th Epoch, 35190th Step, learning rate = 0.006399535197502154 - Loss: 0.24787071347236633, aux loss1: 0.7370476126670837, 
		 aux loss2: 0.3717932403087616, total loss: 0.617702305316925
48th Epoch, 35195th Step, learning rate = 0.006399009772120394 - Loss: 0.2981913387775421, aux loss1: 0.87450110912323, 
		 aux loss2: 0.479149729013443, total loss: 0.7522015571594238
48th Epoch, 35200th Step, learning rate = 0.006398484341944935 - Loss: 0.23678772151470184, aux loss1: 0.6831570863723755, 
		 aux loss2: 0.3538363575935364, total loss: 0.5832694172859192
<35200th step>
*************************** Test ***************************
time:3m 15s, 35200th Step, Loss: 0.5530399680137634, Mean IoU = 46.016%
************************************************************
48th Epoch, 35205th Step, learning rate = 0.006397958906975294 - Loss: 0.26480621099472046, aux loss1: 0.7438092231750488, 
		 aux loss2: 0.3835563361644745, total loss: 0.641371488571167
48th Epoch, 35210th Step, learning rate = 0.006397433467210993 - Loss: 0.3053702712059021, aux loss1: 0.8358306288719177, 
		 aux loss2: 0.48321452736854553, total loss: 0.7494052648544312
48th Epoch, 35215th Step, learning rate = 0.006396908022651549 - Loss: 0.2712121903896332, aux loss1: 0.824327826499939, 
		 aux loss2: 0.43470221757888794, total loss: 0.6923914551734924
48th Epoch, 35220th Step, learning rate = 0.0063963825732964805 - Loss: 0.3349209427833557, aux loss1: 0.8598252534866333, 
		 aux loss2: 0.47936123609542847, total loss: 0.7846130728721619
48th Epoch, 35225th Step, learning rate = 0.006395857119145308 - Loss: 0.3448514938354492, aux loss1: 0.8705614805221558, 
		 aux loss2: 0.48783522844314575, total loss: 0.8011540770530701
48th Epoch, 35230th Step, learning rate = 0.006395331660197546 - Loss: 0.2527748644351959, aux loss1: 0.7336660027503967, 
		 aux loss2: 0.3676958680152893, total loss: 0.6199530363082886
48th Epoch, 35235th Step, learning rate = 0.006394806196452715 - Loss: 0.3016625940799713, aux loss1: 0.9071399569511414, 
		 aux loss2: 0.5037297010421753, total loss: 0.7752965092658997
48th Epoch, 35240th Step, learning rate = 0.006394280727910333 - Loss: 0.3458208441734314, aux loss1: 0.9766307473182678, 
		 aux loss2: 0.5882043838500977, total loss: 0.8740918040275574
48th Epoch, 35245th Step, learning rate = 0.00639375525456992 - Loss: 0.36651021242141724, aux loss1: 1.037081241607666, 
		 aux loss2: 0.6480478048324585, total loss: 0.9368537664413452
48th Epoch, 35250th Step, learning rate = 0.006393229776430991 - Loss: 0.22831305861473083, aux loss1: 0.6717055439949036, 
		 aux loss2: 0.34774699807167053, total loss: 0.5689235329627991
48th Epoch, 35255th Step, learning rate = 0.006392704293493066 - Loss: 0.3875149190425873, aux loss1: 0.9277961850166321, 
		 aux loss2: 0.5870140194892883, total loss: 0.900659441947937
48th Epoch, 35260th Step, learning rate = 0.006392178805755661 - Loss: 0.2624155580997467, aux loss1: 0.7605951428413391, 
		 aux loss2: 0.41241854429244995, total loss: 0.6555615067481995
48th Epoch, 35265th Step, learning rate = 0.0063916533132182965 - Loss: 0.30263060331344604, aux loss1: 0.8809300661087036, 
		 aux loss2: 0.47914573550224304, total loss: 0.7585679888725281
48th Epoch, 35270th Step, learning rate = 0.006391127815880487 - Loss: 0.2232583910226822, aux loss1: 0.7017859816551208, 
		 aux loss2: 0.37068724632263184, total loss: 0.5820690989494324
48th Epoch, 35275th Step, learning rate = 0.006390602313741753 - Loss: 0.3005591630935669, aux loss1: 0.8055375218391418, 
		 aux loss2: 0.4623942971229553, total loss: 0.727178156375885
48th Epoch, 35280th Step, learning rate = 0.0063900768068016105 - Loss: 0.29152989387512207, aux loss1: 0.9133372902870178, 
		 aux loss2: 0.4765542149543762, total loss: 0.7561528086662292
48th Epoch, 35285th Step, learning rate = 0.006389551295059576 - Loss: 0.3011050522327423, aux loss1: 0.9568397998809814, 
		 aux loss2: 0.5055769681930542, total loss: 0.7903878092765808
48th Epoch, 35290th Step, learning rate = 0.0063890257785151686 - Loss: 0.26718172430992126, aux loss1: 0.7423197031021118, 
		 aux loss2: 0.3976895809173584, total loss: 0.6489534974098206
48th Epoch, 35295th Step, learning rate = 0.006388500257167905 - Loss: 0.2531830370426178, aux loss1: 0.8055700659751892, 
		 aux loss2: 0.4179899990558624, total loss: 0.6620500683784485
48th Epoch, 35300th Step, learning rate = 0.006387974731017302 - Loss: 0.23941655457019806, aux loss1: 0.6606460809707642, 
		 aux loss2: 0.3615756928920746, total loss: 0.5822407007217407
<35300th step>
*************************** Test ***************************
time:3m 21s, 35300th Step, Loss: 0.56358402967453, Mean IoU = 46.046%
************************************************************
48th Epoch, 35305th Step, learning rate = 0.006387449200062876 - Loss: 0.31116634607315063, aux loss1: 0.8472786545753479, 
		 aux loss2: 0.42887037992477417, total loss: 0.7368980646133423
49th Epoch, 35310th Step, learning rate = 0.0063869236643041465 - Loss: 0.2344038039445877, aux loss1: 0.7282676696777344, 
		 aux loss2: 0.36981016397476196, total loss: 0.6008081436157227
49th Epoch, 35315th Step, learning rate = 0.006386398123740625 - Loss: 0.2828095555305481, aux loss1: 0.871687650680542, 
		 aux loss2: 0.44213542342185974, total loss: 0.7211700677871704
49th Epoch, 35320th Step, learning rate = 0.006385872578371836 - Loss: 0.24920803308486938, aux loss1: 0.6876921653747559, 
		 aux loss2: 0.3787083625793457, total loss: 0.6069990396499634
49th Epoch, 35325th Step, learning rate = 0.0063853470281972895 - Loss: 0.28820255398750305, aux loss1: 0.7627279162406921, 
		 aux loss2: 0.41308197379112244, total loss: 0.6822537183761597
49th Epoch, 35330th Step, learning rate = 0.006384821473216503 - Loss: 0.30953502655029297, aux loss1: 0.7560941576957703, 
		 aux loss2: 0.4416854977607727, total loss: 0.7130374908447266
49th Epoch, 35335th Step, learning rate = 0.006384295913428997 - Loss: 0.29446208477020264, aux loss1: 0.8262794017791748, 
		 aux loss2: 0.4376601576805115, total loss: 0.7174099683761597
49th Epoch, 35340th Step, learning rate = 0.006383770348834284 - Loss: 0.22168980538845062, aux loss1: 0.7096320390701294, 
		 aux loss2: 0.33061686158180237, total loss: 0.5668261647224426
49th Epoch, 35345th Step, learning rate = 0.006383244779431881 - Loss: 0.22292932868003845, aux loss1: 0.6637446880340576, 
		 aux loss2: 0.34936168789863586, total loss: 0.5617974400520325
49th Epoch, 35350th Step, learning rate = 0.0063827192052213055 - Loss: 0.26236897706985474, aux loss1: 0.9230434894561768, 
		 aux loss2: 0.46161577105522156, total loss: 0.7239283323287964
49th Epoch, 35355th Step, learning rate = 0.006382193626202073 - Loss: 0.2986655831336975, aux loss1: 1.1075563430786133, 
		 aux loss2: 0.49167704582214355, total loss: 0.8276033401489258
49th Epoch, 35360th Step, learning rate = 0.006381668042373698 - Loss: 0.3520316183567047, aux loss1: 1.1335086822509766, 
		 aux loss2: 0.5964264869689941, total loss: 0.930654764175415
49th Epoch, 35365th Step, learning rate = 0.0063811424537357 - Loss: 0.31769755482673645, aux loss1: 0.9017574787139893, 
		 aux loss2: 0.5027151107788086, total loss: 0.7893108129501343
49th Epoch, 35370th Step, learning rate = 0.00638061686028759 - Loss: 0.1959448605775833, aux loss1: 0.7400006651878357, 
		 aux loss2: 0.32968297600746155, total loss: 0.5498182773590088
49th Epoch, 35375th Step, learning rate = 0.006380091262028887 - Loss: 0.28085532784461975, aux loss1: 0.7972766757011414, 
		 aux loss2: 0.39875704050064087, total loss: 0.6795411705970764
49th Epoch, 35380th Step, learning rate = 0.006379565658959108 - Loss: 0.2051132321357727, aux loss1: 0.6668455600738525, 
		 aux loss2: 0.3281939923763275, total loss: 0.5364445447921753
49th Epoch, 35385th Step, learning rate = 0.0063790400510777626 - Loss: 0.24149015545845032, aux loss1: 0.8152396082878113, 
		 aux loss2: 0.3990851044654846, total loss: 0.6456961035728455
49th Epoch, 35390th Step, learning rate = 0.006378514438384373 - Loss: 0.2635083496570587, aux loss1: 0.7446754574775696, 
		 aux loss2: 0.38236987590789795, total loss: 0.6398589611053467
49th Epoch, 35395th Step, learning rate = 0.00637798882087845 - Loss: 0.25783780217170715, aux loss1: 0.8080779910087585, 
		 aux loss2: 0.4095247983932495, total loss: 0.6640710830688477
49th Epoch, 35400th Step, learning rate = 0.006377463198559511 - Loss: 0.26074010133743286, aux loss1: 0.9091070890426636, 
		 aux loss2: 0.5420147180557251, total loss: 0.750278115272522
<35400th step>
*************************** Test ***************************
time:3m 15s, 35400th Step, Loss: 0.6065825819969177, Mean IoU = 45.266%
************************************************************
49th Epoch, 35405th Step, learning rate = 0.0063769375714270715 - Loss: 0.27415820956230164, aux loss1: 0.8119863867759705, 
		 aux loss2: 0.4346359968185425, total loss: 0.6916085481643677
49th Epoch, 35410th Step, learning rate = 0.0063764119394806446 - Loss: 0.26063916087150574, aux loss1: 0.8138793706893921, 
		 aux loss2: 0.4221048951148987, total loss: 0.6736449599266052
49th Epoch, 35415th Step, learning rate = 0.006375886302719746 - Loss: 0.3390576243400574, aux loss1: 0.9507561922073364, 
		 aux loss2: 0.5229262113571167, total loss: 0.833454966545105
49th Epoch, 35420th Step, learning rate = 0.006375360661143892 - Loss: 0.22684134542942047, aux loss1: 0.7008373737335205, 
		 aux loss2: 0.364530473947525, total loss: 0.5829047560691833
49th Epoch, 35425th Step, learning rate = 0.0063748350147525955 - Loss: 0.2912460267543793, aux loss1: 0.9930674433708191, 
		 aux loss2: 0.5047569870948792, total loss: 0.7910690903663635
49th Epoch, 35430th Step, learning rate = 0.006374309363545372 - Loss: 0.2733182907104492, aux loss1: 1.0526866912841797, 
		 aux loss2: 0.4761810004711151, total loss: 0.779596745967865
49th Epoch, 35435th Step, learning rate = 0.006373783707521737 - Loss: 0.31619885563850403, aux loss1: 0.8722301125526428, 
		 aux loss2: 0.5193130970001221, total loss: 0.7855930924415588
49th Epoch, 35440th Step, learning rate = 0.006373258046681203 - Loss: 0.21839621663093567, aux loss1: 0.774056613445282, 
		 aux loss2: 0.35262906551361084, total loss: 0.5916648507118225
49th Epoch, 35445th Step, learning rate = 0.006372732381023287 - Loss: 0.24076786637306213, aux loss1: 0.7227572202682495, 
		 aux loss2: 0.3864728808403015, total loss: 0.6121842265129089
49th Epoch, 35450th Step, learning rate = 0.006372206710547501 - Loss: 0.25547465682029724, aux loss1: 0.7630342245101929, 
		 aux loss2: 0.38902488350868225, total loss: 0.6399949193000793
49th Epoch, 35455th Step, learning rate = 0.006371681035253358 - Loss: 0.32142528891563416, aux loss1: 0.928482174873352, 
		 aux loss2: 0.5135389566421509, total loss: 0.8053855895996094
49th Epoch, 35460th Step, learning rate = 0.006371155355140377 - Loss: 0.2969115376472473, aux loss1: 0.8254950046539307, 
		 aux loss2: 0.46593621373176575, total loss: 0.7309345602989197
49th Epoch, 35465th Step, learning rate = 0.006370629670208068 - Loss: 0.35276007652282715, aux loss1: 0.975836455821991, 
		 aux loss2: 0.6175532937049866, total loss: 0.8925323486328125
49th Epoch, 35470th Step, learning rate = 0.006370103980455947 - Loss: 0.28861379623413086, aux loss1: 0.8706576228141785, 
		 aux loss2: 0.4908481240272522, total loss: 0.7461503744125366
49th Epoch, 35475th Step, learning rate = 0.006369578285883527 - Loss: 0.29709288477897644, aux loss1: 0.7739384174346924, 
		 aux loss2: 0.44785547256469727, total loss: 0.7084165811538696
49th Epoch, 35480th Step, learning rate = 0.006369052586490322 - Loss: 0.21625854074954987, aux loss1: 0.6233793497085571, 
		 aux loss2: 0.32149145007133484, total loss: 0.5318689346313477
49th Epoch, 35485th Step, learning rate = 0.006368526882275844 - Loss: 0.2961950898170471, aux loss1: 0.946029007434845, 
		 aux loss2: 0.47879189252853394, total loss: 0.7715205550193787
49th Epoch, 35490th Step, learning rate = 0.006368001173239609 - Loss: 0.26194632053375244, aux loss1: 0.8988488912582397, 
		 aux loss2: 0.4812150001525879, total loss: 0.7240869998931885
49th Epoch, 35495th Step, learning rate = 0.006367475459381129 - Loss: 0.30758681893348694, aux loss1: 0.8624337911605835, 
		 aux loss2: 0.4878421127796173, total loss: 0.7614538073539734
49th Epoch, 35500th Step, learning rate = 0.006366949740699919 - Loss: 0.288174033164978, aux loss1: 0.7286005020141602, 
		 aux loss2: 0.40786972641944885, total loss: 0.6699020862579346
<35500th step>
*************************** Test ***************************
time:3m 15s, 35500th Step, Loss: 0.5718024969100952, Mean IoU = 46.492%
************************************************************
49th Epoch, 35505th Step, learning rate = 0.006366424017195491 - Loss: 0.23821263015270233, aux loss1: 0.750169575214386, 
		 aux loss2: 0.39956605434417725, total loss: 0.6230899095535278
49th Epoch, 35510th Step, learning rate = 0.006365898288867356 - Loss: 0.37055519223213196, aux loss1: 1.0341001749038696, 
		 aux loss2: 0.6442105770111084, total loss: 0.9384695291519165
49th Epoch, 35515th Step, learning rate = 0.006365372555715033 - Loss: 0.2515403926372528, aux loss1: 0.7159677147865295, 
		 aux loss2: 0.40262481570243835, total loss: 0.6273806095123291
49th Epoch, 35520th Step, learning rate = 0.00636484681773803 - Loss: 0.3748300075531006, aux loss1: 1.1907860040664673, 
		 aux loss2: 0.6946821212768555, total loss: 1.0099387168884277
49th Epoch, 35525th Step, learning rate = 0.0063643210749358605 - Loss: 0.26755455136299133, aux loss1: 0.8357113003730774, 
		 aux loss2: 0.46432846784591675, total loss: 0.703999400138855
49th Epoch, 35530th Step, learning rate = 0.00636379532730804 - Loss: 0.2857542634010315, aux loss1: 0.8661457300186157, 
		 aux loss2: 0.4921075105667114, total loss: 0.7424410581588745
49th Epoch, 35535th Step, learning rate = 0.006363269574854078 - Loss: 0.2515825033187866, aux loss1: 0.8021528720855713, 
		 aux loss2: 0.39150625467300415, total loss: 0.6488308906555176
49th Epoch, 35540th Step, learning rate = 0.0063627438175734895 - Loss: 0.2677379846572876, aux loss1: 0.7137387990951538, 
		 aux loss2: 0.3792479336261749, total loss: 0.6335588097572327
49th Epoch, 35545th Step, learning rate = 0.0063622180554657876 - Loss: 0.26215648651123047, aux loss1: 0.773765504360199, 
		 aux loss2: 0.4244447350502014, total loss: 0.6640640497207642
49th Epoch, 35550th Step, learning rate = 0.00636169228853048 - Loss: 0.3297862410545349, aux loss1: 1.1543859243392944, 
		 aux loss2: 0.6920667886734009, total loss: 0.9529287815093994
49th Epoch, 35555th Step, learning rate = 0.006361166516767084 - Loss: 0.30818384885787964, aux loss1: 1.0013667345046997, 
		 aux loss2: 0.5849543809890747, total loss: 0.8425756692886353
49th Epoch, 35560th Step, learning rate = 0.006360640740175111 - Loss: 0.2543894648551941, aux loss1: 0.7704771161079407, 
		 aux loss2: 0.3680954575538635, total loss: 0.6327707767486572
49th Epoch, 35565th Step, learning rate = 0.006360114958754069 - Loss: 0.2399480640888214, aux loss1: 0.744113564491272, 
		 aux loss2: 0.3597540557384491, total loss: 0.607083797454834
49th Epoch, 35570th Step, learning rate = 0.006359589172503478 - Loss: 0.3015725016593933, aux loss1: 0.7922231554985046, 
		 aux loss2: 0.45317789912223816, total loss: 0.7205106019973755
49th Epoch, 35575th Step, learning rate = 0.006359063381422843 - Loss: 0.27114006876945496, aux loss1: 0.8300071954727173, 
		 aux loss2: 0.4406720697879791, total loss: 0.6964110732078552
49th Epoch, 35580th Step, learning rate = 0.006358537585511679 - Loss: 0.2566659450531006, aux loss1: 0.772512674331665, 
		 aux loss2: 0.38378655910491943, total loss: 0.6419343948364258
49th Epoch, 35585th Step, learning rate = 0.006358011784769497 - Loss: 0.33031049370765686, aux loss1: 0.9394534230232239, 
		 aux loss2: 0.5300093293190002, total loss: 0.8241502046585083
49th Epoch, 35590th Step, learning rate = 0.006357485979195808 - Loss: 0.26553812623023987, aux loss1: 0.8352970480918884, 
		 aux loss2: 0.3958216607570648, total loss: 0.6744558811187744
49th Epoch, 35595th Step, learning rate = 0.006356960168790124 - Loss: 0.3026561141014099, aux loss1: 0.842524528503418, 
		 aux loss2: 0.50589919090271, total loss: 0.7577731609344482
49th Epoch, 35600th Step, learning rate = 0.00635643435355196 - Loss: 0.3837491571903229, aux loss1: 1.1793692111968994, 
		 aux loss2: 0.6383410096168518, total loss: 0.992896318435669
<35600th step>
*************************** Test ***************************
time:3m 17s, 35600th Step, Loss: 0.5508970022201538, Mean IoU = 46.436%
************************************************************
49th Epoch, 35605th Step, learning rate = 0.006355908533480822 - Loss: 0.2912456691265106, aux loss1: 0.8740931749343872, 
		 aux loss2: 0.44257062673568726, total loss: 0.7305018305778503
49th Epoch, 35610th Step, learning rate = 0.006355382708576223 - Loss: 0.24715617299079895, aux loss1: 0.8208481073379517, 
		 aux loss2: 0.4340687394142151, total loss: 0.667038083076477
49th Epoch, 35615th Step, learning rate = 0.006354856878837676 - Loss: 0.3105596899986267, aux loss1: 0.8821454644203186, 
		 aux loss2: 0.4934843182563782, total loss: 0.7725970149040222
49th Epoch, 35620th Step, learning rate = 0.0063543310442646895 - Loss: 0.23853635787963867, aux loss1: 0.7616459727287292, 
		 aux loss2: 0.4055314064025879, total loss: 0.6292427182197571
49th Epoch, 35625th Step, learning rate = 0.006353805204856777 - Loss: 0.2642986476421356, aux loss1: 0.7728394269943237, 
		 aux loss2: 0.4144223928451538, total loss: 0.6619194746017456
49th Epoch, 35630th Step, learning rate = 0.0063532793606134496 - Loss: 0.2848185896873474, aux loss1: 0.7790138125419617, 
		 aux loss2: 0.4247146546840668, total loss: 0.688408613204956
49th Epoch, 35635th Step, learning rate = 0.006352753511534215 - Loss: 0.28107839822769165, aux loss1: 0.914076030254364, 
		 aux loss2: 0.4852020740509033, total loss: 0.7493820190429688
49th Epoch, 35640th Step, learning rate = 0.006352227657618587 - Loss: 0.23291708528995514, aux loss1: 0.7081664800643921, 
		 aux loss2: 0.36091387271881104, total loss: 0.5897325873374939
49th Epoch, 35645th Step, learning rate = 0.006351701798866075 - Loss: 0.2607862651348114, aux loss1: 0.7938600182533264, 
		 aux loss2: 0.41791194677352905, total loss: 0.6661090850830078
49th Epoch, 35650th Step, learning rate = 0.00635117593527619 - Loss: 0.2456638514995575, aux loss1: 0.7087379097938538, 
		 aux loss2: 0.37129348516464233, total loss: 0.6068025827407837
49th Epoch, 35655th Step, learning rate = 0.006350650066848443 - Loss: 0.2783457934856415, aux loss1: 0.7733536958694458, 
		 aux loss2: 0.4023043215274811, total loss: 0.6712736487388611
49th Epoch, 35660th Step, learning rate = 0.0063501241935823415 - Loss: 0.25598788261413574, aux loss1: 0.7990125417709351, 
		 aux loss2: 0.41272440552711487, total loss: 0.6607814431190491
49th Epoch, 35665th Step, learning rate = 0.006349598315477398 - Loss: 0.26105591654777527, aux loss1: 0.9832218885421753, 
		 aux loss2: 0.5115801095962524, total loss: 0.7606545686721802
49th Epoch, 35670th Step, learning rate = 0.006349072432533125 - Loss: 0.1927899420261383, aux loss1: 0.6014310717582703, 
		 aux loss2: 0.3046889007091522, total loss: 0.49509480595588684
49th Epoch, 35675th Step, learning rate = 0.006348546544749027 - Loss: 0.25312188267707825, aux loss1: 0.8487777709960938, 
		 aux loss2: 0.4402250647544861, total loss: 0.6838452816009521
49th Epoch, 35680th Step, learning rate = 0.00634802065212462 - Loss: 0.292355477809906, aux loss1: 0.7772762179374695, 
		 aux loss2: 0.41467729210853577, total loss: 0.6914092302322388
50th Epoch, 35685th Step, learning rate = 0.00634749475465941 - Loss: 0.2247035950422287, aux loss1: 0.6783123016357422, 
		 aux loss2: 0.3408312499523163, total loss: 0.5645297765731812
50th Epoch, 35690th Step, learning rate = 0.006346968852352906 - Loss: 0.2697344422340393, aux loss1: 0.8591753840446472, 
		 aux loss2: 0.4754597246646881, total loss: 0.7176709175109863
50th Epoch, 35695th Step, learning rate = 0.006346442945204621 - Loss: 0.1989881545305252, aux loss1: 0.6491351127624512, 
		 aux loss2: 0.31328079104423523, total loss: 0.5190410017967224
50th Epoch, 35700th Step, learning rate = 0.006345917033214064 - Loss: 0.2792631983757019, aux loss1: 0.9215139746665955, 
		 aux loss2: 0.5194634795188904, total loss: 0.763502836227417
<35700th step>
*************************** Test ***************************
time:3m 15s, 35700th Step, Loss: 0.5725061297416687, Mean IoU = 45.235%
************************************************************
50th Epoch, 35705th Step, learning rate = 0.006345391116380742 - Loss: 0.22854316234588623, aux loss1: 0.7450439929962158, 
		 aux loss2: 0.391667902469635, total loss: 0.608723521232605
50th Epoch, 35710th Step, learning rate = 0.006344865194704168 - Loss: 0.23791907727718353, aux loss1: 0.773279070854187, 
		 aux loss2: 0.4142177999019623, total loss: 0.6355899572372437
50th Epoch, 35715th Step, learning rate = 0.006344339268183848 - Loss: 0.24569891393184662, aux loss1: 0.7670348882675171, 
		 aux loss2: 0.4073525071144104, total loss: 0.638750433921814
50th Epoch, 35720th Step, learning rate = 0.006343813336819293 - Loss: 0.24886752665042877, aux loss1: 0.7216396331787109, 
		 aux loss2: 0.3652862310409546, total loss: 0.6114739179611206
50th Epoch, 35725th Step, learning rate = 0.006343287400610013 - Loss: 0.2746986150741577, aux loss1: 0.8921135663986206, 
		 aux loss2: 0.4813719689846039, total loss: 0.7348815202713013
50th Epoch, 35730th Step, learning rate = 0.006342761459555514 - Loss: 0.21906976401805878, aux loss1: 0.6771920919418335, 
		 aux loss2: 0.32905152440071106, total loss: 0.5538480281829834
50th Epoch, 35735th Step, learning rate = 0.0063422355136553065 - Loss: 0.23560842871665955, aux loss1: 0.7212915420532227, 
		 aux loss2: 0.3694627583026886, total loss: 0.5997810363769531
50th Epoch, 35740th Step, learning rate = 0.006341709562908902 - Loss: 0.2694407105445862, aux loss1: 0.7930561304092407, 
		 aux loss2: 0.39710554480552673, total loss: 0.6661997437477112
50th Epoch, 35745th Step, learning rate = 0.006341183607315804 - Loss: 0.332219660282135, aux loss1: 0.9799527525901794, 
		 aux loss2: 0.5018773674964905, total loss: 0.8269564509391785
50th Epoch, 35750th Step, learning rate = 0.006340657646875526 - Loss: 0.34476158022880554, aux loss1: 0.9504438638687134, 
		 aux loss2: 0.5552752614021301, total loss: 0.8520048260688782
50th Epoch, 35755th Step, learning rate = 0.006340131681587574 - Loss: 0.23608358204364777, aux loss1: 0.7531755566596985, 
		 aux loss2: 0.3693681061267853, total loss: 0.6097835302352905
50th Epoch, 35760th Step, learning rate = 0.0063396057114514575 - Loss: 0.2635760009288788, aux loss1: 0.8318775296211243, 
		 aux loss2: 0.42995426058769226, total loss: 0.6851209402084351
50th Epoch, 35765th Step, learning rate = 0.006339079736466684 - Loss: 0.2508033215999603, aux loss1: 0.8121899962425232, 
		 aux loss2: 0.40686720609664917, total loss: 0.6572072505950928
50th Epoch, 35770th Step, learning rate = 0.006338553756632762 - Loss: 0.2553258538246155, aux loss1: 0.7211270332336426, 
		 aux loss2: 0.40456822514533997, total loss: 0.6334912776947021
50th Epoch, 35775th Step, learning rate = 0.006338027771949201 - Loss: 0.25808900594711304, aux loss1: 0.7810993790626526, 
		 aux loss2: 0.422497034072876, total loss: 0.6614176630973816
50th Epoch, 35780th Step, learning rate = 0.006337501782415508 - Loss: 0.23879338800907135, aux loss1: 0.7147932052612305, 
		 aux loss2: 0.3522918224334717, total loss: 0.5941480994224548
50th Epoch, 35785th Step, learning rate = 0.0063369757880311905 - Loss: 0.4504247009754181, aux loss1: 1.2430163621902466, 
		 aux loss2: 0.7537801265716553, total loss: 1.1248416900634766
50th Epoch, 35790th Step, learning rate = 0.006336449788795756 - Loss: 0.2856004238128662, aux loss1: 0.8176287412643433, 
		 aux loss2: 0.4217401146888733, total loss: 0.6995850801467896
50th Epoch, 35795th Step, learning rate = 0.006335923784708716 - Loss: 0.4211084842681885, aux loss1: 1.1248117685317993, 
		 aux loss2: 0.6770311594009399, total loss: 1.0293644666671753
50th Epoch, 35800th Step, learning rate = 0.006335397775769572 - Loss: 0.24393333494663239, aux loss1: 0.728871762752533, 
		 aux loss2: 0.39544427394866943, total loss: 0.6207726001739502
<35800th step>
*************************** Test ***************************
time:3m 17s, 35800th Step, Loss: 0.5690338015556335, Mean IoU = 46.363%
************************************************************
50th Epoch, 35805th Step, learning rate = 0.006334871761977837 - Loss: 0.2746686637401581, aux loss1: 0.797894299030304, 
		 aux loss2: 0.4224223792552948, total loss: 0.6830059289932251
50th Epoch, 35810th Step, learning rate = 0.0063343457433330174 - Loss: 0.3043586015701294, aux loss1: 0.889511227607727, 
		 aux loss2: 0.4765014350414276, total loss: 0.7618125677108765
50th Epoch, 35815th Step, learning rate = 0.006333819719834618 - Loss: 0.24708876013755798, aux loss1: 0.8168461322784424, 
		 aux loss2: 0.400544136762619, total loss: 0.6523602604866028
50th Epoch, 35820th Step, learning rate = 0.00633329369148215 - Loss: 0.23932096362113953, aux loss1: 0.8998419046401978, 
		 aux loss2: 0.3961675465106964, total loss: 0.6677405834197998
50th Epoch, 35825th Step, learning rate = 0.006332767658275117 - Loss: 0.2541576027870178, aux loss1: 0.7587754726409912, 
		 aux loss2: 0.4147743284702301, total loss: 0.6476999521255493
50th Epoch, 35830th Step, learning rate = 0.006332241620213027 - Loss: 0.27861905097961426, aux loss1: 0.7845503687858582, 
		 aux loss2: 0.42286887764930725, total loss: 0.683131754398346
50th Epoch, 35835th Step, learning rate = 0.00633171557729539 - Loss: 0.29639190435409546, aux loss1: 0.9258708357810974, 
		 aux loss2: 0.5100654363632202, total loss: 0.7781793475151062
50th Epoch, 35840th Step, learning rate = 0.00633118952952171 - Loss: 0.22584488987922668, aux loss1: 0.6292242407798767, 
		 aux loss2: 0.3319758474826813, total loss: 0.5474025011062622
50th Epoch, 35845th Step, learning rate = 0.006330663476891494 - Loss: 0.302549809217453, aux loss1: 0.8115742802619934, 
		 aux loss2: 0.4537236988544464, total loss: 0.7275115847587585
50th Epoch, 35850th Step, learning rate = 0.0063301374194042505 - Loss: 0.3185611069202423, aux loss1: 0.9845872521400452, 
		 aux loss2: 0.5715668797492981, total loss: 0.8425639867782593
50th Epoch, 35855th Step, learning rate = 0.006329611357059484 - Loss: 0.3246232271194458, aux loss1: 0.9233198165893555, 
		 aux loss2: 0.5341988801956177, total loss: 0.8152987360954285
50th Epoch, 35860th Step, learning rate = 0.006329085289856702 - Loss: 0.2623473107814789, aux loss1: 0.7526000738143921, 
		 aux loss2: 0.3891969323158264, total loss: 0.6438060998916626
50th Epoch, 35865th Step, learning rate = 0.006328559217795412 - Loss: 0.2857123911380768, aux loss1: 0.919262707233429, 
		 aux loss2: 0.4798946976661682, total loss: 0.7534491419792175
50th Epoch, 35870th Step, learning rate = 0.0063280331408751165 - Loss: 0.32294175028800964, aux loss1: 0.9078025817871094, 
		 aux loss2: 0.4811660647392273, total loss: 0.7877489924430847
50th Epoch, 35875th Step, learning rate = 0.006327507059095329 - Loss: 0.31586939096450806, aux loss1: 0.8848950862884521, 
		 aux loss2: 0.5014289617538452, total loss: 0.7819095253944397
50th Epoch, 35880th Step, learning rate = 0.006326980972455549 - Loss: 0.28385239839553833, aux loss1: 0.9290710687637329, 
		 aux loss2: 0.4933220446109772, total loss: 0.7599025368690491
50th Epoch, 35885th Step, learning rate = 0.006326454880955285 - Loss: 0.22148318588733673, aux loss1: 0.743050217628479, 
		 aux loss2: 0.3696361482143402, total loss: 0.5922527313232422
50th Epoch, 35890th Step, learning rate = 0.006325928784594044 - Loss: 0.32029154896736145, aux loss1: 0.8882850408554077, 
		 aux loss2: 0.512840211391449, total loss: 0.7919131517410278
50th Epoch, 35895th Step, learning rate = 0.00632540268337133 - Loss: 0.23441742360591888, aux loss1: 0.8003683090209961, 
		 aux loss2: 0.39936473965644836, total loss: 0.6342738270759583
50th Epoch, 35900th Step, learning rate = 0.006324876577286649 - Loss: 0.33583617210388184, aux loss1: 1.0127692222595215, 
		 aux loss2: 0.6329990029335022, total loss: 0.8928664922714233
<35900th step>
*************************** Test ***************************
time:3m 16s, 35900th Step, Loss: 0.5650907158851624, Mean IoU = 46.561%
************************************************************
50th Epoch, 35905th Step, learning rate = 0.006324350466339508 - Loss: 0.3038724362850189, aux loss1: 0.838230550289154, 
		 aux loss2: 0.4628235995769501, total loss: 0.7404710650444031
50th Epoch, 35910th Step, learning rate = 0.006323824350529412 - Loss: 0.29893946647644043, aux loss1: 0.9140005111694336, 
		 aux loss2: 0.4527930021286011, total loss: 0.7542568445205688
50th Epoch, 35915th Step, learning rate = 0.006323298229855866 - Loss: 0.3003759980201721, aux loss1: 0.8133159279823303, 
		 aux loss2: 0.4696786403656006, total loss: 0.732242226600647
50th Epoch, 35920th Step, learning rate = 0.006322772104318378 - Loss: 0.23253147304058075, aux loss1: 0.6992661952972412, 
		 aux loss2: 0.3696267902851105, total loss: 0.5901620388031006
50th Epoch, 35925th Step, learning rate = 0.006322245973916448 - Loss: 0.27546051144599915, aux loss1: 0.8580797910690308, 
		 aux loss2: 0.440387487411499, total loss: 0.7090394496917725
50th Epoch, 35930th Step, learning rate = 0.006321719838649586 - Loss: 0.20291975140571594, aux loss1: 0.5559209585189819, 
		 aux loss2: 0.2939004898071289, total loss: 0.48725625872612
50th Epoch, 35935th Step, learning rate = 0.006321193698517295 - Loss: 0.2805485129356384, aux loss1: 0.8548076152801514, 
		 aux loss2: 0.4400080442428589, total loss: 0.7129940390586853
50th Epoch, 35940th Step, learning rate = 0.0063206675535190816 - Loss: 0.24006672203540802, aux loss1: 0.7356966137886047, 
		 aux loss2: 0.3957986831665039, total loss: 0.6190952062606812
50th Epoch, 35945th Step, learning rate = 0.006320141403654451 - Loss: 0.3514713943004608, aux loss1: 1.073889970779419, 
		 aux loss2: 0.6390070915222168, total loss: 0.9292412400245667
50th Epoch, 35950th Step, learning rate = 0.006319615248922904 - Loss: 0.2315537929534912, aux loss1: 0.702576756477356, 
		 aux loss2: 0.3586375117301941, total loss: 0.5857818722724915
50th Epoch, 35955th Step, learning rate = 0.006319089089323949 - Loss: 0.26154446601867676, aux loss1: 0.773686408996582, 
		 aux loss2: 0.4175204932689667, total loss: 0.660658597946167
50th Epoch, 35960th Step, learning rate = 0.006318562924857091 - Loss: 0.2642640173435211, aux loss1: 0.7528507709503174, 
		 aux loss2: 0.41365882754325867, total loss: 0.6555827856063843
50th Epoch, 35965th Step, learning rate = 0.006318036755521832 - Loss: 0.23287297785282135, aux loss1: 0.6707453727722168, 
		 aux loss2: 0.3398897349834442, total loss: 0.5700525045394897
50th Epoch, 35970th Step, learning rate = 0.006317510581317678 - Loss: 0.26056477427482605, aux loss1: 0.7307153940200806, 
		 aux loss2: 0.3953190743923187, total loss: 0.6379070281982422
50th Epoch, 35975th Step, learning rate = 0.006316984402244133 - Loss: 0.2707678973674774, aux loss1: 0.7984428405761719, 
		 aux loss2: 0.4647822082042694, total loss: 0.6962136626243591
50th Epoch, 35980th Step, learning rate = 0.006316458218300701 - Loss: 0.2594146430492401, aux loss1: 0.8358102440834045, 
		 aux loss2: 0.4111149311065674, total loss: 0.6746037006378174
50th Epoch, 35985th Step, learning rate = 0.006315932029486888 - Loss: 0.2579301595687866, aux loss1: 0.8634400367736816, 
		 aux loss2: 0.47648218274116516, total loss: 0.7075550556182861
50th Epoch, 35990th Step, learning rate = 0.006315405835802196 - Loss: 0.28123152256011963, aux loss1: 0.8773035407066345, 
		 aux loss2: 0.46483200788497925, total loss: 0.730355441570282
50th Epoch, 35995th Step, learning rate = 0.006314879637246128 - Loss: 0.29373911023139954, aux loss1: 0.7736960053443909, 
		 aux loss2: 0.4214687645435333, total loss: 0.6944354176521301
50th Epoch, 36000th Step, learning rate = 0.006314353433818191 - Loss: 0.29756349325180054, aux loss1: 1.0044318437576294, 
		 aux loss2: 0.5394507050514221, total loss: 0.8146733045578003
<36000th step>
*************************** Test ***************************
time:3m 17s, 36000th Step, Loss: 0.5408529043197632, Mean IoU = 47.128%
************************************************************
50th Epoch, 36005th Step, learning rate = 0.0063138272255178875 - Loss: 0.2163977473974228, aux loss1: 0.7151029706001282, 
		 aux loss2: 0.34525784850120544, total loss: 0.5690317749977112
50th Epoch, 36010th Step, learning rate = 0.00631330101234472 - Loss: 0.2856208086013794, aux loss1: 0.8390063047409058, 
		 aux loss2: 0.467861533164978, total loss: 0.7244673371315002
50th Epoch, 36015th Step, learning rate = 0.006312774794298194 - Loss: 0.20447516441345215, aux loss1: 0.6772107481956482, 
		 aux loss2: 0.34323811531066895, total loss: 0.5449336767196655
50th Epoch, 36020th Step, learning rate = 0.006312248571377811 - Loss: 0.2990477383136749, aux loss1: 0.8911052942276001, 
		 aux loss2: 0.4918975830078125, total loss: 0.7631383538246155
50th Epoch, 36025th Step, learning rate = 0.0063117223435830766 - Loss: 0.2718442380428314, aux loss1: 0.825634241104126, 
		 aux loss2: 0.4430740475654602, total loss: 0.6967641711235046
50th Epoch, 36030th Step, learning rate = 0.006311196110913493 - Loss: 0.24192047119140625, aux loss1: 0.7877513766288757, 
		 aux loss2: 0.3911028504371643, total loss: 0.634687066078186
50th Epoch, 36035th Step, learning rate = 0.006310669873368562 - Loss: 0.21953362226486206, aux loss1: 0.8199537396430969, 
		 aux loss2: 0.374142050743103, total loss: 0.6151765584945679
50th Epoch, 36040th Step, learning rate = 0.006310143630947788 - Loss: 0.2562640309333801, aux loss1: 0.9010544419288635, 
		 aux loss2: 0.4248640835285187, total loss: 0.6965259909629822
50th Epoch, 36045th Step, learning rate = 0.0063096173836506755 - Loss: 0.345134973526001, aux loss1: 0.9156749248504639, 
		 aux loss2: 0.48515012860298157, total loss: 0.8138974905014038
50th Epoch, 36050th Step, learning rate = 0.006309091131476723 - Loss: 0.26459306478500366, aux loss1: 0.8530130386352539, 
		 aux loss2: 0.42806220054626465, total loss: 0.6917218565940857
51th Epoch, 36055th Step, learning rate = 0.006308564874425438 - Loss: 0.29048001766204834, aux loss1: 0.9708175659179688, 
		 aux loss2: 0.5551396608352661, total loss: 0.8037811517715454
51th Epoch, 36060th Step, learning rate = 0.006308038612496322 - Loss: 0.21928618848323822, aux loss1: 0.7838500738143921, 
		 aux loss2: 0.3442624807357788, total loss: 0.5921462178230286
51th Epoch, 36065th Step, learning rate = 0.006307512345688876 - Loss: 0.2039407193660736, aux loss1: 0.7774971723556519, 
		 aux loss2: 0.41645383834838867, total loss: 0.603771448135376
51th Epoch, 36070th Step, learning rate = 0.006306986074002605 - Loss: 0.22876743972301483, aux loss1: 0.7836551666259766, 
		 aux loss2: 0.3834374248981476, total loss: 0.6172389984130859
51th Epoch, 36075th Step, learning rate = 0.00630645979743701 - Loss: 0.31526461243629456, aux loss1: 0.8189769983291626, 
		 aux loss2: 0.48445361852645874, total loss: 0.7547391653060913
51th Epoch, 36080th Step, learning rate = 0.006305933515991591 - Loss: 0.26048046350479126, aux loss1: 0.8261696696281433, 
		 aux loss2: 0.43736737966537476, total loss: 0.6832783222198486
51th Epoch, 36085th Step, learning rate = 0.006305407229665855 - Loss: 0.30852609872817993, aux loss1: 0.908831000328064, 
		 aux loss2: 0.5247372388839722, total loss: 0.7910703420639038
51th Epoch, 36090th Step, learning rate = 0.006304880938459301 - Loss: 0.3115980327129364, aux loss1: 0.9086339473724365, 
		 aux loss2: 0.5282914042472839, total loss: 0.7955048084259033
51th Epoch, 36095th Step, learning rate = 0.006304354642371432 - Loss: 0.2929866909980774, aux loss1: 0.8244391083717346, 
		 aux loss2: 0.47078678011894226, total loss: 0.7286331653594971
51th Epoch, 36100th Step, learning rate = 0.00630382834140175 - Loss: 0.2999795973300934, aux loss1: 0.891710102558136, 
		 aux loss2: 0.5007474422454834, total loss: 0.7677915692329407
<36100th step>
*************************** Test ***************************
time:3m 19s, 36100th Step, Loss: 0.5572377443313599, Mean IoU = 46.393%
************************************************************
51th Epoch, 36105th Step, learning rate = 0.006303302035549754 - Loss: 0.2245987504720688, aux loss1: 0.6528999209403992, 
		 aux loss2: 0.3359031677246094, total loss: 0.554830014705658
51th Epoch, 36110th Step, learning rate = 0.006302775724814951 - Loss: 0.24323788285255432, aux loss1: 0.693437397480011, 
		 aux loss2: 0.34154677391052246, total loss: 0.5878878235816956
51th Epoch, 36115th Step, learning rate = 0.00630224940919684 - Loss: 0.23699632287025452, aux loss1: 0.8304678201675415, 
		 aux loss2: 0.4233134388923645, total loss: 0.6554620265960693
51th Epoch, 36120th Step, learning rate = 0.00630172308869492 - Loss: 0.2314179539680481, aux loss1: 0.6630330681800842, 
		 aux loss2: 0.35239696502685547, total loss: 0.571286678314209
51th Epoch, 36125th Step, learning rate = 0.006301196763308696 - Loss: 0.23706352710723877, aux loss1: 0.6936584711074829, 
		 aux loss2: 0.3791053593158722, total loss: 0.5968031883239746
51th Epoch, 36130th Step, learning rate = 0.006300670433037669 - Loss: 0.3008755147457123, aux loss1: 0.8848870992660522, 
		 aux loss2: 0.4868931770324707, total loss: 0.7610989212989807
51th Epoch, 36135th Step, learning rate = 0.006300144097881338 - Loss: 0.24057738482952118, aux loss1: 0.8496697545051575, 
		 aux loss2: 0.3825163245201111, total loss: 0.6484848856925964
51th Epoch, 36140th Step, learning rate = 0.0062996177578392085 - Loss: 0.25918805599212646, aux loss1: 0.8083168864250183, 
		 aux loss2: 0.44640907645225525, total loss: 0.6802467703819275
51th Epoch, 36145th Step, learning rate = 0.0062990914129107765 - Loss: 0.2822021245956421, aux loss1: 0.8201895952224731, 
		 aux loss2: 0.4594406187534332, total loss: 0.7120352983474731
51th Epoch, 36150th Step, learning rate = 0.006298565063095546 - Loss: 0.28553736209869385, aux loss1: 0.8206366300582886, 
		 aux loss2: 0.4288436472415924, total loss: 0.7032658457756042
51th Epoch, 36155th Step, learning rate = 0.006298038708393018 - Loss: 0.3137757182121277, aux loss1: 0.9185953736305237, 
		 aux loss2: 0.5416006445884705, total loss: 0.8059946298599243
51th Epoch, 36160th Step, learning rate = 0.006297512348802692 - Loss: 0.2379402071237564, aux loss1: 0.8623011112213135, 
		 aux loss2: 0.45546436309814453, total loss: 0.6788163185119629
51th Epoch, 36165th Step, learning rate = 0.006296985984324068 - Loss: 0.26562267541885376, aux loss1: 0.7809975743293762, 
		 aux loss2: 0.46022671461105347, total loss: 0.6840126514434814
51th Epoch, 36170th Step, learning rate = 0.006296459614956649 - Loss: 0.1919846385717392, aux loss1: 0.6086623668670654, 
		 aux loss2: 0.30104783177375793, total loss: 0.49500250816345215
51th Epoch, 36175th Step, learning rate = 0.006295933240699932 - Loss: 0.2869264483451843, aux loss1: 0.8244639039039612, 
		 aux loss2: 0.4121969938278198, total loss: 0.6991444230079651
51th Epoch, 36180th Step, learning rate = 0.006295406861553422 - Loss: 0.30698278546333313, aux loss1: 0.8700698018074036, 
		 aux loss2: 0.4978561997413635, total loss: 0.7671462297439575
51th Epoch, 36185th Step, learning rate = 0.006294880477516616 - Loss: 0.277150958776474, aux loss1: 0.963066816329956, 
		 aux loss2: 0.4521997570991516, total loss: 0.7469509243965149
51th Epoch, 36190th Step, learning rate = 0.006294354088589014 - Loss: 0.2583179771900177, aux loss1: 0.950646162033081, 
		 aux loss2: 0.4857833683490753, total loss: 0.7378252148628235
51th Epoch, 36195th Step, learning rate = 0.006293827694770119 - Loss: 0.3288065791130066, aux loss1: 0.9443905353546143, 
		 aux loss2: 0.5431440472602844, total loss: 0.8293813467025757
51th Epoch, 36200th Step, learning rate = 0.006293301296059427 - Loss: 0.26854264736175537, aux loss1: 0.7548648715019226, 
		 aux loss2: 0.39824163913726807, total loss: 0.6542987823486328
<36200th step>
*************************** Test ***************************
time:3m 19s, 36200th Step, Loss: 0.5476048588752747, Mean IoU = 44.946%
************************************************************
51th Epoch, 36205th Step, learning rate = 0.006292774892456441 - Loss: 0.30442625284194946, aux loss1: 1.0581554174423218, 
		 aux loss2: 0.5602011680603027, total loss: 0.8459533452987671
51th Epoch, 36210th Step, learning rate = 0.006292248483960661 - Loss: 0.2723456919193268, aux loss1: 0.8164274096488953, 
		 aux loss2: 0.41431674361228943, total loss: 0.6830006241798401
51th Epoch, 36215th Step, learning rate = 0.006291722070571584 - Loss: 0.2739371061325073, aux loss1: 0.8201195001602173, 
		 aux loss2: 0.4452664852142334, total loss: 0.6980795860290527
51th Epoch, 36220th Step, learning rate = 0.006291195652288711 - Loss: 0.28217872977256775, aux loss1: 0.8541224598884583, 
		 aux loss2: 0.45388007164001465, total loss: 0.7199675440788269
51th Epoch, 36225th Step, learning rate = 0.006290669229111543 - Loss: 0.21166212856769562, aux loss1: 0.7745569348335266, 
		 aux loss2: 0.34196457266807556, total loss: 0.5808150768280029
51th Epoch, 36230th Step, learning rate = 0.006290142801039575 - Loss: 0.32796457409858704, aux loss1: 1.0260289907455444, 
		 aux loss2: 0.6075952649116516, total loss: 0.8788114190101624
51th Epoch, 36235th Step, learning rate = 0.006289616368072313 - Loss: 0.28163212537765503, aux loss1: 0.8091952800750732, 
		 aux loss2: 0.45535916090011597, total loss: 0.7065343856811523
51th Epoch, 36240th Step, learning rate = 0.006289089930209251 - Loss: 0.24526119232177734, aux loss1: 0.7437196373939514, 
		 aux loss2: 0.40312668681144714, total loss: 0.6296278238296509
51th Epoch, 36245th Step, learning rate = 0.006288563487449889 - Loss: 0.23644769191741943, aux loss1: 0.6499186754226685, 
		 aux loss2: 0.3410131335258484, total loss: 0.5678285360336304
51th Epoch, 36250th Step, learning rate = 0.006288037039793728 - Loss: 0.2953977882862091, aux loss1: 1.1188766956329346, 
		 aux loss2: 0.571141242980957, total loss: 0.8595173358917236
51th Epoch, 36255th Step, learning rate = 0.006287510587240265 - Loss: 0.3174421191215515, aux loss1: 0.7589259147644043, 
		 aux loss2: 0.4373320937156677, total loss: 0.7200527191162109
51th Epoch, 36260th Step, learning rate = 0.006286984129788999 - Loss: 0.3492615222930908, aux loss1: 1.001247763633728, 
		 aux loss2: 0.5509241223335266, total loss: 0.8700054883956909
51th Epoch, 36265th Step, learning rate = 0.006286457667439431 - Loss: 0.3058340847492218, aux loss1: 0.9480145573616028, 
		 aux loss2: 0.5176207423210144, total loss: 0.7972867488861084
51th Epoch, 36270th Step, learning rate = 0.006285931200191055 - Loss: 0.24092549085617065, aux loss1: 0.6714467406272888, 
		 aux loss2: 0.37325412034988403, total loss: 0.5916611552238464
51th Epoch, 36275th Step, learning rate = 0.0062854047280433735 - Loss: 0.2851228415966034, aux loss1: 0.7715864181518555, 
		 aux loss2: 0.4300348460674286, total loss: 0.688612699508667
51th Epoch, 36280th Step, learning rate = 0.0062848782509958845 - Loss: 0.2814609706401825, aux loss1: 0.9091044664382935, 
		 aux loss2: 0.47875338792800903, total loss: 0.7456936836242676
51th Epoch, 36285th Step, learning rate = 0.0062843517690480835 - Loss: 0.2702975273132324, aux loss1: 0.8262022733688354, 
		 aux loss2: 0.4081128239631653, total loss: 0.6814033389091492
51th Epoch, 36290th Step, learning rate = 0.006283825282199472 - Loss: 0.2638888359069824, aux loss1: 0.7195457816123962, 
		 aux loss2: 0.39467158913612366, total loss: 0.6376212239265442
51th Epoch, 36295th Step, learning rate = 0.006283298790449548 - Loss: 0.2747122347354889, aux loss1: 0.8038378953933716, 
		 aux loss2: 0.4515056312084198, total loss: 0.6964658498764038
51th Epoch, 36300th Step, learning rate = 0.006282772293797807 - Loss: 0.2711199223995209, aux loss1: 0.913230836391449, 
		 aux loss2: 0.47905030846595764, total loss: 0.7367092967033386
<36300th step>
*************************** Test ***************************
time:3m 19s, 36300th Step, Loss: 0.5722137093544006, Mean IoU = 46.628%
************************************************************
51th Epoch, 36305th Step, learning rate = 0.0062822457922437494 - Loss: 0.2873295843601227, aux loss1: 0.8677971959114075, 
		 aux loss2: 0.5098822116851807, total loss: 0.751621663570404
51th Epoch, 36310th Step, learning rate = 0.0062817192857868714 - Loss: 0.27385494112968445, aux loss1: 0.7548280954360962, 
		 aux loss2: 0.4081134796142578, total loss: 0.6635487675666809
51th Epoch, 36315th Step, learning rate = 0.006281192774426672 - Loss: 0.31145352125167847, aux loss1: 0.8709027171134949, 
		 aux loss2: 0.5054742097854614, total loss: 0.774914026260376
51th Epoch, 36320th Step, learning rate = 0.006280666258162648 - Loss: 0.22975505888462067, aux loss1: 0.7673420310020447, 
		 aux loss2: 0.38373973965644836, total loss: 0.6134535670280457
51th Epoch, 36325th Step, learning rate = 0.006280139736994297 - Loss: 0.25577500462532043, aux loss1: 0.7046725153923035, 
		 aux loss2: 0.37704914808273315, total loss: 0.6179964542388916
51th Epoch, 36330th Step, learning rate = 0.006279613210921117 - Loss: 0.2633799910545349, aux loss1: 0.9860929250717163, 
		 aux loss2: 0.4324578642845154, total loss: 0.7321910858154297
51th Epoch, 36335th Step, learning rate = 0.006279086679942605 - Loss: 0.21287782490253448, aux loss1: 0.7063063383102417, 
		 aux loss2: 0.31929540634155273, total loss: 0.5524879097938538
51th Epoch, 36340th Step, learning rate = 0.006278560144058257 - Loss: 0.289326548576355, aux loss1: 0.9880375862121582, 
		 aux loss2: 0.5108532905578613, total loss: 0.7900791168212891
51th Epoch, 36345th Step, learning rate = 0.006278033603267572 - Loss: 0.33572596311569214, aux loss1: 0.8699676394462585, 
		 aux loss2: 0.5220649242401123, total loss: 0.8055422306060791
51th Epoch, 36350th Step, learning rate = 0.006277507057570048 - Loss: 0.22168588638305664, aux loss1: 0.6846341490745544, 
		 aux loss2: 0.3359292447566986, total loss: 0.5614478588104248
51th Epoch, 36355th Step, learning rate = 0.006276980506965179 - Loss: 0.23307597637176514, aux loss1: 0.657089352607727, 
		 aux loss2: 0.34277576208114624, total loss: 0.5673130750656128
51th Epoch, 36360th Step, learning rate = 0.006276453951452463 - Loss: 0.26089712977409363, aux loss1: 0.7128887176513672, 
		 aux loss2: 0.3902167081832886, total loss: 0.6308504343032837
51th Epoch, 36365th Step, learning rate = 0.006275927391031397 - Loss: 0.30044305324554443, aux loss1: 1.0230915546417236, 
		 aux loss2: 0.4909217059612274, total loss: 0.8037391901016235
51th Epoch, 36370th Step, learning rate = 0.00627540082570148 - Loss: 0.23373492062091827, aux loss1: 0.6743665933609009, 
		 aux loss2: 0.32211580872535706, total loss: 0.5648912191390991
51th Epoch, 36375th Step, learning rate = 0.006274874255462204 - Loss: 0.32255226373672485, aux loss1: 1.0849241018295288, 
		 aux loss2: 0.6169484853744507, total loss: 0.8948088884353638
51th Epoch, 36380th Step, learning rate = 0.0062743476803130685 - Loss: 0.31525593996047974, aux loss1: 0.9019032120704651, 
		 aux loss2: 0.510419487953186, total loss: 0.7899946570396423
51th Epoch, 36385th Step, learning rate = 0.006273821100253568 - Loss: 0.23886556923389435, aux loss1: 0.8342997431755066, 
		 aux loss2: 0.4067178964614868, total loss: 0.6518427133560181
51th Epoch, 36390th Step, learning rate = 0.006273294515283202 - Loss: 0.22125403583049774, aux loss1: 0.7381905913352966, 
		 aux loss2: 0.36096063256263733, total loss: 0.5870954990386963
51th Epoch, 36395th Step, learning rate = 0.006272767925401462 - Loss: 0.28036946058273315, aux loss1: 0.8816909790039062, 
		 aux loss2: 0.4974634051322937, total loss: 0.7438621520996094
51th Epoch, 36400th Step, learning rate = 0.006272241330607849 - Loss: 0.3541506826877594, aux loss1: 0.9435450434684753, 
		 aux loss2: 0.5283214449882507, total loss: 0.8485427498817444
<36400th step>
*************************** Test ***************************
time:3m 19s, 36400th Step, Loss: 0.5316921472549438, Mean IoU = 46.607%
************************************************************
51th Epoch, 36405th Step, learning rate = 0.006271714730901855 - Loss: 0.38086917996406555, aux loss1: 1.0173221826553345, 
		 aux loss2: 0.6380026936531067, total loss: 0.9412668943405151
51th Epoch, 36410th Step, learning rate = 0.006271188126282978 - Loss: 0.3051486015319824, aux loss1: 0.8224069476127625, 
		 aux loss2: 0.44383299350738525, total loss: 0.7294039130210876
51th Epoch, 36415th Step, learning rate = 0.006270661516750713 - Loss: 0.23255567252635956, aux loss1: 0.6744344830513, 
		 aux loss2: 0.35299012064933777, total loss: 0.5760821104049683
51th Epoch, 36420th Step, learning rate = 0.006270134902304555 - Loss: 0.2654626667499542, aux loss1: 0.8080332279205322, 
		 aux loss2: 0.4186171293258667, total loss: 0.675319492816925
52th Epoch, 36425th Step, learning rate = 0.006269608282944002 - Loss: 0.24932681024074554, aux loss1: 0.800467848777771, 
		 aux loss2: 0.42320841550827026, total loss: 0.6587505340576172
52th Epoch, 36430th Step, learning rate = 0.006269081658668547 - Loss: 0.22227448225021362, aux loss1: 0.7571148872375488, 
		 aux loss2: 0.38184449076652527, total loss: 0.6021467447280884
52th Epoch, 36435th Step, learning rate = 0.006268555029477687 - Loss: 0.3221084475517273, aux loss1: 0.8695067763328552, 
		 aux loss2: 0.4923399090766907, total loss: 0.7798964381217957
52th Epoch, 36440th Step, learning rate = 0.006268028395370916 - Loss: 0.2495528608560562, aux loss1: 0.7366164326667786, 
		 aux loss2: 0.3966841697692871, total loss: 0.62921142578125
52th Epoch, 36445th Step, learning rate = 0.006267501756347731 - Loss: 0.21074435114860535, aux loss1: 0.6685279607772827, 
		 aux loss2: 0.31742939352989197, total loss: 0.5382745265960693
52th Epoch, 36450th Step, learning rate = 0.006266975112407625 - Loss: 0.2505900263786316, aux loss1: 0.869751513004303, 
		 aux loss2: 0.45011815428733826, total loss: 0.6915627717971802
52th Epoch, 36455th Step, learning rate = 0.006266448463550093 - Loss: 0.20575742423534393, aux loss1: 0.684932291507721, 
		 aux loss2: 0.3365754783153534, total loss: 0.5458673238754272
52th Epoch, 36460th Step, learning rate = 0.006265921809774632 - Loss: 0.24503910541534424, aux loss1: 0.9635215401649475, 
		 aux loss2: 0.4939991235733032, total loss: 0.7316952347755432
52th Epoch, 36465th Step, learning rate = 0.006265395151080734 - Loss: 0.25598788261413574, aux loss1: 0.884738028049469, 
		 aux loss2: 0.4419199228286743, total loss: 0.6981772184371948
52th Epoch, 36470th Step, learning rate = 0.006264868487467897 - Loss: 0.20744995772838593, aux loss1: 0.7861344218254089, 
		 aux loss2: 0.37394797801971436, total loss: 0.5928695201873779
52th Epoch, 36475th Step, learning rate = 0.0062643418189356126 - Loss: 0.2818109691143036, aux loss1: 0.7899428606033325, 
		 aux loss2: 0.40165719389915466, total loss: 0.6794567108154297
52th Epoch, 36480th Step, learning rate = 0.006263815145483376 - Loss: 0.26067906618118286, aux loss1: 0.7712676525115967, 
		 aux loss2: 0.4370136559009552, total loss: 0.666864812374115
52th Epoch, 36485th Step, learning rate = 0.006263288467110684 - Loss: 0.2229575216770172, aux loss1: 0.7629799842834473, 
		 aux loss2: 0.3755452036857605, total loss: 0.602069616317749
52th Epoch, 36490th Step, learning rate = 0.006262761783817027 - Loss: 0.27090585231781006, aux loss1: 0.8574731349945068, 
		 aux loss2: 0.45078861713409424, total loss: 0.7084632515907288
52th Epoch, 36495th Step, learning rate = 0.006262235095601901 - Loss: 0.2126619815826416, aux loss1: 0.6414681673049927, 
		 aux loss2: 0.3259276747703552, total loss: 0.5354735255241394
52th Epoch, 36500th Step, learning rate = 0.006261708402464803 - Loss: 0.20093318819999695, aux loss1: 0.6576693058013916, 
		 aux loss2: 0.3491518795490265, total loss: 0.5378947854042053
<36500th step>
*************************** Test ***************************
time:3m 19s, 36500th Step, Loss: 0.5572304129600525, Mean IoU = 47.223%
************************************************************
52th Epoch, 36505th Step, learning rate = 0.006261181704405222 - Loss: 0.2241075485944748, aux loss1: 0.8368580341339111, 
		 aux loss2: 0.42634689807891846, total loss: 0.6457037329673767
52th Epoch, 36510th Step, learning rate = 0.006260655001422654 - Loss: 0.27525249123573303, aux loss1: 0.8970876932144165, 
		 aux loss2: 0.4752916991710663, total loss: 0.7344955205917358
52th Epoch, 36515th Step, learning rate = 0.006260128293516594 - Loss: 0.227370485663414, aux loss1: 0.7650880217552185, 
		 aux loss2: 0.3898067772388458, total loss: 0.6128196120262146
52th Epoch, 36520th Step, learning rate = 0.006259601580686534 - Loss: 0.2541399300098419, aux loss1: 0.7715686559677124, 
		 aux loss2: 0.40973371267318726, total loss: 0.6495040655136108
52th Epoch, 36525th Step, learning rate = 0.006259074862931968 - Loss: 0.2275562435388565, aux loss1: 0.8754388093948364, 
		 aux loss2: 0.4741305410861969, total loss: 0.679840087890625
52th Epoch, 36530th Step, learning rate = 0.0062585481402523905 - Loss: 0.2250903993844986, aux loss1: 0.7050107717514038, 
		 aux loss2: 0.36490821838378906, total loss: 0.582556962966919
52th Epoch, 36535th Step, learning rate = 0.006258021412647292 - Loss: 0.2192189246416092, aux loss1: 0.7255054712295532, 
		 aux loss2: 0.3565552532672882, total loss: 0.5794926881790161
52th Epoch, 36540th Step, learning rate = 0.006257494680116171 - Loss: 0.23298263549804688, aux loss1: 0.714124858379364, 
		 aux loss2: 0.3527621626853943, total loss: 0.5883249640464783
52th Epoch, 36545th Step, learning rate = 0.006256967942658515 - Loss: 0.29149240255355835, aux loss1: 0.8553443551063538, 
		 aux loss2: 0.46555769443511963, total loss: 0.7343187928199768
52th Epoch, 36550th Step, learning rate = 0.006256441200273819 - Loss: 0.2830269932746887, aux loss1: 0.8305262923240662, 
		 aux loss2: 0.4656529128551483, total loss: 0.7184460759162903
52th Epoch, 36555th Step, learning rate = 0.006255914452961579 - Loss: 0.24941478669643402, aux loss1: 0.7895044684410095, 
		 aux loss2: 0.3917611539363861, total loss: 0.642970621585846
52th Epoch, 36560th Step, learning rate = 0.006255387700721284 - Loss: 0.30033838748931885, aux loss1: 0.8751322031021118, 
		 aux loss2: 0.4741891920566559, total loss: 0.7525537610054016
52th Epoch, 36565th Step, learning rate = 0.00625486094355243 - Loss: 0.29789313673973083, aux loss1: 0.775809645652771, 
		 aux loss2: 0.45768269896507263, total loss: 0.7137091755867004
52th Epoch, 36570th Step, learning rate = 0.006254334181454507 - Loss: 0.2423652559518814, aux loss1: 0.8054223656654358, 
		 aux loss2: 0.3919457495212555, total loss: 0.6407703161239624
52th Epoch, 36575th Step, learning rate = 0.0062538074144270085 - Loss: 0.2587224841117859, aux loss1: 0.7852343916893005, 
		 aux loss2: 0.40661585330963135, total loss: 0.6569391489028931
52th Epoch, 36580th Step, learning rate = 0.0062532806424694274 - Loss: 0.29598310589790344, aux loss1: 0.8735122084617615, 
		 aux loss2: 0.4474412798881531, total loss: 0.7370133399963379
52th Epoch, 36585th Step, learning rate = 0.006252753865581257 - Loss: 0.22611680626869202, aux loss1: 0.7284548282623291, 
		 aux loss2: 0.3422372341156006, total loss: 0.5815481543540955
52th Epoch, 36590th Step, learning rate = 0.006252227083761985 - Loss: 0.2369251400232315, aux loss1: 0.7290447354316711, 
		 aux loss2: 0.3833360970020294, total loss: 0.6089730262756348
52th Epoch, 36595th Step, learning rate = 0.00625170029701111 - Loss: 0.2908443510532379, aux loss1: 0.833096444606781, 
		 aux loss2: 0.4909064769744873, total loss: 0.7371358871459961
52th Epoch, 36600th Step, learning rate = 0.00625117350532812 - Loss: 0.2747609317302704, aux loss1: 0.7237672805786133, 
		 aux loss2: 0.394319623708725, total loss: 0.6496189832687378
<36600th step>
*************************** Test ***************************
time:3m 19s, 36600th Step, Loss: 0.545029878616333, Mean IoU = 46.497%
************************************************************
52th Epoch, 36605th Step, learning rate = 0.00625064670871251 - Loss: 0.25987330079078674, aux loss1: 0.8185693025588989, 
		 aux loss2: 0.4370565712451935, total loss: 0.6802667379379272
52th Epoch, 36610th Step, learning rate = 0.006250119907163768 - Loss: 0.22916868329048157, aux loss1: 0.8605812191963196, 
		 aux loss2: 0.3888862431049347, total loss: 0.6428976058959961
52th Epoch, 36615th Step, learning rate = 0.006249593100681389 - Loss: 0.24096140265464783, aux loss1: 0.8573190569877625, 
		 aux loss2: 0.4655314087867737, total loss: 0.684369683265686
52th Epoch, 36620th Step, learning rate = 0.006249066289264862 - Loss: 0.2803535759449005, aux loss1: 0.7688230276107788, 
		 aux loss2: 0.4253748953342438, total loss: 0.681150496006012
52th Epoch, 36625th Step, learning rate = 0.006248539472913682 - Loss: 0.2986993193626404, aux loss1: 0.9569834470748901, 
		 aux loss2: 0.5163039565086365, total loss: 0.7923159003257751
52th Epoch, 36630th Step, learning rate = 0.006248012651627337 - Loss: 0.27187544107437134, aux loss1: 0.8365445137023926, 
		 aux loss2: 0.418396919965744, total loss: 0.6901975870132446
52th Epoch, 36635th Step, learning rate = 0.006247485825405321 - Loss: 0.21576528251171112, aux loss1: 0.712363600730896, 
		 aux loss2: 0.3429909944534302, total loss: 0.5666707754135132
52th Epoch, 36640th Step, learning rate = 0.006246958994247125 - Loss: 0.2716066241264343, aux loss1: 0.7219603657722473, 
		 aux loss2: 0.4081459641456604, total loss: 0.6514531373977661
52th Epoch, 36645th Step, learning rate = 0.006246432158152237 - Loss: 0.19135268032550812, aux loss1: 0.7684757709503174, 
		 aux loss2: 0.33443793654441833, total loss: 0.5556706190109253
52th Epoch, 36650th Step, learning rate = 0.006245905317120153 - Loss: 0.23744799196720123, aux loss1: 0.7956703901290894, 
		 aux loss2: 0.38874751329421997, total loss: 0.6316481232643127
52th Epoch, 36655th Step, learning rate = 0.006245378471150361 - Loss: 0.33945149183273315, aux loss1: 0.8952517509460449, 
		 aux loss2: 0.5296022295951843, total loss: 0.8198679685592651
52th Epoch, 36660th Step, learning rate = 0.0062448516202423515 - Loss: 0.3360164165496826, aux loss1: 0.981241762638092, 
		 aux loss2: 0.5763543248176575, total loss: 0.8609306812286377
52th Epoch, 36665th Step, learning rate = 0.006244324764395618 - Loss: 0.42912557721138, aux loss1: 1.1985716819763184, 
		 aux loss2: 0.6972256898880005, total loss: 1.0675873756408691
52th Epoch, 36670th Step, learning rate = 0.006243797903609648 - Loss: 0.2724505364894867, aux loss1: 0.8288580179214478, 
		 aux loss2: 0.4276503324508667, total loss: 0.692168116569519
52th Epoch, 36675th Step, learning rate = 0.006243271037883934 - Loss: 0.24731022119522095, aux loss1: 0.7260817289352417, 
		 aux loss2: 0.3770599365234375, total loss: 0.6159586906433105
52th Epoch, 36680th Step, learning rate = 0.0062427441672179675 - Loss: 0.33258968591690063, aux loss1: 0.9020124077796936, 
		 aux loss2: 0.5173234939575195, total loss: 0.8101227879524231
52th Epoch, 36685th Step, learning rate = 0.0062422172916112365 - Loss: 0.25908419489860535, aux loss1: 0.7569674253463745, 
		 aux loss2: 0.40734654664993286, total loss: 0.6491130590438843
52th Epoch, 36690th Step, learning rate = 0.0062416904110632315 - Loss: 0.2529069185256958, aux loss1: 0.8301140069961548, 
		 aux loss2: 0.4398488700389862, total loss: 0.6778807044029236
52th Epoch, 36695th Step, learning rate = 0.006241163525573446 - Loss: 0.29174190759658813, aux loss1: 0.9170627593994141, 
		 aux loss2: 0.4667208790779114, total loss: 0.7535490989685059
52th Epoch, 36700th Step, learning rate = 0.006240636635141365 - Loss: 0.3482624888420105, aux loss1: 0.9954075813293457, 
		 aux loss2: 0.5435678958892822, total loss: 0.864311933517456
<36700th step>
*************************** Test ***************************
time:3m 20s, 36700th Step, Loss: 0.5907290577888489, Mean IoU = 45.650%
************************************************************
52th Epoch, 36705th Step, learning rate = 0.0062401097397664805 - Loss: 0.2714120149612427, aux loss1: 0.7783929109573364, 
		 aux loss2: 0.4213322103023529, total loss: 0.6734628081321716
52th Epoch, 36710th Step, learning rate = 0.006239582839448286 - Loss: 0.4133303165435791, aux loss1: 1.122715950012207, 
		 aux loss2: 0.623038649559021, total loss: 0.9993605613708496
52th Epoch, 36715th Step, learning rate = 0.006239055934186265 - Loss: 0.36014214158058167, aux loss1: 0.9895349144935608, 
		 aux loss2: 0.5928453207015991, total loss: 0.8941407799720764
52th Epoch, 36720th Step, learning rate = 0.006238529023979913 - Loss: 0.3557669222354889, aux loss1: 1.1267863512039185, 
		 aux loss2: 0.6314130425453186, total loss: 0.9463680982589722
52th Epoch, 36725th Step, learning rate = 0.006238002108828716 - Loss: 0.2853269577026367, aux loss1: 0.8299369215965271, 
		 aux loss2: 0.4539554715156555, total loss: 0.7158902883529663
52th Epoch, 36730th Step, learning rate = 0.006237475188732165 - Loss: 0.26296165585517883, aux loss1: 0.701560378074646, 
		 aux loss2: 0.3780178427696228, total loss: 0.6246369481086731
52th Epoch, 36735th Step, learning rate = 0.006236948263689749 - Loss: 0.226115882396698, aux loss1: 0.8139094114303589, 
		 aux loss2: 0.43946874141693115, total loss: 0.6460762023925781
52th Epoch, 36740th Step, learning rate = 0.006236421333700956 - Loss: 0.28660324215888977, aux loss1: 0.8285611271858215, 
		 aux loss2: 0.4542602300643921, total loss: 0.7168756723403931
52th Epoch, 36745th Step, learning rate = 0.006235894398765278 - Loss: 0.2988445460796356, aux loss1: 0.793429970741272, 
		 aux loss2: 0.4426725208759308, total loss: 0.7139425873756409
52th Epoch, 36750th Step, learning rate = 0.0062353674588822025 - Loss: 0.324020653963089, aux loss1: 0.8846479058265686, 
		 aux loss2: 0.5279327034950256, total loss: 0.8005881309509277
52th Epoch, 36755th Step, learning rate = 0.0062348405140512176 - Loss: 0.23232924938201904, aux loss1: 0.7287916541099548, 
		 aux loss2: 0.3796423375606537, total loss: 0.6028237342834473
52th Epoch, 36760th Step, learning rate = 0.006234313564271814 - Loss: 0.2546299695968628, aux loss1: 0.6831167340278625, 
		 aux loss2: 0.3536248207092285, total loss: 0.6010149121284485
52th Epoch, 36765th Step, learning rate = 0.006233786609543479 - Loss: 0.31709998846054077, aux loss1: 0.8686355948448181, 
		 aux loss2: 0.4976946711540222, total loss: 0.7767685651779175
52th Epoch, 36770th Step, learning rate = 0.006233259649865701 - Loss: 0.2651481330394745, aux loss1: 0.8794856071472168, 
		 aux loss2: 0.45085203647613525, total loss: 0.709334671497345
52th Epoch, 36775th Step, learning rate = 0.006232732685237971 - Loss: 0.22114142775535583, aux loss1: 0.6679893732070923, 
		 aux loss2: 0.35175469517707825, total loss: 0.5622401237487793
52th Epoch, 36780th Step, learning rate = 0.0062322057156597764 - Loss: 0.25353071093559265, aux loss1: 0.7266822457313538, 
		 aux loss2: 0.40857377648353577, total loss: 0.6349648833274841
52th Epoch, 36785th Step, learning rate = 0.006231678741130603 - Loss: 0.20977123081684113, aux loss1: 0.6024836301803589, 
		 aux loss2: 0.3091924786567688, total loss: 0.5141933560371399
52th Epoch, 36790th Step, learning rate = 0.006231151761649943 - Loss: 0.3335137367248535, aux loss1: 1.0580213069915771, 
		 aux loss2: 0.5629745125770569, total loss: 0.8761099576950073
53th Epoch, 36795th Step, learning rate = 0.0062306247772172816 - Loss: 0.2657424211502075, aux loss1: 0.9107750654220581, 
		 aux loss2: 0.4490191638469696, total loss: 0.7185826301574707
53th Epoch, 36800th Step, learning rate = 0.006230097787832109 - Loss: 0.26477769017219543, aux loss1: 0.8575769066810608, 
		 aux loss2: 0.45144346356391907, total loss: 0.7026281356811523
<36800th step>
*************************** Test ***************************
time:3m 15s, 36800th Step, Loss: 0.5448903441429138, Mean IoU = 46.737%
************************************************************
53th Epoch, 36805th Step, learning rate = 0.0062295707934939114 - Loss: 0.2710377275943756, aux loss1: 0.7333663105964661, 
		 aux loss2: 0.3956683874130249, total loss: 0.6493149995803833
53th Epoch, 36810th Step, learning rate = 0.006229043794202178 - Loss: 0.2456279993057251, aux loss1: 0.7471297383308411, 
		 aux loss2: 0.3909573256969452, total loss: 0.6261498332023621
53th Epoch, 36815th Step, learning rate = 0.006228516789956395 - Loss: 0.2830398380756378, aux loss1: 0.8658137321472168, 
		 aux loss2: 0.5131730437278748, total loss: 0.7480531930923462
53th Epoch, 36820th Step, learning rate = 0.006227989780756053 - Loss: 0.22768954932689667, aux loss1: 0.8920243382453918, 
		 aux loss2: 0.44712018966674805, total loss: 0.6741449236869812
53th Epoch, 36825th Step, learning rate = 0.006227462766600638 - Loss: 0.3053111135959625, aux loss1: 0.7900569438934326, 
		 aux loss2: 0.4765372574329376, total loss: 0.7329431772232056
53th Epoch, 36830th Step, learning rate = 0.006226935747489636 - Loss: 0.28945767879486084, aux loss1: 1.0031615495681763, 
		 aux loss2: 0.5620453357696533, total loss: 0.815224289894104
53th Epoch, 36835th Step, learning rate = 0.006226408723422536 - Loss: 0.297981858253479, aux loss1: 0.9632973074913025, 
		 aux loss2: 0.512257993221283, total loss: 0.7918742299079895
53th Epoch, 36840th Step, learning rate = 0.006225881694398824 - Loss: 0.2892557382583618, aux loss1: 0.928248405456543, 
		 aux loss2: 0.45471709966659546, total loss: 0.7496171593666077
53th Epoch, 36845th Step, learning rate = 0.00622535466041799 - Loss: 0.2575083374977112, aux loss1: 0.8048211336135864, 
		 aux loss2: 0.4233817458152771, total loss: 0.668307363986969
53th Epoch, 36850th Step, learning rate = 0.006224827621479518 - Loss: 0.35591208934783936, aux loss1: 0.8519643545150757, 
		 aux loss2: 0.5419583916664124, total loss: 0.828284740447998
53th Epoch, 36855th Step, learning rate = 0.006224300577582895 - Loss: 0.28288957476615906, aux loss1: 0.8498866558074951, 
		 aux loss2: 0.45741161704063416, total loss: 0.7208203077316284
53th Epoch, 36860th Step, learning rate = 0.006223773528727611 - Loss: 0.2371988743543625, aux loss1: 0.7712604999542236, 
		 aux loss2: 0.3846780061721802, total loss: 0.622448205947876
53th Epoch, 36865th Step, learning rate = 0.006223246474913149 - Loss: 0.4287489354610443, aux loss1: 1.2331302165985107, 
		 aux loss2: 0.7916104793548584, total loss: 1.1153322458267212
53th Epoch, 36870th Step, learning rate = 0.006222719416138998 - Loss: 0.3043976128101349, aux loss1: 0.901948869228363, 
		 aux loss2: 0.44859424233436584, total loss: 0.7544199824333191
53th Epoch, 36875th Step, learning rate = 0.006222192352404645 - Loss: 0.27405571937561035, aux loss1: 0.8452531695365906, 
		 aux loss2: 0.44729849696159363, total loss: 0.7065510749816895
53th Epoch, 36880th Step, learning rate = 0.006221665283709574 - Loss: 0.2602367699146271, aux loss1: 0.822800874710083, 
		 aux loss2: 0.4345460832118988, total loss: 0.6808954477310181
53th Epoch, 36885th Step, learning rate = 0.006221138210053274 - Loss: 0.2238827645778656, aux loss1: 0.6233515739440918, 
		 aux loss2: 0.34391385316848755, total loss: 0.5484538078308105
53th Epoch, 36890th Step, learning rate = 0.00622061113143523 - Loss: 0.25467151403427124, aux loss1: 0.9780715107917786, 
		 aux loss2: 0.5014057755470276, total loss: 0.7486552596092224
53th Epoch, 36895th Step, learning rate = 0.006220084047854926 - Loss: 0.29547905921936035, aux loss1: 0.9835571050643921, 
		 aux loss2: 0.514599084854126, total loss: 0.7963858246803284
53th Epoch, 36900th Step, learning rate = 0.006219556959311853 - Loss: 0.40684768557548523, aux loss1: 1.0697659254074097, 
		 aux loss2: 0.6524012684822083, total loss: 0.9887380003929138
<36900th step>
*************************** Test ***************************
time:3m 15s, 36900th Step, Loss: 0.5535187125205994, Mean IoU = 46.365%
************************************************************
53th Epoch, 36905th Step, learning rate = 0.0062190298658054925 - Loss: 0.2466127723455429, aux loss1: 0.8121165633201599, 
		 aux loss2: 0.38822832703590393, total loss: 0.6455391049385071
53th Epoch, 36910th Step, learning rate = 0.006218502767335332 - Loss: 0.23339800536632538, aux loss1: 0.722543478012085, 
		 aux loss2: 0.36065474152565, total loss: 0.5944229364395142
53th Epoch, 36915th Step, learning rate = 0.0062179756639008585 - Loss: 0.22701624035835266, aux loss1: 0.7338123917579651, 
		 aux loss2: 0.3903662860393524, total loss: 0.6033064723014832
53th Epoch, 36920th Step, learning rate = 0.006217448555501556 - Loss: 0.20691053569316864, aux loss1: 0.6531060338020325, 
		 aux loss2: 0.3432680368423462, total loss: 0.5401495695114136
53th Epoch, 36925th Step, learning rate = 0.006216921442136909 - Loss: 0.220200777053833, aux loss1: 0.8150030374526978, 
		 aux loss2: 0.4295443892478943, total loss: 0.6365194916725159
53th Epoch, 36930th Step, learning rate = 0.006216394323806407 - Loss: 0.24549418687820435, aux loss1: 0.7228031754493713, 
		 aux loss2: 0.39415451884269714, total loss: 0.619996964931488
53th Epoch, 36935th Step, learning rate = 0.006215867200509531 - Loss: 0.31247615814208984, aux loss1: 0.8992257118225098, 
		 aux loss2: 0.4788699150085449, total loss: 0.7737919092178345
53th Epoch, 36940th Step, learning rate = 0.006215340072245769 - Loss: 0.24351827800273895, aux loss1: 0.9360909461975098, 
		 aux loss2: 0.44467729330062866, total loss: 0.7022165060043335
53th Epoch, 36945th Step, learning rate = 0.006214812939014605 - Loss: 0.26326724886894226, aux loss1: 0.7980518937110901, 
		 aux loss2: 0.4307515025138855, total loss: 0.6749833822250366
53th Epoch, 36950th Step, learning rate = 0.006214285800815522 - Loss: 0.33451831340789795, aux loss1: 0.938892662525177, 
		 aux loss2: 0.5536112785339355, total loss: 0.8376306295394897
53th Epoch, 36955th Step, learning rate = 0.00621375865764801 - Loss: 0.2691580057144165, aux loss1: 0.8009588718414307, 
		 aux loss2: 0.43560582399368286, total loss: 0.6836879849433899
53th Epoch, 36960th Step, learning rate = 0.006213231509511551 - Loss: 0.3527241051197052, aux loss1: 0.872373104095459, 
		 aux loss2: 0.5282100439071655, total loss: 0.8257200717926025
53th Epoch, 36965th Step, learning rate = 0.0062127043564056275 - Loss: 0.2784078121185303, aux loss1: 0.825283408164978, 
		 aux loss2: 0.46165773272514343, total loss: 0.7106559872627258
53th Epoch, 36970th Step, learning rate = 0.006212177198329728 - Loss: 0.2741294801235199, aux loss1: 0.9305415749549866, 
		 aux loss2: 0.4852502942085266, total loss: 0.7473921179771423
53th Epoch, 36975th Step, learning rate = 0.006211650035283335 - Loss: 0.27767103910446167, aux loss1: 0.769342839717865, 
		 aux loss2: 0.4446924924850464, total loss: 0.6863508820533752
53th Epoch, 36980th Step, learning rate = 0.006211122867265932 - Loss: 0.22940921783447266, aux loss1: 0.8168931007385254, 
		 aux loss2: 0.389957070350647, total loss: 0.6304600238800049
53th Epoch, 36985th Step, learning rate = 0.006210595694277007 - Loss: 0.2787633538246155, aux loss1: 0.7930266261100769, 
		 aux loss2: 0.4402316212654114, total loss: 0.6927640438079834
53th Epoch, 36990th Step, learning rate = 0.006210068516316041 - Loss: 0.2289505898952484, aux loss1: 0.7647262215614319, 
		 aux loss2: 0.36492374539375305, total loss: 0.6043379902839661
53th Epoch, 36995th Step, learning rate = 0.006209541333382518 - Loss: 0.2532450258731842, aux loss1: 0.839619517326355, 
		 aux loss2: 0.4365881681442261, total loss: 0.6797661781311035
53th Epoch, 37000th Step, learning rate = 0.006209014145475924 - Loss: 0.2249564677476883, aux loss1: 0.7329254746437073, 
		 aux loss2: 0.3800124526023865, total loss: 0.5968390703201294
<37000th step>
*************************** Test ***************************
time:3m 20s, 37000th Step, Loss: 0.5672193169593811, Mean IoU = 47.085%
************************************************************
53th Epoch, 37005th Step, learning rate = 0.006208486952595741 - Loss: 0.2659018933773041, aux loss1: 0.8458111882209778, 
		 aux loss2: 0.4314373731613159, total loss: 0.6922202110290527
53th Epoch, 37010th Step, learning rate = 0.006207959754741453 - Loss: 0.27205345034599304, aux loss1: 0.88216233253479, 
		 aux loss2: 0.4358865022659302, total loss: 0.7110567688941956
53th Epoch, 37015th Step, learning rate = 0.0062074325519125475 - Loss: 0.3424600660800934, aux loss1: 0.8033806681632996, 
		 aux loss2: 0.47678154706954956, total loss: 0.774186909198761
53th Epoch, 37020th Step, learning rate = 0.006206905344108501 - Loss: 0.1936694085597992, aux loss1: 0.6632252335548401, 
		 aux loss2: 0.3014686107635498, total loss: 0.5132244229316711
53th Epoch, 37025th Step, learning rate = 0.006206378131328804 - Loss: 0.2456396222114563, aux loss1: 0.7014097571372986, 
		 aux loss2: 0.3837655186653137, total loss: 0.6095687747001648
53th Epoch, 37030th Step, learning rate = 0.006205850913572936 - Loss: 0.2759047746658325, aux loss1: 0.886006236076355, 
		 aux loss2: 0.4764012098312378, total loss: 0.7322671413421631
53th Epoch, 37035th Step, learning rate = 0.00620532369084038 - Loss: 0.2550191283226013, aux loss1: 0.8244682550430298, 
		 aux loss2: 0.4505103528499603, total loss: 0.6825637817382812
53th Epoch, 37040th Step, learning rate = 0.006204796463130622 - Loss: 0.23525077104568481, aux loss1: 0.6695776581764221, 
		 aux loss2: 0.3672860860824585, total loss: 0.5830385088920593
53th Epoch, 37045th Step, learning rate = 0.006204269230443144 - Loss: 0.22346369922161102, aux loss1: 0.7056967616081238, 
		 aux loss2: 0.3630906641483307, total loss: 0.5804089903831482
53th Epoch, 37050th Step, learning rate = 0.006203741992777427 - Loss: 0.262205570936203, aux loss1: 0.7566394209861755, 
		 aux loss2: 0.39897385239601135, total loss: 0.6487869620323181
53th Epoch, 37055th Step, learning rate = 0.006203214750132956 - Loss: 0.29788389801979065, aux loss1: 0.8760183453559875, 
		 aux loss2: 0.5022361278533936, total loss: 0.7615839242935181
53th Epoch, 37060th Step, learning rate = 0.006202687502509212 - Loss: 0.26900529861450195, aux loss1: 0.8415841460227966, 
		 aux loss2: 0.4461494982242584, total loss: 0.6999403834342957
53th Epoch, 37065th Step, learning rate = 0.00620216024990568 - Loss: 0.25874245166778564, aux loss1: 0.7754622101783752, 
		 aux loss2: 0.41540032625198364, total loss: 0.6575412750244141
53th Epoch, 37070th Step, learning rate = 0.006201632992321843 - Loss: 0.3322333097457886, aux loss1: 0.9910871982574463, 
		 aux loss2: 0.566673994064331, total loss: 0.8562291264533997
53th Epoch, 37075th Step, learning rate = 0.0062011057297571785 - Loss: 0.25712478160858154, aux loss1: 0.9315232634544373, 
		 aux loss2: 0.4716587960720062, total loss: 0.7252452969551086
53th Epoch, 37080th Step, learning rate = 0.006200578462211175 - Loss: 0.23456420004367828, aux loss1: 0.6569414734840393, 
		 aux loss2: 0.3419451415538788, total loss: 0.5684247016906738
53th Epoch, 37085th Step, learning rate = 0.006200051189683311 - Loss: 0.2818947434425354, aux loss1: 0.9748535752296448, 
		 aux loss2: 0.4724397361278534, total loss: 0.7633267641067505
53th Epoch, 37090th Step, learning rate = 0.00619952391217307 - Loss: 0.26677393913269043, aux loss1: 0.8268295526504517, 
		 aux loss2: 0.4199710488319397, total loss: 0.6828112602233887
53th Epoch, 37095th Step, learning rate = 0.006198996629679934 - Loss: 0.31581634283065796, aux loss1: 0.8040667176246643, 
		 aux loss2: 0.47176221013069153, total loss: 0.7457413077354431
53th Epoch, 37100th Step, learning rate = 0.006198469342203384 - Loss: 0.24052345752716064, aux loss1: 0.9035464525222778, 
		 aux loss2: 0.45054173469543457, total loss: 0.691804051399231
<37100th step>
*************************** Test ***************************
time:3m 18s, 37100th Step, Loss: 0.5541415214538574, Mean IoU = 46.560%
************************************************************
53th Epoch, 37105th Step, learning rate = 0.006197942049742903 - Loss: 0.2534588873386383, aux loss1: 0.6731082201004028, 
		 aux loss2: 0.38076651096343994, total loss: 0.6076979637145996
53th Epoch, 37110th Step, learning rate = 0.006197414752297973 - Loss: 0.31209591031074524, aux loss1: 0.9127517342567444, 
		 aux loss2: 0.5011258125305176, total loss: 0.7863717079162598
53th Epoch, 37115th Step, learning rate = 0.006196887449868075 - Loss: 0.3014843463897705, aux loss1: 1.0019747018814087, 
		 aux loss2: 0.5974920392036438, total loss: 0.8410735726356506
53th Epoch, 37120th Step, learning rate = 0.006196360142452689 - Loss: 0.2667197585105896, aux loss1: 0.8934910297393799, 
		 aux loss2: 0.4802265763282776, total loss: 0.7268577218055725
53th Epoch, 37125th Step, learning rate = 0.0061958328300513 - Loss: 0.23359425365924835, aux loss1: 0.7800285816192627, 
		 aux loss2: 0.35368669033050537, total loss: 0.609077513217926
53th Epoch, 37130th Step, learning rate = 0.0061953055126633865 - Loss: 0.2681758403778076, aux loss1: 0.8705341219902039, 
		 aux loss2: 0.4733833372592926, total loss: 0.7186894416809082
53th Epoch, 37135th Step, learning rate = 0.0061947781902884315 - Loss: 0.2517889142036438, aux loss1: 0.8510985970497131, 
		 aux loss2: 0.42931339144706726, total loss: 0.6788438558578491
53th Epoch, 37140th Step, learning rate = 0.006194250862925916 - Loss: 0.25100573897361755, aux loss1: 0.7574381232261658, 
		 aux loss2: 0.4054296314716339, total loss: 0.6404090523719788
53th Epoch, 37145th Step, learning rate = 0.006193723530575317 - Loss: 0.33318108320236206, aux loss1: 0.9880010485649109, 
		 aux loss2: 0.5357416272163391, total loss: 0.8438780903816223
53th Epoch, 37150th Step, learning rate = 0.006193196193236121 - Loss: 0.3382854461669922, aux loss1: 0.8617639541625977, 
		 aux loss2: 0.5151970982551575, total loss: 0.8028934597969055
53th Epoch, 37155th Step, learning rate = 0.006192668850907807 - Loss: 0.3012787997722626, aux loss1: 0.9078052043914795, 
		 aux loss2: 0.49537423253059387, total loss: 0.7717700600624084
53th Epoch, 37160th Step, learning rate = 0.006192141503589855 - Loss: 0.28082558512687683, aux loss1: 0.912334144115448, 
		 aux loss2: 0.46644270420074463, total loss: 0.741102933883667
54th Epoch, 37165th Step, learning rate = 0.006191614151281746 - Loss: 0.2390543818473816, aux loss1: 0.7473673820495605, 
		 aux loss2: 0.38457825779914856, total loss: 0.6170958876609802
54th Epoch, 37170th Step, learning rate = 0.006191086793982959 - Loss: 0.2281816452741623, aux loss1: 0.8127259016036987, 
		 aux loss2: 0.3810155987739563, total loss: 0.6244056224822998
54th Epoch, 37175th Step, learning rate = 0.006190559431692978 - Loss: 0.3015708029270172, aux loss1: 0.9745544195175171, 
		 aux loss2: 0.5306040048599243, total loss: 0.8061787486076355
54th Epoch, 37180th Step, learning rate = 0.006190032064411281 - Loss: 0.2644853889942169, aux loss1: 1.0367753505706787, 
		 aux loss2: 0.5597397685050964, total loss: 0.7994139194488525
54th Epoch, 37185th Step, learning rate = 0.006189504692137348 - Loss: 0.3964610695838928, aux loss1: 0.9783685803413391, 
		 aux loss2: 0.6139901876449585, total loss: 0.9355677366256714
54th Epoch, 37190th Step, learning rate = 0.006188977314870658 - Loss: 0.21262510120868683, aux loss1: 0.7221705913543701, 
		 aux loss2: 0.35473477840423584, total loss: 0.5711702108383179
54th Epoch, 37195th Step, learning rate = 0.006188449932610696 - Loss: 0.2535441517829895, aux loss1: 0.7421643137931824, 
		 aux loss2: 0.40787065029144287, total loss: 0.6393417119979858
54th Epoch, 37200th Step, learning rate = 0.006187922545356934 - Loss: 0.2206597477197647, aux loss1: 0.7221029996871948, 
		 aux loss2: 0.3352142572402954, total loss: 0.571376383304596
<37200th step>
*************************** Test ***************************
time:3m 21s, 37200th Step, Loss: 0.6163883209228516, Mean IoU = 45.121%
************************************************************
54th Epoch, 37205th Step, learning rate = 0.00618739515310886 - Loss: 0.28608426451683044, aux loss1: 0.8043804168701172, 
		 aux loss2: 0.4487479031085968, total loss: 0.7068975567817688
54th Epoch, 37210th Step, learning rate = 0.006186867755865949 - Loss: 0.22794267535209656, aux loss1: 0.6614575386047363, 
		 aux loss2: 0.3379300534725189, total loss: 0.5615519881248474
54th Epoch, 37215th Step, learning rate = 0.006186340353627681 - Loss: 0.26147085428237915, aux loss1: 0.7972661256790161, 
		 aux loss2: 0.41123753786087036, total loss: 0.665145754814148
54th Epoch, 37220th Step, learning rate = 0.006185812946393536 - Loss: 0.24058625102043152, aux loss1: 0.6925008296966553, 
		 aux loss2: 0.35347816348075867, total loss: 0.5897277593612671
54th Epoch, 37225th Step, learning rate = 0.006185285534162995 - Loss: 0.21054627001285553, aux loss1: 0.6758109927177429, 
		 aux loss2: 0.32571694254875183, total loss: 0.5435763597488403
54th Epoch, 37230th Step, learning rate = 0.006184758116935534 - Loss: 0.21745628118515015, aux loss1: 0.668269157409668, 
		 aux loss2: 0.32813379168510437, total loss: 0.5491905808448792
54th Epoch, 37235th Step, learning rate = 0.006184230694710635 - Loss: 0.24599863588809967, aux loss1: 0.7831370830535889, 
		 aux loss2: 0.38751962780952454, total loss: 0.6359476447105408
54th Epoch, 37240th Step, learning rate = 0.006183703267487775 - Loss: 0.2872171401977539, aux loss1: 0.8446226119995117, 
		 aux loss2: 0.4684535562992096, total loss: 0.7279853820800781
54th Epoch, 37245th Step, learning rate = 0.006183175835266435 - Loss: 0.27863645553588867, aux loss1: 0.8245211839675903, 
		 aux loss2: 0.42433953285217285, total loss: 0.6957286596298218
54th Epoch, 37250th Step, learning rate = 0.006182648398046092 - Loss: 0.27858641743659973, aux loss1: 0.7931841015815735, 
		 aux loss2: 0.46990931034088135, total loss: 0.7045053839683533
54th Epoch, 37255th Step, learning rate = 0.006182120955826225 - Loss: 0.27382269501686096, aux loss1: 0.8123936653137207, 
		 aux loss2: 0.45884647965431213, total loss: 0.7010794281959534
54th Epoch, 37260th Step, learning rate = 0.006181593508606315 - Loss: 0.3495577871799469, aux loss1: 1.0002577304840088, 
		 aux loss2: 0.5505880117416382, total loss: 0.8698703050613403
54th Epoch, 37265th Step, learning rate = 0.006181066056385837 - Loss: 0.2400248944759369, aux loss1: 0.793403148651123, 
		 aux loss2: 0.3959372639656067, total loss: 0.636420726776123
54th Epoch, 37270th Step, learning rate = 0.006180538599164271 - Loss: 0.28323251008987427, aux loss1: 0.7444294691085815, 
		 aux loss2: 0.40793582797050476, total loss: 0.6697356700897217
54th Epoch, 37275th Step, learning rate = 0.006180011136941098 - Loss: 0.23082460463047028, aux loss1: 0.714768648147583, 
		 aux loss2: 0.3872772753238678, total loss: 0.6001661419868469
54th Epoch, 37280th Step, learning rate = 0.006179483669715793 - Loss: 0.2471202164888382, aux loss1: 0.8669284582138062, 
		 aux loss2: 0.4153502285480499, total loss: 0.6733388304710388
54th Epoch, 37285th Step, learning rate = 0.006178956197487834 - Loss: 0.22068601846694946, aux loss1: 0.7113258242607117, 
		 aux loss2: 0.35032889246940613, total loss: 0.574215292930603
54th Epoch, 37290th Step, learning rate = 0.006178428720256701 - Loss: 0.2956581115722656, aux loss1: 0.7647101879119873, 
		 aux loss2: 0.44022244215011597, total loss: 0.7011601328849792
54th Epoch, 37295th Step, learning rate = 0.006177901238021872 - Loss: 0.2847725450992584, aux loss1: 0.945366621017456, 
		 aux loss2: 0.5113236308097839, total loss: 0.7729119658470154
54th Epoch, 37300th Step, learning rate = 0.006177373750782821 - Loss: 0.2843948006629944, aux loss1: 0.7800098657608032, 
		 aux loss2: 0.4541860818862915, total loss: 0.700072169303894
<37300th step>
*************************** Test ***************************
time:3m 22s, 37300th Step, Loss: 0.5630850195884705, Mean IoU = 45.830%
************************************************************
54th Epoch, 37305th Step, learning rate = 0.00617684625853903 - Loss: 0.26948806643486023, aux loss1: 0.7743369936943054, 
		 aux loss2: 0.4650905430316925, total loss: 0.6878253817558289
54th Epoch, 37310th Step, learning rate = 0.006176318761289974 - Loss: 0.24090971052646637, aux loss1: 0.9655134081840515, 
		 aux loss2: 0.4444292187690735, total loss: 0.7083354592323303
54th Epoch, 37315th Step, learning rate = 0.0061757912590351335 - Loss: 0.2500726580619812, aux loss1: 0.7178770303726196, 
		 aux loss2: 0.3932497203350067, total loss: 0.6227356791496277
54th Epoch, 37320th Step, learning rate = 0.006175263751773984 - Loss: 0.23486270010471344, aux loss1: 0.6876544952392578, 
		 aux loss2: 0.3528873026371002, total loss: 0.5823140144348145
54th Epoch, 37325th Step, learning rate = 0.006174736239506001 - Loss: 0.27437421679496765, aux loss1: 0.867567777633667, 
		 aux loss2: 0.45912379026412964, total loss: 0.7182941436767578
54th Epoch, 37330th Step, learning rate = 0.0061742087222306655 - Loss: 0.2525305151939392, aux loss1: 0.8461466431617737, 
		 aux loss2: 0.45232459902763367, total loss: 0.6873043179512024
54th Epoch, 37335th Step, learning rate = 0.006173681199947452 - Loss: 0.23161093890666962, aux loss1: 0.8084251880645752, 
		 aux loss2: 0.40171942114830017, total loss: 0.6348263025283813
54th Epoch, 37340th Step, learning rate = 0.006173153672655838 - Loss: 0.23954932391643524, aux loss1: 0.7427986264228821, 
		 aux loss2: 0.3979707658290863, total loss: 0.621577262878418
54th Epoch, 37345th Step, learning rate = 0.006172626140355301 - Loss: 0.18462923169136047, aux loss1: 0.7441058158874512, 
		 aux loss2: 0.32696419954299927, total loss: 0.5386466979980469
54th Epoch, 37350th Step, learning rate = 0.006172098603045318 - Loss: 0.3261311650276184, aux loss1: 0.8656616806983948, 
		 aux loss2: 0.5018482804298401, total loss: 0.7865689992904663
54th Epoch, 37355th Step, learning rate = 0.006171571060725363 - Loss: 0.26428401470184326, aux loss1: 0.8352767825126648, 
		 aux loss2: 0.4571828246116638, total loss: 0.6977401971817017
54th Epoch, 37360th Step, learning rate = 0.006171043513394916 - Loss: 0.23031020164489746, aux loss1: 0.7705715894699097, 
		 aux loss2: 0.393600732088089, total loss: 0.6189219951629639
54th Epoch, 37365th Step, learning rate = 0.006170515961053453 - Loss: 0.2636500298976898, aux loss1: 0.7299708127975464, 
		 aux loss2: 0.4054727554321289, total loss: 0.6448304057121277
54th Epoch, 37370th Step, learning rate = 0.006169988403700448 - Loss: 0.21726638078689575, aux loss1: 0.6652400493621826, 
		 aux loss2: 0.33653295040130615, total loss: 0.551451563835144
54th Epoch, 37375th Step, learning rate = 0.006169460841335379 - Loss: 0.31241855025291443, aux loss1: 0.8295552134513855, 
		 aux loss2: 0.4899585247039795, total loss: 0.7572685480117798
54th Epoch, 37380th Step, learning rate = 0.006168933273957721 - Loss: 0.24357187747955322, aux loss1: 0.6295682191848755, 
		 aux loss2: 0.33111563324928284, total loss: 0.564888596534729
54th Epoch, 37385th Step, learning rate = 0.006168405701566952 - Loss: 0.21522916853427887, aux loss1: 0.6797663569450378, 
		 aux loss2: 0.34217900037765503, total loss: 0.5560306906700134
54th Epoch, 37390th Step, learning rate = 0.006167878124162547 - Loss: 0.2452617585659027, aux loss1: 0.7987987399101257, 
		 aux loss2: 0.41777303814888, total loss: 0.6520105600357056
54th Epoch, 37395th Step, learning rate = 0.0061673505417439815 - Loss: 0.24000637233257294, aux loss1: 0.6474194526672363, 
		 aux loss2: 0.36305901408195496, total loss: 0.5794558525085449
54th Epoch, 37400th Step, learning rate = 0.006166822954310733 - Loss: 0.25972095131874084, aux loss1: 0.925645112991333, 
		 aux loss2: 0.4387161433696747, total loss: 0.7129009366035461
<37400th step>
*************************** Test ***************************
time:3m 20s, 37400th Step, Loss: 0.5435934662818909, Mean IoU = 46.834%
************************************************************
54th Epoch, 37405th Step, learning rate = 0.006166295361862273 - Loss: 0.22256331145763397, aux loss1: 0.7803594470024109, 
		 aux loss2: 0.3657585680484772, total loss: 0.6029745936393738
54th Epoch, 37410th Step, learning rate = 0.00616576776439808 - Loss: 0.2193606048822403, aux loss1: 0.682877779006958, 
		 aux loss2: 0.3554142713546753, total loss: 0.5663896799087524
54th Epoch, 37415th Step, learning rate = 0.006165240161917631 - Loss: 0.26842200756073, aux loss1: 0.8901162147521973, 
		 aux loss2: 0.47907429933547974, total loss: 0.72708660364151
54th Epoch, 37420th Step, learning rate = 0.006164712554420399 - Loss: 0.29231131076812744, aux loss1: 0.8847262263298035, 
		 aux loss2: 0.47104960680007935, total loss: 0.7461490631103516
54th Epoch, 37425th Step, learning rate = 0.0061641849419058585 - Loss: 0.2495686113834381, aux loss1: 0.7346475124359131, 
		 aux loss2: 0.38512641191482544, total loss: 0.6240134835243225
54th Epoch, 37430th Step, learning rate = 0.006163657324373488 - Loss: 0.2163470983505249, aux loss1: 0.6616725325584412, 
		 aux loss2: 0.3297256827354431, total loss: 0.5467391610145569
54th Epoch, 37435th Step, learning rate = 0.006163129701822756 - Loss: 0.31386810541152954, aux loss1: 0.8816689252853394, 
		 aux loss2: 0.5044301748275757, total loss: 0.7801408767700195
54th Epoch, 37440th Step, learning rate = 0.006162602074253145 - Loss: 0.286567747592926, aux loss1: 1.0234276056289673, 
		 aux loss2: 0.5474595427513123, total loss: 0.812579870223999
54th Epoch, 37445th Step, learning rate = 0.006162074441664127 - Loss: 0.28265437483787537, aux loss1: 0.9171403646469116, 
		 aux loss2: 0.4658049941062927, total loss: 0.7441184520721436
54th Epoch, 37450th Step, learning rate = 0.0061615468040551735 - Loss: 0.3178410530090332, aux loss1: 1.1027636528015137, 
		 aux loss2: 0.5673850178718567, total loss: 0.8756241798400879
54th Epoch, 37455th Step, learning rate = 0.006161019161425764 - Loss: 0.26695436239242554, aux loss1: 0.821834146976471, 
		 aux loss2: 0.43443605303764343, total loss: 0.6872790455818176
54th Epoch, 37460th Step, learning rate = 0.00616049151377537 - Loss: 0.28649619221687317, aux loss1: 0.819417417049408, 
		 aux loss2: 0.44356995820999146, total loss: 0.7097494602203369
54th Epoch, 37465th Step, learning rate = 0.0061599638611034655 - Loss: 0.26508986949920654, aux loss1: 0.8411717414855957, 
		 aux loss2: 0.4141780138015747, total loss: 0.683112621307373
54th Epoch, 37470th Step, learning rate = 0.006159436203409529 - Loss: 0.25285759568214417, aux loss1: 0.8022512197494507, 
		 aux loss2: 0.3983358144760132, total loss: 0.652867317199707
54th Epoch, 37475th Step, learning rate = 0.006158908540693029 - Loss: 0.2517191171646118, aux loss1: 0.8602786064147949, 
		 aux loss2: 0.43122875690460205, total loss: 0.6822941899299622
54th Epoch, 37480th Step, learning rate = 0.006158380872953442 - Loss: 0.20030732452869415, aux loss1: 0.7406952977180481, 
		 aux loss2: 0.3236177861690521, total loss: 0.5519630312919617
54th Epoch, 37485th Step, learning rate = 0.006157853200190244 - Loss: 0.23051634430885315, aux loss1: 0.715216338634491, 
		 aux loss2: 0.3668193817138672, total loss: 0.5918089747428894
54th Epoch, 37490th Step, learning rate = 0.006157325522402906 - Loss: 0.31388190388679504, aux loss1: 0.9520565271377563, 
		 aux loss2: 0.5187146663665771, total loss: 0.8069847226142883
54th Epoch, 37495th Step, learning rate = 0.006156797839590902 - Loss: 0.26900020241737366, aux loss1: 0.9191027283668518, 
		 aux loss2: 0.4713537096977234, total loss: 0.7332724928855896
54th Epoch, 37500th Step, learning rate = 0.006156270151753707 - Loss: 0.2333020269870758, aux loss1: 0.8427467942237854, 
		 aux loss2: 0.4152359068393707, total loss: 0.6522204279899597
<37500th step>
*************************** Test ***************************
time:3m 21s, 37500th Step, Loss: 0.570038914680481, Mean IoU = 45.919%
************************************************************
54th Epoch, 37505th Step, learning rate = 0.006155742458890792 - Loss: 0.21054574847221375, aux loss1: 0.648252010345459, 
		 aux loss2: 0.32805195450782776, total loss: 0.5362421274185181
54th Epoch, 37510th Step, learning rate = 0.006155214761001635 - Loss: 0.2953677773475647, aux loss1: 1.0141639709472656, 
		 aux loss2: 0.5355037450790405, total loss: 0.8138185143470764
54th Epoch, 37515th Step, learning rate = 0.006154687058085705 - Loss: 0.2661706507205963, aux loss1: 0.8406416773796082, 
		 aux loss2: 0.4206492602825165, total loss: 0.6866228580474854
54th Epoch, 37520th Step, learning rate = 0.006154159350142478 - Loss: 0.30978280305862427, aux loss1: 0.9433974623680115, 
		 aux loss2: 0.5586549043655396, total loss: 0.8162640333175659
54th Epoch, 37525th Step, learning rate = 0.006153631637171426 - Loss: 0.2349853813648224, aux loss1: 0.870682418346405, 
		 aux loss2: 0.4189750850200653, total loss: 0.663780152797699
54th Epoch, 37530th Step, learning rate = 0.006153103919172021 - Loss: 0.2405453324317932, aux loss1: 0.8354536294937134, 
		 aux loss2: 0.4461686909198761, total loss: 0.6696488857269287
54th Epoch, 37535th Step, learning rate = 0.006152576196143737 - Loss: 0.35534751415252686, aux loss1: 0.8151218295097351, 
		 aux loss2: 0.4955425262451172, total loss: 0.7981011271476746
55th Epoch, 37540th Step, learning rate = 0.006152048468086048 - Loss: 0.2804458737373352, aux loss1: 0.8284887671470642, 
		 aux loss2: 0.4646075665950775, total loss: 0.7148355841636658
55th Epoch, 37545th Step, learning rate = 0.006151520734998425 - Loss: 0.25667399168014526, aux loss1: 0.7879700064659119, 
		 aux loss2: 0.41957852244377136, total loss: 0.6608964204788208
55th Epoch, 37550th Step, learning rate = 0.006150992996880339 - Loss: 0.3602714538574219, aux loss1: 1.1219383478164673, 
		 aux loss2: 0.6224488019943237, total loss: 0.9458324909210205
55th Epoch, 37555th Step, learning rate = 0.006150465253731267 - Loss: 0.2183942347764969, aux loss1: 0.6628400087356567, 
		 aux loss2: 0.33716341853141785, total loss: 0.5521116256713867
55th Epoch, 37560th Step, learning rate = 0.006149937505550677 - Loss: 0.38577842712402344, aux loss1: 0.9528628587722778, 
		 aux loss2: 0.5990363955497742, total loss: 0.9112518429756165
55th Epoch, 37565th Step, learning rate = 0.006149409752338044 - Loss: 0.23556382954120636, aux loss1: 0.8095417618751526, 
		 aux loss2: 0.40116140246391296, total loss: 0.6388909220695496
55th Epoch, 37570th Step, learning rate = 0.0061488819940928394 - Loss: 0.20966516435146332, aux loss1: 0.6542516946792603, 
		 aux loss2: 0.33579155802726746, total loss: 0.5402573347091675
55th Epoch, 37575th Step, learning rate = 0.006148354230814535 - Loss: 0.2462809830904007, aux loss1: 0.7702295184135437, 
		 aux loss2: 0.41267168521881104, total loss: 0.6424185037612915
55th Epoch, 37580th Step, learning rate = 0.006147826462502603 - Loss: 0.216891810297966, aux loss1: 0.7765260338783264, 
		 aux loss2: 0.38465043902397156, total loss: 0.6037098169326782
55th Epoch, 37585th Step, learning rate = 0.0061472986891565155 - Loss: 0.24812430143356323, aux loss1: 0.9695850014686584, 
		 aux loss2: 0.4993564486503601, total loss: 0.7387423515319824
55th Epoch, 37590th Step, learning rate = 0.006146770910775743 - Loss: 0.23955462872982025, aux loss1: 0.8530530333518982, 
		 aux loss2: 0.4470168650150299, total loss: 0.6742773056030273
55th Epoch, 37595th Step, learning rate = 0.006146243127359758 - Loss: 0.2276330590248108, aux loss1: 0.786456286907196, 
		 aux loss2: 0.41115954518318176, total loss: 0.6280337572097778
55th Epoch, 37600th Step, learning rate = 0.006145715338908033 - Loss: 0.2989960312843323, aux loss1: 0.8613303899765015, 
		 aux loss2: 0.5260641574859619, total loss: 0.7678208351135254
<37600th step>
*************************** Test ***************************
time:3m 20s, 37600th Step, Loss: 0.5998708009719849, Mean IoU = 46.731%
************************************************************
55th Epoch, 37605th Step, learning rate = 0.006145187545420038 - Loss: 0.26678746938705444, aux loss1: 0.8072883486747742, 
		 aux loss2: 0.4308762550354004, total loss: 0.6813244819641113
55th Epoch, 37610th Step, learning rate = 0.0061446597468952455 - Loss: 0.22233188152313232, aux loss1: 0.7055801153182983, 
		 aux loss2: 0.37230128049850464, total loss: 0.5829264521598816
55th Epoch, 37615th Step, learning rate = 0.006144131943333124 - Loss: 0.2256774604320526, aux loss1: 0.6672335267066956, 
		 aux loss2: 0.3193022310733795, total loss: 0.553568422794342
55th Epoch, 37620th Step, learning rate = 0.0061436041347331495 - Loss: 0.2729322612285614, aux loss1: 0.8407384157180786, 
		 aux loss2: 0.4476720988750458, total loss: 0.7042226195335388
55th Epoch, 37625th Step, learning rate = 0.0061430763210947896 - Loss: 0.26879262924194336, aux loss1: 0.7530840635299683, 
		 aux loss2: 0.4260103404521942, total loss: 0.6651219725608826
55th Epoch, 37630th Step, learning rate = 0.006142548502417513 - Loss: 0.234332874417305, aux loss1: 0.7504446506500244, 
		 aux loss2: 0.3951164186000824, total loss: 0.6175128221511841
55th Epoch, 37635th Step, learning rate = 0.006142020678700796 - Loss: 0.32008975744247437, aux loss1: 1.0754094123840332, 
		 aux loss2: 0.6173941493034363, total loss: 0.8896702527999878
55th Epoch, 37640th Step, learning rate = 0.006141492849944106 - Loss: 0.26539576053619385, aux loss1: 0.8351584076881409, 
		 aux loss2: 0.45264866948127747, total loss: 0.6970027685165405
55th Epoch, 37645th Step, learning rate = 0.006140965016146914 - Loss: 0.21265079081058502, aux loss1: 0.667325496673584, 
		 aux loss2: 0.3456868529319763, total loss: 0.5511232018470764
55th Epoch, 37650th Step, learning rate = 0.00614043717730869 - Loss: 0.2076278179883957, aux loss1: 0.796424388885498, 
		 aux loss2: 0.37902212142944336, total loss: 0.5981639623641968
55th Epoch, 37655th Step, learning rate = 0.006139909333428905 - Loss: 0.23399221897125244, aux loss1: 0.716972291469574, 
		 aux loss2: 0.35974442958831787, total loss: 0.5929816961288452
55th Epoch, 37660th Step, learning rate = 0.006139381484507029 - Loss: 0.2400766760110855, aux loss1: 0.7211046814918518, 
		 aux loss2: 0.37752917408943176, total loss: 0.6074197292327881
55th Epoch, 37665th Step, learning rate = 0.006138853630542534 - Loss: 0.24702513217926025, aux loss1: 1.0113816261291504, 
		 aux loss2: 0.47621452808380127, total loss: 0.7409254312515259
55th Epoch, 37670th Step, learning rate = 0.006138325771534886 - Loss: 0.3112425208091736, aux loss1: 0.9357371926307678, 
		 aux loss2: 0.5399728417396545, total loss: 0.8079527616500854
55th Epoch, 37675th Step, learning rate = 0.006137797907483559 - Loss: 0.2673375904560089, aux loss1: 0.8191041350364685, 
		 aux loss2: 0.4275389015674591, total loss: 0.684084415435791
55th Epoch, 37680th Step, learning rate = 0.006137270038388021 - Loss: 0.2890380620956421, aux loss1: 0.9108982682228088, 
		 aux loss2: 0.486865758895874, total loss: 0.7570539116859436
55th Epoch, 37685th Step, learning rate = 0.006136742164247741 - Loss: 0.2355726957321167, aux loss1: 0.813656747341156, 
		 aux loss2: 0.42485305666923523, total loss: 0.6496109962463379
55th Epoch, 37690th Step, learning rate = 0.00613621428506219 - Loss: 0.2799854576587677, aux loss1: 0.7963061928749084, 
		 aux loss2: 0.44917774200439453, total loss: 0.698548436164856
55th Epoch, 37695th Step, learning rate = 0.006135686400830838 - Loss: 0.25930652022361755, aux loss1: 0.8922900557518005, 
		 aux loss2: 0.41251036524772644, total loss: 0.6919976472854614
55th Epoch, 37700th Step, learning rate = 0.006135158511553151 - Loss: 0.26993438601493835, aux loss1: 0.8928434252738953, 
		 aux loss2: 0.4738948345184326, total loss: 0.72734534740448
<37700th step>
*************************** Test ***************************
time:3m 15s, 37700th Step, Loss: 0.5577012896537781, Mean IoU = 46.467%
************************************************************
55th Epoch, 37705th Step, learning rate = 0.006134630617228604 - Loss: 0.27179431915283203, aux loss1: 0.743346095085144, 
		 aux loss2: 0.41101643443107605, total loss: 0.6592047214508057
55th Epoch, 37710th Step, learning rate = 0.006134102717856661 - Loss: 0.23099562525749207, aux loss1: 0.7099901437759399, 
		 aux loss2: 0.3725365698337555, total loss: 0.5930073261260986
55th Epoch, 37715th Step, learning rate = 0.006133574813436793 - Loss: 0.287405788898468, aux loss1: 0.8209486603736877, 
		 aux loss2: 0.42345523834228516, total loss: 0.7030724883079529
55th Epoch, 37720th Step, learning rate = 0.006133046903968471 - Loss: 0.2898835837841034, aux loss1: 0.9147866368293762, 
		 aux loss2: 0.5436736941337585, total loss: 0.7817890644073486
55th Epoch, 37725th Step, learning rate = 0.006132518989451159 - Loss: 0.2692365348339081, aux loss1: 0.9365201592445374, 
		 aux loss2: 0.5039157867431641, total loss: 0.7517589330673218
55th Epoch, 37730th Step, learning rate = 0.006131991069884331 - Loss: 0.1882791519165039, aux loss1: 0.709511399269104, 
		 aux loss2: 0.3095889091491699, total loss: 0.524968147277832
55th Epoch, 37735th Step, learning rate = 0.006131463145267452 - Loss: 0.21749550104141235, aux loss1: 0.7921356558799744, 
		 aux loss2: 0.3654220402240753, total loss: 0.6013050079345703
55th Epoch, 37740th Step, learning rate = 0.006130935215599991 - Loss: 0.3142887055873871, aux loss1: 0.9354360103607178, 
		 aux loss2: 0.5500757694244385, total loss: 0.8149498701095581
55th Epoch, 37745th Step, learning rate = 0.00613040728088142 - Loss: 0.27593985199928284, aux loss1: 0.7402873039245605, 
		 aux loss2: 0.43851032853126526, total loss: 0.6734302043914795
55th Epoch, 37750th Step, learning rate = 0.006129879341111202 - Loss: 0.2589266002178192, aux loss1: 0.8703262209892273, 
		 aux loss2: 0.4229133129119873, total loss: 0.6891897916793823
55th Epoch, 37755th Step, learning rate = 0.006129351396288809 - Loss: 0.27105405926704407, aux loss1: 0.7842889428138733, 
		 aux loss2: 0.397960901260376, total loss: 0.6655250787734985
55th Epoch, 37760th Step, learning rate = 0.006128823446413709 - Loss: 0.36807191371917725, aux loss1: 0.9691998362541199, 
		 aux loss2: 0.5823060870170593, total loss: 0.8917542695999146
55th Epoch, 37765th Step, learning rate = 0.006128295491485369 - Loss: 0.22139644622802734, aux loss1: 0.6926060914993286, 
		 aux loss2: 0.37016916275024414, total loss: 0.5772459506988525
55th Epoch, 37770th Step, learning rate = 0.006127767531503256 - Loss: 0.20442193746566772, aux loss1: 0.744010329246521, 
		 aux loss2: 0.34979701042175293, total loss: 0.5675438642501831
55th Epoch, 37775th Step, learning rate = 0.006127239566466839 - Loss: 0.1991148144006729, aux loss1: 0.6714147329330444, 
		 aux loss2: 0.31245777010917664, total loss: 0.5255223512649536
55th Epoch, 37780th Step, learning rate = 0.006126711596375585 - Loss: 0.25916486978530884, aux loss1: 0.7837721109390259, 
		 aux loss2: 0.4182000160217285, total loss: 0.661576509475708
55th Epoch, 37785th Step, learning rate = 0.006126183621228963 - Loss: 0.2718939185142517, aux loss1: 0.823112428188324, 
		 aux loss2: 0.398060142993927, total loss: 0.6780517101287842
55th Epoch, 37790th Step, learning rate = 0.006125655641026438 - Loss: 0.2435663342475891, aux loss1: 0.7208235859870911, 
		 aux loss2: 0.37604910135269165, total loss: 0.6102330684661865
55th Epoch, 37795th Step, learning rate = 0.0061251276557674796 - Loss: 0.27701157331466675, aux loss1: 0.9527305364608765, 
		 aux loss2: 0.5216004848480225, total loss: 0.7714709639549255
55th Epoch, 37800th Step, learning rate = 0.0061245996654515555 - Loss: 0.21711523830890656, aux loss1: 0.6879369616508484, 
		 aux loss2: 0.3430446982383728, total loss: 0.5607142448425293
<37800th step>
*************************** Test ***************************
time:3m 13s, 37800th Step, Loss: 0.5756443738937378, Mean IoU = 46.161%
************************************************************
55th Epoch, 37805th Step, learning rate = 0.006124071670078132 - Loss: 0.298615038394928, aux loss1: 0.791445791721344, 
		 aux loss2: 0.4486124813556671, total loss: 0.7154937982559204
55th Epoch, 37810th Step, learning rate = 0.006123543669646674 - Loss: 0.2632107138633728, aux loss1: 0.7684179544448853, 
		 aux loss2: 0.4269731938838959, total loss: 0.6645253896713257
55th Epoch, 37815th Step, learning rate = 0.006123015664156651 - Loss: 0.2999119162559509, aux loss1: 0.943771481513977, 
		 aux loss2: 0.4907851219177246, total loss: 0.779357373714447
55th Epoch, 37820th Step, learning rate = 0.00612248765360753 - Loss: 0.26380908489227295, aux loss1: 0.7722474336624146, 
		 aux loss2: 0.39011162519454956, total loss: 0.651528000831604
55th Epoch, 37825th Step, learning rate = 0.006121959637998776 - Loss: 0.220950648188591, aux loss1: 0.7781985998153687, 
		 aux loss2: 0.3702504336833954, total loss: 0.6025104522705078
55th Epoch, 37830th Step, learning rate = 0.006121431617329859 - Loss: 0.30754712224006653, aux loss1: 0.8299471139907837, 
		 aux loss2: 0.4630352556705475, total loss: 0.7417453527450562
55th Epoch, 37835th Step, learning rate = 0.006120903591600241 - Loss: 0.26655447483062744, aux loss1: 0.7627004981040955, 
		 aux loss2: 0.40373632311820984, total loss: 0.6568591594696045
55th Epoch, 37840th Step, learning rate = 0.00612037556080939 - Loss: 0.2619980275630951, aux loss1: 0.7876899838447571, 
		 aux loss2: 0.39623671770095825, total loss: 0.6567997336387634
55th Epoch, 37845th Step, learning rate = 0.0061198475249567745 - Loss: 0.20546720921993256, aux loss1: 0.6735689640045166, 
		 aux loss2: 0.3325284421443939, total loss: 0.5405492782592773
55th Epoch, 37850th Step, learning rate = 0.0061193194840418585 - Loss: 0.38915470242500305, aux loss1: 0.9869197010993958, 
		 aux loss2: 0.6699373722076416, total loss: 0.9532055854797363
55th Epoch, 37855th Step, learning rate = 0.006118791438064108 - Loss: 0.3326558768749237, aux loss1: 0.8880881071090698, 
		 aux loss2: 0.5743815898895264, total loss: 0.8288350105285645
55th Epoch, 37860th Step, learning rate = 0.0061182633870229906 - Loss: 0.27279508113861084, aux loss1: 0.8549803495407104, 
		 aux loss2: 0.4838743507862091, total loss: 0.7228389382362366
55th Epoch, 37865th Step, learning rate = 0.006117735330917969 - Loss: 0.28521788120269775, aux loss1: 0.87888103723526, 
		 aux loss2: 0.4842764139175415, total loss: 0.7425928115844727
55th Epoch, 37870th Step, learning rate = 0.006117207269748514 - Loss: 0.22230368852615356, aux loss1: 0.7016833424568176, 
		 aux loss2: 0.3891614079475403, total loss: 0.5884732604026794
55th Epoch, 37875th Step, learning rate = 0.0061166792035140865 - Loss: 0.3300076723098755, aux loss1: 0.7842214703559875, 
		 aux loss2: 0.4578474164009094, total loss: 0.7484130859375
55th Epoch, 37880th Step, learning rate = 0.006116151132214154 - Loss: 0.2892441749572754, aux loss1: 0.8858168721199036, 
		 aux loss2: 0.45080405473709106, total loss: 0.7353108525276184
55th Epoch, 37885th Step, learning rate = 0.006115623055848184 - Loss: 0.2672001123428345, aux loss1: 0.7404663562774658, 
		 aux loss2: 0.42964503169059753, total loss: 0.6611980199813843
55th Epoch, 37890th Step, learning rate = 0.006115094974415638 - Loss: 0.23271901905536652, aux loss1: 0.6977025270462036, 
		 aux loss2: 0.354775071144104, total loss: 0.583939790725708
55th Epoch, 37895th Step, learning rate = 0.006114566887915982 - Loss: 0.21920618414878845, aux loss1: 0.7384697198867798, 
		 aux loss2: 0.3906262218952179, total loss: 0.5969976186752319
55th Epoch, 37900th Step, learning rate = 0.0061140387963486845 - Loss: 0.335810124874115, aux loss1: 0.7810230255126953, 
		 aux loss2: 0.4826316833496094, total loss: 0.7631697654724121
<37900th step>
*************************** Test ***************************
time:3m 10s, 37900th Step, Loss: 0.5827714800834656, Mean IoU = 46.789%
************************************************************
55th Epoch, 37905th Step, learning rate = 0.0061135106997132075 - Loss: 0.26896965503692627, aux loss1: 0.822847843170166, 
		 aux loss2: 0.4296300411224365, total loss: 0.6876760721206665
56th Epoch, 37910th Step, learning rate = 0.006112982598009015 - Loss: 0.2568723261356354, aux loss1: 0.7834246158599854, 
		 aux loss2: 0.4008130729198456, total loss: 0.6522249579429626
56th Epoch, 37915th Step, learning rate = 0.0061124544912355755 - Loss: 0.22813236713409424, aux loss1: 0.7620622515678406, 
		 aux loss2: 0.37896525859832764, total loss: 0.6083371639251709
56th Epoch, 37920th Step, learning rate = 0.006111926379392348 - Loss: 0.2260769009590149, aux loss1: 0.8332281112670898, 
		 aux loss2: 0.4342098534107208, total loss: 0.6497292518615723
56th Epoch, 37925th Step, learning rate = 0.006111398262478805 - Loss: 0.304827481508255, aux loss1: 0.9627052545547485, 
		 aux loss2: 0.5364262461662292, total loss: 0.8082095980644226
56th Epoch, 37930th Step, learning rate = 0.006110870140494404 - Loss: 0.20881764590740204, aux loss1: 0.6920918226242065, 
		 aux loss2: 0.33723315596580505, total loss: 0.5513384342193604
56th Epoch, 37935th Step, learning rate = 0.006110342013438613 - Loss: 0.29400119185447693, aux loss1: 0.8493791818618774, 
		 aux loss2: 0.46039146184921265, total loss: 0.7329715490341187
56th Epoch, 37940th Step, learning rate = 0.006109813881310895 - Loss: 0.2329145073890686, aux loss1: 0.7145442366600037, 
		 aux loss2: 0.38754624128341675, total loss: 0.6022962927818298
56th Epoch, 37945th Step, learning rate = 0.006109285744110714 - Loss: 0.2284780740737915, aux loss1: 0.8299652338027954, 
		 aux loss2: 0.4076145887374878, total loss: 0.6405134797096252
56th Epoch, 37950th Step, learning rate = 0.006108757601837535 - Loss: 0.23860704898834229, aux loss1: 1.0183988809585571, 
		 aux loss2: 0.45173558592796326, total loss: 0.7248209714889526
56th Epoch, 37955th Step, learning rate = 0.0061082294544908215 - Loss: 0.28656136989593506, aux loss1: 0.8913644552230835, 
		 aux loss2: 0.5347188711166382, total loss: 0.7678582668304443
56th Epoch, 37960th Step, learning rate = 0.006107701302070036 - Loss: 0.2008625566959381, aux loss1: 0.6654843688011169, 
		 aux loss2: 0.3550986349582672, total loss: 0.542547345161438
56th Epoch, 37965th Step, learning rate = 0.0061071731445746435 - Loss: 0.2399941086769104, aux loss1: 0.7602154016494751, 
		 aux loss2: 0.39910048246383667, total loss: 0.6276988983154297
56th Epoch, 37970th Step, learning rate = 0.006106644982004108 - Loss: 0.245993509888649, aux loss1: 0.9655954241752625, 
		 aux loss2: 0.5181809067726135, total loss: 0.7429444789886475
56th Epoch, 37975th Step, learning rate = 0.006106116814357893 - Loss: 0.2295130491256714, aux loss1: 0.7164320349693298, 
		 aux loss2: 0.3742097020149231, total loss: 0.5941265821456909
56th Epoch, 37980th Step, learning rate = 0.00610558864163546 - Loss: 0.23323127627372742, aux loss1: 0.7907013893127441, 
		 aux loss2: 0.3985540568828583, total loss: 0.6298633217811584
56th Epoch, 37985th Step, learning rate = 0.006105060463836275 - Loss: 0.2622098922729492, aux loss1: 0.9944030046463013, 
		 aux loss2: 0.48952072858810425, total loss: 0.7563390731811523
56th Epoch, 37990th Step, learning rate = 0.006104532280959798 - Loss: 0.245998814702034, aux loss1: 0.697896420955658, 
		 aux loss2: 0.392813116312027, total loss: 0.6124929785728455
56th Epoch, 37995th Step, learning rate = 0.006104004093005496 - Loss: 0.2139453887939453, aux loss1: 0.7432916760444641, 
		 aux loss2: 0.3723965883255005, total loss: 0.5858915448188782
56th Epoch, 38000th Step, learning rate = 0.0061034758999728295 - Loss: 0.23201151192188263, aux loss1: 0.74556565284729, 
		 aux loss2: 0.3790165185928345, total loss: 0.6072878241539001
<38000th step>
*************************** Test ***************************
time:3m 11s, 38000th Step, Loss: 0.5765261650085449, Mean IoU = 45.363%
************************************************************
56th Epoch, 38005th Step, learning rate = 0.006102947701861261 - Loss: 0.2905864417552948, aux loss1: 0.8128263354301453, 
		 aux loss2: 0.4655013680458069, total loss: 0.7206348776817322
56th Epoch, 38010th Step, learning rate = 0.006102419498670256 - Loss: 0.2732912302017212, aux loss1: 0.9169040322303772, 
		 aux loss2: 0.534031331539154, total loss: 0.7619750499725342
56th Epoch, 38015th Step, learning rate = 0.006101891290399273 - Loss: 0.3402901589870453, aux loss1: 0.9498337507247925, 
		 aux loss2: 0.5206489562988281, total loss: 0.8334999084472656
56th Epoch, 38020th Step, learning rate = 0.006101363077047776 - Loss: 0.2856535315513611, aux loss1: 1.0481023788452148, 
		 aux loss2: 0.5145785212516785, total loss: 0.8059156537055969
56th Epoch, 38025th Step, learning rate = 0.00610083485861523 - Loss: 0.25217899680137634, aux loss1: 0.8219627141952515, 
		 aux loss2: 0.45127809047698975, total loss: 0.679279088973999
56th Epoch, 38030th Step, learning rate = 0.006100306635101095 - Loss: 0.25980475544929504, aux loss1: 0.684093177318573, 
		 aux loss2: 0.39546459913253784, total loss: 0.6232185363769531
56th Epoch, 38035th Step, learning rate = 0.006099778406504833 - Loss: 0.22641393542289734, aux loss1: 0.6892971992492676, 
		 aux loss2: 0.3372628688812256, total loss: 0.5681082606315613
56th Epoch, 38040th Step, learning rate = 0.006099250172825908 - Loss: 0.2126365453004837, aux loss1: 0.6641821265220642, 
		 aux loss2: 0.3310377299785614, total loss: 0.5443062782287598
56th Epoch, 38045th Step, learning rate = 0.006098721934063778 - Loss: 0.23276717960834503, aux loss1: 0.7426795363426208, 
		 aux loss2: 0.40402328968048096, total loss: 0.617180347442627
56th Epoch, 38050th Step, learning rate = 0.006098193690217909 - Loss: 0.19090522825717926, aux loss1: 0.7245098352432251, 
		 aux loss2: 0.4107002913951874, total loss: 0.5725383162498474
56th Epoch, 38055th Step, learning rate = 0.006097665441287762 - Loss: 0.26698604226112366, aux loss1: 0.6889713406562805, 
		 aux loss2: 0.3891336917877197, total loss: 0.6293309330940247
56th Epoch, 38060th Step, learning rate = 0.006097137187272797 - Loss: 0.28588733077049255, aux loss1: 0.9331309795379639, 
		 aux loss2: 0.4602644443511963, total loss: 0.7499324083328247
56th Epoch, 38065th Step, learning rate = 0.006096608928172478 - Loss: 0.46249252557754517, aux loss1: 1.0092909336090088, 
		 aux loss2: 0.5979700088500977, total loss: 1.0044678449630737
56th Epoch, 38070th Step, learning rate = 0.006096080663986263 - Loss: 0.19325366616249084, aux loss1: 0.7692226767539978, 
		 aux loss2: 0.33232900500297546, total loss: 0.5569520592689514
56th Epoch, 38075th Step, learning rate = 0.006095552394713616 - Loss: 0.22439420223236084, aux loss1: 0.7679790258407593, 
		 aux loss2: 0.3726404309272766, total loss: 0.6038441061973572
56th Epoch, 38080th Step, learning rate = 0.006095024120353998 - Loss: 0.28620773553848267, aux loss1: 0.9830129146575928, 
		 aux loss2: 0.5169666409492493, total loss: 0.7878983020782471
56th Epoch, 38085th Step, learning rate = 0.0060944958409068686 - Loss: 0.24177242815494537, aux loss1: 0.9209709763526917, 
		 aux loss2: 0.4985729157924652, total loss: 0.7174928784370422
56th Epoch, 38090th Step, learning rate = 0.0060939675563716905 - Loss: 0.25099676847457886, aux loss1: 0.7970456480979919, 
		 aux loss2: 0.41979116201400757, total loss: 0.658026933670044
56th Epoch, 38095th Step, learning rate = 0.006093439266747924 - Loss: 0.261994868516922, aux loss1: 0.8170977234840393, 
		 aux loss2: 0.42076268792152405, total loss: 0.6754292845726013
56th Epoch, 38100th Step, learning rate = 0.006092910972035029 - Loss: 0.2641717493534088, aux loss1: 0.7940682172775269, 
		 aux loss2: 0.41299712657928467, total loss: 0.6675910949707031
<38100th step>
*************************** Test ***************************
time:3m 19s, 38100th Step, Loss: 0.5716967582702637, Mean IoU = 46.183%
************************************************************
56th Epoch, 38105th Step, learning rate = 0.006092382672232468 - Loss: 0.2810128331184387, aux loss1: 0.9133186936378479, 
		 aux loss2: 0.49116212129592896, total loss: 0.7514732480049133
56th Epoch, 38110th Step, learning rate = 0.006091854367339701 - Loss: 0.25776320695877075, aux loss1: 0.8408640623092651, 
		 aux loss2: 0.41843387484550476, total loss: 0.6773959398269653
56th Epoch, 38115th Step, learning rate = 0.006091326057356186 - Loss: 0.31380975246429443, aux loss1: 0.9611620903015137, 
		 aux loss2: 0.5532546639442444, total loss: 0.8234602808952332
56th Epoch, 38120th Step, learning rate = 0.006090797742281387 - Loss: 0.273662269115448, aux loss1: 0.8462939262390137, 
		 aux loss2: 0.41589781641960144, total loss: 0.6939095854759216
56th Epoch, 38125th Step, learning rate = 0.006090269422114761 - Loss: 0.29882141947746277, aux loss1: 0.9671903848648071, 
		 aux loss2: 0.5019102096557617, total loss: 0.7897425889968872
56th Epoch, 38130th Step, learning rate = 0.006089741096855771 - Loss: 0.2430872619152069, aux loss1: 0.7896427512168884, 
		 aux loss2: 0.40762463212013245, total loss: 0.6430299878120422
56th Epoch, 38135th Step, learning rate = 0.006089212766503875 - Loss: 0.2394537776708603, aux loss1: 0.8432332873344421, 
		 aux loss2: 0.4197233021259308, total loss: 0.6603131294250488
56th Epoch, 38140th Step, learning rate = 0.006088684431058534 - Loss: 0.253461629152298, aux loss1: 0.7939489483833313, 
		 aux loss2: 0.3861137926578522, total loss: 0.6460918188095093
56th Epoch, 38145th Step, learning rate = 0.0060881560905192075 - Loss: 0.22513926029205322, aux loss1: 0.7524820566177368, 
		 aux loss2: 0.38368096947669983, total loss: 0.6043562889099121
56th Epoch, 38150th Step, learning rate = 0.0060876277448853565 - Loss: 0.26005005836486816, aux loss1: 0.748518705368042, 
		 aux loss2: 0.40483152866363525, total loss: 0.646538257598877
56th Epoch, 38155th Step, learning rate = 0.006087099394156438 - Loss: 0.23453697562217712, aux loss1: 0.7584062218666077, 
		 aux loss2: 0.39910653233528137, total loss: 0.6217014789581299
56th Epoch, 38160th Step, learning rate = 0.006086571038331912 - Loss: 0.3700738251209259, aux loss1: 1.0756276845932007, 
		 aux loss2: 0.656520426273346, total loss: 0.955370306968689
56th Epoch, 38165th Step, learning rate = 0.00608604267741124 - Loss: 0.2896936535835266, aux loss1: 0.8759784698486328, 
		 aux loss2: 0.49385836720466614, total loss: 0.750030517578125
56th Epoch, 38170th Step, learning rate = 0.006085514311393877 - Loss: 0.2846653461456299, aux loss1: 0.8012542724609375, 
		 aux loss2: 0.4283466637134552, total loss: 0.6963803172111511
56th Epoch, 38175th Step, learning rate = 0.006084985940279289 - Loss: 0.28047096729278564, aux loss1: 0.7682919502258301, 
		 aux loss2: 0.45457273721694946, total loss: 0.6927876472473145
56th Epoch, 38180th Step, learning rate = 0.006084457564066927 - Loss: 0.2497003823518753, aux loss1: 0.8951572179794312, 
		 aux loss2: 0.45511090755462646, total loss: 0.7002919316291809
56th Epoch, 38185th Step, learning rate = 0.006083929182756256 - Loss: 0.27711302042007446, aux loss1: 0.7087358832359314, 
		 aux loss2: 0.38538631796836853, total loss: 0.6438883543014526
56th Epoch, 38190th Step, learning rate = 0.006083400796346734 - Loss: 0.27042362093925476, aux loss1: 1.0102297067642212, 
		 aux loss2: 0.4749602675437927, total loss: 0.7634766101837158
56th Epoch, 38195th Step, learning rate = 0.006082872404837817 - Loss: 0.27563950419425964, aux loss1: 0.9728354215621948, 
		 aux loss2: 0.5044071674346924, total loss: 0.7692529559135437
56th Epoch, 38200th Step, learning rate = 0.006082344008228965 - Loss: 0.3943641781806946, aux loss1: 1.247973918914795, 
		 aux loss2: 0.760282576084137, total loss: 1.0728694200515747
<38200th step>
*************************** Test ***************************
time:3m 12s, 38200th Step, Loss: 0.6104578375816345, Mean IoU = 45.167%
************************************************************
56th Epoch, 38205th Step, learning rate = 0.006081815606519637 - Loss: 0.33778807520866394, aux loss1: 0.9853389859199524, 
		 aux loss2: 0.5955939888954163, total loss: 0.8716273903846741
56th Epoch, 38210th Step, learning rate = 0.00608128719970929 - Loss: 0.29585352540016174, aux loss1: 0.7684451341629028, 
		 aux loss2: 0.4238165318965912, total loss: 0.6959137320518494
56th Epoch, 38215th Step, learning rate = 0.006080758787797383 - Loss: 0.30553239583969116, aux loss1: 0.8582576513290405, 
		 aux loss2: 0.4623785614967346, total loss: 0.747961163520813
56th Epoch, 38220th Step, learning rate = 0.006080230370783377 - Loss: 0.24283064901828766, aux loss1: 0.677454948425293, 
		 aux loss2: 0.37619251012802124, total loss: 0.5965441465377808
56th Epoch, 38225th Step, learning rate = 0.006079701948666724 - Loss: 0.254984587430954, aux loss1: 0.727971613407135, 
		 aux loss2: 0.3964368999004364, total loss: 0.631950855255127
56th Epoch, 38230th Step, learning rate = 0.006079173521446888 - Loss: 0.24797503650188446, aux loss1: 0.8015357255935669, 
		 aux loss2: 0.4142070412635803, total loss: 0.654118537902832
56th Epoch, 38235th Step, learning rate = 0.006078645089123322 - Loss: 0.2619931697845459, aux loss1: 0.7097247242927551, 
		 aux loss2: 0.3616495430469513, total loss: 0.6195704340934753
56th Epoch, 38240th Step, learning rate = 0.006078116651695486 - Loss: 0.2240726798772812, aux loss1: 0.6313634514808655, 
		 aux loss2: 0.3347005546092987, total loss: 0.5473619699478149
56th Epoch, 38245th Step, learning rate = 0.00607758820916284 - Loss: 0.21284998953342438, aux loss1: 0.700681746006012, 
		 aux loss2: 0.3504551649093628, total loss: 0.5632365942001343
56th Epoch, 38250th Step, learning rate = 0.006077059761524838 - Loss: 0.24635395407676697, aux loss1: 0.694694459438324, 
		 aux loss2: 0.3585246801376343, total loss: 0.5981721878051758
56th Epoch, 38255th Step, learning rate = 0.006076531308780937 - Loss: 0.2187090665102005, aux loss1: 0.7091144323348999, 
		 aux loss2: 0.3331443965435028, total loss: 0.5647011399269104
56th Epoch, 38260th Step, learning rate = 0.006076002850930597 - Loss: 0.3560222387313843, aux loss1: 1.096655249595642, 
		 aux loss2: 0.6245384812355042, total loss: 0.9348342418670654
56th Epoch, 38265th Step, learning rate = 0.006075474387973273 - Loss: 0.22428704798221588, aux loss1: 0.7425550818443298, 
		 aux loss2: 0.4204334616661072, total loss: 0.6152269840240479
56th Epoch, 38270th Step, learning rate = 0.006074945919908424 - Loss: 0.25868651270866394, aux loss1: 0.7897505760192871, 
		 aux loss2: 0.4531102776527405, total loss: 0.6768558025360107
56th Epoch, 38275th Step, learning rate = 0.006074417446735505 - Loss: 0.1897038221359253, aux loss1: 0.6335080862045288, 
		 aux loss2: 0.31241634488105774, total loss: 0.5047228336334229
57th Epoch, 38280th Step, learning rate = 0.006073888968453972 - Loss: 0.27566778659820557, aux loss1: 0.6675082445144653, 
		 aux loss2: 0.3824036121368408, total loss: 0.6288816928863525
57th Epoch, 38285th Step, learning rate = 0.006073360485063286 - Loss: 0.26540473103523254, aux loss1: 0.8274634480476379, 
		 aux loss2: 0.42086583375930786, total loss: 0.6819900870323181
57th Epoch, 38290th Step, learning rate = 0.006072831996562901 - Loss: 0.2554280757904053, aux loss1: 0.8641154170036316, 
		 aux loss2: 0.42368847131729126, total loss: 0.6841381192207336
57th Epoch, 38295th Step, learning rate = 0.006072303502952271 - Loss: 0.23448146879673004, aux loss1: 0.7937510013580322, 
		 aux loss2: 0.40196704864501953, total loss: 0.6333935856819153
57th Epoch, 38300th Step, learning rate = 0.006071775004230858 - Loss: 0.24868875741958618, aux loss1: 0.8652995824813843, 
		 aux loss2: 0.4289148151874542, total loss: 0.6798445582389832
<38300th step>
*************************** Test ***************************
time:3m 11s, 38300th Step, Loss: 0.5620623826980591, Mean IoU = 47.021%
************************************************************
57th Epoch, 38305th Step, learning rate = 0.006071246500398113 - Loss: 0.21893543004989624, aux loss1: 0.6672347784042358, 
		 aux loss2: 0.3393022119998932, total loss: 0.5548267960548401
57th Epoch, 38310th Step, learning rate = 0.006070717991453495 - Loss: 0.19670259952545166, aux loss1: 0.7002673149108887, 
		 aux loss2: 0.3562225103378296, total loss: 0.549271821975708
57th Epoch, 38315th Step, learning rate = 0.00607018947739646 - Loss: 0.27277129888534546, aux loss1: 0.8826596140861511, 
		 aux loss2: 0.4827674925327301, total loss: 0.7306761741638184
57th Epoch, 38320th Step, learning rate = 0.006069660958226463 - Loss: 0.20595058798789978, aux loss1: 0.6958895921707153, 
		 aux loss2: 0.34539592266082764, total loss: 0.5528758764266968
57th Epoch, 38325th Step, learning rate = 0.00606913243394296 - Loss: 0.30792146921157837, aux loss1: 0.9563472270965576, 
		 aux loss2: 0.5626473426818848, total loss: 0.8198845386505127
57th Epoch, 38330th Step, learning rate = 0.006068603904545408 - Loss: 0.2891610860824585, aux loss1: 0.9635480046272278, 
		 aux loss2: 0.5298954248428345, total loss: 0.7901836633682251
57th Epoch, 38335th Step, learning rate = 0.00606807537003326 - Loss: 0.35000303387641907, aux loss1: 0.858070433139801, 
		 aux loss2: 0.5138897895812988, total loss: 0.812980055809021
57th Epoch, 38340th Step, learning rate = 0.006067546830405974 - Loss: 0.25461119413375854, aux loss1: 0.8287393450737, 
		 aux loss2: 0.4579763412475586, total loss: 0.6864235401153564
57th Epoch, 38345th Step, learning rate = 0.006067018285663005 - Loss: 0.21042124927043915, aux loss1: 0.6743306517601013, 
		 aux loss2: 0.34726575016975403, total loss: 0.5516267418861389
57th Epoch, 38350th Step, learning rate = 0.006066489735803806 - Loss: 0.23736882209777832, aux loss1: 0.8553385138511658, 
		 aux loss2: 0.4500194489955902, total loss: 0.6739782094955444
57th Epoch, 38355th Step, learning rate = 0.006065961180827837 - Loss: 0.24284370243549347, aux loss1: 0.7548844218254089, 
		 aux loss2: 0.41140982508659363, total loss: 0.6338729858398438
57th Epoch, 38360th Step, learning rate = 0.006065432620734548 - Loss: 0.3202948272228241, aux loss1: 1.022691011428833, 
		 aux loss2: 0.5865708589553833, total loss: 0.8617304563522339
57th Epoch, 38365th Step, learning rate = 0.006064904055523396 - Loss: 0.2802293300628662, aux loss1: 0.7512889504432678, 
		 aux loss2: 0.3937014043331146, total loss: 0.66309654712677
57th Epoch, 38370th Step, learning rate = 0.006064375485193837 - Loss: 0.21727842092514038, aux loss1: 0.746812105178833, 
		 aux loss2: 0.41048696637153625, total loss: 0.6055168509483337
57th Epoch, 38375th Step, learning rate = 0.006063846909745323 - Loss: 0.22459357976913452, aux loss1: 0.7074539065361023, 
		 aux loss2: 0.39459559321403503, total loss: 0.5946679711341858
57th Epoch, 38380th Step, learning rate = 0.006063318329177311 - Loss: 0.2812579572200775, aux loss1: 1.0199990272521973, 
		 aux loss2: 0.5645278692245483, total loss: 0.8130688667297363
57th Epoch, 38385th Step, learning rate = 0.006062789743489255 - Loss: 0.2366325557231903, aux loss1: 0.7476581335067749, 
		 aux loss2: 0.37342309951782227, total loss: 0.6102992296218872
57th Epoch, 38390th Step, learning rate = 0.00606226115268061 - Loss: 0.30499184131622314, aux loss1: 0.8175880908966064, 
		 aux loss2: 0.4360498785972595, total loss: 0.7246882319450378
57th Epoch, 38395th Step, learning rate = 0.006061732556750827 - Loss: 0.27870503067970276, aux loss1: 0.8771325945854187, 
		 aux loss2: 0.4940783381462097, total loss: 0.739476203918457
57th Epoch, 38400th Step, learning rate = 0.0060612039556993645 - Loss: 0.25997480750083923, aux loss1: 0.8072296977043152, 
		 aux loss2: 0.43765541911125183, total loss: 0.6772059202194214
<38400th step>
*************************** Test ***************************
time:3m 12s, 38400th Step, Loss: 0.5612882375717163, Mean IoU = 46.718%
************************************************************
57th Epoch, 38405th Step, learning rate = 0.006060675349525673 - Loss: 0.24068193137645721, aux loss1: 0.7916870713233948, 
		 aux loss2: 0.3974241614341736, total loss: 0.6371577382087708
57th Epoch, 38410th Step, learning rate = 0.006060146738229211 - Loss: 0.2428562343120575, aux loss1: 0.8350521326065063, 
		 aux loss2: 0.45570477843284607, total loss: 0.6756538152694702
57th Epoch, 38415th Step, learning rate = 0.006059618121809427 - Loss: 0.22381295263767242, aux loss1: 0.7657073140144348, 
		 aux loss2: 0.3755550682544708, total loss: 0.6037471890449524
57th Epoch, 38420th Step, learning rate = 0.006059089500265778 - Loss: 0.35509562492370605, aux loss1: 0.9190671443939209, 
		 aux loss2: 0.5517247319221497, total loss: 0.8515056371688843
57th Epoch, 38425th Step, learning rate = 0.006058560873597717 - Loss: 0.21506367623806, aux loss1: 0.6968885064125061, 
		 aux loss2: 0.34046846628189087, total loss: 0.5603176355361938
57th Epoch, 38430th Step, learning rate = 0.0060580322418046974 - Loss: 0.3171459436416626, aux loss1: 0.9155563712120056, 
		 aux loss2: 0.6003183126449585, total loss: 0.8319401741027832
57th Epoch, 38435th Step, learning rate = 0.006057503604886172 - Loss: 0.21944406628608704, aux loss1: 0.7040339708328247, 
		 aux loss2: 0.38570287823677063, total loss: 0.5849354267120361
57th Epoch, 38440th Step, learning rate = 0.006056974962841596 - Loss: 0.29757583141326904, aux loss1: 0.8239728808403015, 
		 aux loss2: 0.4670766294002533, total loss: 0.7315983772277832
57th Epoch, 38445th Step, learning rate = 0.00605644631567042 - Loss: 0.24470894038677216, aux loss1: 0.6991241574287415, 
		 aux loss2: 0.3781171143054962, total loss: 0.6056930422782898
57th Epoch, 38450th Step, learning rate = 0.0060559176633720995 - Loss: 0.2695690095424652, aux loss1: 0.8147929906845093, 
		 aux loss2: 0.444653183221817, total loss: 0.6918681859970093
57th Epoch, 38455th Step, learning rate = 0.006055389005946086 - Loss: 0.24836353957653046, aux loss1: 0.8855211138725281, 
		 aux loss2: 0.4498644471168518, total loss: 0.6939656734466553
57th Epoch, 38460th Step, learning rate = 0.00605486034339183 - Loss: 0.23835301399230957, aux loss1: 0.7891173958778381, 
		 aux loss2: 0.3944033980369568, total loss: 0.6328495740890503
57th Epoch, 38465th Step, learning rate = 0.006054331675708791 - Loss: 0.25023308396339417, aux loss1: 0.708945095539093, 
		 aux loss2: 0.3924718499183655, total loss: 0.6199053525924683
57th Epoch, 38470th Step, learning rate = 0.006053803002896417 - Loss: 0.22344668209552765, aux loss1: 0.7223463654518127, 
		 aux loss2: 0.3928101360797882, total loss: 0.597274661064148
57th Epoch, 38475th Step, learning rate = 0.006053274324954158 - Loss: 0.24539554119110107, aux loss1: 0.8147582411766052, 
		 aux loss2: 0.4220193922519684, total loss: 0.6586307883262634
57th Epoch, 38480th Step, learning rate = 0.006052745641881471 - Loss: 0.18681395053863525, aux loss1: 0.668225109577179, 
		 aux loss2: 0.3001393973827362, total loss: 0.507337212562561
57th Epoch, 38485th Step, learning rate = 0.006052216953677806 - Loss: 0.3754640817642212, aux loss1: 1.0910073518753052, 
		 aux loss2: 0.7008820176124573, total loss: 0.9831191301345825
57th Epoch, 38490th Step, learning rate = 0.006051688260342617 - Loss: 0.25036972761154175, aux loss1: 0.8810986280441284, 
		 aux loss2: 0.45013192296028137, total loss: 0.6947520971298218
57th Epoch, 38495th Step, learning rate = 0.006051159561875356 - Loss: 0.34064173698425293, aux loss1: 0.8248737454414368, 
		 aux loss2: 0.4734152555465698, total loss: 0.7774699926376343
57th Epoch, 38500th Step, learning rate = 0.006050630858275471 - Loss: 0.24395202100276947, aux loss1: 0.8074470162391663, 
		 aux loss2: 0.4123792052268982, total loss: 0.6511378288269043
<38500th step>
*************************** Test ***************************
time:3m 15s, 38500th Step, Loss: 0.5516931414604187, Mean IoU = 47.138%
************************************************************
57th Epoch, 38505th Step, learning rate = 0.006050102149542418 - Loss: 0.3472348153591156, aux loss1: 1.1258176565170288, 
		 aux loss2: 0.6036733984947205, total loss: 0.9264495372772217
57th Epoch, 38510th Step, learning rate = 0.006049573435675648 - Loss: 0.16466806828975677, aux loss1: 0.5828163623809814, 
		 aux loss2: 0.2817011773586273, total loss: 0.4521934688091278
57th Epoch, 38515th Step, learning rate = 0.006049044716674612 - Loss: 0.3257089853286743, aux loss1: 0.9503926038742065, 
		 aux loss2: 0.5602604746818542, total loss: 0.8349310159683228
57th Epoch, 38520th Step, learning rate = 0.006048515992538761 - Loss: 0.2844458520412445, aux loss1: 0.8183232545852661, 
		 aux loss2: 0.4350208640098572, total loss: 0.7039512395858765
57th Epoch, 38525th Step, learning rate = 0.006047987263267548 - Loss: 0.29029083251953125, aux loss1: 0.7754793167114258, 
		 aux loss2: 0.43524661660194397, total loss: 0.6970332860946655
57th Epoch, 38530th Step, learning rate = 0.006047458528860421 - Loss: 0.2714124619960785, aux loss1: 0.8725911974906921, 
		 aux loss2: 0.44828376173973083, total loss: 0.7125033140182495
57th Epoch, 38535th Step, learning rate = 0.006046929789316836 - Loss: 0.3629436194896698, aux loss1: 0.9233094453811646, 
		 aux loss2: 0.5792625546455383, total loss: 0.8716414570808411
57th Epoch, 38540th Step, learning rate = 0.006046401044636241 - Loss: 0.2314900904893875, aux loss1: 0.6588209271430969, 
		 aux loss2: 0.3657428026199341, total loss: 0.5754334926605225
57th Epoch, 38545th Step, learning rate = 0.0060458722948180865 - Loss: 0.349098265171051, aux loss1: 1.0156176090240479, 
		 aux loss2: 0.6320432424545288, total loss: 0.906600832939148
57th Epoch, 38550th Step, learning rate = 0.006045343539861825 - Loss: 0.26018670201301575, aux loss1: 0.7305376529693604, 
		 aux loss2: 0.3933570086956024, total loss: 0.6366907954216003
57th Epoch, 38555th Step, learning rate = 0.006044814779766906 - Loss: 0.2680452764034271, aux loss1: 0.7587151527404785, 
		 aux loss2: 0.392190158367157, total loss: 0.6525359153747559
57th Epoch, 38560th Step, learning rate = 0.0060442860145327815 - Loss: 0.3078407645225525, aux loss1: 0.8849986791610718, 
		 aux loss2: 0.5234909653663635, total loss: 0.7827367782592773
57th Epoch, 38565th Step, learning rate = 0.006043757244158901 - Loss: 0.23808889091014862, aux loss1: 0.8330103754997253, 
		 aux loss2: 0.44259536266326904, total loss: 0.6650301814079285
57th Epoch, 38570th Step, learning rate = 0.0060432284686447145 - Loss: 0.22987401485443115, aux loss1: 0.7908074855804443, 
		 aux loss2: 0.41527825593948364, total loss: 0.6332275867462158
57th Epoch, 38575th Step, learning rate = 0.0060426996879896725 - Loss: 0.2558397948741913, aux loss1: 0.7451987862586975, 
		 aux loss2: 0.3919112980365753, total loss: 0.6361639499664307
57th Epoch, 38580th Step, learning rate = 0.006042170902193227 - Loss: 0.251422643661499, aux loss1: 0.8671743869781494, 
		 aux loss2: 0.45685115456581116, total loss: 0.6943154335021973
57th Epoch, 38585th Step, learning rate = 0.006041642111254824 - Loss: 0.22172260284423828, aux loss1: 0.7058013677597046, 
		 aux loss2: 0.3513248860836029, total loss: 0.5739929676055908
57th Epoch, 38590th Step, learning rate = 0.006041113315173917 - Loss: 0.2426082193851471, aux loss1: 0.6560105085372925, 
		 aux loss2: 0.33329537510871887, total loss: 0.5727295875549316
57th Epoch, 38595th Step, learning rate = 0.006040584513949956 - Loss: 0.27303871512413025, aux loss1: 0.8637552261352539, 
		 aux loss2: 0.47013694047927856, total loss: 0.7202200889587402
57th Epoch, 38600th Step, learning rate = 0.006040055707582387 - Loss: 0.2366122156381607, aux loss1: 0.6477227210998535, 
		 aux loss2: 0.35889291763305664, total loss: 0.5744861960411072
<38600th step>
*************************** Test ***************************
time:3m 13s, 38600th Step, Loss: 0.6032945513725281, Mean IoU = 45.643%
************************************************************
57th Epoch, 38605th Step, learning rate = 0.0060395268960706655 - Loss: 0.24839185178279877, aux loss1: 0.7464715838432312, 
		 aux loss2: 0.3948083817958832, total loss: 0.630256712436676
57th Epoch, 38610th Step, learning rate = 0.006038998079414235 - Loss: 0.24350666999816895, aux loss1: 0.7190337181091309, 
		 aux loss2: 0.3763344883918762, total loss: 0.6097505688667297
57th Epoch, 38615th Step, learning rate = 0.006038469257612548 - Loss: 0.22082559764385223, aux loss1: 0.6902737617492676, 
		 aux loss2: 0.3483312726020813, total loss: 0.5672402381896973
57th Epoch, 38620th Step, learning rate = 0.006037940430665053 - Loss: 0.24390926957130432, aux loss1: 0.7244794368743896, 
		 aux loss2: 0.3886282444000244, total loss: 0.6167044043540955
57th Epoch, 38625th Step, learning rate = 0.0060374115985712 - Loss: 0.2526904046535492, aux loss1: 0.7238187193870544, 
		 aux loss2: 0.38135281205177307, total loss: 0.6223771572113037
57th Epoch, 38630th Step, learning rate = 0.0060368827613304366 - Loss: 0.29805895686149597, aux loss1: 0.8220965266227722, 
		 aux loss2: 0.4612645208835602, total loss: 0.7291937470436096
57th Epoch, 38635th Step, learning rate = 0.0060363539189422135 - Loss: 0.22149132192134857, aux loss1: 0.641065239906311, 
		 aux loss2: 0.3210206925868988, total loss: 0.5422191619873047
57th Epoch, 38640th Step, learning rate = 0.006035825071405978 - Loss: 0.2840152382850647, aux loss1: 0.9017137885093689, 
		 aux loss2: 0.5016773343086243, total loss: 0.7552003860473633
57th Epoch, 38645th Step, learning rate = 0.006035296218721179 - Loss: 0.28801047801971436, aux loss1: 0.8729844093322754, 
		 aux loss2: 0.45203542709350586, total loss: 0.7307199239730835
58th Epoch, 38650th Step, learning rate = 0.006034767360887267 - Loss: 0.2772090435028076, aux loss1: 0.8859453797340393, 
		 aux loss2: 0.45616376399993896, total loss: 0.7254582047462463
58th Epoch, 38655th Step, learning rate = 0.006034238497903686 - Loss: 0.2858482897281647, aux loss1: 0.9267157316207886, 
		 aux loss2: 0.5177693367004395, total loss: 0.7709707617759705
58th Epoch, 38660th Step, learning rate = 0.00603370962976989 - Loss: 0.2709716260433197, aux loss1: 0.7778425216674805, 
		 aux loss2: 0.42896711826324463, total loss: 0.6759112477302551
58th Epoch, 38665th Step, learning rate = 0.006033180756485322 - Loss: 0.21015574038028717, aux loss1: 0.8382500410079956, 
		 aux loss2: 0.3658207952976227, total loss: 0.6079590916633606
58th Epoch, 38670th Step, learning rate = 0.006032651878049434 - Loss: 0.27853164076805115, aux loss1: 0.7808354496955872, 
		 aux loss2: 0.4443936347961426, total loss: 0.6905397176742554
58th Epoch, 38675th Step, learning rate = 0.006032122994461674 - Loss: 0.2834155559539795, aux loss1: 0.7721304893493652, 
		 aux loss2: 0.4270017743110657, total loss: 0.6858553886413574
58th Epoch, 38680th Step, learning rate = 0.0060315941057214875 - Loss: 0.2275620400905609, aux loss1: 0.7246576547622681, 
		 aux loss2: 0.3831073045730591, total loss: 0.5982022881507874
58th Epoch, 38685th Step, learning rate = 0.006031065211828323 - Loss: 0.2275075614452362, aux loss1: 0.8435168862342834, 
		 aux loss2: 0.44388464093208313, total loss: 0.6581164598464966
58th Epoch, 38690th Step, learning rate = 0.006030536312781629 - Loss: 0.21737943589687347, aux loss1: 0.7548370361328125, 
		 aux loss2: 0.36874252557754517, total loss: 0.5913275480270386
58th Epoch, 38695th Step, learning rate = 0.006030007408580852 - Loss: 0.2336311638355255, aux loss1: 0.7308166027069092, 
		 aux loss2: 0.4166392385959625, total loss: 0.6195318698883057
58th Epoch, 38700th Step, learning rate = 0.00602947849922544 - Loss: 0.23770515620708466, aux loss1: 0.7118658423423767, 
		 aux loss2: 0.3917223811149597, total loss: 0.6079539060592651
<38700th step>
*************************** Test ***************************
time:3m 15s, 38700th Step, Loss: 0.5763838887214661, Mean IoU = 46.571%
************************************************************
58th Epoch, 38705th Step, learning rate = 0.006028949584714842 - Loss: 0.20432943105697632, aux loss1: 0.7349526286125183, 
		 aux loss2: 0.3579457402229309, total loss: 0.5679935216903687
58th Epoch, 38710th Step, learning rate = 0.006028420665048501 - Loss: 0.2385907769203186, aux loss1: 0.7680560946464539, 
		 aux loss2: 0.3887869417667389, total loss: 0.6245223879814148
58th Epoch, 38715th Step, learning rate = 0.006027891740225869 - Loss: 0.27473771572113037, aux loss1: 0.8102596998214722, 
		 aux loss2: 0.4265856146812439, total loss: 0.6884499192237854
58th Epoch, 38720th Step, learning rate = 0.00602736281024639 - Loss: 0.21180109679698944, aux loss1: 0.6418379545211792, 
		 aux loss2: 0.3281964957714081, total loss: 0.5356310606002808
58th Epoch, 38725th Step, learning rate = 0.006026833875109512 - Loss: 0.26278749108314514, aux loss1: 0.7374966740608215, 
		 aux loss2: 0.4198828935623169, total loss: 0.6519896984100342
58th Epoch, 38730th Step, learning rate = 0.006026304934814681 - Loss: 0.25611311197280884, aux loss1: 0.7711718082427979, 
		 aux loss2: 0.401867538690567, total loss: 0.6482117176055908
58th Epoch, 38735th Step, learning rate = 0.006025775989361345 - Loss: 0.2046443074941635, aux loss1: 0.7184513807296753, 
		 aux loss2: 0.34685713052749634, total loss: 0.5589225888252258
58th Epoch, 38740th Step, learning rate = 0.0060252470387489486 - Loss: 0.29684561491012573, aux loss1: 0.9095621109008789, 
		 aux loss2: 0.5053297281265259, total loss: 0.7718461751937866
58th Epoch, 38745th Step, learning rate = 0.00602471808297694 - Loss: 0.2938101589679718, aux loss1: 0.9105699062347412, 
		 aux loss2: 0.48880311846733093, total loss: 0.7625023722648621
58th Epoch, 38750th Step, learning rate = 0.006024189122044765 - Loss: 0.22167281806468964, aux loss1: 0.6912893652915955, 
		 aux loss2: 0.342643141746521, total loss: 0.5661168694496155
58th Epoch, 38755th Step, learning rate = 0.006023660155951869 - Loss: 0.2893639802932739, aux loss1: 0.9914482235908508, 
		 aux loss2: 0.5530086755752563, total loss: 0.8080018758773804
58th Epoch, 38760th Step, learning rate = 0.0060231311846977 - Loss: 0.22600817680358887, aux loss1: 0.7146918177604675, 
		 aux loss2: 0.3619535267353058, total loss: 0.5851971507072449
58th Epoch, 38765th Step, learning rate = 0.0060226022082817 - Loss: 0.24332484602928162, aux loss1: 0.8010294437408447, 
		 aux loss2: 0.4229899048805237, total loss: 0.652829647064209
58th Epoch, 38770th Step, learning rate = 0.00602207322670332 - Loss: 0.2692008912563324, aux loss1: 0.8549723625183105, 
		 aux loss2: 0.4746234118938446, total loss: 0.7155419588088989
58th Epoch, 38775th Step, learning rate = 0.006021544239962004 - Loss: 0.2472231239080429, aux loss1: 0.8181313276290894, 
		 aux loss2: 0.43090683221817017, total loss: 0.6650252938270569
58th Epoch, 38780th Step, learning rate = 0.006021015248057195 - Loss: 0.3623444139957428, aux loss1: 1.1071401834487915, 
		 aux loss2: 0.6661915183067322, total loss: 0.9609631299972534
58th Epoch, 38785th Step, learning rate = 0.0060204862509883415 - Loss: 0.23211118578910828, aux loss1: 0.8583199977874756, 
		 aux loss2: 0.45576712489128113, total loss: 0.6719140410423279
58th Epoch, 38790th Step, learning rate = 0.0060199572487548885 - Loss: 0.4602039158344269, aux loss1: 1.3426055908203125, 
		 aux loss2: 0.8428253531455994, total loss: 1.2001157999038696
58th Epoch, 38795th Step, learning rate = 0.00601942824135628 - Loss: 0.24438264966011047, aux loss1: 0.7438722252845764, 
		 aux loss2: 0.37190908193588257, total loss: 0.6163079738616943
58th Epoch, 38800th Step, learning rate = 0.006018899228791962 - Loss: 0.27544334530830383, aux loss1: 0.8546522259712219, 
		 aux loss2: 0.49456021189689636, total loss: 0.7296631336212158
<38800th step>
*************************** Test ***************************
time:3m 14s, 38800th Step, Loss: 0.5900934338569641, Mean IoU = 45.163%
************************************************************
58th Epoch, 38805th Step, learning rate = 0.006018370211061379 - Loss: 0.2763918340206146, aux loss1: 0.9615671634674072, 
		 aux loss2: 0.4935174882411957, total loss: 0.7622690200805664
58th Epoch, 38810th Step, learning rate = 0.006017841188163977 - Loss: 0.2557600736618042, aux loss1: 0.7799128890037537, 
		 aux loss2: 0.4052964448928833, total loss: 0.6518524885177612
58th Epoch, 38815th Step, learning rate = 0.006017312160099201 - Loss: 0.2436685860157013, aux loss1: 0.8411991000175476, 
		 aux loss2: 0.425750732421875, total loss: 0.6663286089897156
58th Epoch, 38820th Step, learning rate = 0.006016783126866494 - Loss: 0.24739961326122284, aux loss1: 0.7526194453239441, 
		 aux loss2: 0.3894515335559845, total loss: 0.6289660930633545
58th Epoch, 38825th Step, learning rate = 0.006016254088465303 - Loss: 0.28216981887817383, aux loss1: 0.9118024706840515, 
		 aux loss2: 0.4568707048892975, total loss: 0.7384588718414307
58th Epoch, 38830th Step, learning rate = 0.006015725044895071 - Loss: 0.25164613127708435, aux loss1: 0.7658452391624451, 
		 aux loss2: 0.3941210210323334, total loss: 0.6390480995178223
58th Epoch, 38835th Step, learning rate = 0.006015195996155241 - Loss: 0.2821428179740906, aux loss1: 1.0252801179885864, 
		 aux loss2: 0.5491287112236023, total loss: 0.8093783855438232
58th Epoch, 38840th Step, learning rate = 0.00601466694224526 - Loss: 0.26347649097442627, aux loss1: 0.8319599032402039, 
		 aux loss2: 0.4527018070220947, total loss: 0.6941452026367188
58th Epoch, 38845th Step, learning rate = 0.006014137883164571 - Loss: 0.2281360924243927, aux loss1: 0.7360999584197998, 
		 aux loss2: 0.35303795337677, total loss: 0.590181291103363
58th Epoch, 38850th Step, learning rate = 0.006013608818912618 - Loss: 0.1901547759771347, aux loss1: 0.641959011554718, 
		 aux loss2: 0.2819295823574066, total loss: 0.4955143332481384
58th Epoch, 38855th Step, learning rate = 0.006013079749488845 - Loss: 0.2357361614704132, aux loss1: 0.8371174335479736, 
		 aux loss2: 0.42067718505859375, total loss: 0.6551422476768494
58th Epoch, 38860th Step, learning rate = 0.006012550674892696 - Loss: 0.21534258127212524, aux loss1: 0.7380265593528748, 
		 aux loss2: 0.3740712106227875, total loss: 0.5863790512084961
58th Epoch, 38865th Step, learning rate = 0.006012021595123615 - Loss: 0.28274813294410706, aux loss1: 0.7577760219573975, 
		 aux loss2: 0.4141662120819092, total loss: 0.6757473945617676
58th Epoch, 38870th Step, learning rate = 0.006011492510181044 - Loss: 0.38292399048805237, aux loss1: 1.1660135984420776, 
		 aux loss2: 0.6627365350723267, total loss: 0.9978227615356445
58th Epoch, 38875th Step, learning rate = 0.006010963420064429 - Loss: 0.2824353277683258, aux loss1: 0.7601630091667175, 
		 aux loss2: 0.421893447637558, total loss: 0.6792415976524353
58th Epoch, 38880th Step, learning rate = 0.006010434324773212 - Loss: 0.25660303235054016, aux loss1: 0.8867571353912354, 
		 aux loss2: 0.521497905254364, total loss: 0.7312293648719788
58th Epoch, 38885th Step, learning rate = 0.0060099052243068355 - Loss: 0.256371408700943, aux loss1: 0.8231446146965027, 
		 aux loss2: 0.48269715905189514, total loss: 0.6963936686515808
58th Epoch, 38890th Step, learning rate = 0.006009376118664742 - Loss: 0.21688491106033325, aux loss1: 0.7476153373718262, 
		 aux loss2: 0.3541135787963867, total loss: 0.5828149318695068
58th Epoch, 38895th Step, learning rate = 0.006008847007846378 - Loss: 0.23736873269081116, aux loss1: 0.7455615997314453, 
		 aux loss2: 0.39189857244491577, total loss: 0.6177966594696045
58th Epoch, 38900th Step, learning rate = 0.006008317891851184 - Loss: 0.2687389850616455, aux loss1: 0.7828809022903442, 
		 aux loss2: 0.4562213122844696, total loss: 0.6860917806625366
<38900th step>
*************************** Test ***************************
time:3m 16s, 38900th Step, Loss: 0.5474951863288879, Mean IoU = 46.466%
************************************************************
58th Epoch, 38905th Step, learning rate = 0.0060077887706786025 - Loss: 0.23765449225902557, aux loss1: 0.7358012795448303, 
		 aux loss2: 0.38690298795700073, total loss: 0.6131560802459717
58th Epoch, 38910th Step, learning rate = 0.006007259644328078 - Loss: 0.25608161091804504, aux loss1: 0.8872496485710144, 
		 aux loss2: 0.4230489134788513, total loss: 0.691476047039032
58th Epoch, 38915th Step, learning rate = 0.0060067305127990515 - Loss: 0.2846066951751709, aux loss1: 0.8665996789932251, 
		 aux loss2: 0.48843351006507874, total loss: 0.7399600148200989
58th Epoch, 38920th Step, learning rate = 0.006006201376090964 - Loss: 0.22710250318050385, aux loss1: 0.8116191029548645, 
		 aux loss2: 0.3699415922164917, total loss: 0.6185648441314697
58th Epoch, 38925th Step, learning rate = 0.006005672234203262 - Loss: 0.27979299426078796, aux loss1: 1.0424704551696777, 
		 aux loss2: 0.5281257033348083, total loss: 0.8037844896316528
58th Epoch, 38930th Step, learning rate = 0.006005143087135384 - Loss: 0.22685208916664124, aux loss1: 0.6671369671821594, 
		 aux loss2: 0.3534814119338989, total loss: 0.5683857798576355
58th Epoch, 38935th Step, learning rate = 0.006004613934886774 - Loss: 0.2858113944530487, aux loss1: 0.9380804300308228, 
		 aux loss2: 0.4833924472332001, total loss: 0.760592520236969
58th Epoch, 38940th Step, learning rate = 0.006004084777456874 - Loss: 0.22267812490463257, aux loss1: 0.768348217010498, 
		 aux loss2: 0.37611091136932373, total loss: 0.6036269664764404
58th Epoch, 38945th Step, learning rate = 0.006003555614845123 - Loss: 0.26329898834228516, aux loss1: 0.9033738374710083, 
		 aux loss2: 0.4761904776096344, total loss: 0.7247873544692993
58th Epoch, 38950th Step, learning rate = 0.006003026447050967 - Loss: 0.24751418828964233, aux loss1: 0.720986545085907, 
		 aux loss2: 0.40087470412254333, total loss: 0.6241600513458252
58th Epoch, 38955th Step, learning rate = 0.006002497274073847 - Loss: 0.23704974353313446, aux loss1: 0.6905323266983032, 
		 aux loss2: 0.35792580246925354, total loss: 0.5873798131942749
58th Epoch, 38960th Step, learning rate = 0.006001968095913201 - Loss: 0.23573043942451477, aux loss1: 0.7073730230331421, 
		 aux loss2: 0.37488633394241333, total loss: 0.597896933555603
58th Epoch, 38965th Step, learning rate = 0.0060014389125684735 - Loss: 0.30460941791534424, aux loss1: 0.797285795211792, 
		 aux loss2: 0.47797223925590515, total loss: 0.7349840402603149
58th Epoch, 38970th Step, learning rate = 0.006000909724039104 - Loss: 0.365497887134552, aux loss1: 1.2823258638381958, 
		 aux loss2: 0.7975801229476929, total loss: 1.069227695465088
58th Epoch, 38975th Step, learning rate = 0.0060003805303245365 - Loss: 0.24807238578796387, aux loss1: 0.790351927280426, 
		 aux loss2: 0.4382874667644501, total loss: 0.660493016242981
58th Epoch, 38980th Step, learning rate = 0.00599985133142421 - Loss: 0.24806825816631317, aux loss1: 0.7456479668617249, 
		 aux loss2: 0.41413334012031555, total loss: 0.6374160051345825
58th Epoch, 38985th Step, learning rate = 0.005999322127337565 - Loss: 0.25558847188949585, aux loss1: 0.761348307132721, 
		 aux loss2: 0.4006393253803253, total loss: 0.6442487239837646
58th Epoch, 38990th Step, learning rate = 0.0059987929180640425 - Loss: 0.23868094384670258, aux loss1: 0.7727062106132507, 
		 aux loss2: 0.3816384971141815, total loss: 0.6231482028961182
58th Epoch, 38995th Step, learning rate = 0.005998263703603085 - Loss: 0.24962414801120758, aux loss1: 0.8520037531852722, 
		 aux loss2: 0.42287275195121765, total loss: 0.6743744015693665
58th Epoch, 39000th Step, learning rate = 0.005997734483954131 - Loss: 0.2536369562149048, aux loss1: 0.8022793531417847, 
		 aux loss2: 0.41672417521476746, total loss: 0.6610104441642761
<39000th step>
*************************** Test ***************************
time:3m 14s, 39000th Step, Loss: 0.5849687457084656, Mean IoU = 46.811%
************************************************************
58th Epoch, 39005th Step, learning rate = 0.005997205259116622 - Loss: 0.31332555413246155, aux loss1: 0.8739845752716064, 
		 aux loss2: 0.4750377833843231, total loss: 0.7655360698699951
58th Epoch, 39010th Step, learning rate = 0.005996676029089999 - Loss: 0.3067527115345001, aux loss1: 0.8430404663085938, 
		 aux loss2: 0.5053211450576782, total loss: 0.761793315410614
58th Epoch, 39015th Step, learning rate = 0.0059961467938737 - Loss: 0.3029983937740326, aux loss1: 0.817064642906189, 
		 aux loss2: 0.46811071038246155, total loss: 0.7353621125221252
59th Epoch, 39020th Step, learning rate = 0.005995617553467169 - Loss: 0.1998899281024933, aux loss1: 0.717018723487854, 
		 aux loss2: 0.3387337028980255, total loss: 0.550489068031311
59th Epoch, 39025th Step, learning rate = 0.005995088307869842 - Loss: 0.28550422191619873, aux loss1: 0.814515233039856, 
		 aux loss2: 0.476766973733902, total loss: 0.7205656170845032
59th Epoch, 39030th Step, learning rate = 0.00599455905708116 - Loss: 0.23825791478157043, aux loss1: 0.8203374147415161, 
		 aux loss2: 0.3911941945552826, total loss: 0.6408368349075317
59th Epoch, 39035th Step, learning rate = 0.005994029801100566 - Loss: 0.21319355070590973, aux loss1: 0.6634069681167603, 
		 aux loss2: 0.35331830382347107, total loss: 0.553542971611023
59th Epoch, 39040th Step, learning rate = 0.005993500539927495 - Loss: 0.2751823365688324, aux loss1: 0.8063983917236328, 
		 aux loss2: 0.45784902572631836, total loss: 0.7002415060997009
59th Epoch, 39045th Step, learning rate = 0.0059929712735613885 - Loss: 0.2765175700187683, aux loss1: 0.844902753829956, 
		 aux loss2: 0.4264882504940033, total loss: 0.7005836963653564
59th Epoch, 39050th Step, learning rate = 0.005992442002001688 - Loss: 0.21409690380096436, aux loss1: 0.7913143038749695, 
		 aux loss2: 0.3794260621070862, total loss: 0.6032616496086121
59th Epoch, 39055th Step, learning rate = 0.00599191272524783 - Loss: 0.35777074098587036, aux loss1: 1.0630947351455688, 
		 aux loss2: 0.5892229676246643, total loss: 0.9123883247375488
59th Epoch, 39060th Step, learning rate = 0.005991383443299254 - Loss: 0.26150357723236084, aux loss1: 0.8387307524681091, 
		 aux loss2: 0.4068790674209595, total loss: 0.6758744120597839
59th Epoch, 39065th Step, learning rate = 0.005990854156155402 - Loss: 0.250675767660141, aux loss1: 0.8121857643127441, 
		 aux loss2: 0.4634520411491394, total loss: 0.6797122955322266
59th Epoch, 39070th Step, learning rate = 0.005990324863815708 - Loss: 0.24556618928909302, aux loss1: 0.8135720491409302, 
		 aux loss2: 0.4419686496257782, total loss: 0.6664252281188965
59th Epoch, 39075th Step, learning rate = 0.005989795566279615 - Loss: 0.2873125672340393, aux loss1: 0.7715123295783997, 
		 aux loss2: 0.4447067677974701, total loss: 0.6966490149497986
59th Epoch, 39080th Step, learning rate = 0.005989266263546561 - Loss: 0.3521193861961365, aux loss1: 1.2073969841003418, 
		 aux loss2: 0.6695085167884827, total loss: 0.9821418523788452
59th Epoch, 39085th Step, learning rate = 0.0059887369556159845 - Loss: 0.25363579392433167, aux loss1: 0.804587185382843, 
		 aux loss2: 0.4322414994239807, total loss: 0.6679085493087769
59th Epoch, 39090th Step, learning rate = 0.0059882076424873235 - Loss: 0.2520448863506317, aux loss1: 0.8559498190879822, 
		 aux loss2: 0.4269084632396698, total loss: 0.6795932054519653
59th Epoch, 39095th Step, learning rate = 0.005987678324160015 - Loss: 0.2560863196849823, aux loss1: 0.772744357585907, 
		 aux loss2: 0.40310484170913696, total loss: 0.6491515636444092
59th Epoch, 39100th Step, learning rate = 0.005987149000633501 - Loss: 0.22070249915122986, aux loss1: 0.821618378162384, 
		 aux loss2: 0.38588517904281616, total loss: 0.6215420961380005
<39100th step>
*************************** Test ***************************
time:3m 10s, 39100th Step, Loss: 0.5346072912216187, Mean IoU = 45.570%
************************************************************
59th Epoch, 39105th Step, learning rate = 0.005986619671907216 - Loss: 0.2603616416454315, aux loss1: 0.8073585033416748, 
		 aux loss2: 0.46944013237953186, total loss: 0.690345287322998
59th Epoch, 39110th Step, learning rate = 0.005986090337980601 - Loss: 0.23961971700191498, aux loss1: 0.8106772303581238, 
		 aux loss2: 0.41801533102989197, total loss: 0.6500290632247925
59th Epoch, 39115th Step, learning rate = 0.005985560998853091 - Loss: 0.2274003028869629, aux loss1: 0.7936075329780579, 
		 aux loss2: 0.43454205989837646, total loss: 0.6392993927001953
59th Epoch, 39120th Step, learning rate = 0.005985031654524128 - Loss: 0.2512464225292206, aux loss1: 0.7714768648147583, 
		 aux loss2: 0.4040699601173401, total loss: 0.6443175077438354
59th Epoch, 39125th Step, learning rate = 0.005984502304993144 - Loss: 0.2885330319404602, aux loss1: 1.0654385089874268, 
		 aux loss2: 0.6011081337928772, total loss: 0.8486078977584839
59th Epoch, 39130th Step, learning rate = 0.005983972950259582 - Loss: 0.2361302375793457, aux loss1: 0.7186380624771118, 
		 aux loss2: 0.3861013650894165, total loss: 0.6061621904373169
59th Epoch, 39135th Step, learning rate = 0.005983443590322877 - Loss: 0.2704022228717804, aux loss1: 0.8898239731788635, 
		 aux loss2: 0.4709669351577759, total loss: 0.7257362604141235
59th Epoch, 39140th Step, learning rate = 0.0059829142251824645 - Loss: 0.2198745757341385, aux loss1: 0.9155328273773193, 
		 aux loss2: 0.4555491507053375, total loss: 0.6767541170120239
59th Epoch, 39145th Step, learning rate = 0.005982384854837787 - Loss: 0.3900792896747589, aux loss1: 0.9594672918319702, 
		 aux loss2: 0.6386069059371948, total loss: 0.9333622455596924
59th Epoch, 39150th Step, learning rate = 0.005981855479288276 - Loss: 0.4022971987724304, aux loss1: 1.198668360710144, 
		 aux loss2: 0.7192167639732361, total loss: 1.0495843887329102
59th Epoch, 39155th Step, learning rate = 0.005981326098533372 - Loss: 0.2693330943584442, aux loss1: 0.9691197276115417, 
		 aux loss2: 0.5149534940719604, total loss: 0.7660504579544067
59th Epoch, 39160th Step, learning rate = 0.0059807967125725114 - Loss: 0.2823898494243622, aux loss1: 0.9051818251609802, 
		 aux loss2: 0.4795699119567871, total loss: 0.7457723617553711
59th Epoch, 39165th Step, learning rate = 0.005980267321405131 - Loss: 0.3017714023590088, aux loss1: 0.8563605546951294, 
		 aux loss2: 0.4916481077671051, total loss: 0.7553388476371765
59th Epoch, 39170th Step, learning rate = 0.005979737925030665 - Loss: 0.289726197719574, aux loss1: 0.9568975567817688, 
		 aux loss2: 0.5086489319801331, total loss: 0.7802550196647644
59th Epoch, 39175th Step, learning rate = 0.005979208523448555 - Loss: 0.2534678280353546, aux loss1: 0.8043915629386902, 
		 aux loss2: 0.4102509915828705, total loss: 0.6588857173919678
59th Epoch, 39180th Step, learning rate = 0.005978679116658232 - Loss: 0.32854893803596497, aux loss1: 0.8785212635993958, 
		 aux loss2: 0.47151103615760803, total loss: 0.7807097434997559
59th Epoch, 39185th Step, learning rate = 0.005978149704659135 - Loss: 0.27042707800865173, aux loss1: 0.7749285697937012, 
		 aux loss2: 0.41556867957115173, total loss: 0.6691331267356873
59th Epoch, 39190th Step, learning rate = 0.005977620287450702 - Loss: 0.2635240852832794, aux loss1: 0.8352046608924866, 
		 aux loss2: 0.4240002930164337, total loss: 0.6836856603622437
59th Epoch, 39195th Step, learning rate = 0.005977090865032363 - Loss: 0.27111050486564636, aux loss1: 0.8453600406646729, 
		 aux loss2: 0.46163928508758545, total loss: 0.7093742489814758
59th Epoch, 39200th Step, learning rate = 0.005976561437403561 - Loss: 0.30565592646598816, aux loss1: 0.8248764872550964, 
		 aux loss2: 0.4960997998714447, total loss: 0.751558780670166
<39200th step>
*************************** Test ***************************
time:3m 11s, 39200th Step, Loss: 0.5854623913764954, Mean IoU = 46.289%
************************************************************
59th Epoch, 39205th Step, learning rate = 0.00597603200456373 - Loss: 0.24693019688129425, aux loss1: 0.6893322467803955, 
		 aux loss2: 0.3900132477283478, total loss: 0.6097351908683777
59th Epoch, 39210th Step, learning rate = 0.005975502566512302 - Loss: 0.24910968542099, aux loss1: 0.8417942523956299, 
		 aux loss2: 0.451729416847229, total loss: 0.6823397278785706
59th Epoch, 39215th Step, learning rate = 0.005974973123248717 - Loss: 0.19999577105045319, aux loss1: 0.7070698142051697, 
		 aux loss2: 0.3313649296760559, total loss: 0.5446627140045166
59th Epoch, 39220th Step, learning rate = 0.005974443674772408 - Loss: 0.2905406653881073, aux loss1: 0.8724985122680664, 
		 aux loss2: 0.49331751465797424, total loss: 0.7496172189712524
59th Epoch, 39225th Step, learning rate = 0.005973914221082811 - Loss: 0.20592114329338074, aux loss1: 0.6546601057052612, 
		 aux loss2: 0.3314518630504608, total loss: 0.5348999500274658
59th Epoch, 39230th Step, learning rate = 0.005973384762179362 - Loss: 0.2527640759944916, aux loss1: 0.8987988829612732, 
		 aux loss2: 0.457896888256073, total loss: 0.7055624723434448
59th Epoch, 39235th Step, learning rate = 0.005972855298061496 - Loss: 0.2662222385406494, aux loss1: 0.9155638217926025, 
		 aux loss2: 0.551937460899353, total loss: 0.7616664171218872
59th Epoch, 39240th Step, learning rate = 0.005972325828728646 - Loss: 0.21811190247535706, aux loss1: 0.7864461541175842, 
		 aux loss2: 0.3951197862625122, total loss: 0.6120936870574951
59th Epoch, 39245th Step, learning rate = 0.005971796354180251 - Loss: 0.2515847384929657, aux loss1: 0.7246245741844177, 
		 aux loss2: 0.3888854384422302, total loss: 0.6245262622833252
59th Epoch, 39250th Step, learning rate = 0.005971266874415741 - Loss: 0.24402277171611786, aux loss1: 0.7944435477256775, 
		 aux loss2: 0.4035595655441284, total loss: 0.6437796354293823
59th Epoch, 39255th Step, learning rate = 0.005970737389434555 - Loss: 0.2636888921260834, aux loss1: 0.9178361296653748, 
		 aux loss2: 0.5304902195930481, total loss: 0.751235842704773
59th Epoch, 39260th Step, learning rate = 0.005970207899236126 - Loss: 0.25670140981674194, aux loss1: 0.8008712530136108, 
		 aux loss2: 0.4054737091064453, total loss: 0.6591522693634033
59th Epoch, 39265th Step, learning rate = 0.005969678403819886 - Loss: 0.2826748490333557, aux loss1: 0.9314206838607788, 
		 aux loss2: 0.5036733150482178, total loss: 0.7635704278945923
59th Epoch, 39270th Step, learning rate = 0.005969148903185273 - Loss: 0.36499518156051636, aux loss1: 1.0628443956375122, 
		 aux loss2: 0.6363469362258911, total loss: 0.9383872747421265
59th Epoch, 39275th Step, learning rate = 0.005968619397331718 - Loss: 0.24533601105213165, aux loss1: 0.8565047979354858, 
		 aux loss2: 0.43662017583847046, total loss: 0.6769355535507202
59th Epoch, 39280th Step, learning rate = 0.005968089886258659 - Loss: 0.326816201210022, aux loss1: 0.9512227177619934, 
		 aux loss2: 0.5903377532958984, total loss: 0.8483181595802307
59th Epoch, 39285th Step, learning rate = 0.005967560369965527 - Loss: 0.26975175738334656, aux loss1: 0.8063822388648987, 
		 aux loss2: 0.4242432415485382, total loss: 0.6813637018203735
59th Epoch, 39290th Step, learning rate = 0.005967030848451757 - Loss: 0.2060350626707077, aux loss1: 0.6749857068061829, 
		 aux loss2: 0.3442714512348175, total loss: 0.5462393760681152
59th Epoch, 39295th Step, learning rate = 0.005966501321716781 - Loss: 0.24463306367397308, aux loss1: 0.759810209274292, 
		 aux loss2: 0.3976447582244873, total loss: 0.6316340565681458
59th Epoch, 39300th Step, learning rate = 0.005965971789760036 - Loss: 0.28095927834510803, aux loss1: 0.8037612438201904, 
		 aux loss2: 0.4824807941913605, total loss: 0.7150800228118896
<39300th step>
*************************** Test ***************************
time:3m 9s, 39300th Step, Loss: 0.5580490231513977, Mean IoU = 46.007%
************************************************************
59th Epoch, 39305th Step, learning rate = 0.005965442252580951 - Loss: 0.2615014314651489, aux loss1: 0.7438356280326843, 
		 aux loss2: 0.4090942144393921, total loss: 0.6482897996902466
59th Epoch, 39310th Step, learning rate = 0.005964912710178964 - Loss: 0.23443585634231567, aux loss1: 0.7790942192077637, 
		 aux loss2: 0.4134664237499237, total loss: 0.6335507035255432
59th Epoch, 39315th Step, learning rate = 0.005964383162553507 - Loss: 0.23463040590286255, aux loss1: 0.7626854777336121, 
		 aux loss2: 0.3856915533542633, total loss: 0.617712676525116
59th Epoch, 39320th Step, learning rate = 0.005963853609704009 - Loss: 0.28835415840148926, aux loss1: 0.7595006227493286, 
		 aux loss2: 0.4510752260684967, total loss: 0.6966344714164734
59th Epoch, 39325th Step, learning rate = 0.00596332405162991 - Loss: 0.2748239040374756, aux loss1: 0.8313305974006653, 
		 aux loss2: 0.4450005292892456, total loss: 0.7022233009338379
59th Epoch, 39330th Step, learning rate = 0.0059627944883306385 - Loss: 0.29623323678970337, aux loss1: 0.8907601237297058, 
		 aux loss2: 0.5081459283828735, total loss: 0.7667196989059448
59th Epoch, 39335th Step, learning rate = 0.005962264919805628 - Loss: 0.23108814656734467, aux loss1: 0.7586256861686707, 
		 aux loss2: 0.39894261956214905, total loss: 0.6182529330253601
59th Epoch, 39340th Step, learning rate = 0.005961735346054312 - Loss: 0.2786753177642822, aux loss1: 0.8071469068527222, 
		 aux loss2: 0.45420023798942566, total loss: 0.702499508857727
59th Epoch, 39345th Step, learning rate = 0.005961205767076122 - Loss: 0.22017855942249298, aux loss1: 0.7664706110954285, 
		 aux loss2: 0.3709115982055664, total loss: 0.5984843969345093
59th Epoch, 39350th Step, learning rate = 0.00596067618287049 - Loss: 0.26656535267829895, aux loss1: 0.8693522214889526, 
		 aux loss2: 0.4654463231563568, total loss: 0.7135496139526367
59th Epoch, 39355th Step, learning rate = 0.005960146593436851 - Loss: 0.35155874490737915, aux loss1: 1.0908238887786865, 
		 aux loss2: 0.6355519890785217, total loss: 0.9330267906188965
59th Epoch, 39360th Step, learning rate = 0.005959616998774635 - Loss: 0.3511049449443817, aux loss1: 0.8775084018707275, 
		 aux loss2: 0.5133818984031677, total loss: 0.8197102546691895
59th Epoch, 39365th Step, learning rate = 0.005959087398883274 - Loss: 0.2940862476825714, aux loss1: 0.8882228136062622, 
		 aux loss2: 0.5222823619842529, total loss: 0.7694660425186157
59th Epoch, 39370th Step, learning rate = 0.005958557793762202 - Loss: 0.2177160084247589, aux loss1: 0.8166846036911011, 
		 aux loss2: 0.4070732891559601, total loss: 0.6255507469177246
59th Epoch, 39375th Step, learning rate = 0.005958028183410847 - Loss: 0.2795114815235138, aux loss1: 0.9583280086517334, 
		 aux loss2: 0.5025467276573181, total loss: 0.7680286169052124
59th Epoch, 39380th Step, learning rate = 0.005957498567828646 - Loss: 0.2649228572845459, aux loss1: 0.8349694609642029, 
		 aux loss2: 0.43096134066581726, total loss: 0.687798261642456
59th Epoch, 39385th Step, learning rate = 0.005956968947015028 - Loss: 0.2771836817264557, aux loss1: 0.8836285471916199, 
		 aux loss2: 0.5449876189231873, total loss: 0.7602673172950745
59th Epoch, 39390th Step, learning rate = 0.005956439320969424 - Loss: 0.22024975717067719, aux loss1: 0.6851687431335449, 
		 aux loss2: 0.3741670250892639, total loss: 0.5754672288894653
60th Epoch, 39395th Step, learning rate = 0.005955909689691266 - Loss: 0.2334122210741043, aux loss1: 0.7167532444000244, 
		 aux loss2: 0.368445485830307, total loss: 0.5958163738250732
60th Epoch, 39400th Step, learning rate = 0.005955380053179984 - Loss: 0.14909367263317108, aux loss1: 0.5863897800445557, 
		 aux loss2: 0.24635502696037292, total loss: 0.42355260252952576
<39400th step>
*************************** Test ***************************
time:3m 7s, 39400th Step, Loss: 0.5365608930587769, Mean IoU = 47.369%
************************************************************
60th Epoch, 39405th Step, learning rate = 0.00595485041143501 - Loss: 0.3177729547023773, aux loss1: 1.233802080154419, 
		 aux loss2: 0.7277194261550903, total loss: 0.9790014028549194
60th Epoch, 39410th Step, learning rate = 0.005954320764455777 - Loss: 0.3150932192802429, aux loss1: 1.0581583976745605, 
		 aux loss2: 0.5619686841964722, total loss: 0.8573282361030579
60th Epoch, 39415th Step, learning rate = 0.005953791112241714 - Loss: 0.22744736075401306, aux loss1: 0.639246940612793, 
		 aux loss2: 0.35417643189430237, total loss: 0.5608920454978943
60th Epoch, 39420th Step, learning rate = 0.005953261454792251 - Loss: 0.22643043100833893, aux loss1: 0.8016183972358704, 
		 aux loss2: 0.3856603503227234, total loss: 0.6211801171302795
60th Epoch, 39425th Step, learning rate = 0.005952731792106821 - Loss: 0.35516437888145447, aux loss1: 1.0420446395874023, 
		 aux loss2: 0.6189142465591431, total loss: 0.9153434634208679
60th Epoch, 39430th Step, learning rate = 0.005952202124184853 - Loss: 0.25618845224380493, aux loss1: 0.8014775514602661, 
		 aux loss2: 0.46298038959503174, total loss: 0.6818239092826843
60th Epoch, 39435th Step, learning rate = 0.005951672451025778 - Loss: 0.2298070192337036, aux loss1: 0.6937116384506226, 
		 aux loss2: 0.3764156699180603, total loss: 0.5884867906570435
60th Epoch, 39440th Step, learning rate = 0.005951142772629027 - Loss: 0.2349715530872345, aux loss1: 0.8014161586761475, 
		 aux loss2: 0.42562419176101685, total loss: 0.6456460952758789
60th Epoch, 39445th Step, learning rate = 0.005950613088994027 - Loss: 0.31149178743362427, aux loss1: 0.7682717442512512, 
		 aux loss2: 0.500389814376831, total loss: 0.7421292662620544
60th Epoch, 39450th Step, learning rate = 0.005950083400120213 - Loss: 0.24453985691070557, aux loss1: 0.6962887048721313, 
		 aux loss2: 0.3616264760494232, total loss: 0.5980770587921143
60th Epoch, 39455th Step, learning rate = 0.005949553706007011 - Loss: 0.23353654146194458, aux loss1: 0.6471509337425232, 
		 aux loss2: 0.3601464033126831, total loss: 0.5717403888702393
60th Epoch, 39460th Step, learning rate = 0.005949024006653853 - Loss: 0.2349715232849121, aux loss1: 0.8037277460098267, 
		 aux loss2: 0.3882948160171509, total loss: 0.6314077377319336
60th Epoch, 39465th Step, learning rate = 0.005948494302060169 - Loss: 0.2745610475540161, aux loss1: 1.0158039331436157, 
		 aux loss2: 0.4893460273742676, total loss: 0.7750406861305237
60th Epoch, 39470th Step, learning rate = 0.005947964592225387 - Loss: 0.2240784764289856, aux loss1: 0.9467832446098328, 
		 aux loss2: 0.437730073928833, total loss: 0.6832055449485779
60th Epoch, 39475th Step, learning rate = 0.0059474348771489365 - Loss: 0.2197338342666626, aux loss1: 0.732884407043457, 
		 aux loss2: 0.3749407231807709, total loss: 0.589575469493866
60th Epoch, 39480th Step, learning rate = 0.005946905156830249 - Loss: 0.2558949291706085, aux loss1: 0.8591432571411133, 
		 aux loss2: 0.42437154054641724, total loss: 0.683386504650116
60th Epoch, 39485th Step, learning rate = 0.005946375431268751 - Loss: 0.2367793172597885, aux loss1: 0.781557559967041, 
		 aux loss2: 0.4047166109085083, total loss: 0.6331332325935364
60th Epoch, 39490th Step, learning rate = 0.005945845700463874 - Loss: 0.2224855273962021, aux loss1: 0.8173112273216248, 
		 aux loss2: 0.39412951469421387, total loss: 0.6253306865692139
60th Epoch, 39495th Step, learning rate = 0.005945315964415047 - Loss: 0.2478526532649994, aux loss1: 0.7560946345329285, 
		 aux loss2: 0.3870494067668915, total loss: 0.6295008063316345
60th Epoch, 39500th Step, learning rate = 0.005944786223121695 - Loss: 0.21903200447559357, aux loss1: 0.7018263936042786, 
		 aux loss2: 0.3450416922569275, total loss: 0.5675966143608093
<39500th step>
*************************** Test ***************************
time:3m 8s, 39500th Step, Loss: 0.5593220591545105, Mean IoU = 47.608%
************************************************************
60th Epoch, 39505th Step, learning rate = 0.005944256476583253 - Loss: 0.2349248230457306, aux loss1: 0.779488205909729, 
		 aux loss2: 0.37107691168785095, total loss: 0.6172020435333252
60th Epoch, 39510th Step, learning rate = 0.005943726724799146 - Loss: 0.27703404426574707, aux loss1: 0.9625031352043152, 
		 aux loss2: 0.5251425504684448, total loss: 0.775842010974884
60th Epoch, 39515th Step, learning rate = 0.005943196967768802 - Loss: 0.2799501121044159, aux loss1: 0.8676412105560303, 
		 aux loss2: 0.4619848132133484, total loss: 0.7250364422798157
60th Epoch, 39520th Step, learning rate = 0.005942667205491652 - Loss: 0.2821473777294159, aux loss1: 0.8497099280357361, 
		 aux loss2: 0.4802381098270416, total loss: 0.7291556596755981
60th Epoch, 39525th Step, learning rate = 0.005942137437967121 - Loss: 0.20476225018501282, aux loss1: 0.628745436668396, 
		 aux loss2: 0.33052322268486023, total loss: 0.5255951881408691
60th Epoch, 39530th Step, learning rate = 0.0059416076651946405 - Loss: 0.21737217903137207, aux loss1: 0.7022762298583984, 
		 aux loss2: 0.352279394865036, total loss: 0.568966805934906
60th Epoch, 39535th Step, learning rate = 0.005941077887173637 - Loss: 0.21379691362380981, aux loss1: 0.6906198263168335, 
		 aux loss2: 0.3459848463535309, total loss: 0.5593768358230591
60th Epoch, 39540th Step, learning rate = 0.005940548103903539 - Loss: 0.24508756399154663, aux loss1: 0.7053517699241638, 
		 aux loss2: 0.3927837014198303, total loss: 0.6138066053390503
60th Epoch, 39545th Step, learning rate = 0.005940018315383773 - Loss: 0.2252267748117447, aux loss1: 0.6814181804656982, 
		 aux loss2: 0.34761863946914673, total loss: 0.5686997175216675
60th Epoch, 39550th Step, learning rate = 0.005939488521613768 - Loss: 0.2447793036699295, aux loss1: 0.8611695766448975, 
		 aux loss2: 0.48682284355163574, total loss: 0.6978593468666077
60th Epoch, 39555th Step, learning rate = 0.005938958722592951 - Loss: 0.31366875767707825, aux loss1: 0.9198918342590332, 
		 aux loss2: 0.5311834812164307, total loss: 0.8021097183227539
60th Epoch, 39560th Step, learning rate = 0.005938428918320751 - Loss: 0.21923841536045074, aux loss1: 0.7158273458480835, 
		 aux loss2: 0.34440135955810547, total loss: 0.5717471837997437
60th Epoch, 39565th Step, learning rate = 0.005937899108796593 - Loss: 0.23727810382843018, aux loss1: 0.7179653644561768, 
		 aux loss2: 0.3767435550689697, total loss: 0.6033651232719421
60th Epoch, 39570th Step, learning rate = 0.005937369294019905 - Loss: 0.24475157260894775, aux loss1: 0.9403097033500671, 
		 aux loss2: 0.43718400597572327, total loss: 0.7017180919647217
60th Epoch, 39575th Step, learning rate = 0.005936839473990116 - Loss: 0.24884699285030365, aux loss1: 0.7456173896789551, 
		 aux loss2: 0.38892316818237305, total loss: 0.6281014680862427
60th Epoch, 39580th Step, learning rate = 0.005936309648706652 - Loss: 0.2862291634082794, aux loss1: 0.9292157292366028, 
		 aux loss2: 0.5069434642791748, total loss: 0.7677712440490723
60th Epoch, 39585th Step, learning rate = 0.005935779818168938 - Loss: 0.2203446328639984, aux loss1: 0.6895822286605835, 
		 aux loss2: 0.3448534607887268, total loss: 0.5651607513427734
60th Epoch, 39590th Step, learning rate = 0.005935249982376404 - Loss: 0.2584412395954132, aux loss1: 0.7424004673957825, 
		 aux loss2: 0.3937913179397583, total loss: 0.6386778950691223
60th Epoch, 39595th Step, learning rate = 0.0059347201413284725 - Loss: 0.2466738373041153, aux loss1: 0.8061894774436951, 
		 aux loss2: 0.40952086448669434, total loss: 0.6523390412330627
60th Epoch, 39600th Step, learning rate = 0.005934190295024574 - Loss: 0.22695420682430267, aux loss1: 0.7198342084884644, 
		 aux loss2: 0.37436777353286743, total loss: 0.5926516056060791
<39600th step>
*************************** Test ***************************
time:3m 9s, 39600th Step, Loss: 0.6269846558570862, Mean IoU = 44.432%
************************************************************
60th Epoch, 39605th Step, learning rate = 0.005933660443464134 - Loss: 0.2235003560781479, aux loss1: 0.7460090517997742, 
		 aux loss2: 0.38132819533348083, total loss: 0.5998343825340271
60th Epoch, 39610th Step, learning rate = 0.005933130586646576 - Loss: 0.3183372914791107, aux loss1: 1.068937063217163, 
		 aux loss2: 0.609782338142395, total loss: 0.8829313516616821
60th Epoch, 39615th Step, learning rate = 0.00593260072457133 - Loss: 0.2543162703514099, aux loss1: 0.8907517790794373, 
		 aux loss2: 0.47793060541152954, total loss: 0.7127140760421753
60th Epoch, 39620th Step, learning rate = 0.00593207085723782 - Loss: 0.3076910078525543, aux loss1: 0.9984694719314575, 
		 aux loss2: 0.559868335723877, total loss: 0.8311792016029358
60th Epoch, 39625th Step, learning rate = 0.005931540984645472 - Loss: 0.25330719351768494, aux loss1: 0.8686569929122925, 
		 aux loss2: 0.45872488617897034, total loss: 0.6973943114280701
60th Epoch, 39630th Step, learning rate = 0.0059310111067937136 - Loss: 0.22518999874591827, aux loss1: 0.8102940917015076, 
		 aux loss2: 0.37998637557029724, total loss: 0.6202727556228638
60th Epoch, 39635th Step, learning rate = 0.0059304812236819675 - Loss: 0.20441900193691254, aux loss1: 0.6147547960281372, 
		 aux loss2: 0.30215147137641907, total loss: 0.5097060203552246
60th Epoch, 39640th Step, learning rate = 0.00592995133530966 - Loss: 0.23456507921218872, aux loss1: 0.7329967021942139, 
		 aux loss2: 0.38261911273002625, total loss: 0.6075117588043213
60th Epoch, 39645th Step, learning rate = 0.005929421441676221 - Loss: 0.26889824867248535, aux loss1: 0.7276678681373596, 
		 aux loss2: 0.3889920711517334, total loss: 0.6427954435348511
60th Epoch, 39650th Step, learning rate = 0.005928891542781069 - Loss: 0.23501384258270264, aux loss1: 0.7647665143013, 
		 aux loss2: 0.39775994420051575, total loss: 0.6235477924346924
60th Epoch, 39655th Step, learning rate = 0.005928361638623633 - Loss: 0.2320995032787323, aux loss1: 0.7847581505775452, 
		 aux loss2: 0.4440334439277649, total loss: 0.6451403498649597
60th Epoch, 39660th Step, learning rate = 0.005927831729203339 - Loss: 0.282978355884552, aux loss1: 0.8352584838867188, 
		 aux loss2: 0.5166528224945068, total loss: 0.7402170896530151
60th Epoch, 39665th Step, learning rate = 0.005927301814519609 - Loss: 0.2303311675786972, aux loss1: 0.7509068846702576, 
		 aux loss2: 0.3583911955356598, total loss: 0.598959743976593
60th Epoch, 39670th Step, learning rate = 0.00592677189457187 - Loss: 0.23366160690784454, aux loss1: 0.7524216175079346, 
		 aux loss2: 0.39755091071128845, total loss: 0.6184084415435791
60th Epoch, 39675th Step, learning rate = 0.005926241969359547 - Loss: 0.18967103958129883, aux loss1: 0.6859827637672424, 
		 aux loss2: 0.31216317415237427, total loss: 0.5203311443328857
60th Epoch, 39680th Step, learning rate = 0.005925712038882062 - Loss: 0.24830244481563568, aux loss1: 0.7284849882125854, 
		 aux loss2: 0.3908572494983673, total loss: 0.6231908798217773
60th Epoch, 39685th Step, learning rate = 0.005925182103138842 - Loss: 0.27241823077201843, aux loss1: 0.8421997427940369, 
		 aux loss2: 0.5227358937263489, total loss: 0.734172523021698
60th Epoch, 39690th Step, learning rate = 0.005924652162129312 - Loss: 0.2575864791870117, aux loss1: 0.8772938251495361, 
		 aux loss2: 0.44758152961730957, total loss: 0.6998072266578674
60th Epoch, 39695th Step, learning rate = 0.005924122215852893 - Loss: 0.2976458668708801, aux loss1: 0.793140709400177, 
		 aux loss2: 0.5077657103538513, total loss: 0.7386943697929382
60th Epoch, 39700th Step, learning rate = 0.005923592264309012 - Loss: 0.2581961154937744, aux loss1: 0.8536049127578735, 
		 aux loss2: 0.5058141946792603, total loss: 0.7166032791137695
<39700th step>
*************************** Test ***************************
time:3m 10s, 39700th Step, Loss: 0.5641156435012817, Mean IoU = 46.777%
************************************************************
60th Epoch, 39705th Step, learning rate = 0.005923062307497093 - Loss: 0.21404579281806946, aux loss1: 0.8535448908805847, 
		 aux loss2: 0.43167296051979065, total loss: 0.6427784562110901
60th Epoch, 39710th Step, learning rate = 0.005922532345416557 - Loss: 0.2604331374168396, aux loss1: 0.9260540008544922, 
		 aux loss2: 0.49504509568214417, total loss: 0.7362674474716187
60th Epoch, 39715th Step, learning rate = 0.0059220023780668304 - Loss: 0.24234549701213837, aux loss1: 0.7149045467376709, 
		 aux loss2: 0.37407922744750977, total loss: 0.6064485311508179
60th Epoch, 39720th Step, learning rate = 0.005921472405447337 - Loss: 0.24962717294692993, aux loss1: 0.8056631088256836, 
		 aux loss2: 0.41162824630737305, total loss: 0.6559773683547974
60th Epoch, 39725th Step, learning rate = 0.005920942427557498 - Loss: 0.22718200087547302, aux loss1: 0.9155309796333313, 
		 aux loss2: 0.45719417929649353, total loss: 0.6847189664840698
60th Epoch, 39730th Step, learning rate = 0.0059204124443967415 - Loss: 0.2710484564304352, aux loss1: 1.0045130252838135, 
		 aux loss2: 0.5497149229049683, total loss: 0.7922883033752441
60th Epoch, 39735th Step, learning rate = 0.005919882455964484 - Loss: 0.22335374355316162, aux loss1: 0.7651920318603516, 
		 aux loss2: 0.3741665780544281, total loss: 0.6025780439376831
60th Epoch, 39740th Step, learning rate = 0.005919352462260155 - Loss: 0.27762311697006226, aux loss1: 0.7326388955116272, 
		 aux loss2: 0.41161537170410156, total loss: 0.6620609760284424
60th Epoch, 39745th Step, learning rate = 0.005918822463283173 - Loss: 0.2854790687561035, aux loss1: 0.9076498746871948, 
		 aux loss2: 0.501476526260376, total loss: 0.7583646774291992
60th Epoch, 39750th Step, learning rate = 0.005918292459032965 - Loss: 0.26179319620132446, aux loss1: 0.8940533399581909, 
		 aux loss2: 0.4518502950668335, total loss: 0.7107493281364441
60th Epoch, 39755th Step, learning rate = 0.00591776244950895 - Loss: 0.2786514461040497, aux loss1: 0.8202740550041199, 
		 aux loss2: 0.4594852924346924, total loss: 0.7085278034210205
60th Epoch, 39760th Step, learning rate = 0.005917232434710554 - Loss: 0.28944170475006104, aux loss1: 0.7750272154808044, 
		 aux loss2: 0.4190747141838074, total loss: 0.6895797848701477
61th Epoch, 39765th Step, learning rate = 0.0059167024146371955 - Loss: 0.2970998287200928, aux loss1: 0.9545927047729492, 
		 aux loss2: 0.541566014289856, total loss: 0.800104022026062
61th Epoch, 39770th Step, learning rate = 0.005916172389288301 - Loss: 0.26063084602355957, aux loss1: 0.7757114171981812, 
		 aux loss2: 0.3999879062175751, total loss: 0.6533394455909729
61th Epoch, 39775th Step, learning rate = 0.005915642358663291 - Loss: 0.24099287390708923, aux loss1: 0.7646149396896362, 
		 aux loss2: 0.4300493001937866, total loss: 0.6423971056938171
61th Epoch, 39780th Step, learning rate = 0.005915112322761588 - Loss: 0.19130225479602814, aux loss1: 0.8208920955657959, 
		 aux loss2: 0.3846983313560486, total loss: 0.5914492011070251
61th Epoch, 39785th Step, learning rate = 0.005914582281582615 - Loss: 0.20935675501823425, aux loss1: 0.7516143918037415, 
		 aux loss2: 0.3434416949748993, total loss: 0.5722177624702454
61th Epoch, 39790th Step, learning rate = 0.00591405223512579 - Loss: 0.2647283971309662, aux loss1: 0.8097684383392334, 
		 aux loss2: 0.4786318242549896, total loss: 0.6991117000579834
61th Epoch, 39795th Step, learning rate = 0.005913522183390541 - Loss: 0.33035314083099365, aux loss1: 1.0317111015319824, 
		 aux loss2: 0.5707241296768188, total loss: 0.8681561350822449
61th Epoch, 39800th Step, learning rate = 0.005912992126376285 - Loss: 0.2584612965583801, aux loss1: 0.7031220197677612, 
		 aux loss2: 0.37915483117103577, total loss: 0.6210598349571228
<39800th step>
*************************** Test ***************************
time:3m 13s, 39800th Step, Loss: 0.5891028046607971, Mean IoU = 46.521%
************************************************************
61th Epoch, 39805th Step, learning rate = 0.0059124620640824445 - Loss: 0.22510486841201782, aux loss1: 0.7417016625404358, 
		 aux loss2: 0.3616602420806885, total loss: 0.5922794938087463
61th Epoch, 39810th Step, learning rate = 0.005911931996508444 - Loss: 0.25823119282722473, aux loss1: 0.8078559637069702, 
		 aux loss2: 0.4414769113063812, total loss: 0.6771787405014038
61th Epoch, 39815th Step, learning rate = 0.0059114019236537006 - Loss: 0.24392849206924438, aux loss1: 0.8022787570953369, 
		 aux loss2: 0.40270182490348816, total loss: 0.6456928253173828
61th Epoch, 39820th Step, learning rate = 0.005910871845517638 - Loss: 0.39902573823928833, aux loss1: 0.8947854042053223, 
		 aux loss2: 0.5578941702842712, total loss: 0.8906190395355225
61th Epoch, 39825th Step, learning rate = 0.005910341762099678 - Loss: 0.3011643588542938, aux loss1: 0.9285018444061279, 
		 aux loss2: 0.5576614737510681, total loss: 0.802779495716095
61th Epoch, 39830th Step, learning rate = 0.005909811673399239 - Loss: 0.26442426443099976, aux loss1: 0.8335839509963989, 
		 aux loss2: 0.413769394159317, total loss: 0.6800072193145752
61th Epoch, 39835th Step, learning rate = 0.0059092815794157426 - Loss: 0.26443997025489807, aux loss1: 1.0227329730987549, 
		 aux loss2: 0.5503327250480652, total loss: 0.7913929224014282
61th Epoch, 39840th Step, learning rate = 0.005908751480148613 - Loss: 0.3230823278427124, aux loss1: 0.9294825196266174, 
		 aux loss2: 0.48061037063598633, total loss: 0.7941712737083435
61th Epoch, 39845th Step, learning rate = 0.005908221375597266 - Loss: 0.2885980010032654, aux loss1: 0.9865071773529053, 
		 aux loss2: 0.5736486315727234, total loss: 0.8140096068382263
61th Epoch, 39850th Step, learning rate = 0.0059076912657611245 - Loss: 0.26085665822029114, aux loss1: 0.854629635810852, 
		 aux loss2: 0.4915255308151245, total loss: 0.7138557434082031
61th Epoch, 39855th Step, learning rate = 0.0059071611506396095 - Loss: 0.27984488010406494, aux loss1: 0.9963134527206421, 
		 aux loss2: 0.534177303314209, total loss: 0.7924098372459412
61th Epoch, 39860th Step, learning rate = 0.005906631030232138 - Loss: 0.2007225900888443, aux loss1: 0.7608751654624939, 
		 aux loss2: 0.34384527802467346, total loss: 0.5665232539176941
61th Epoch, 39865th Step, learning rate = 0.005906100904538135 - Loss: 0.3155837655067444, aux loss1: 0.8493114113807678, 
		 aux loss2: 0.4690589904785156, total loss: 0.7580008506774902
61th Epoch, 39870th Step, learning rate = 0.005905570773557018 - Loss: 0.2527383863925934, aux loss1: 0.823418140411377, 
		 aux loss2: 0.41766223311424255, total loss: 0.6668287515640259
61th Epoch, 39875th Step, learning rate = 0.005905040637288206 - Loss: 0.20373845100402832, aux loss1: 0.6936103105545044, 
		 aux loss2: 0.3398672938346863, total loss: 0.5477684736251831
61th Epoch, 39880th Step, learning rate = 0.00590451049573112 - Loss: 0.2736884653568268, aux loss1: 0.9326118230819702, 
		 aux loss2: 0.49429085850715637, total loss: 0.7511883974075317
61th Epoch, 39885th Step, learning rate = 0.00590398034888518 - Loss: 0.26837417483329773, aux loss1: 0.7212222218513489, 
		 aux loss2: 0.4150097668170929, total loss: 0.6507447957992554
61th Epoch, 39890th Step, learning rate = 0.005903450196749804 - Loss: 0.30214688181877136, aux loss1: 0.8338701128959656, 
		 aux loss2: 0.5438182950019836, total loss: 0.7698352932929993
61th Epoch, 39895th Step, learning rate = 0.005902920039324413 - Loss: 0.26754432916641235, aux loss1: 0.7757758498191833, 
		 aux loss2: 0.4330616593360901, total loss: 0.6735017895698547
61th Epoch, 39900th Step, learning rate = 0.005902389876608426 - Loss: 0.17335142195224762, aux loss1: 0.6980281472206116, 
		 aux loss2: 0.3422921895980835, total loss: 0.5196767449378967
<39900th step>
*************************** Test ***************************
time:3m 8s, 39900th Step, Loss: 0.560503363609314, Mean IoU = 47.002%
************************************************************
61th Epoch, 39905th Step, learning rate = 0.005901859708601262 - Loss: 0.27932214736938477, aux loss1: 0.7998934984207153, 
		 aux loss2: 0.44047853350639343, total loss: 0.6954816579818726
61th Epoch, 39910th Step, learning rate = 0.00590132953530234 - Loss: 0.2253464013338089, aux loss1: 0.7325253486633301, 
		 aux loss2: 0.36956602334976196, total loss: 0.5929304361343384
61th Epoch, 39915th Step, learning rate = 0.005900799356711077 - Loss: 0.23918117582798004, aux loss1: 0.9152958393096924, 
		 aux loss2: 0.5296077728271484, total loss: 0.7256130576133728
61th Epoch, 39920th Step, learning rate = 0.005900269172826896 - Loss: 0.2970975339412689, aux loss1: 0.9566134810447693, 
		 aux loss2: 0.5354968905448914, total loss: 0.7982803583145142
61th Epoch, 39925th Step, learning rate = 0.005899738983649213 - Loss: 0.2992652654647827, aux loss1: 0.8568589687347412, 
		 aux loss2: 0.4758360981941223, total loss: 0.7466573715209961
61th Epoch, 39930th Step, learning rate = 0.005899208789177445 - Loss: 0.2558877170085907, aux loss1: 0.7690287828445435, 
		 aux loss2: 0.44707944989204407, total loss: 0.6654281616210938
61th Epoch, 39935th Step, learning rate = 0.005898678589411015 - Loss: 0.20409826934337616, aux loss1: 0.6360107660293579, 
		 aux loss2: 0.35537993907928467, total loss: 0.5370534658432007
61th Epoch, 39940th Step, learning rate = 0.005898148384349338 - Loss: 0.23147925734519958, aux loss1: 0.8260175585746765, 
		 aux loss2: 0.3877377212047577, total loss: 0.6343796253204346
61th Epoch, 39945th Step, learning rate = 0.0058976181739918325 - Loss: 0.236487478017807, aux loss1: 0.7262351512908936, 
		 aux loss2: 0.38598570227622986, total loss: 0.6087523102760315
61th Epoch, 39950th Step, learning rate = 0.005897087958337918 - Loss: 0.25402751564979553, aux loss1: 0.7477474808692932, 
		 aux loss2: 0.39049258828163147, total loss: 0.6345487833023071
61th Epoch, 39955th Step, learning rate = 0.00589655773738701 - Loss: 0.24888400733470917, aux loss1: 0.7506869435310364, 
		 aux loss2: 0.42651432752609253, total loss: 0.6446958184242249
61th Epoch, 39960th Step, learning rate = 0.005896027511138529 - Loss: 0.2423676699399948, aux loss1: 0.906264066696167, 
		 aux loss2: 0.44118526577949524, total loss: 0.6907209753990173
61th Epoch, 39965th Step, learning rate = 0.005895497279591892 - Loss: 0.2332662045955658, aux loss1: 0.9137097597122192, 
		 aux loss2: 0.4547206163406372, total loss: 0.6892673969268799
61th Epoch, 39970th Step, learning rate = 0.005894967042746516 - Loss: 0.26182982325553894, aux loss1: 0.8869926929473877, 
		 aux loss2: 0.4398978352546692, total loss: 0.7038867473602295
61th Epoch, 39975th Step, learning rate = 0.005894436800601817 - Loss: 0.2787702977657318, aux loss1: 0.9326890707015991, 
		 aux loss2: 0.4762621819972992, total loss: 0.7490819692611694
61th Epoch, 39980th Step, learning rate = 0.005893906553157215 - Loss: 0.27413174510002136, aux loss1: 0.8100295066833496, 
		 aux loss2: 0.4612049162387848, total loss: 0.7016226053237915
61th Epoch, 39985th Step, learning rate = 0.005893376300412125 - Loss: 0.2179919183254242, aux loss1: 0.7972061038017273, 
		 aux loss2: 0.37981951236724854, total loss: 0.6090815663337708
61th Epoch, 39990th Step, learning rate = 0.005892846042365968 - Loss: 0.2255687415599823, aux loss1: 0.6566988229751587, 
		 aux loss2: 0.34559932351112366, total loss: 0.5608181357383728
61th Epoch, 39995th Step, learning rate = 0.005892315779018157 - Loss: 0.22884637117385864, aux loss1: 0.7543576955795288, 
		 aux loss2: 0.3515900671482086, total loss: 0.5957897305488586
61th Epoch, 40000th Step, learning rate = 0.00589178551036811 - Loss: 0.22062429785728455, aux loss1: 0.7763606309890747, 
		 aux loss2: 0.37066105008125305, total loss: 0.6017969250679016
<40000th step>
*************************** Test ***************************
time:3m 5s, 40000th Step, Loss: 0.5355463027954102, Mean IoU = 47.134%
************************************************************
61th Epoch, 40005th Step, learning rate = 0.005891255236415245 - Loss: 0.22003616392612457, aux loss1: 0.7390407919883728, 
		 aux loss2: 0.35368332266807556, total loss: 0.5832217335700989
61th Epoch, 40010th Step, learning rate = 0.005890724957158976 - Loss: 0.20166364312171936, aux loss1: 0.6796495914459229, 
		 aux loss2: 0.32019731402397156, total loss: 0.5336374640464783
61th Epoch, 40015th Step, learning rate = 0.005890194672598721 - Loss: 0.27390965819358826, aux loss1: 0.8906936645507812, 
		 aux loss2: 0.4830947518348694, total loss: 0.7343556880950928
61th Epoch, 40020th Step, learning rate = 0.005889664382733898 - Loss: 0.23799024522304535, aux loss1: 0.6564010381698608, 
		 aux loss2: 0.3421748876571655, total loss: 0.5717805027961731
61th Epoch, 40025th Step, learning rate = 0.0058891340875639195 - Loss: 0.22012217342853546, aux loss1: 0.6534397602081299, 
		 aux loss2: 0.3314060866832733, total loss: 0.5487165451049805
61th Epoch, 40030th Step, learning rate = 0.005888603787088206 - Loss: 0.26919007301330566, aux loss1: 0.7952896952629089, 
		 aux loss2: 0.41822803020477295, total loss: 0.675068199634552
61th Epoch, 40035th Step, learning rate = 0.005888073481306171 - Loss: 0.31885138154029846, aux loss1: 0.894115149974823, 
		 aux loss2: 0.4930190443992615, total loss: 0.7842935919761658
61th Epoch, 40040th Step, learning rate = 0.005887543170217228 - Loss: 0.3594506084918976, aux loss1: 0.9750734567642212, 
		 aux loss2: 0.6293869018554688, total loss: 0.9037274122238159
61th Epoch, 40045th Step, learning rate = 0.0058870128538207975 - Loss: 0.24790669977664948, aux loss1: 0.7954782247543335, 
		 aux loss2: 0.4340140223503113, total loss: 0.6601557731628418
61th Epoch, 40050th Step, learning rate = 0.005886482532116293 - Loss: 0.31241995096206665, aux loss1: 0.9448112845420837, 
		 aux loss2: 0.5687544941902161, total loss: 0.8233651518821716
61th Epoch, 40055th Step, learning rate = 0.00588595220510313 - Loss: 0.2663934528827667, aux loss1: 0.8470035195350647, 
		 aux loss2: 0.4562110900878906, total loss: 0.7029789686203003
61th Epoch, 40060th Step, learning rate = 0.005885421872780725 - Loss: 0.24175797402858734, aux loss1: 0.7338008284568787, 
		 aux loss2: 0.3963056802749634, total loss: 0.620420515537262
61th Epoch, 40065th Step, learning rate = 0.005884891535148491 - Loss: 0.2967734932899475, aux loss1: 0.8306674957275391, 
		 aux loss2: 0.4514671564102173, total loss: 0.726560652256012
61th Epoch, 40070th Step, learning rate = 0.0058843611922058435 - Loss: 0.23644115030765533, aux loss1: 0.6636800765991211, 
		 aux loss2: 0.3715289533138275, total loss: 0.5841567516326904
61th Epoch, 40075th Step, learning rate = 0.0058838308439522 - Loss: 0.25599947571754456, aux loss1: 0.8248595595359802, 
		 aux loss2: 0.4481509029865265, total loss: 0.6827177405357361
61th Epoch, 40080th Step, learning rate = 0.005883300490386973 - Loss: 0.300253689289093, aux loss1: 0.9076114892959595, 
		 aux loss2: 0.5160037875175476, total loss: 0.7789387106895447
61th Epoch, 40085th Step, learning rate = 0.005882770131509578 - Loss: 0.32179656624794006, aux loss1: 0.9280924201011658, 
		 aux loss2: 0.5659135580062866, total loss: 0.8265897631645203
61th Epoch, 40090th Step, learning rate = 0.005882239767319432 - Loss: 0.2882043123245239, aux loss1: 0.8568242192268372, 
		 aux loss2: 0.47421929240226746, total loss: 0.7349393367767334
61th Epoch, 40095th Step, learning rate = 0.005881709397815943 - Loss: 0.238514706492424, aux loss1: 0.7156242728233337, 
		 aux loss2: 0.3965933620929718, total loss: 0.6118393540382385
61th Epoch, 40100th Step, learning rate = 0.005881179022998533 - Loss: 0.27067357301712036, aux loss1: 0.8644777536392212, 
		 aux loss2: 0.5109770894050598, total loss: 0.7344077229499817
<40100th step>
*************************** Test ***************************
time:3m 12s, 40100th Step, Loss: 0.5530482530593872, Mean IoU = 46.752%
************************************************************
61th Epoch, 40105th Step, learning rate = 0.005880648642866613 - Loss: 0.2226182520389557, aux loss1: 0.7374001145362854, 
		 aux loss2: 0.3984226882457733, total loss: 0.6032073497772217
61th Epoch, 40110th Step, learning rate = 0.0058801182574195945 - Loss: 0.20483702421188354, aux loss1: 0.6642568111419678, 
		 aux loss2: 0.312176376581192, total loss: 0.5289846062660217
61th Epoch, 40115th Step, learning rate = 0.005879587866656896 - Loss: 0.2233249694108963, aux loss1: 0.7148597836494446, 
		 aux loss2: 0.3481079041957855, total loss: 0.5770260691642761
61th Epoch, 40120th Step, learning rate = 0.005879057470577929 - Loss: 0.24448665976524353, aux loss1: 0.9044002294540405, 
		 aux loss2: 0.4277240037918091, total loss: 0.6868963241577148
61th Epoch, 40125th Step, learning rate = 0.005878527069182107 - Loss: 0.2096666693687439, aux loss1: 0.8066592216491699, 
		 aux loss2: 0.35356539487838745, total loss: 0.5930905938148499
61th Epoch, 40130th Step, learning rate = 0.005877996662468846 - Loss: 0.219708651304245, aux loss1: 0.7814119458198547, 
		 aux loss2: 0.3726939857006073, total loss: 0.6032098531723022
62th Epoch, 40135th Step, learning rate = 0.0058774662504375574 - Loss: 0.3293939530849457, aux loss1: 1.1317473649978638, 
		 aux loss2: 0.6373514533042908, total loss: 0.9238587617874146
62th Epoch, 40140th Step, learning rate = 0.005876935833087655 - Loss: 0.2723323702812195, aux loss1: 0.9875708818435669, 
		 aux loss2: 0.5386778712272644, total loss: 0.7840747833251953
62th Epoch, 40145th Step, learning rate = 0.005876405410418554 - Loss: 0.26749956607818604, aux loss1: 0.8378806114196777, 
		 aux loss2: 0.4668956995010376, total loss: 0.7056220769882202
62th Epoch, 40150th Step, learning rate = 0.005875874982429664 - Loss: 0.20861418545246124, aux loss1: 0.6604645848274231, 
		 aux loss2: 0.32481902837753296, total loss: 0.5366811752319336
62th Epoch, 40155th Step, learning rate = 0.0058753445491204 - Loss: 0.23037979006767273, aux loss1: 0.7053457498550415, 
		 aux loss2: 0.3732840120792389, total loss: 0.5912971496582031
62th Epoch, 40160th Step, learning rate = 0.005874814110490177 - Loss: 0.22973084449768066, aux loss1: 0.8140243291854858, 
		 aux loss2: 0.43585196137428284, total loss: 0.6482789516448975
62th Epoch, 40165th Step, learning rate = 0.005874283666538403 - Loss: 0.2720126807689667, aux loss1: 0.926106870174408, 
		 aux loss2: 0.5216548442840576, total loss: 0.7585066556930542
62th Epoch, 40170th Step, learning rate = 0.005873753217264494 - Loss: 0.268282949924469, aux loss1: 0.9055884480476379, 
		 aux loss2: 0.4570998549461365, total loss: 0.7227994203567505
62th Epoch, 40175th Step, learning rate = 0.005873222762667863 - Loss: 0.21496249735355377, aux loss1: 0.7373267412185669, 
		 aux loss2: 0.34866517782211304, total loss: 0.5756266117095947
62th Epoch, 40180th Step, learning rate = 0.005872692302747921 - Loss: 0.2085103690624237, aux loss1: 0.6309224963188171, 
		 aux loss2: 0.3465862572193146, total loss: 0.5364216566085815
62th Epoch, 40185th Step, learning rate = 0.005872161837504081 - Loss: 0.2525491416454315, aux loss1: 0.872745156288147, 
		 aux loss2: 0.4525098204612732, total loss: 0.6953766345977783
62th Epoch, 40190th Step, learning rate = 0.005871631366935754 - Loss: 0.23679886758327484, aux loss1: 0.7835367918014526, 
		 aux loss2: 0.39765840768814087, total loss: 0.6309232711791992
62th Epoch, 40195th Step, learning rate = 0.0058711008910423525 - Loss: 0.23004980385303497, aux loss1: 0.7317763566970825, 
		 aux loss2: 0.378246545791626, total loss: 0.6008813381195068
62th Epoch, 40200th Step, learning rate = 0.00587057040982329 - Loss: 0.24770787358283997, aux loss1: 0.8975755572319031, 
		 aux loss2: 0.4943699538707733, total loss: 0.7147285342216492
<40200th step>
*************************** Test ***************************
time:3m 9s, 40200th Step, Loss: 0.5367136001586914, Mean IoU = 47.011%
************************************************************
62th Epoch, 40205th Step, learning rate = 0.005870039923277976 - Loss: 0.20925340056419373, aux loss1: 0.8059625029563904, 
		 aux loss2: 0.3818058967590332, total loss: 0.603764533996582
62th Epoch, 40210th Step, learning rate = 0.005869509431405824 - Loss: 0.23604151606559753, aux loss1: 0.8713498115539551, 
		 aux loss2: 0.4553077518939972, total loss: 0.6795696020126343
62th Epoch, 40215th Step, learning rate = 0.005868978934206246 - Loss: 0.2097732424736023, aux loss1: 0.640322744846344, 
		 aux loss2: 0.3256821632385254, total loss: 0.5321429371833801
62th Epoch, 40220th Step, learning rate = 0.00586844843167865 - Loss: 0.2647516131401062, aux loss1: 0.7718598246574402, 
		 aux loss2: 0.4422483444213867, total loss: 0.6732089519500732
62th Epoch, 40225th Step, learning rate = 0.005867917923822451 - Loss: 0.21559439599514008, aux loss1: 0.6466968059539795, 
		 aux loss2: 0.3442826271057129, total loss: 0.5473164916038513
62th Epoch, 40230th Step, learning rate = 0.00586738741063706 - Loss: 0.2711789906024933, aux loss1: 0.9669862985610962, 
		 aux loss2: 0.5250184535980225, total loss: 0.7712822556495667
62th Epoch, 40235th Step, learning rate = 0.005866856892121884 - Loss: 0.30048346519470215, aux loss1: 1.014100432395935, 
		 aux loss2: 0.6009519696235657, total loss: 0.8450944423675537
62th Epoch, 40240th Step, learning rate = 0.005866326368276339 - Loss: 0.2567804753780365, aux loss1: 0.7371354699134827, 
		 aux loss2: 0.40708425641059875, total loss: 0.6407548189163208
62th Epoch, 40245th Step, learning rate = 0.005865795839099833 - Loss: 0.270251989364624, aux loss1: 0.9707596302032471, 
		 aux loss2: 0.5221953988075256, total loss: 0.7703580856323242
62th Epoch, 40250th Step, learning rate = 0.005865265304591777 - Loss: 0.20282717049121857, aux loss1: 0.6298354864120483, 
		 aux loss2: 0.3206064999103546, total loss: 0.5200204253196716
62th Epoch, 40255th Step, learning rate = 0.005864734764751584 - Loss: 0.23973245918750763, aux loss1: 0.8348392844200134, 
		 aux loss2: 0.4298466145992279, total loss: 0.662122905254364
62th Epoch, 40260th Step, learning rate = 0.0058642042195786595 - Loss: 0.2662847936153412, aux loss1: 0.915504515171051, 
		 aux loss2: 0.48857030272483826, total loss: 0.7363643050193787
62th Epoch, 40265th Step, learning rate = 0.005863673669072418 - Loss: 0.2713369131088257, aux loss1: 0.76609867811203, 
		 aux loss2: 0.4343229830265045, total loss: 0.674895703792572
62th Epoch, 40270th Step, learning rate = 0.0058631431132322685 - Loss: 0.22575309872627258, aux loss1: 0.9555714130401611, 
		 aux loss2: 0.5065461993217468, total loss: 0.7150430083274841
62th Epoch, 40275th Step, learning rate = 0.00586261255205762 - Loss: 0.2980749309062958, aux loss1: 0.8262832164764404, 
		 aux loss2: 0.5008014440536499, total loss: 0.7462804913520813
62th Epoch, 40280th Step, learning rate = 0.0058620819855478845 - Loss: 0.2861577868461609, aux loss1: 0.9207357168197632, 
		 aux loss2: 0.5487448573112488, total loss: 0.7818764448165894
62th Epoch, 40285th Step, learning rate = 0.00586155141370247 - Loss: 0.18475928902626038, aux loss1: 0.6351897120475769, 
		 aux loss2: 0.2978920042514801, total loss: 0.49447301030158997
62th Epoch, 40290th Step, learning rate = 0.005861020836520787 - Loss: 0.26786336302757263, aux loss1: 0.9276319742202759, 
		 aux loss2: 0.4847171902656555, total loss: 0.7400398254394531
62th Epoch, 40295th Step, learning rate = 0.005860490254002246 - Loss: 0.2726132273674011, aux loss1: 0.8551560044288635, 
		 aux loss2: 0.47894930839538574, total loss: 0.7207397222518921
62th Epoch, 40300th Step, learning rate = 0.005859959666146254 - Loss: 0.24089747667312622, aux loss1: 0.9250059723854065, 
		 aux loss2: 0.48553845286369324, total loss: 0.7126146554946899
<40300th step>
*************************** Test ***************************
time:3m 16s, 40300th Step, Loss: 0.5668975114822388, Mean IoU = 47.048%
************************************************************
62th Epoch, 40305th Step, learning rate = 0.005859429072952222 - Loss: 0.25763174891471863, aux loss1: 0.9246346950531006, 
		 aux loss2: 0.4459459185600281, total loss: 0.7134004831314087
62th Epoch, 40310th Step, learning rate = 0.00585889847441956 - Loss: 0.24095970392227173, aux loss1: 0.7670914530754089, 
		 aux loss2: 0.3933413326740265, total loss: 0.6284236907958984
62th Epoch, 40315th Step, learning rate = 0.005858367870547675 - Loss: 0.2397025227546692, aux loss1: 0.7005892395973206, 
		 aux loss2: 0.3732573091983795, total loss: 0.5991822481155396
62th Epoch, 40320th Step, learning rate = 0.005857837261335977 - Loss: 0.35306885838508606, aux loss1: 1.2677315473556519, 
		 aux loss2: 0.7084521055221558, total loss: 1.0167691707611084
62th Epoch, 40325th Step, learning rate = 0.005857306646783875 - Loss: 0.2898062467575073, aux loss1: 0.9787403345108032, 
		 aux loss2: 0.5025612711906433, total loss: 0.7844529151916504
62th Epoch, 40330th Step, learning rate = 0.005856776026890778 - Loss: 0.2207440286874771, aux loss1: 0.7193233370780945, 
		 aux loss2: 0.34149402379989624, total loss: 0.5731386542320251
62th Epoch, 40335th Step, learning rate = 0.005856245401656093 - Loss: 0.19809022545814514, aux loss1: 0.6869829893112183, 
		 aux loss2: 0.32621315121650696, total loss: 0.534670352935791
62th Epoch, 40340th Step, learning rate = 0.0058557147710792306 - Loss: 0.2865530848503113, aux loss1: 1.0007517337799072, 
		 aux loss2: 0.5005714893341064, total loss: 0.787007212638855
62th Epoch, 40345th Step, learning rate = 0.005855184135159596 - Loss: 0.3274219036102295, aux loss1: 0.8542653918266296, 
		 aux loss2: 0.4828948974609375, total loss: 0.7768594622612
62th Epoch, 40350th Step, learning rate = 0.005854653493896601 - Loss: 0.2670978307723999, aux loss1: 0.7716158032417297, 
		 aux loss2: 0.43078064918518066, total loss: 0.6708948612213135
62th Epoch, 40355th Step, learning rate = 0.005854122847289652 - Loss: 0.27723410725593567, aux loss1: 0.8839221000671387, 
		 aux loss2: 0.48531702160835266, total loss: 0.7365375757217407
62th Epoch, 40360th Step, learning rate = 0.005853592195338157 - Loss: 0.24114227294921875, aux loss1: 0.7712190747261047, 
		 aux loss2: 0.3904910683631897, total loss: 0.6287044286727905
62th Epoch, 40365th Step, learning rate = 0.005853061538041524 - Loss: 0.24152149260044098, aux loss1: 0.7698109745979309, 
		 aux loss2: 0.4028410017490387, total loss: 0.633601188659668
62th Epoch, 40370th Step, learning rate = 0.00585253087539916 - Loss: 0.2656971514225006, aux loss1: 0.8710206747055054, 
		 aux loss2: 0.4683287739753723, total loss: 0.7143349051475525
62th Epoch, 40375th Step, learning rate = 0.005852000207410473 - Loss: 0.19560788571834564, aux loss1: 0.7180171012878418, 
		 aux loss2: 0.35953229665756226, total loss: 0.5548259019851685
62th Epoch, 40380th Step, learning rate = 0.005851469534074873 - Loss: 0.25640740990638733, aux loss1: 0.8424581289291382, 
		 aux loss2: 0.4477365016937256, total loss: 0.6882395148277283
62th Epoch, 40385th Step, learning rate = 0.005850938855391762 - Loss: 0.3810744285583496, aux loss1: 1.0541168451309204, 
		 aux loss2: 0.6422287821769714, total loss: 0.9542009830474854
62th Epoch, 40390th Step, learning rate = 0.00585040817136055 - Loss: 0.26235446333885193, aux loss1: 0.8053303360939026, 
		 aux loss2: 0.4667398929595947, total loss: 0.6906495094299316
62th Epoch, 40395th Step, learning rate = 0.005849877481980646 - Loss: 0.2489137351512909, aux loss1: 0.8669031858444214, 
		 aux loss2: 0.4701979160308838, total loss: 0.6970638632774353
62th Epoch, 40400th Step, learning rate = 0.0058493467872514525 - Loss: 0.21355651319026947, aux loss1: 0.738885223865509, 
		 aux loss2: 0.370847225189209, total loss: 0.5835610032081604
<40400th step>
*************************** Test ***************************
time:3m 7s, 40400th Step, Loss: 0.5931361317634583, Mean IoU = 46.976%
************************************************************
62th Epoch, 40405th Step, learning rate = 0.005848816087172382 - Loss: 0.24332523345947266, aux loss1: 0.8171336650848389, 
		 aux loss2: 0.45509564876556396, total loss: 0.6705036163330078
62th Epoch, 40410th Step, learning rate = 0.005848285381742836 - Loss: 0.30395936965942383, aux loss1: 0.9342084527015686, 
		 aux loss2: 0.5370923280715942, total loss: 0.7990589141845703
62th Epoch, 40415th Step, learning rate = 0.005847754670962224 - Loss: 0.2454260140657425, aux loss1: 0.7815871238708496, 
		 aux loss2: 0.4433712363243103, total loss: 0.6572506427764893
62th Epoch, 40420th Step, learning rate = 0.0058472239548299524 - Loss: 0.20155400037765503, aux loss1: 0.7467963099479675, 
		 aux loss2: 0.3816377818584442, total loss: 0.5782480239868164
62th Epoch, 40425th Step, learning rate = 0.005846693233345425 - Loss: 0.22803117334842682, aux loss1: 0.7532246112823486, 
		 aux loss2: 0.3959805965423584, total loss: 0.6123908162117004
62th Epoch, 40430th Step, learning rate = 0.00584616250650805 - Loss: 0.4285646378993988, aux loss1: 1.1272860765457153, 
		 aux loss2: 0.7215399146080017, total loss: 1.0553663969039917
62th Epoch, 40435th Step, learning rate = 0.005845631774317235 - Loss: 0.24342948198318481, aux loss1: 0.8323069214820862, 
		 aux loss2: 0.41045448184013367, total loss: 0.6573033332824707
62th Epoch, 40440th Step, learning rate = 0.005845101036772382 - Loss: 0.3376254141330719, aux loss1: 1.1442053318023682, 
		 aux loss2: 0.6457959413528442, total loss: 0.9392054080963135
62th Epoch, 40445th Step, learning rate = 0.005844570293872899 - Loss: 0.2797856032848358, aux loss1: 0.8691877722740173, 
		 aux loss2: 0.49856728315353394, total loss: 0.7399688959121704
62th Epoch, 40450th Step, learning rate = 0.0058440395456181935 - Loss: 0.29108235239982605, aux loss1: 0.9883246421813965, 
		 aux loss2: 0.5683319568634033, total loss: 0.8149124979972839
62th Epoch, 40455th Step, learning rate = 0.005843508792007668 - Loss: 0.2262120544910431, aux loss1: 0.7331798076629639, 
		 aux loss2: 0.38258981704711914, total loss: 0.5992019176483154
62th Epoch, 40460th Step, learning rate = 0.0058429780330407285 - Loss: 0.25691547989845276, aux loss1: 0.7459838390350342, 
		 aux loss2: 0.3845495283603668, total loss: 0.6345304250717163
62th Epoch, 40465th Step, learning rate = 0.005842447268716783 - Loss: 0.2352745085954666, aux loss1: 0.8971712589263916, 
		 aux loss2: 0.4136064946651459, total loss: 0.6698684692382812
62th Epoch, 40470th Step, learning rate = 0.0058419164990352315 - Loss: 0.20294922590255737, aux loss1: 0.7868231534957886, 
		 aux loss2: 0.3800535500049591, total loss: 0.5910176038742065
62th Epoch, 40475th Step, learning rate = 0.005841385723995485 - Loss: 0.2162897288799286, aux loss1: 0.6317768692970276, 
		 aux loss2: 0.3409709930419922, total loss: 0.5422112345695496
62th Epoch, 40480th Step, learning rate = 0.005840854943596944 - Loss: 0.2460995465517044, aux loss1: 0.7079564332962036, 
		 aux loss2: 0.3954530656337738, total loss: 0.6166677474975586
62th Epoch, 40485th Step, learning rate = 0.005840324157839015 - Loss: 0.24962382018566132, aux loss1: 0.743428111076355, 
		 aux loss2: 0.38840752840042114, total loss: 0.6280152797698975
62th Epoch, 40490th Step, learning rate = 0.005839793366721104 - Loss: 0.25940507650375366, aux loss1: 0.9313072562217712, 
		 aux loss2: 0.47171780467033386, total loss: 0.727484405040741
62th Epoch, 40495th Step, learning rate = 0.005839262570242613 - Loss: 0.2517963647842407, aux loss1: 0.8428756594657898, 
		 aux loss2: 0.44190654158592224, total loss: 0.68142169713974
62th Epoch, 40500th Step, learning rate = 0.005838731768402947 - Loss: 0.21863046288490295, aux loss1: 0.663138747215271, 
		 aux loss2: 0.3482106626033783, total loss: 0.5568563342094421
<40500th step>
*************************** Test ***************************
time:3m 15s, 40500th Step, Loss: 0.577922523021698, Mean IoU = 47.067%
************************************************************
63th Epoch, 40505th Step, learning rate = 0.005838200961201512 - Loss: 0.22968441247940063, aux loss1: 0.7083375453948975, 
		 aux loss2: 0.36976921558380127, total loss: 0.5900933742523193
63th Epoch, 40510th Step, learning rate = 0.00583767014863771 - Loss: 0.24953524768352509, aux loss1: 0.8675044178962708, 
		 aux loss2: 0.4199322462081909, total loss: 0.6777595281600952
63th Epoch, 40515th Step, learning rate = 0.005837139330710946 - Loss: 0.2401328831911087, aux loss1: 0.8602287173271179, 
		 aux loss2: 0.4324672222137451, total loss: 0.6711883544921875
63th Epoch, 40520th Step, learning rate = 0.0058366085074206256 - Loss: 0.1975037157535553, aux loss1: 0.6845976710319519, 
		 aux loss2: 0.3327546715736389, total loss: 0.5359848737716675
63th Epoch, 40525th Step, learning rate = 0.005836077678766149 - Loss: 0.22528183460235596, aux loss1: 0.7410650253295898, 
		 aux loss2: 0.4112747609615326, total loss: 0.6121112704277039
63th Epoch, 40530th Step, learning rate = 0.005835546844746923 - Loss: 0.27698278427124023, aux loss1: 0.8764978051185608, 
		 aux loss2: 0.4422067403793335, total loss: 0.7168148159980774
63th Epoch, 40535th Step, learning rate = 0.0058350160053623505 - Loss: 0.24469517171382904, aux loss1: 0.8288285136222839, 
		 aux loss2: 0.43520429730415344, total loss: 0.6674254536628723
63th Epoch, 40540th Step, learning rate = 0.005834485160611832 - Loss: 0.3380063772201538, aux loss1: 0.9041647911071777, 
		 aux loss2: 0.5179476141929626, total loss: 0.8164348602294922
63th Epoch, 40545th Step, learning rate = 0.005833954310494777 - Loss: 0.23903778195381165, aux loss1: 0.8327329754829407, 
		 aux loss2: 0.43811535835266113, total loss: 0.6641038656234741
63th Epoch, 40550th Step, learning rate = 0.005833423455010581 - Loss: 0.1951269805431366, aux loss1: 0.7637460231781006, 
		 aux loss2: 0.36366987228393555, total loss: 0.5697187185287476
63th Epoch, 40555th Step, learning rate = 0.005832892594158653 - Loss: 0.2466517686843872, aux loss1: 0.855034351348877, 
		 aux loss2: 0.46036824584007263, total loss: 0.6873093843460083
63th Epoch, 40560th Step, learning rate = 0.005832361727938393 - Loss: 0.2516877055168152, aux loss1: 0.8028521537780762, 
		 aux loss2: 0.44153735041618347, total loss: 0.6691582798957825
63th Epoch, 40565th Step, learning rate = 0.005831830856349205 - Loss: 0.2487793266773224, aux loss1: 0.7161868214607239, 
		 aux loss2: 0.4077783226966858, total loss: 0.6267467141151428
63th Epoch, 40570th Step, learning rate = 0.0058312999793904904 - Loss: 0.2815536856651306, aux loss1: 1.0019304752349854, 
		 aux loss2: 0.5611359477043152, total loss: 0.8065872192382812
63th Epoch, 40575th Step, learning rate = 0.005830769097061654 - Loss: 0.2391199767589569, aux loss1: 0.8316517472267151, 
		 aux loss2: 0.4250870645046234, total loss: 0.6586503386497498
63th Epoch, 40580th Step, learning rate = 0.005830238209362095 - Loss: 0.197029247879982, aux loss1: 0.5804581642150879, 
		 aux loss2: 0.3002023994922638, total loss: 0.49124765396118164
63th Epoch, 40585th Step, learning rate = 0.00582970731629122 - Loss: 0.18349163234233856, aux loss1: 0.8145073652267456, 
		 aux loss2: 0.3369441628456116, total loss: 0.562621533870697
63th Epoch, 40590th Step, learning rate = 0.005829176417848427 - Loss: 0.24636705219745636, aux loss1: 0.8353536128997803, 
		 aux loss2: 0.4504452347755432, total loss: 0.6771512627601624
63th Epoch, 40595th Step, learning rate = 0.0058286455140331185 - Loss: 0.2247919738292694, aux loss1: 0.6696920394897461, 
		 aux loss2: 0.3326501250267029, total loss: 0.5587596297264099
63th Epoch, 40600th Step, learning rate = 0.0058281146048447 - Loss: 0.23849520087242126, aux loss1: 0.8002387285232544, 
		 aux loss2: 0.4146239459514618, total loss: 0.6444163918495178
<40600th step>
*************************** Test ***************************
time:3m 16s, 40600th Step, Loss: 0.548439621925354, Mean IoU = 46.995%
************************************************************
63th Epoch, 40605th Step, learning rate = 0.005827583690282569 - Loss: 0.24168959259986877, aux loss1: 0.7625172734260559, 
		 aux loss2: 0.40378084778785706, total loss: 0.6319571733474731
63th Epoch, 40610th Step, learning rate = 0.005827052770346128 - Loss: 0.23763136565685272, aux loss1: 0.8311232328414917, 
		 aux loss2: 0.45896804332733154, total loss: 0.670555591583252
63th Epoch, 40615th Step, learning rate = 0.005826521845034781 - Loss: 0.19596154987812042, aux loss1: 0.6874088048934937, 
		 aux loss2: 0.3283744156360626, total loss: 0.5335339307785034
63th Epoch, 40620th Step, learning rate = 0.005825990914347927 - Loss: 0.36035555601119995, aux loss1: 0.9694149494171143, 
		 aux loss2: 0.5882930159568787, total loss: 0.8864972591400146
63th Epoch, 40625th Step, learning rate = 0.0058254599782849685 - Loss: 0.20122851431369781, aux loss1: 0.6502376198768616, 
		 aux loss2: 0.3404347598552704, total loss: 0.5324736833572388
63th Epoch, 40630th Step, learning rate = 0.005824929036845307 - Loss: 0.20973452925682068, aux loss1: 0.6862180233001709, 
		 aux loss2: 0.36396080255508423, total loss: 0.561184287071228
63th Epoch, 40635th Step, learning rate = 0.005824398090028341 - Loss: 0.27332377433776855, aux loss1: 0.855419397354126, 
		 aux loss2: 0.4589073956012726, total loss: 0.7135125398635864
63th Epoch, 40640th Step, learning rate = 0.005823867137833474 - Loss: 0.24260281026363373, aux loss1: 0.7932068705558777, 
		 aux loss2: 0.42131683230400085, total loss: 0.6490916013717651
63th Epoch, 40645th Step, learning rate = 0.005823336180260106 - Loss: 0.250009149312973, aux loss1: 0.7813608646392822, 
		 aux loss2: 0.4119231402873993, total loss: 0.6491867303848267
63th Epoch, 40650th Step, learning rate = 0.005822805217307635 - Loss: 0.29558125138282776, aux loss1: 1.0228222608566284, 
		 aux loss2: 0.5908392071723938, total loss: 0.8387636542320251
63th Epoch, 40655th Step, learning rate = 0.005822274248975467 - Loss: 0.27036023139953613, aux loss1: 0.8751538991928101, 
		 aux loss2: 0.4706743359565735, total loss: 0.7211761474609375
63th Epoch, 40660th Step, learning rate = 0.005821743275262997 - Loss: 0.26735711097717285, aux loss1: 0.7847968935966492, 
		 aux loss2: 0.4270438551902771, total loss: 0.6736137270927429
63th Epoch, 40665th Step, learning rate = 0.005821212296169628 - Loss: 0.2717355489730835, aux loss1: 0.945789098739624, 
		 aux loss2: 0.5200448632240295, total loss: 0.7634902000427246
63th Epoch, 40670th Step, learning rate = 0.005820681311694761 - Loss: 0.33086854219436646, aux loss1: 0.8268774151802063, 
		 aux loss2: 0.490437388420105, total loss: 0.7751067876815796
63th Epoch, 40675th Step, learning rate = 0.005820150321837793 - Loss: 0.25535058975219727, aux loss1: 0.824725329875946, 
		 aux loss2: 0.41560792922973633, total loss: 0.6690114140510559
63th Epoch, 40680th Step, learning rate = 0.005819619326598126 - Loss: 0.32013460993766785, aux loss1: 1.0097455978393555, 
		 aux loss2: 0.6185638308525085, total loss: 0.8704838752746582
63th Epoch, 40685th Step, learning rate = 0.005819088325975159 - Loss: 0.3087945580482483, aux loss1: 0.9966185092926025, 
		 aux loss2: 0.48883262276649475, total loss: 0.803313136100769
63th Epoch, 40690th Step, learning rate = 0.005818557319968292 - Loss: 0.22829151153564453, aux loss1: 0.7203418016433716, 
		 aux loss2: 0.35920485854148865, total loss: 0.5880759954452515
63th Epoch, 40695th Step, learning rate = 0.005818026308576924 - Loss: 0.32135897874832153, aux loss1: 1.231523871421814, 
		 aux loss2: 0.6624479293823242, total loss: 0.9557953476905823
63th Epoch, 40700th Step, learning rate = 0.005817495291800454 - Loss: 0.2780504822731018, aux loss1: 0.9047066569328308, 
		 aux loss2: 0.5070679783821106, total loss: 0.7522897124290466
<40700th step>
*************************** Test ***************************
time:3m 9s, 40700th Step, Loss: 0.5773946046829224, Mean IoU = 46.913%
************************************************************
63th Epoch, 40705th Step, learning rate = 0.005816964269638282 - Loss: 0.22315773367881775, aux loss1: 0.7055144906044006, 
		 aux loss2: 0.35297513008117676, total loss: 0.5760021209716797
63th Epoch, 40710th Step, learning rate = 0.005816433242089807 - Loss: 0.22142274677753448, aux loss1: 0.7569830417633057, 
		 aux loss2: 0.362618625164032, total loss: 0.5935651063919067
63th Epoch, 40715th Step, learning rate = 0.005815902209154428 - Loss: 0.28824955224990845, aux loss1: 0.9850888252258301, 
		 aux loss2: 0.5260019898414612, total loss: 0.7941770553588867
63th Epoch, 40720th Step, learning rate = 0.005815371170831542 - Loss: 0.2330004721879959, aux loss1: 0.828156054019928, 
		 aux loss2: 0.422148197889328, total loss: 0.6503065824508667
63th Epoch, 40725th Step, learning rate = 0.005814840127120552 - Loss: 0.2824748456478119, aux loss1: 0.8554395437240601, 
		 aux loss2: 0.4603504538536072, total loss: 0.7232469320297241
63th Epoch, 40730th Step, learning rate = 0.005814309078020853 - Loss: 0.2687847912311554, aux loss1: 0.8337295651435852, 
		 aux loss2: 0.48308929800987244, total loss: 0.712139368057251
63th Epoch, 40735th Step, learning rate = 0.0058137780235318435 - Loss: 0.27077099680900574, aux loss1: 0.7761614322662354, 
		 aux loss2: 0.446941077709198, total loss: 0.682395875453949
63th Epoch, 40740th Step, learning rate = 0.005813246963652924 - Loss: 0.2570919394493103, aux loss1: 0.821847677230835, 
		 aux loss2: 0.4354519546031952, total loss: 0.6778270602226257
63th Epoch, 40745th Step, learning rate = 0.00581271589838349 - Loss: 0.211626797914505, aux loss1: 0.7998202443122864, 
		 aux loss2: 0.3997815251350403, total loss: 0.611485481262207
63th Epoch, 40750th Step, learning rate = 0.005812184827722942 - Loss: 0.2384093552827835, aux loss1: 0.7598604559898376, 
		 aux loss2: 0.37636852264404297, total loss: 0.6169148683547974
63th Epoch, 40755th Step, learning rate = 0.005811653751670677 - Loss: 0.2573363780975342, aux loss1: 0.9319882392883301, 
		 aux loss2: 0.466551274061203, total loss: 0.7235533595085144
63th Epoch, 40760th Step, learning rate = 0.00581112267022609 - Loss: 0.23126843571662903, aux loss1: 0.8016738891601562, 
		 aux loss2: 0.3976295292377472, total loss: 0.6308224201202393
63th Epoch, 40765th Step, learning rate = 0.0058105915833885835 - Loss: 0.27752894163131714, aux loss1: 0.7083650231361389, 
		 aux loss2: 0.4162349998950958, total loss: 0.6565324664115906
63th Epoch, 40770th Step, learning rate = 0.005810060491157554 - Loss: 0.20987433195114136, aux loss1: 0.7157297730445862, 
		 aux loss2: 0.33425602316856384, total loss: 0.5582956671714783
63th Epoch, 40775th Step, learning rate = 0.005809529393532394 - Loss: 0.18768508732318878, aux loss1: 0.5998266935348511, 
		 aux loss2: 0.2895366847515106, total loss: 0.483447790145874
63th Epoch, 40780th Step, learning rate = 0.005808998290512508 - Loss: 0.2093745768070221, aux loss1: 0.6238554120063782, 
		 aux loss2: 0.31848055124282837, total loss: 0.5239234566688538
63th Epoch, 40785th Step, learning rate = 0.005808467182097289 - Loss: 0.3385224938392639, aux loss1: 1.1277735233306885, 
		 aux loss2: 0.5751621723175049, total loss: 0.9069194197654724
63th Epoch, 40790th Step, learning rate = 0.005807936068286133 - Loss: 0.24056212604045868, aux loss1: 0.767599880695343, 
		 aux loss2: 0.39350441098213196, total loss: 0.6282438635826111
63th Epoch, 40795th Step, learning rate = 0.005807404949078442 - Loss: 0.2659633755683899, aux loss1: 0.7884731888771057, 
		 aux loss2: 0.4151500165462494, total loss: 0.6685653924942017
